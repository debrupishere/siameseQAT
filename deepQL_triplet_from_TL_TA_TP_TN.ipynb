{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Propose centroid replacing the masters with BERT siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import keras\n",
    "# from tensorflow.python import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the use of GPUs\n",
    "# https://datascience.stackexchange.com/questions/23895/multi-gpu-in-keras\n",
    "# https://keras.io/getting-started/faq/#how-can-i-run-a-keras-model-on-multiple-gpus\n",
    "# https://stackoverflow.com/questions/56316451/how-to-use-specific-gpus-in-keras-for-multi-gpu-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 20\n",
    "MAX_SEQUENCE_LENGTH_D = 20 # 80\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'eclipse'\n",
    "METHOD = 'deepQL_triplet_from_TL_TA_TP_TN_{}'.format(epochs)\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Path embeddings\n",
    "EMBED_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_feature@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_feature_@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "# !unzip -o uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "model_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_vocabulary\n",
    "\n",
    "token_dict = load_vocabulary(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 30522'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(token_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DOMAIN, DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, \n",
    "                    token_dict['[CLS]'], token_dict['[SEP]'])\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0bc7338ae94ca0bef4227c74d036c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322339), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2337121f5d4a3b81f947c1fad11abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39545), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "361006"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5957ca05ef5246eb8ca8d3c6f87b018c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=361006), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c998a7261f54f01a1a53da0bf6a05cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 30.8 s, sys: 3.34 s, total: 34.2 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9194c74266ba481eb025e2d03e0fe5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=321536), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a random bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_idx = bug_train_ids[0]\n",
    "vector = baseline.bug_set[bug_idx]['textual_word']\n",
    "annoy_train = AnnoyIndex(vector.shape[0])\n",
    "for bug_id in bug_train_ids:\n",
    "    annoy_train.add_item(bug_id, baseline.bug_set[bug_id]['textual_word'])\n",
    "annoy_train.build(10) # 10 trees\n",
    "\"Indexed all train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, \\\n",
    "                            valid_master_sample, valid_master_neg, valid_sim = experiment.batch_iterator_bert(None, baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train,\n",
    "                                                                                          bug_train_ids,\n",
    "                                                                                          batch_size_test, 1, \n",
    "                                                                                              issues_by_buckets, INCLUDE_MASTER=True)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title']['token'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description']['token'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input_sample['title']['token'].shape, valid_input_sample['description']['token'].shape, \\\n",
    "    valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5, batch_iterator, issues_by_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Propose\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomUniform, RandomNormal, Ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "https://github.com/CyberZHG/keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import compile_model, get_model\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "def bert_model(MAX_SEQUENCE_LENGTH, name):\n",
    "    layer_num = 8\n",
    "#     model = load_trained_model_from_checkpoint(\n",
    "#             config_path,\n",
    "#             model_path,\n",
    "#             training=True,\n",
    "#             trainable=True,\n",
    "#             seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#     )\n",
    "    model = load_trained_model_from_checkpoint(\n",
    "        config_path,\n",
    "        model_path,\n",
    "        training=True,\n",
    "        use_adapter=True,\n",
    "        seq_len=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=['Encoder-{}-MultiHeadSelfAttention-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-MultiHeadSelfAttention-Norm'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Norm'.format(i + 1) for i in range(layer_num)],\n",
    "    )\n",
    "#     model = get_model(\n",
    "#         token_num=len(token_dict),\n",
    "#         head_num=10,\n",
    "#         transformer_num=layer_num,\n",
    "#         embed_dim=100,\n",
    "#         feed_forward_dim=100,\n",
    "#         seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#         pos_num=MAX_SEQUENCE_LENGTH,\n",
    "#         dropout_rate=0.05,\n",
    "#     )\n",
    "    compile_model(model)\n",
    "    inputs = model.inputs[:2]\n",
    "    outputs = model.get_layer('Encoder-{}-FeedForward-Norm'.format(layer_num)).output\n",
    "    #outputs = model.get_layer('Extract').output\n",
    "    outputs = GlobalAveragePooling1D()(outputs)\n",
    "#     outputs = Dense(300, activation='tanh')(outputs)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='FeatureBERTGenerationModel{}'.format(name))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    #layer = GRU(100, activation='tanh')(layer)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "'''\n",
    "    Some loss ideas\n",
    "    hinge loss Kullback-Leibler\n",
    "    https://stackoverflow.com/questions/53581298/custom-combined-hinge-kb-divergence-loss-function-in-siamese-net-fails-to-genera\n",
    "'''\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=True)\n",
    "    #return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def triplet_loss(vects):\n",
    "    pos = vects[0]\n",
    "    neg = vects[1]\n",
    "    margin = K.constant(1.0)\n",
    "    return K.maximum(0.0, margin - pos + neg)\n",
    "    #return K.mean(K.maximum(0.0, margin - pos + neg), keepdims=False)\n",
    "    \n",
    "def custom_loss(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def triplet_bug(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "def triplet_anchor(y_true, y_pred):\n",
    "    return y_pred[2]\n",
    "def triplet_pos(y_true, y_pred):\n",
    "    return y_pred[3]\n",
    "def triplet_neg(y_true, y_pred):\n",
    "    return y_pred[4]\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)\n",
    "\n",
    "# https://www.kaggle.com/c/quora-question-pairs/discussion/33631\n",
    "# https://www.researchgate.net/figure/Illustration-of-triplet-loss-contrastive-loss-for-negative-samples-and-binomial_fig2_322060548\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    margin = 1\n",
    "    return K.mean(pos * K.square(neg) +\n",
    "                  (1 - pos) * K.square(K.maximum(margin - neg, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, Average, Maximum, Subtract, Average, AveragePooling1D, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "    \n",
    "    # Title\n",
    "    bug_t_token = Input(shape = (sequence_length_t, ), name = 'title_token_{}'.format(name))\n",
    "    bug_t_segment = Input(shape = (sequence_length_t, ), name = 'title_segment_{}'.format(name))\n",
    "    # Description\n",
    "    bug_d_token = Input(shape = (sequence_length_d, ), name = 'desc_token_{}'.format(name))\n",
    "    bug_d_segment = Input(shape = (sequence_length_d, ), name = 'desc_segment_{}'.format(name))\n",
    "    # Categorical\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model([bug_t_token, bug_t_segment])\n",
    "    bug_d_feat = desc_feature_model([bug_d_token, bug_d_segment])\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t_token, bug_t_segment, bug_d_token, bug_d_segment, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model_centroid(sequence_length, name):\n",
    "    \n",
    "    # Bug Centroid Feature\n",
    "    bug_centroid = Input(shape = (sequence_length, ), name = 'bug_centroid_feature_{}'.format(name))\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_centroid], outputs=[bug_centroid], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Average, Reshape, Add\n",
    "from keras_radam import RAdam\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, \n",
    "                             master_anchor, master_negative, master_positive, \n",
    "                         NUMBER_OF_INSTANCES, BATCH_SIZE, EPOCHS, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    inputs.append(master_anchor.input)\n",
    "    inputs.append(master_positive.input)\n",
    "    inputs.append(master_negative.input)\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    master_anchor = master_anchor.output\n",
    "    master_negative = master_negative.output\n",
    "    master_positive = master_positive.output\n",
    "    \n",
    "    # Distance bugs\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance')([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance')([encoded_anchor, encoded_negative])\n",
    "    \n",
    "    # Distance masters anchor\n",
    "    master_anchor_positive_d = Lambda(cosine_distance, name='pos_master_cosine_distance')([encoded_anchor, master_positive])\n",
    "    master_anchor_negative_d = Lambda(cosine_distance, name='neg_master_cosine_distance')([encoded_anchor, master_negative])\n",
    "    \n",
    "    # Distance master positive\n",
    "    master_pos_positive_d = Lambda(cosine_distance, name='pos_master_pos_cosine_distance')([encoded_positive, master_positive])\n",
    "    master_pos_negative_d = Lambda(cosine_distance, name='neg_master_pos_cosine_distance')([encoded_positive, master_negative])\n",
    "    \n",
    "    # Distance master negative\n",
    "    master_neg_positive_d = Lambda(cosine_distance, name='pos_master_neg_cosine_distance')([encoded_negative, master_negative])\n",
    "    master_neg_negative_d = Lambda(cosine_distance, name='neg_master_neg_cosine_distance')([encoded_negative, master_positive])\n",
    "     \n",
    "#     output_bug = Triplet(1)([positive_d, negative_d])\n",
    "#     output_bug = QuintetWeights((1,2))(output_bug)\n",
    "    loss_TL = Lambda(triplet_loss, name='triplet_pos_neg')([positive_d, negative_d])\n",
    "    loss_TL_a = Lambda(triplet_loss, name='triplet_anchor_centroid')([master_anchor_positive_d, master_anchor_negative_d])\n",
    "    loss_TL_p = Lambda(triplet_loss, name='triplet_pos_centroid')([master_pos_positive_d, master_pos_negative_d])\n",
    "    loss_TL_n = Lambda(triplet_loss, name='triplet_neg_centroid')([master_neg_positive_d, master_neg_negative_d])\n",
    "    \n",
    "    # Triplet between TL, TL_A, TL_P, TL_N\n",
    "    loss_TL_ap = Average()([loss_TL_a, loss_TL_p])\n",
    "    loss_TL_AP_and_N = Lambda(triplet_loss, name='triplet_TL_AP_and_TL_N')([loss_TL_ap, loss_TL_n])\n",
    "    new_loss_TL = Average()([loss_TL, loss_TL_AP_and_N])\n",
    "    # Output triplet \n",
    "    output = concatenate([new_loss_TL, loss_TL, loss_TL_a, loss_TL_p, loss_TL_n])\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = [output], name = 'Similarity_Model')\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer='adam',\n",
    "                             metrics=[triplet_bug, triplet_anchor, triplet_pos, triplet_neg],\n",
    "                             loss=custom_loss)\n",
    "\n",
    "    # metrics=[triplet_bug, triplet_anchor, triplet_pos, triplet_neg],\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 1.01, TL: 1.02, TL_A: 0.96, TL_P: 0.96, TL_N: 0.97\n",
      "Epoch: 2 Loss: 1.01, TL: 1.02, TL_A: 0.97, TL_P: 0.96, TL_N: 0.97\n",
      "Epoch: 3 Loss: 1.02, TL: 1.02, TL_A: 0.97, TL_P: 0.96, TL_N: 0.98\n",
      "Epoch: 4 Loss: 1.01, TL: 1.01, TL_A: 0.97, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 5 Loss: 1.01, TL: 1.01, TL_A: 0.97, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 6 Loss: 1.01, TL: 1.01, TL_A: 0.97, TL_P: 0.96, TL_N: 0.97\n",
      "Epoch: 7 Loss: 1.01, TL: 1.02, TL_A: 0.98, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 8 Loss: 1.01, TL: 1.01, TL_A: 0.98, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 9 Loss: 1.01, TL: 1.01, TL_A: 0.98, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 10 Loss: 1.01, TL: 1.02, TL_A: 0.98, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 11 Loss: 1.01, TL: 1.02, TL_A: 0.98, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 12 Loss: 1.01, TL: 1.01, TL_A: 0.98, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 13 Loss: 1.01, TL: 1.01, TL_A: 0.98, TL_P: 0.98, TL_N: 0.98\n",
      "Epoch: 14 Loss: 1.01, TL: 1.01, TL_A: 0.98, TL_P: 0.98, TL_N: 0.98\n",
      "Epoch: 15 Loss: 1.01, TL: 1.01, TL_A: 0.98, TL_P: 0.98, TL_N: 0.98\n",
      "Epoch: 16 Loss: 1.00, TL: 1.01, TL_A: 0.98, TL_P: 0.98, TL_N: 0.99\n",
      "Epoch: 17 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.98, TL_N: 0.99\n",
      "Epoch: 18 Loss: 1.00, TL: 1.01, TL_A: 0.99, TL_P: 0.98, TL_N: 0.99\n",
      "Epoch: 20 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.98, TL_N: 0.99\n",
      "Epoch: 21 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 22 Loss: 1.00, TL: 1.01, TL_A: 0.99, TL_P: 0.98, TL_N: 0.99\n",
      "Epoch: 23 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 24 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 25 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 26 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 27 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 28 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 29 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 30 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 31 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 1.00\n",
      "Epoch: 32 Loss: 1.00, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 33 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 0.99, TL_N: 1.00\n",
      "Epoch: 34 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 0.99, TL_N: 1.00\n",
      "Epoch: 35 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 36 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 37 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 38 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 39 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 40 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 41 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 42 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 43 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 44 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 45 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 46 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 47 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 48 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 49 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 50 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 51 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 52 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 53 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 54 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 55 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 56 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 57 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 58 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 59 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 60 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 61 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 62 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 63 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 64 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 65 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 66 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 67 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 68 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 69 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 70 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 71 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 72 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 73 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 74 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 75 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 76 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 77 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 78 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 79 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 80 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 81 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 82 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 83 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 84 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 85 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 86 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 87 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 88 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 89 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 90 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 91 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 92 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 93 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 94 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 95 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 96 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 97 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 98 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 99 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 100 Loss: 1.00, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00, recall@25: 0.35\n",
      "Saved model 'modelos/model_deepQL_triplet_from_TL_TA_TP_TN_100_feature_100epochs_64batch(eclipse).h5' to disk\n",
      "Best_epoch=0, Best_loss=1.00s, Recall@25=0.35\n",
      "CPU times: user 51min 17s, sys: 1h 31min 42s, total: 2h 22min 59s\n",
      "Wall time: 2h 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "print(\"Batch size \", batch_size)\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_dilated_model\n",
    "    arcii_model\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    bilstm_model\n",
    "'''\n",
    "# title_feature_model = bilstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "title_feature_model = bert_model(MAX_SEQUENCE_LENGTH_T, 'Title')\n",
    "desc_feature_model = bert_model(MAX_SEQUENCE_LENGTH_D, 'Description')\n",
    "#desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "# Master model\n",
    "embed_size = K.int_shape(title_feature_model.get_output_at(0))[1] + K.int_shape(desc_feature_model.get_output_at(0))[1] + K.int_shape(categorical_feature_model.get_output_at(0))[1] \n",
    "\n",
    "master_anchor = siamese_model_centroid(embed_size, 'master_anchor')\n",
    "master_pos = siamese_model_centroid(embed_size, 'master_pos')\n",
    "master_negative = siamese_model_centroid(embed_size, 'master_neg')\n",
    "\n",
    "NUMBER_OF_INSTANCES = len(baseline.dup_sets_train)\n",
    "BATCH_SIZE = batch_size\n",
    "EPOCHS = epochs\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, \n",
    "                                            master_anchor, master_negative, master_pos,\n",
    "                                            NUMBER_OF_INSTANCES, BATCH_SIZE, EPOCHS, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, train_master_input, train_master_neg, \\\n",
    "            train_sim = experiment.batch_iterator_bert(encoded_anchor, baseline.train_data, baseline.dup_sets_train, \\\n",
    "                                                       bug_train_ids, \n",
    "                                                       batch_size, 1, \n",
    "                                                       issues_by_buckets, \n",
    "                                                       TRIPLET_HARD=True, USE_CENTROID=True)\n",
    "    \n",
    "    train_batch = [train_input_sample['title']['token'], train_input_sample['title']['segment'], train_input_sample['description']['token'], train_input_sample['description']['segment'], train_input_sample['info'],\n",
    "                   train_input_pos['title']['token'], train_input_pos['title']['segment'], train_input_pos['description']['token'], train_input_pos['description']['segment'], train_input_pos['info'], \n",
    "                   train_input_neg['title']['token'], train_input_neg['title']['segment'], train_input_neg['description']['token'], train_input_neg['description']['segment'], train_input_neg['info'],\n",
    "                   train_master_input['centroid_embed'],\n",
    "                   train_master_input['centroid_embed'],\n",
    "                   train_master_neg['centroid_embed']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, \n",
    "                                                               bug_train_ids, method='bert')\n",
    "        print(\"Epoch: {} Loss: {:.2f}, TL: {:.2f}, TL_A: {:.2f}, TL_P: {:.2f}, TL_N: {:.2f}, recall@25: {:.2f}\".format(epoch+1, h[0], h[1], h[2], h[3], h[4], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, TL: {:.2f}, TL_A: {:.2f}, TL_P: {:.2f}, TL_N: {:.2f}\".format(epoch+1,h[0], h[1], h[2], h[3], h[4]))\n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}s, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['327681:324658|324421:0.9574945978820324,324647:0.9569953270256519,339214:0.9562794417142868,412415:0.9561496861279011,373911:0.9560513496398926,362593:0.9558182768523693,403813:0.9557586871087551,408804:0.9557166993618011,406764:0.9556085094809532,396844:0.9555880352854729,387094:0.9555224850773811,339046:0.9553549736738205,232438:0.955350399017334,377553:0.9553251378238201,371466:0.9552884995937347,408743:0.9552522078156471,347642:0.9552487395703793,332542:0.9552146680653095,355445:0.9551834836602211,319622:0.9551736824214458,396463:0.9551396109163761,389991:0.9550440609455109,335844:0.9550113715231419,327528:0.9550004862248898,329797:0.9549567513167858,360390:0.9549298025667667,401546:0.9548051655292511,389162:0.9547975473105907,385231:0.9547455124557018',\n",
       " '360457:362252|364552:0.9879186162725091,353222:0.9846596671268344,353496:0.9819956198334694,355947:0.9762726780027151,368089:0.9747012816369534,348343:0.9743369072675705,391011:0.97419773042202,351842:0.973735747858882,402100:0.9736384265124798,372903:0.9735701289027929,378207:0.9734930712729692,342301:0.9733771793544292,377371:0.973145293071866,347293:0.9731196817010641,343310:0.9728776998817921,343568:0.9728650134056807,396905:0.9728180393576622,344823:0.9726530127227306,419520:0.9724808465689421,338252:0.9723478220403194,367431:0.972013970836997,346926:0.9717838112264872,335711:0.9715402573347092,364134:0.971454780548811,354118:0.9708404894918203,339527:0.9703887514770031,401758:0.9696822222322226,364856:0.9693198166787624,351765:0.9691988043487072',\n",
       " '393230:393054|398880:0.9873042730614543,398917:0.9848254416137934,394256:0.9833628870546818,359800:0.9733708016574383,345712:0.9727381579577923,338053:0.9726162273436785,355704:0.9725520741194487,340714:0.9724157992750406,358505:0.972193032503128,328406:0.9720185324549675,367722:0.9719364810734987,333063:0.9718903992325068,323275:0.9718258157372475,334998:0.9717063568532467,398963:0.971671961247921,360384:0.9715102221816778,338250:0.9714927058666945,367937:0.9714874178171158,397934:0.9714227076619864,374146:0.9714098013937473,361691:0.9713707230985165,356765:0.9713681470602751,366294:0.9712744373828173,349752:0.9711905065923929,359491:0.9711772203445435,346351:0.9710749480873346,414668:0.9710429552942514,337532:0.9709811564534903,337553:0.9709118586033583',\n",
       " '393232:393282,390667,383388|406941:0.9865712681785226,421036:0.9856928419321775,411120:0.9856849610805511,415235:0.9854987114667892,408678:0.9852593271061778,412105:0.9851495940238237,408203:0.9850816279649734,403754:0.9848271384835243,421072:0.9848087402060628,395005:0.9846429610624909,399657:0.9846341628581285,409961:0.984589695930481,399971:0.9845255985856056,392565:0.9844442987814546,405416:0.9842926859855652,401108:0.9841600749641657,395921:0.9839657377451658,410955:0.983920868486166,402011:0.9837881941348314,409369:0.9837609808892012,400975:0.983103085309267,399354:0.9830032717436552,416464:0.9829482901841402,415326:0.9829085152596235,413509:0.9829013161361217,408756:0.9828300904482603,414929:0.9824190195649862,410468:0.9822644721716642,405488:0.9821985997259617',\n",
       " '393247:401563,396542|419072:0.9853477831929922,380240:0.9827946368604898,384286:0.9818342737853527,355970:0.9813882932066917,340898:0.9789614751935005,392911:0.9700605906546116,370995:0.9699863996356726,338783:0.9699526336044073,367791:0.9696134906262159,382388:0.9694841336458921,336140:0.9693265371024609,337365:0.9693196099251509,354166:0.969269659370184,361860:0.9692694880068302,412417:0.9692202620208263,411001:0.9692144468426704,368283:0.9691317528486252,375838:0.9690399579703808,383424:0.9688999652862549,376407:0.968838008120656,419352:0.9686153940856457,365614:0.9685661233961582,363197:0.9680992662906647,414924:0.9679038934409618,412307:0.9678517021238804,376751:0.9678355269134045,352908:0.9676343724131584,318357:0.9659013040363789,400536:0.9646772220730782',\n",
       " '360484:359237|376808:0.9836395028978586,376460:0.9827119391411543,372824:0.9822440147399902,358243:0.9820232093334198,363917:0.9818602930754423,381045:0.9813306704163551,378666:0.9811149407178164,382011:0.9807731453329325,378916:0.9798364788293839,380714:0.9750623647123575,377735:0.9727739132940769,373912:0.9720380548387766,366655:0.9718702491372824,397804:0.9713894687592983,383181:0.9709050748497248,385536:0.970730422064662,365414:0.9704775344580412,349243:0.9704654049128294,339673:0.9703615438193083,356829:0.9702242016792297,350030:0.9700768496841192,359780:0.9700574986636639,410744:0.9697083290666342,390153:0.9693803265690804,397854:0.9692441392689943,343711:0.9690397717058659,392061:0.9690214805305004,404182:0.9689717423170805,384676:0.9688522107899189',\n",
       " '360489:358624,354593,355714,357219,358267,362534,356295,356871,355722,356717,356973,358774,360214,356122,355803,356413|350902:0.995048067998141,375934:0.9936964078806341,356717:0.9936498091556132,382668:0.9935698113404214,350122:0.993520503398031,373897:0.9934907206334174,352438:0.9933999599888921,355803:0.9933420410379767,356871:0.9932106910273433,374595:0.993126146029681,375915:0.9930950743146241,355722:0.9929958488792181,375914:0.9929900360293686,355580:0.992971932515502,380477:0.9928282876498997,406956:0.9928075196221471,350900:0.99268389493227,360214:0.9926761747337878,369211:0.9926660633645952,352802:0.9926423160359263,337008:0.9925927012227476,370503:0.9925918052904308,369310:0.9925050502642989,386746:0.9924764530733228,356973:0.9924736893735826,380915:0.9924608152359724,370558:0.9923844956792891,358624:0.9923812509514391,363005:0.9922973741777241',\n",
       " '262194:331909|285268:0.9858906883746386,298750:0.9837238565087318,418241:0.9702420923858881,380848:0.9697031415998936,409794:0.9694281350821257,382533:0.9693775437772274,424389:0.9693544395267963,389221:0.969055999070406,415484:0.9689763970673084,385769:0.9689586572349072,386608:0.9688416887074709,386382:0.968838520348072,403935:0.9688158240169287,403532:0.9688042439520359,380138:0.9687671680003405,376439:0.9686951972544193,394500:0.9686876200139523,362661:0.9686776399612427,324470:0.9686639495193958,343258:0.9686332754790783,303746:0.9686319269239902,380864:0.9685974083840847,387658:0.968594416975975,383388:0.968568716198206,340599:0.9685573279857635,355404:0.9685552231967449,382184:0.9685275219380856,386059:0.9685175083577633,402824:0.9684969633817673',\n",
       " '327731:328902|318915:0.9837685488164425,337392:0.9731726385653019,323275:0.9725587405264378,328406:0.9721568003296852,358103:0.9721564501523972,330019:0.9720969647169113,336223:0.9720499105751514,358629:0.9718308504670858,342792:0.971525676548481,398963:0.9714034888893366,351254:0.9711516555398703,359268:0.9709944929927588,360200:0.9709897246211767,338579:0.9702251143753529,352310:0.9701403956860304,344939:0.9697927460074425,333429:0.9696733243763447,322454:0.9693651739507914,389775:0.9692552201449871,347159:0.9691596422344446,319056:0.9690858665853739,331293:0.9688532706350088,394884:0.9685600697994232,394117:0.9685434810817242,316521:0.9675404392182827,375396:0.9674678146839142,376242:0.9667644165456295,322920:0.9666696265339851,338717:0.9659049957990646',\n",
       " '393277:393864,400436|320329:0.9688800852745771,407749:0.9669442363083363,417537:0.9663885273039341,336311:0.9655367694795132,411452:0.9653380364179611,404189:0.9653281792998314,393670:0.9651559628546238,402038:0.9650309272110462,401963:0.9650297500193119,411006:0.9649578854441643,398225:0.9646830856800079,321640:0.9646635539829731,356306:0.9646485857665539,407824:0.9641257002949715,398028:0.964104175567627,394469:0.9639774784445763,353740:0.9636627323925495,403040:0.9633406698703766,348787:0.9632846713066101,408069:0.9632568061351776,413977:0.9630943052470684,354593:0.9630338102579117,327415:0.9630222320556641,409746:0.9629510715603828,331297:0.9629244767129421,401709:0.9628062136471272,413096:0.9626972153782845,347560:0.9625333324074745,405731:0.962385181337595',\n",
       " '393282:393232,390667,383388|341569:0.9743371214717627,383982:0.970623753964901,350769:0.9699719827622175,338958:0.9671074077486992,394628:0.9669265262782574,325749:0.9668801799416542,409932:0.9668627008795738,378553:0.9666859246790409,411172:0.9666164144873619,371215:0.9664787463843822,393339:0.966217540204525,405172:0.9659575782716274,415759:0.9655649699270725,409429:0.9654931649565697,404329:0.9643893577158451,313334:0.9603017456829548,338488:0.9585957527160645,332840:0.9583340026438236,401105:0.9582998193800449,369513:0.9579678326845169,343640:0.9576822444796562,320919:0.9572413824498653,351910:0.9556154794991016,350890:0.9552836678922176,364749:0.9551216997206211,288841:0.955038957297802,423215:0.9534938372671604,325652:0.9526050053536892,423045:0.9525462202727795',\n",
       " '327748:330466|340565:0.9852125477045774,339286:0.9851325768977404,338735:0.9847520720213652,345193:0.9841211903840303,385265:0.9835587088018656,320553:0.9828338976949453,347983:0.9768793676048517,341497:0.9765040148049593,346156:0.9763090666383505,329382:0.9762606974691153,385266:0.9754752181470394,318499:0.9754685219377279,332759:0.9754560478031635,393144:0.9754156302660704,395308:0.9753919504582882,371989:0.9753474220633507,376087:0.9753218423575163,379215:0.975318418815732,371549:0.9747795928269625,339737:0.9747413713485003,387923:0.974739970639348,376055:0.9747362397611141,320097:0.9747258685529232,328835:0.9743437338620424,318821:0.9738063178956509,320789:0.9737493749707937,328499:0.9713479764759541,345631:0.97076615691185,368804:0.9703651331365108',\n",
       " '327754:330209,331297,332294,327303,327528,329166,329232,330705,326194,329778,331186,332594,333917,327415,327548,333341,333342,332927|329232:0.9844817938283086,331186:0.9759823922067881,324636:0.9718545656651258,338291:0.9710542634129524,326757:0.9698946159332991,327231:0.9688116926699877,326247:0.9650367833673954,326795:0.9645809382200241,321880:0.9617888629436493,384731:0.9616251029074192,388062:0.9606408402323723,395813:0.9602315239608288,358668:0.9583740010857582,354044:0.9582748748362064,319265:0.9580711424350739,367785:0.9576577059924603,355254:0.9573879390954971,324647:0.9573789574205875,324421:0.9573208317160606,389162:0.9572414569556713,330409:0.957201637327671,364063:0.9571973383426666,339214:0.9570867121219635,361773:0.9570578783750534,376670:0.9570321142673492,373911:0.9570317715406418,374798:0.9570283703505993,402003:0.9570005349814892,359768:0.9569688551127911',\n",
       " '360529:354495,343276,347031|349752:0.9879276044666767,360822:0.9875378357246518,346806:0.985896110534668,350583:0.9853378348052502,356765:0.9851832371205091,353537:0.9841334465891123,345504:0.9838780462741852,357606:0.9763134680688381,347929:0.9753400310873985,320320:0.9721698835492134,315086:0.972023094072938,321117:0.9718101024627686,374146:0.9717687889933586,328825:0.9717606492340565,318845:0.9716985989362001,316135:0.9716488122940063,318846:0.9716306962072849,318753:0.971515441313386,367937:0.9714677985757589,318744:0.9713928755372763,327520:0.9712730925530195,320744:0.9711787067353725,328406:0.9711772240698338,320321:0.9711434170603752,352310:0.9711179789155722,326688:0.9710041843354702,325924:0.9709962923079729,381052:0.970907473936677,323275:0.9708255622535944',\n",
       " '393303:392707|365750:0.9739074371755123,396520:0.9725632183253765,395794:0.9712818581610918,399108:0.9712557084858418,400689:0.9638809859752655,405281:0.9631674215197563,345290:0.9631247632205486,334311:0.9629549495875835,362614:0.9628511182963848,345679:0.962810929864645,383116:0.9627831354737282,360912:0.9626959003508091,408909:0.9626015536487103,341694:0.9625803269445896,351624:0.9625156112015247,401382:0.9623648412525654,368992:0.9623012244701385,330229:0.9622947312891483,357318:0.9622897282242775,362113:0.9620098434388638,376366:0.9619348049163818,415330:0.9618921391665936,322520:0.9618311002850533,408446:0.9617830701172352,389956:0.961611557751894,407173:0.9613786712288857,382174:0.9613358080387115,353534:0.9612873941659927,365746:0.9612042717635632',\n",
       " '327769:177756,329721|395421:0.9680969379842281,325997:0.9662221148610115,323953:0.9652394391596317,359456:0.9648054614663124,324625:0.9637695290148258,337327:0.9637614153325558,336397:0.9636181183159351,373613:0.9633032791316509,336936:0.9620303772389889,414851:0.9618789665400982,325125:0.9600721746683121,356184:0.9598341137170792,319645:0.9597571603953838,322312:0.9596384614706039,387865:0.959528774023056,356306:0.959482628852129,314484:0.9594291225075722,321640:0.9588967747986317,325356:0.9581760466098785,325995:0.9577591121196747,352626:0.9576775245368481,320329:0.9575992375612259,317783:0.9574767351150513,318006:0.9572445042431355,313597:0.9570876806974411,323681:0.9570795930922031,187502:0.9570782519876957,369837:0.9569862075150013,326029:0.9563718624413013',\n",
       " '393305:381846|403948:0.9615926221013069,390320:0.9608775116503239,386095:0.9599608145654202,377553:0.9592836983501911,371466:0.9589938148856163,367642:0.9588086009025574,394186:0.9587082453072071,411777:0.9586827419698238,409532:0.9586537703871727,398339:0.9584442973136902,407664:0.95831398665905,381123:0.9582471661269665,398916:0.9580920375883579,416252:0.958051260560751,404624:0.9578959345817566,355445:0.9574910327792168,360277:0.9574552811682224,335787:0.9573911800980568,423757:0.9573554061353207,404262:0.9573532044887543,359355:0.9572700895369053,417612:0.9572408981621265,359259:0.9572393633425236,361103:0.9572071693837643,339046:0.9571960307657719,406772:0.9571860507130623,360390:0.9571754634380341,359169:0.9571524113416672,387094:0.9571522362530231',\n",
       " '360540:355108|360574:0.9862233670428395,359609:0.9746162183582783,363063:0.9736268687993288,362575:0.9725976213812828,360980:0.9725684635341167,378375:0.9725214969366789,368969:0.9722054060548544,367434:0.9721729420125484,366212:0.9721463192254305,363108:0.9720056261867285,369585:0.9719265550374985,365263:0.9718363080173731,379307:0.9716955348849297,364398:0.971525352448225,368868:0.9715180415660143,361447:0.9714576229453087,370853:0.9713673703372478,367243:0.9711226746439934,372040:0.9710844196379185,382604:0.971076363697648,371739:0.970950422808528,368850:0.9708140082657337,380734:0.9704983327537775,371617:0.9703622832894325,382274:0.9702703878283501,374336:0.9696821123361588,366094:0.9694314170628786,389938:0.9693095237016678,382657:0.9692148845642805',\n",
       " '327772:326427|351083:0.9740807879716158,342114:0.9737351052463055,328795:0.9734858479350805,348805:0.9734006114304066,358923:0.9727485738694668,369880:0.9726477954536676,348806:0.9725625608116388,365722:0.9723308328539133,393787:0.972113898023963,328926:0.9720723815262318,327233:0.9719664063304663,320005:0.9719270374625921,344833:0.971916439011693,385286:0.9715417809784412,329375:0.9715036544948816,359535:0.9714866187423468,351519:0.97139011323452,375783:0.9711646568030119,393612:0.9707422759383917,320546:0.9703270681202412,387699:0.969927417114377,325294:0.9682597219944,317929:0.967581819742918,402343:0.9668400660157204,319123:0.9655569046735764,378155:0.9653414823114872,347183:0.9648616462945938,354820:0.9647161550819874,341643:0.964559618383646',\n",
       " '360547:360548,360549|360548:1.0,360549:1.0,398091:0.9691109601408243,398316:0.9659534208476543,351666:0.9654550105333328,413551:0.965103667229414,326729:0.9648310728371143,412782:0.9645902626216412,399699:0.9645397327840328,350877:0.964486837387085,407464:0.9638764075934887,369920:0.963767483830452,402343:0.9611759856343269,399434:0.9611731991171837,328795:0.9610130488872528,372838:0.960999246686697,364772:0.9609625935554504,350658:0.9609265178442001,390175:0.960889745503664,350561:0.96081917360425,333329:0.960300087928772,395217:0.9602950476109982,349023:0.9602621980011463,388299:0.9602308571338654,403525:0.9600049965083599,378155:0.9598727971315384,389853:0.9598336219787598,415478:0.9598242454230785,373113:0.9597003683447838']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall, exported_rank, debug = experiment.evaluate_validation_test(experiment, retrieval, verbose, \n",
    "#                                                         encoded_anchor, issues_by_buckets, evaluate_validation_test)\n",
    "# test_vectorized, queries_test_vectorized, annoy, X_test, distance_test, indices_test = debug\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 4641\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepQL_triplet_from_TL_TA_TP_TN_100_feature_100epochs_64batch(eclipse)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoded_anchor\n",
    "# model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 768)          80346736    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 768)          80346736    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1836)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "==================================================================================================\n",
      "Total params: 161,198,372\n",
      "Trainable params: 726,196\n",
      "Non-trainable params: 160,472,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, \n",
    "                                                                   bug_train_ids, method='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/eclipse/exported_rank_deepQL_triplet_from_TL_TA_TP_TN_100.txt'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.22,\n",
       " '2 - recall_at_10': 0.28,\n",
       " '3 - recall_at_15': 0.31,\n",
       " '4 - recall_at_20': 0.33,\n",
       " '5 - recall_at_25': 0.35}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
