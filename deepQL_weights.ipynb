{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Propose centroid replacing the masters with BERT siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import keras\n",
    "# from tensorflow.python import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the use of GPUs\n",
    "# https://datascience.stackexchange.com/questions/23895/multi-gpu-in-keras\n",
    "# https://keras.io/getting-started/faq/#how-can-i-run-a-keras-model-on-multiple-gpus\n",
    "# https://stackoverflow.com/questions/56316451/how-to-use-specific-gpus-in-keras-for-multi-gpu-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 20\n",
    "MAX_SEQUENCE_LENGTH_D = 20 # 80\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'eclipse'\n",
    "METHOD = 'deepQL_weights_{}'.format(epochs)\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Path embeddings\n",
    "EMBED_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_feature@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_feature_@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "# !unzip -o uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "model_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_vocabulary\n",
    "\n",
    "token_dict = load_vocabulary(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 30522'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(token_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DOMAIN, DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, \n",
    "                    token_dict['[CLS]'], token_dict['[SEP]'])\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329f1522472b4410b8030c42d90c69a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322339), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a42031bf1fa45b397dbb4f2da91f356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39545), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "361006"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6efb31fb148423296446c441f08bfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=361006), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce79d4a72ce74e7e8a058e5ef46d1421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 36.5 s, sys: 9.52 s, total: 46 s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d8a6186709458da83f61d33740eb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=321536), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n",
      "CPU times: user 2min 36s, sys: 15.9 ms, total: 2min 36s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a random bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': '1\\n',\n",
       " 'bug_status': '2\\n',\n",
       " 'component': '475\\n',\n",
       " 'creation_ts': '2005-07-15 18:39:00 -0400',\n",
       " 'delta_ts': '2013-02-20 16:06:43 -0500',\n",
       " 'description': '[CLS] the sql editor should use . sql as the default extension . this will allows the sql editor to be used the next time the user tries to open the script . [SEP]',\n",
       " 'description_bert': '[CLS] the sql editor should use . sql as the default extension . this will allows the sql editor to be used the next time the user tries to open the script . [SEP]',\n",
       " 'description_word': array([  101,  1996, 29296,  3559,  2323,  2224,  1012, 29296,  2004,\n",
       "         1996, 12398,  5331,  1012,  2023,  2097,  4473,  1996, 29296,\n",
       "         3559,   102]),\n",
       " 'description_word_bert': [101,\n",
       "  1996,\n",
       "  29296,\n",
       "  3559,\n",
       "  2323,\n",
       "  2224,\n",
       "  1012,\n",
       "  29296,\n",
       "  2004,\n",
       "  1996,\n",
       "  12398,\n",
       "  5331,\n",
       "  1012,\n",
       "  2023,\n",
       "  2097,\n",
       "  4473,\n",
       "  1996,\n",
       "  29296,\n",
       "  3559,\n",
       "  2000,\n",
       "  2022,\n",
       "  2109,\n",
       "  1996,\n",
       "  2279,\n",
       "  2051,\n",
       "  1996,\n",
       "  5310,\n",
       "  5363,\n",
       "  2000,\n",
       "  2330,\n",
       "  1996,\n",
       "  5896,\n",
       "  1012,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'dup_id': '[]',\n",
       " 'issue_id': 104125,\n",
       " 'priority': '1\\n',\n",
       " 'product': '15\\n',\n",
       " 'resolution': 'FIXED',\n",
       " 'textual_word': array([  101,  1996, 29296,  3559,  2323,  2224,  1012, 29296,  2004,\n",
       "         1996, 12398,  5331,     0,     0,     0,     0,     0,     0,\n",
       "            0,   102,   101,  1996, 29296,  3559,  2323,  2224,  1012,\n",
       "        29296,  2004,  1996, 12398,  5331,  1012,  2023,  2097,  4473,\n",
       "         1996, 29296,  3559,   102]),\n",
       " 'title': '[CLS] the sql editor should use . sql as the default extension [SEP]',\n",
       " 'title_bert': '[CLS] the sql editor should use . sql as the default extension [SEP]',\n",
       " 'title_word': array([  101,  1996, 29296,  3559,  2323,  2224,  1012, 29296,  2004,\n",
       "         1996, 12398,  5331,     0,     0,     0,     0,     0,     0,\n",
       "            0,   102]),\n",
       " 'title_word_bert': [101,\n",
       "  1996,\n",
       "  29296,\n",
       "  3559,\n",
       "  2323,\n",
       "  2224,\n",
       "  1012,\n",
       "  29296,\n",
       "  2004,\n",
       "  1996,\n",
       "  12398,\n",
       "  5331,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'version': '334\\n'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 34882)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indexed all train'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_idx = bug_train_ids[0]\n",
    "vector = baseline.bug_set[bug_idx]['textual_word']\n",
    "annoy_train = AnnoyIndex(vector.shape[0])\n",
    "for bug_id in bug_train_ids:\n",
    "    annoy_train.add_item(bug_id, baseline.bug_set[bug_id]['textual_word'])\n",
    "annoy_train.build(10) # 10 trees\n",
    "\"Indexed all train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.3 ms, sys: 0 ns, total: 66.3 ms\n",
      "Wall time: 65.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, \\\n",
    "                            valid_master_sample, valid_master_neg, valid_sim = experiment.batch_iterator_bert(None, baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train,\n",
    "                                                                                          bug_train_ids,\n",
    "                                                                                          batch_size_test, 1, \n",
    "                                                                                              issues_by_buckets, INCLUDE_MASTER=True)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title']['token'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description']['token'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 20), (128, 20), (128, 1682), (128,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title']['token'].shape, valid_input_sample['description']['token'].shape, \\\n",
    "    valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5, batch_iterator, issues_by_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Propose\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomUniform, RandomNormal, Ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "https://github.com/CyberZHG/keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import compile_model, get_model\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "def bert_model(MAX_SEQUENCE_LENGTH, name):\n",
    "    layer_num = 8\n",
    "#     model = load_trained_model_from_checkpoint(\n",
    "#             config_path,\n",
    "#             model_path,\n",
    "#             training=True,\n",
    "#             trainable=True,\n",
    "#             seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#     )\n",
    "    model = load_trained_model_from_checkpoint(\n",
    "        config_path,\n",
    "        model_path,\n",
    "        training=True,\n",
    "        use_adapter=True,\n",
    "        seq_len=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=['Encoder-{}-MultiHeadSelfAttention-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-MultiHeadSelfAttention-Norm'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Norm'.format(i + 1) for i in range(layer_num)],\n",
    "    )\n",
    "#     model = get_model(\n",
    "#         token_num=len(token_dict),\n",
    "#         head_num=10,\n",
    "#         transformer_num=layer_num,\n",
    "#         embed_dim=100,\n",
    "#         feed_forward_dim=100,\n",
    "#         seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#         pos_num=MAX_SEQUENCE_LENGTH,\n",
    "#         dropout_rate=0.05,\n",
    "#     )\n",
    "    compile_model(model)\n",
    "    inputs = model.inputs[:2]\n",
    "    outputs = model.get_layer('Encoder-{}-FeedForward-Norm'.format(layer_num)).output\n",
    "    #outputs = model.get_layer('Extract').output\n",
    "    outputs = GlobalAveragePooling1D()(outputs)\n",
    "#     outputs = Dense(300, activation='tanh')(outputs)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='FeatureBERTGenerationModel{}'.format(name))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    #layer = GRU(100, activation='tanh')(layer)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "'''\n",
    "    Some loss ideas\n",
    "    hinge loss Kullback-Leibler\n",
    "    https://stackoverflow.com/questions/53581298/custom-combined-hinge-kb-divergence-loss-function-in-siamese-net-fails-to-genera\n",
    "'''\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=True)\n",
    "    #return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def _triplet_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.mean(K.maximum(0.0, pos - neg + margin))\n",
    "\n",
    "def triplet_loss(vects):\n",
    "    pos = vects[0]\n",
    "    neg = vects[1]\n",
    "    margin = K.constant(1.0)\n",
    "    return K.maximum(0.0, margin - pos + neg)\n",
    "    #return K.mean(K.maximum(0.0, margin - pos + neg), keepdims=False)\n",
    "\n",
    "class QuintetWeights(Layer):\n",
    " \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(QuintetWeights, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        self.W= self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.built = False \n",
    " \n",
    "    def call(self, x):\n",
    "        return K.dot(x, self.W)\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "class Triplet(Layer):\n",
    " \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(Triplet, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    " \n",
    "    def call(self, x):\n",
    "        pos, neg  = x\n",
    "        margin = K.constant(1.0)\n",
    "        return K.maximum(0.0, margin - pos + neg)\n",
    "    \n",
    "def custom_loss(y_true, y_pred):\n",
    "    return y_pred[0][0]\n",
    "\n",
    "def triplet_bug(y_true, y_pred):\n",
    "    return y_pred[0][1]\n",
    "def triplet_anchor(y_true, y_pred):\n",
    "    return y_pred[0][2]\n",
    "def triplet_pos(y_true, y_pred):\n",
    "    return y_pred[0][3]\n",
    "def triplet_neg(y_true, y_pred):\n",
    "    return y_pred[0][4]\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)\n",
    "\n",
    "# https://www.kaggle.com/c/quora-question-pairs/discussion/33631\n",
    "# https://www.researchgate.net/figure/Illustration-of-triplet-loss-contrastive-loss-for-negative-samples-and-binomial_fig2_322060548\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    margin = 1\n",
    "    return K.mean(pos * K.square(neg) +\n",
    "                  (1 - pos) * K.square(K.maximum(margin - neg, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, Average, Maximum, Subtract, Average, AveragePooling1D, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "    \n",
    "    # Title\n",
    "    bug_t_token = Input(shape = (sequence_length_t, ), name = 'title_token_{}'.format(name))\n",
    "    bug_t_segment = Input(shape = (sequence_length_t, ), name = 'title_segment_{}'.format(name))\n",
    "    # Description\n",
    "    bug_d_token = Input(shape = (sequence_length_d, ), name = 'desc_token_{}'.format(name))\n",
    "    bug_d_segment = Input(shape = (sequence_length_d, ), name = 'desc_segment_{}'.format(name))\n",
    "    # Categorical\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model([bug_t_token, bug_t_segment])\n",
    "    bug_d_feat = desc_feature_model([bug_d_token, bug_d_segment])\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t_token, bug_t_segment, bug_d_token, bug_d_segment, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model_centroid(sequence_length, name):\n",
    "    \n",
    "    # Bug Centroid Feature\n",
    "    bug_centroid = Input(shape = (sequence_length, ), name = 'bug_centroid_feature_{}'.format(name))\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_centroid], outputs=[bug_centroid], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Average, Reshape, Add\n",
    "from keras_radam import RAdam\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, \n",
    "                             master_anchor, master_negative, master_positive, \n",
    "                         NUMBER_OF_INSTANCES, BATCH_SIZE, EPOCHS, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    inputs.append(master_anchor.input)\n",
    "    inputs.append(master_positive.input)\n",
    "    inputs.append(master_negative.input)\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    master_anchor = master_anchor.output\n",
    "    master_negative = master_negative.output\n",
    "    master_positive = master_positive.output\n",
    "    \n",
    "    # Distance bugs\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance')([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance')([encoded_anchor, encoded_negative])\n",
    "    \n",
    "    # Distance masters anchor\n",
    "    master_anchor_positive_d = Lambda(cosine_distance, name='pos_master_cosine_distance')([encoded_anchor, master_positive])\n",
    "    master_anchor_negative_d = Lambda(cosine_distance, name='neg_master_cosine_distance')([encoded_anchor, master_negative])\n",
    "    \n",
    "    # Distance master positive\n",
    "    master_pos_positive_d = Lambda(cosine_distance, name='pos_master_pos_cosine_distance')([encoded_positive, master_positive])\n",
    "    master_pos_negative_d = Lambda(cosine_distance, name='neg_master_pos_cosine_distance')([encoded_positive, master_negative])\n",
    "    \n",
    "    # Distance master negative\n",
    "    master_neg_positive_d = Lambda(cosine_distance, name='pos_master_neg_cosine_distance')([encoded_negative, master_negative])\n",
    "    master_neg_negative_d = Lambda(cosine_distance, name='neg_master_neg_cosine_distance')([encoded_negative, master_positive])\n",
    "     \n",
    "#     output_bug = Triplet(1)([positive_d, negative_d])\n",
    "#     output_bug = QuintetWeights((1,2))(output_bug)\n",
    "    output_bug = Lambda(triplet_loss, name='triplet_pos_neg')([positive_d, negative_d])\n",
    "    output_master = Lambda(triplet_loss, name='triplet_anchor_centroid')([master_anchor_positive_d, master_anchor_negative_d])\n",
    "    output_master_pos = Lambda(triplet_loss, name='triplet_pos_centroid')([master_pos_positive_d, master_pos_negative_d])\n",
    "    output_master_neg = Lambda(triplet_loss, name='triplet_neg_centroid')([master_neg_positive_d, master_neg_negative_d])\n",
    "    \n",
    "    # Weights for each loss\n",
    "    output_bug = Reshape((1, ))(output_bug)\n",
    "    output_anchor = Reshape((1, ))(output_master)\n",
    "    output_pos = Reshape((1, ))(output_master_pos)\n",
    "    output_neg = Reshape((1, ))(output_master_neg)\n",
    "    \n",
    "    sum_all_losses = Add()([output_bug, output_master, output_master_pos, output_master_neg])\n",
    "    output_bug_w = Dense(1, input_shape=(1,), use_bias=False)(output_bug)\n",
    "    output_master_w = Dense(1, input_shape=(1,), use_bias=False)(output_anchor)\n",
    "    output_master_pos_w = Dense(1, input_shape=(1,), use_bias=False)(output_pos)\n",
    "    output_master_neg_w = Dense(1, input_shape=(1,), use_bias=False)(output_neg)\n",
    "    sum_all_loss_w = Add()([output_bug_w, output_master_w, output_master_pos_w, output_master_neg_w])\n",
    "    # Weighted Median Loss\n",
    "    output_median = Lambda(\n",
    "            lambda inputs: inputs[0] / inputs[1], \n",
    "            name = 'Weighted_Median_Loss')([sum_all_loss_w, sum_all_losses])\n",
    "    \n",
    "    output = concatenate([output_median, output_bug, output_anchor, output_pos, output_neg])\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = [output], name = 'Similarity_Model')\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer='adam',\n",
    "                             metrics=[triplet_bug, triplet_anchor, triplet_pos, triplet_neg],\n",
    "                             loss=custom_loss)\n",
    "\n",
    "    # metrics=[triplet_bug, triplet_anchor, triplet_pos, triplet_neg],\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size  64\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_pos (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_pos (InputLayer)  (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_pos (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_pos (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_neg (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_neg (InputLayer)  (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_neg (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_neg (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 768)          80346736    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "                                                                 title_token_pos[0][0]            \n",
      "                                                                 title_segment_pos[0][0]          \n",
      "                                                                 title_token_neg[0][0]            \n",
      "                                                                 title_segment_neg[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 768)          80346736    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "                                                                 desc_token_pos[0][0]             \n",
      "                                                                 desc_segment_pos[0][0]           \n",
      "                                                                 desc_token_neg[0][0]             \n",
      "                                                                 desc_segment_neg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1836)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 1836)         0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[2\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 1836)         0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[3\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "bug_centroid_feature_master_pos (None, 1836)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bug_centroid_feature_master_neg (None, 1836)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "pos_master_cosine_distance (Lam (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 bug_centroid_feature_master_pos[0\n",
      "__________________________________________________________________________________________________\n",
      "neg_master_cosine_distance (Lam (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 bug_centroid_feature_master_neg[0\n",
      "__________________________________________________________________________________________________\n",
      "pos_master_pos_cosine_distance  (None, 1)            0           merge_features_pos[0][0]         \n",
      "                                                                 bug_centroid_feature_master_pos[0\n",
      "__________________________________________________________________________________________________\n",
      "neg_master_pos_cosine_distance  (None, 1)            0           merge_features_pos[0][0]         \n",
      "                                                                 bug_centroid_feature_master_neg[0\n",
      "__________________________________________________________________________________________________\n",
      "pos_master_neg_cosine_distance  (None, 1)            0           merge_features_neg[0][0]         \n",
      "                                                                 bug_centroid_feature_master_neg[0\n",
      "__________________________________________________________________________________________________\n",
      "neg_master_neg_cosine_distance  (None, 1)            0           merge_features_neg[0][0]         \n",
      "                                                                 bug_centroid_feature_master_pos[0\n",
      "__________________________________________________________________________________________________\n",
      "triplet_pos_neg (Lambda)        (None, 1)            0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "triplet_anchor_centroid (Lambda (None, 1)            0           pos_master_cosine_distance[0][0] \n",
      "                                                                 neg_master_cosine_distance[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "triplet_pos_centroid (Lambda)   (None, 1)            0           pos_master_pos_cosine_distance[0]\n",
      "                                                                 neg_master_pos_cosine_distance[0]\n",
      "__________________________________________________________________________________________________\n",
      "triplet_neg_centroid (Lambda)   (None, 1)            0           pos_master_neg_cosine_distance[0]\n",
      "                                                                 neg_master_neg_cosine_distance[0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           triplet_pos_neg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1)            0           triplet_anchor_centroid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1)            0           triplet_pos_centroid[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1)            0           triplet_neg_centroid[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            1           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1)            0           reshape_1[0][0]                  \n",
      "                                                                 triplet_anchor_centroid[0][0]    \n",
      "                                                                 triplet_pos_centroid[0][0]       \n",
      "                                                                 triplet_neg_centroid[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Weighted_Median_Loss (Lambda)   (None, 1)            0           add_2[0][0]                      \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5)            0           Weighted_Median_Loss[0][0]       \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 161,198,376\n",
      "Trainable params: 726,200\n",
      "Non-trainable params: 160,472,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.93, TL: 1.00, TL_A: 0.96, TL_P: 0.95, TL_N: 0.97\n",
      "Epoch: 2 Loss: 0.93, TL: 1.01, TL_A: 0.97, TL_P: 0.96, TL_N: 0.97\n",
      "Epoch: 3 Loss: 0.93, TL: 1.01, TL_A: 0.97, TL_P: 0.96, TL_N: 0.97\n",
      "Epoch: 4 Loss: 0.93, TL: 1.01, TL_A: 0.97, TL_P: 0.96, TL_N: 0.97\n",
      "Epoch: 5 Loss: 0.93, TL: 1.02, TL_A: 0.97, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 6 Loss: 0.93, TL: 1.02, TL_A: 0.98, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 7 Loss: 0.92, TL: 1.01, TL_A: 0.97, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 8 Loss: 0.92, TL: 1.02, TL_A: 0.98, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 9 Loss: 0.92, TL: 1.02, TL_A: 0.98, TL_P: 0.97, TL_N: 0.98\n",
      "Epoch: 10 Loss: 0.92, TL: 1.01, TL_A: 0.98, TL_P: 0.98, TL_N: 0.98\n",
      "Epoch: 11 Loss: 0.92, TL: 1.01, TL_A: 0.98, TL_P: 0.98, TL_N: 0.98\n",
      "Epoch: 12 Loss: 0.92, TL: 1.00, TL_A: 0.98, TL_P: 0.98, TL_N: 0.98\n",
      "Epoch: 13 Loss: 0.92, TL: 1.01, TL_A: 0.99, TL_P: 0.98, TL_N: 0.99\n",
      "Epoch: 14 Loss: 0.92, TL: 1.01, TL_A: 0.99, TL_P: 0.98, TL_N: 0.99\n",
      "Epoch: 15 Loss: 0.91, TL: 1.01, TL_A: 0.99, TL_P: 0.98, TL_N: 0.99\n",
      "Epoch: 16 Loss: 0.91, TL: 1.00, TL_A: 0.99, TL_P: 0.98, TL_N: 0.99\n",
      "Epoch: 17 Loss: 0.91, TL: 1.01, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 18 Loss: 0.91, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 19 Loss: 0.91, TL: 1.01, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 20 Loss: 0.91, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 21 Loss: 0.91, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 22 Loss: 0.91, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 23 Loss: 0.91, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 24 Loss: 0.90, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 27 Loss: 0.90, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 28 Loss: 0.90, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 0.99\n",
      "Epoch: 29 Loss: 0.90, TL: 1.00, TL_A: 1.00, TL_P: 0.99, TL_N: 1.00\n",
      "Epoch: 30 Loss: 0.90, TL: 1.00, TL_A: 1.00, TL_P: 0.99, TL_N: 1.00\n",
      "Epoch: 31 Loss: 0.90, TL: 1.00, TL_A: 0.99, TL_P: 0.99, TL_N: 1.00\n",
      "Epoch: 32 Loss: 0.90, TL: 1.00, TL_A: 1.00, TL_P: 0.99, TL_N: 1.00\n",
      "Epoch: 33 Loss: 0.89, TL: 1.00, TL_A: 1.00, TL_P: 0.99, TL_N: 1.00\n",
      "Epoch: 34 Loss: 0.89, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 35 Loss: 0.89, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 36 Loss: 0.89, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 37 Loss: 0.89, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 38 Loss: 0.89, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 39 Loss: 0.89, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 40 Loss: 0.89, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 41 Loss: 0.89, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 42 Loss: 0.88, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 43 Loss: 0.88, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 44 Loss: 0.88, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 45 Loss: 0.88, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 46 Loss: 0.88, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 47 Loss: 0.88, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 48 Loss: 0.88, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 49 Loss: 0.88, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 50 Loss: 0.88, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 51 Loss: 0.88, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 52 Loss: 0.87, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 53 Loss: 0.87, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 54 Loss: 0.87, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 55 Loss: 0.87, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 56 Loss: 0.87, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 57 Loss: 0.87, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 58 Loss: 0.87, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 59 Loss: 0.87, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 60 Loss: 0.87, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 61 Loss: 0.87, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 62 Loss: 0.86, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 63 Loss: 0.86, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 64 Loss: 0.86, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 65 Loss: 0.86, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 66 Loss: 0.86, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 67 Loss: 0.86, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 68 Loss: 0.86, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 69 Loss: 0.86, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 70 Loss: 0.86, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 71 Loss: 0.86, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 72 Loss: 0.85, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 73 Loss: 0.85, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 74 Loss: 0.85, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 75 Loss: 0.85, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 76 Loss: 0.85, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 77 Loss: 0.85, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 78 Loss: 0.85, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 79 Loss: 0.85, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 80 Loss: 0.85, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 81 Loss: 0.85, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 82 Loss: 0.84, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 83 Loss: 0.84, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 84 Loss: 0.84, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 85 Loss: 0.84, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 86 Loss: 0.84, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 87 Loss: 0.84, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 88 Loss: 0.84, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 89 Loss: 0.84, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 90 Loss: 0.84, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 91 Loss: 0.83, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 92 Loss: 0.83, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 93 Loss: 0.83, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 94 Loss: 0.83, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 95 Loss: 0.83, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 96 Loss: 0.83, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 97 Loss: 0.83, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 98 Loss: 0.83, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 99 Loss: 0.83, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00\n",
      "Epoch: 100 Loss: 0.83, TL: 1.00, TL_A: 1.00, TL_P: 1.00, TL_N: 1.00, recall@25: 0.37\n",
      "Saved model 'modelos/model_deepQL_weights_100_feature_100epochs_64batch(eclipse).h5' to disk\n",
      "Best_epoch=10, Best_loss=-0.60s, Recall@25=0.37\n",
      "CPU times: user 49min 6s, sys: 1h 31min 33s, total: 2h 20min 39s\n",
      "Wall time: 1h 59min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "print(\"Batch size \", batch_size)\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_dilated_model\n",
    "    arcii_model\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    bilstm_model\n",
    "'''\n",
    "# title_feature_model = bilstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "title_feature_model = bert_model(MAX_SEQUENCE_LENGTH_T, 'Title')\n",
    "desc_feature_model = bert_model(MAX_SEQUENCE_LENGTH_D, 'Description')\n",
    "#desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "# Master model\n",
    "embed_size = K.int_shape(title_feature_model.get_output_at(0))[1] + K.int_shape(desc_feature_model.get_output_at(0))[1] + K.int_shape(categorical_feature_model.get_output_at(0))[1] \n",
    "\n",
    "master_anchor = siamese_model_centroid(embed_size, 'master_anchor')\n",
    "master_pos = siamese_model_centroid(embed_size, 'master_pos')\n",
    "master_negative = siamese_model_centroid(embed_size, 'master_neg')\n",
    "\n",
    "NUMBER_OF_INSTANCES = len(baseline.dup_sets_train)\n",
    "BATCH_SIZE = batch_size\n",
    "EPOCHS = epochs\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, \n",
    "                                            master_anchor, master_negative, master_pos,\n",
    "                                            NUMBER_OF_INSTANCES, BATCH_SIZE, EPOCHS, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, train_master_input, train_master_neg, \\\n",
    "            train_sim = experiment.batch_iterator_bert(encoded_anchor, baseline.train_data, baseline.dup_sets_train, \\\n",
    "                                                       bug_train_ids, \n",
    "                                                       batch_size, 1, \n",
    "                                                       issues_by_buckets, \n",
    "                                                       TRIPLET_HARD=True, USE_CENTROID=True)\n",
    "    \n",
    "    train_batch = [train_input_sample['title']['token'], train_input_sample['title']['segment'], train_input_sample['description']['token'], train_input_sample['description']['segment'], train_input_sample['info'],\n",
    "                   train_input_pos['title']['token'], train_input_pos['title']['segment'], train_input_pos['description']['token'], train_input_pos['description']['segment'], train_input_pos['info'], \n",
    "                   train_input_neg['title']['token'], train_input_neg['title']['segment'], train_input_neg['description']['token'], train_input_neg['description']['segment'], train_input_neg['info'],\n",
    "                   train_master_input['centroid_embed'],\n",
    "                   train_master_input['centroid_embed'],\n",
    "                   train_master_neg['centroid_embed']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, \n",
    "                                                               bug_train_ids, method='bert')\n",
    "        print(\"Epoch: {} Loss: {:.2f}, TL: {:.2f}, TL_A: {:.2f}, TL_P: {:.2f}, TL_N: {:.2f}, recall@25: {:.2f}\".format(epoch+1, h[0], h[1], h[2], h[3], h[4], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, TL: {:.2f}, TL_A: {:.2f}, TL_P: {:.2f}, TL_N: {:.2f}\".format(epoch+1,h[0], h[1], h[2], h[3], h[4]))\n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}s, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['327681:324658|420526:0.955991443246603,422622:0.9559594579041004,411055:0.9557418264448643,418146:0.9555703476071358,376670:0.9554064050316811,403466:0.9549705162644386,419892:0.9549618251621723,403948:0.9549268037080765,418858:0.954805564135313,417798:0.9546240381896496,391963:0.9545932747423649,335784:0.9545860812067986,369596:0.9543934501707554,336922:0.9543560147285461,381119:0.9543355815112591,368850:0.9542971849441528,329597:0.9542873874306679,418838:0.9542631395161152,422095:0.9542536735534668,381298:0.9542535804212093,419581:0.9542295597493649,387326:0.9542203731834888,419879:0.9541943408548832,381296:0.9541781470179558,419883:0.9541210383176804,381138:0.9540407098829746,419880:0.9540344476699829,387399:0.9540259204804897,385830:0.954003244638443',\n",
       " '360457:362252|364552:0.980149183422327,353496:0.975926611572504,353222:0.9745746776461601,351842:0.9709462597966194,355947:0.9703360050916672,368089:0.970120295882225,367431:0.96998062543571,348343:0.9694935996085405,343568:0.9693177174776793,391011:0.969127994030714,346926:0.9689451027661562,342301:0.9684029892086983,378207:0.9683683179318905,344823:0.9683192372322083,347293:0.9682077169418335,372903:0.9679981991648674,364134:0.9679140672087669,343310:0.9677902720868587,402100:0.9676804542541504,354118:0.9676040485501289,377371:0.967292744666338,419520:0.9671629220247269,335711:0.9669464863836765,396905:0.9668535962700844,338252:0.9657650515437126,401758:0.9652396887540817,348933:0.9651774130761623,339527:0.9647107124328613,351556:0.9646068699657917',\n",
       " '393230:393054|398880:0.9800215363502502,398917:0.9775049220770597,345504:0.970632316544652,356765:0.9700827244669199,349752:0.9696676563471556,398963:0.9696353282779455,394256:0.9694961570203304,346806:0.9682950414717197,328406:0.9682716801762581,340714:0.9680932126939297,350711:0.9677561447024345,360529:0.9677315577864647,336087:0.9677162729203701,397934:0.9677035734057426,375114:0.9676727168262005,333063:0.967619776725769,337553:0.9674868173897266,357235:0.967417772859335,353537:0.9672399163246155,337532:0.9672362022101879,345712:0.9672353826463223,390479:0.9672016724944115,338053:0.9671249464154243,338250:0.9670290984213352,380919:0.9669152125716209,337042:0.9668778479099274,412776:0.9668426811695099,330019:0.966831848025322,350583:0.9668041132390499',\n",
       " '393232:393282,390667,383388|415235:0.9817440416663885,408203:0.981636356562376,406941:0.9812778830528259,408678:0.9801344536244869,392565:0.9800013899803162,409961:0.9798729363828897,412105:0.9798669293522835,408095:0.979424299672246,399657:0.9794045239686966,411120:0.979379054158926,395921:0.9793643373996019,421036:0.979197284206748,410955:0.9789662547409534,400975:0.9789336360991001,395005:0.9788013100624084,403754:0.9787997286766768,408756:0.9787161890417337,415326:0.9785729497671127,399971:0.9782668966799974,421072:0.9779195543378592,416464:0.9777355790138245,401108:0.9777051154524088,406503:0.9773902650922537,405563:0.977237019687891,414929:0.9771256577223539,409369:0.9769797883927822,403900:0.9768551550805569,413509:0.9764424450695515,410468:0.9760278128087521',\n",
       " '393247:401563,396542|419072:0.978482810780406,355970:0.9767403844743967,380240:0.9754549693316221,384286:0.9739831332117319,340898:0.9724195096641779,370995:0.9676632843911648,336140:0.9654032364487648,337365:0.9653607681393623,338783:0.9653554931282997,400536:0.9642342105507851,361860:0.9638827107846737,310045:0.9631988368928432,401563:0.9628670290112495,367452:0.9628195911645889,364622:0.9624291881918907,345215:0.9621587134897709,374771:0.9621521718800068,418278:0.9621450155973434,368673:0.9620099328458309,387699:0.9619669988751411,356113:0.9619631245732307,398092:0.961893767118454,379991:0.961882222443819,353538:0.9618694074451923,330712:0.9617746919393539,359474:0.9617705903947353,413577:0.9616771377623081,415360:0.9615952037274837,398316:0.9615837596356869',\n",
       " '360484:359237|372824:0.9782041702419519,376808:0.9776031710207462,381045:0.9768780246376991,363917:0.9763854648917913,376460:0.9755919445306063,358243:0.9750711284577847,378666:0.973277011886239,380714:0.9726779032498598,378916:0.9717724453657866,382011:0.9712732098996639,366655:0.9704068638384342,377735:0.9690588004887104,404213:0.9689170699566603,349243:0.9687587264925241,355433:0.9683598317205906,376229:0.9683060497045517,397804:0.9681389667093754,378374:0.9681325703859329,385536:0.967976950109005,377974:0.9679470136761665,396558:0.9679203517735004,404182:0.9678129479289055,359238:0.967744093388319,369405:0.9676188789308071,365414:0.9675444774329662,339673:0.967472780495882,390153:0.9672954827547073,377691:0.9672740325331688,383044:0.9671708270907402',\n",
       " '360489:358624,354593,355714,357219,358267,362534,356295,356871,355722,356717,356973,358774,360214,356122,355803,356413|350902:0.9934728071093559,350122:0.9924906389787793,373897:0.9920002855360508,356717:0.9919395605102181,382668:0.991637040860951,355580:0.9915255373343825,375934:0.9914856292307377,355803:0.9914334928616881,352438:0.9912625374272466,352470:0.9911428866907954,352802:0.9910607347264886,356871:0.9910604916512966,374595:0.9910601694136858,355722:0.9908618265762925,375914:0.9908327562734485,375915:0.9907381860539317,360214:0.99056835193187,358624:0.9905074974521995,368796:0.9905060883611441,358774:0.990501762367785,350900:0.9904607804492116,369211:0.990433725528419,406956:0.9904036400839686,380915:0.9903903352096677,369310:0.9902973836287856,380477:0.9902382213622332,360213:0.9901495007798076,349594:0.989821994677186,386746:0.9898074362426996',\n",
       " '262194:331909|298750:0.9780744127929211,285268:0.9756303429603577,303746:0.9700696878135204,405563:0.9683841429650784,409794:0.9680551886558533,324470:0.9680370539426804,411120:0.9679879732429981,408203:0.9678523205220699,380848:0.9678198620676994,293689:0.9677512757480145,393232:0.9675648622214794,389221:0.9674534648656845,415235:0.9672409482300282,419808:0.9672020711004734,409217:0.9670700430870056,392565:0.9670687802135944,330258:0.9669497087597847,424389:0.9669367484748363,357861:0.9666518457233906,382533:0.9666003882884979,406941:0.9665729813277721,374420:0.9663454778492451,340599:0.9663175046443939,418241:0.9662957713007927,408678:0.9662539064884186,400975:0.9662119150161743,386382:0.966190792620182,418886:0.9660615585744381,387658:0.9660603031516075',\n",
       " '327731:328902|318915:0.9754529055207968,351254:0.9730015769600868,330019:0.9716571066528559,328406:0.971495134755969,323275:0.970926146954298,337392:0.9709206502884626,322454:0.9699898101389408,338579:0.9699698965996504,333429:0.9697895161807537,352310:0.9690937399864197,319056:0.9690742716193199,389775:0.969013025984168,336223:0.9687459915876389,344939:0.9682333208620548,342792:0.9681542254984379,358629:0.9680944941937923,398963:0.9680869020521641,350583:0.9678545035421848,358103:0.9677194803953171,394884:0.9669964462518692,394117:0.9665779024362564,347159:0.9664055071771145,316521:0.9659891873598099,331293:0.9657672494649887,322920:0.9657293483614922,338717:0.9656376056373119,360200:0.965373907238245,345712:0.9653413780033588,356765:0.9652314409613609',\n",
       " '393277:393864,400436|411452:0.9677976369857788,320329:0.9671544916927814,407749:0.9667103104293346,411006:0.9658914282917976,404189:0.9658396393060684,398225:0.9652406424283981,356306:0.9648909978568554,417537:0.9648027494549751,403040:0.9646158032119274,321640:0.9644788838922977,393670:0.9643643461167812,402038:0.9642930217087269,404425:0.9639578238129616,390853:0.9639142751693726,407314:0.9638744853436947,409746:0.9637524262070656,407824:0.9635664187371731,408505:0.9635192602872849,336311:0.9633629135787487,406808:0.9631435312330723,390713:0.9629649929702282,401963:0.962882824242115,392048:0.9627708122134209,398028:0.9627089276909828,392700:0.9625888541340828,402051:0.9623664170503616,392047:0.962266132235527,402033:0.9622113406658173,392214:0.9621961936354637',\n",
       " '393282:393232,390667,383388|341569:0.9688032623380423,383982:0.9679324701428413,350769:0.966231107711792,394628:0.9656679444015026,338958:0.9650541134178638,411172:0.9648614376783371,393339:0.9645699672400951,409932:0.9639798142015934,378553:0.9638786762952805,415759:0.9634790010750294,371215:0.9631975963711739,403607:0.963076189160347,409429:0.9626315794885159,405172:0.9621893279254436,325749:0.9611954912543297,313334:0.9611832797527313,406690:0.9591989070177078,406039:0.9587628617882729,369513:0.9577056728303432,408751:0.9576743729412556,342430:0.9571951627731323,401105:0.9566509909927845,342271:0.9566251784563065,377934:0.956624586135149,408733:0.956609945744276,378975:0.9564876668155193,404329:0.9564346745610237,396126:0.9562180787324905,376176:0.9561784155666828',\n",
       " '327748:330466|345193:0.9794185683131218,339286:0.9777670782059431,338735:0.9773570671677589,340565:0.9765868000686169,320553:0.9757297448813915,385265:0.9746874198317528,329382:0.9732085280120373,393144:0.9731112662702799,347983:0.9730128645896912,332759:0.9728838391602039,395308:0.9725497215986252,387923:0.9724335968494415,341497:0.9723617695271969,346156:0.9722949229180813,376087:0.9720708075910807,376055:0.9719187151640654,318499:0.9716214332729578,320097:0.9715045727789402,371549:0.9714698065072298,379215:0.9714224077761173,371989:0.9713854975998402,385266:0.9712402150034904,320789:0.9711208790540695,318821:0.9707844369113445,339737:0.9707744549959898,328835:0.9691828638315201,320235:0.9691672194749117,332463:0.9690633378922939,318645:0.9688941072672606',\n",
       " '327754:330209,331297,332294,327303,327528,329166,329232,330705,326194,329778,331186,332594,333917,327415,327548,333341,333342,332927|329232:0.9771033599972725,331186:0.9736176487058401,338291:0.9652209132909775,326757:0.9648867696523666,326247:0.963187288492918,324636:0.9614090248942375,326795:0.9608894400298595,327231:0.9608560763299465,384731:0.9599924236536026,321880:0.9589272551238537,369773:0.9583576880395412,388062:0.9573639929294586,404262:0.9568021111190319,395813:0.9563395008444786,368347:0.9563042968511581,361651:0.9561168104410172,418858:0.9559128805994987,415673:0.9557715468108654,423757:0.9556033834815025,395596:0.9555468261241913,417798:0.9555266089737415,398189:0.9554757885634899,355396:0.9554642252624035,388561:0.9552114345133305,343325:0.9550986029207706,420526:0.9550489634275436,406772:0.9550467319786549,422095:0.9550031870603561,344051:0.9550010487437248',\n",
       " '360529:354495,343276,347031|360822:0.9813682343810797,349752:0.980528162792325,346806:0.979636587202549,353537:0.9789922051131725,356765:0.9789087325334549,350583:0.9773205332458019,345504:0.9772046767175198,357606:0.9749355781823397,347929:0.9720289316028357,313865:0.9707364328205585,352310:0.9706313833594322,350711:0.9704673700034618,342386:0.9703560620546341,359800:0.970122592523694,398917:0.9697227757424116,359014:0.9697028696537018,328406:0.9696587044745684,380919:0.9695726968348026,357235:0.9695658273994923,347159:0.9695418365299702,322498:0.9695022292435169,337553:0.9694942012429237,338053:0.9693597108125687,337042:0.9692581612616777,318822:0.969223115593195,398880:0.9692192897200584,336087:0.9691813811659813,338250:0.969102568924427,359105:0.96899439021945',\n",
       " '393303:392707|365750:0.9693344552069902,396520:0.9692756645381451,399108:0.9680540077388287,395794:0.9674921706318855,351576:0.9633675403892994,322520:0.9631461203098297,408909:0.9629167020320892,400689:0.9619400650262833,389956:0.9618191979825497,409556:0.9617580436170101,362113:0.9616373553872108,345679:0.9616155624389648,405281:0.961080227047205,334311:0.9610135741531849,349430:0.9608417749404907,376366:0.960656400769949,367172:0.9604653231799603,383116:0.9604081735014915,365746:0.9602541737258434,351624:0.9602521397173405,408446:0.9599515609443188,347717:0.959920097142458,415330:0.9598812982439995,353623:0.9598547071218491,407173:0.9598541110754013,341694:0.9597027115523815,401382:0.9596526771783829,330229:0.9595614336431026,362614:0.9594307765364647',\n",
       " '327769:177756,329721|325997:0.9675696827471256,323953:0.9657198712229729,324625:0.9656048081815243,395421:0.9653968252241611,359456:0.9630406834185123,325125:0.9620284885168076,321640:0.9616024680435658,313597:0.9610825926065445,325356:0.960845522582531,337327:0.960728794336319,317783:0.9600912630558014,356306:0.9598846770823002,336397:0.9597874693572521,332662:0.9597734622657299,373613:0.9595709927380085,323681:0.9595526084303856,318006:0.9595131389796734,319872:0.9594492465257645,369837:0.9593867845833302,387865:0.9592717625200748,322329:0.9591653309762478,336062:0.9591302387416363,326029:0.9590578973293304,325995:0.9590478762984276,320329:0.958960022777319,349148:0.9589108005166054,356184:0.9589046388864517,322312:0.9586451686918736,314484:0.9586415961384773',\n",
       " '393305:381846|390320:0.9609954990446568,392283:0.9585649743676186,357665:0.9569737426936626,361773:0.9567853920161724,403948:0.9567623622715473,355014:0.9566738083958626,358102:0.9565445780754089,410424:0.9563964009284973,382971:0.9562501460313797,408577:0.9561643823981285,361301:0.9560780078172684,382781:0.9559408202767372,359768:0.9558637291193008,385830:0.9557881951332092,380455:0.955590009689331,359570:0.9555317871272564,384147:0.9554847180843353,358477:0.9553295448422432,382412:0.9553016163408756,383253:0.9552472308278084,364494:0.9552312344312668,356530:0.9552038237452507,355754:0.955199982970953,368224:0.9551974907517433,422095:0.9551038108766079,391733:0.9550252705812454,358668:0.9549669176340103,381049:0.9549184367060661,381900:0.9548450261354446',\n",
       " '360540:355108|360574:0.978652698919177,359609:0.9701297990977764,364398:0.9684080183506012,368969:0.9681245125830173,380734:0.9680613838136196,378375:0.9670714549720287,367434:0.9668656215071678,363063:0.9665053002536297,382274:0.9661458469927311,366094:0.9661423750221729,382604:0.9657856114208698,368850:0.9656353518366814,396792:0.9653257317841053,411816:0.9646441750228405,389938:0.9645939506590366,379307:0.9644468873739243,362575:0.963793084025383,369585:0.9637659415602684,366212:0.9636498987674713,365263:0.9634118154644966,372040:0.96306237205863,382657:0.9629555866122246,380433:0.9628758206963539,368868:0.9627470634877682,372954:0.9626246243715286,360980:0.9626126103103161,363108:0.9625823125243187,361447:0.9624731242656708,370853:0.9624359533190727',\n",
       " '327772:326427|327233:0.9727992713451385,351083:0.9719109907746315,328795:0.9713999535888433,351519:0.9707765262573957,358923:0.9703804235905409,328926:0.9701412636786699,348805:0.9699312783777714,369880:0.9699081350117922,393787:0.9698519948869944,348806:0.9697016980499029,320546:0.9690377786755562,320005:0.9689285065978765,375783:0.9688944928348064,317929:0.9688512198626995,325294:0.9687506891787052,365722:0.9685852266848087,385286:0.9681948088109493,342114:0.9681879319250584,359535:0.9677879326045513,329375:0.9674284607172012,344833:0.9673342071473598,393612:0.9669766910374165,387699:0.9665243625640869,402343:0.9660761542618275,341643:0.96597496047616,378155:0.9657102823257446,332039:0.9649965912103653,388299:0.9646815173327923,337334:0.9639121256768703',\n",
       " '360547:360548,360549|360548:1.0,360549:1.0,398091:0.9684499017894268,398316:0.9660535901784897,351666:0.9656355082988739,413551:0.9644520245492458,389853:0.9641394056379795,399699:0.9638919606804848,412782:0.9638629965484142,326729:0.963489193469286,399697:0.9632892273366451,407464:0.9628612026572227,334967:0.9628018327057362,350877:0.9625523313879967,350658:0.9624887183308601,374729:0.9623103477060795,372838:0.962062407284975,369920:0.9619448706507683,402343:0.9617534577846527,390175:0.9613933712244034,399434:0.9612029045820236,398482:0.9611026532948017,390366:0.9607871025800705,364772:0.9607659764587879,356113:0.9607402123510838,328795:0.9606280475854874,395217:0.9604833722114563,333329:0.9603717550635338,403525:0.9603548645973206']"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall, exported_rank, debug = experiment.evaluate_validation_test(experiment, retrieval, verbose, \n",
    "#                                                         encoded_anchor, issues_by_buckets, evaluate_validation_test)\n",
    "# test_vectorized, queries_test_vectorized, annoy, X_test, distance_test, indices_test = debug\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 4641\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepQL_weights_100_feature_100epochs_64batch(eclipse)'"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoded_anchor\n",
    "# model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 768)          80346736    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 768)          80346736    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1836)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "==================================================================================================\n",
      "Total params: 161,198,372\n",
      "Trainable params: 726,196\n",
      "Non-trainable params: 160,472,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, \n",
    "                                                                   bug_train_ids, method='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/eclipse/exported_rank_deepQL_weights_100.txt'"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.24,\n",
       " '2 - recall_at_10': 0.29,\n",
       " '3 - recall_at_15': 0.33,\n",
       " '4 - recall_at_20': 0.35,\n",
       " '5 - recall_at_25': 0.37}"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
