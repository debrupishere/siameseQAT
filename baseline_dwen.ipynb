{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning - DWEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 100\n",
    "MAX_SEQUENCE_LENGTH_D = 20 # 500\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = float('inf')\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'netbeans'\n",
    "METHOD = 'baseline_dwen_{}'.format(epochs)\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Path embeddings\n",
    "EMBED_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_feature@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_feature_@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4145d770d35a4c04a1178257b2b82711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=180483), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92cb35aec5541f289bdfee07f201c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36232), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "216715"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccd2f42335d4d61bf4998e0b9129bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=216715), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc9a395000440819182d87bcdc7df2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 16.5 s, sys: 1.93 s, total: 18.4 s\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75a838beaff419bbe94316b4916eb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=181971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[90024, 1289],\n",
       " [1408, 6256],\n",
       " [1787, 14975],\n",
       " [166804, 2020],\n",
       " [2337, 31362],\n",
       " [2337, 46020],\n",
       " [2337, 15205],\n",
       " [2337, 32942],\n",
       " [2337, 35023],\n",
       " [2337, 57495]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': '0\\n',\n",
       " 'bug_status': '0\\n',\n",
       " 'component': '220\\n',\n",
       " 'creation_ts': '2006-12-05 10:32:00 +0000',\n",
       " 'delta_ts': '2007-01-17 10:09:27 +0000',\n",
       " 'description': \"[CLS] please review the friend api used by the j ##2 ##me module to prep ##ro ##ces ##s the java files before they are passed to the id ##e ' s java compiler . use ##case : the j ##2 ##me java file uses prep ##ro ##ces ##sor to allow several different versions of a single java file according to active configuration . when java infrastructure reads such a file from disk ( an initial scan , reading of a non opened file ) it should use the prep ##ro ##ces ##sor to read the right content . in the previous versions of the id ##e the j ##2 ##me module had to open all the source files to force the java infrastructure to read the content from documents not from the disk , but this solution does not scale . stability category : friend - used only by the j ##2 ##me module . implementation : the implementation of the java ##c ' s java ##fi ##lem ##ana ##ger uses the supplied interface to do the prep ##ro ##ces ##sing . limitations : the positions in the filtered content have to correspond to the positions in the document . [SEP]\",\n",
       " 'description_bert': \"[CLS] please review the friend api used by the j ##2 ##me module to prep ##ro ##ces ##s the java files before they are passed to the id ##e ' s java compiler . use ##case : the j ##2 ##me java file uses prep ##ro ##ces ##sor to allow several different versions of a single java file according to active configuration . when java infrastructure reads such a file from disk ( an initial scan , reading of a non opened file ) it should use the prep ##ro ##ces ##sor to read the right content . in the previous versions of the id ##e the j ##2 ##me module had to open all the source files to force the java infrastructure to read the content from documents not from the disk , but this solution does not scale . stability category : friend - used only by the j ##2 ##me module . implementation : the implementation of the java ##c ' s java ##fi ##lem ##ana ##ger uses the supplied interface to do the prep ##ro ##ces ##sing . limitations : the positions in the filtered content have to correspond to the positions in the document . [SEP]\",\n",
       " 'description_word': array([  101,  3531,  3319,  1996,  2767, 17928,  2109,  2011,  1996,\n",
       "         1046,  2475,  4168, 11336,  2000, 17463,  3217,  9623,  2015,\n",
       "         1996,  9262]),\n",
       " 'description_word_bert': [101,\n",
       "  3531,\n",
       "  3319,\n",
       "  1996,\n",
       "  2767,\n",
       "  17928,\n",
       "  2109,\n",
       "  2011,\n",
       "  1996,\n",
       "  1046,\n",
       "  2475,\n",
       "  4168,\n",
       "  11336,\n",
       "  2000,\n",
       "  17463,\n",
       "  3217,\n",
       "  9623,\n",
       "  2015,\n",
       "  1996,\n",
       "  9262,\n",
       "  6764,\n",
       "  2077,\n",
       "  2027,\n",
       "  2024,\n",
       "  2979,\n",
       "  2000,\n",
       "  1996,\n",
       "  8909,\n",
       "  2063,\n",
       "  1005,\n",
       "  1055,\n",
       "  9262,\n",
       "  21624,\n",
       "  1012,\n",
       "  2224,\n",
       "  18382,\n",
       "  1024,\n",
       "  1996,\n",
       "  1046,\n",
       "  2475,\n",
       "  4168,\n",
       "  9262,\n",
       "  5371,\n",
       "  3594,\n",
       "  17463,\n",
       "  3217,\n",
       "  9623,\n",
       "  21748,\n",
       "  2000,\n",
       "  3499,\n",
       "  2195,\n",
       "  2367,\n",
       "  4617,\n",
       "  1997,\n",
       "  1037,\n",
       "  2309,\n",
       "  9262,\n",
       "  5371,\n",
       "  2429,\n",
       "  2000,\n",
       "  3161,\n",
       "  9563,\n",
       "  1012,\n",
       "  2043,\n",
       "  9262,\n",
       "  6502,\n",
       "  9631,\n",
       "  2107,\n",
       "  1037,\n",
       "  5371,\n",
       "  2013,\n",
       "  9785,\n",
       "  1006,\n",
       "  2019,\n",
       "  3988,\n",
       "  13594,\n",
       "  1010,\n",
       "  3752,\n",
       "  1997,\n",
       "  1037,\n",
       "  2512,\n",
       "  2441,\n",
       "  5371,\n",
       "  1007,\n",
       "  2009,\n",
       "  2323,\n",
       "  2224,\n",
       "  1996,\n",
       "  17463,\n",
       "  3217,\n",
       "  9623,\n",
       "  21748,\n",
       "  2000,\n",
       "  3191,\n",
       "  1996,\n",
       "  2157,\n",
       "  4180,\n",
       "  1012,\n",
       "  1999,\n",
       "  1996,\n",
       "  3025,\n",
       "  4617,\n",
       "  1997,\n",
       "  1996,\n",
       "  8909,\n",
       "  2063,\n",
       "  1996,\n",
       "  1046,\n",
       "  2475,\n",
       "  4168,\n",
       "  11336,\n",
       "  2018,\n",
       "  2000,\n",
       "  2330,\n",
       "  2035,\n",
       "  1996,\n",
       "  3120,\n",
       "  6764,\n",
       "  2000,\n",
       "  2486,\n",
       "  1996,\n",
       "  9262,\n",
       "  6502,\n",
       "  2000,\n",
       "  3191,\n",
       "  1996,\n",
       "  4180,\n",
       "  2013,\n",
       "  5491,\n",
       "  2025,\n",
       "  2013,\n",
       "  1996,\n",
       "  9785,\n",
       "  1010,\n",
       "  2021,\n",
       "  2023,\n",
       "  5576,\n",
       "  2515,\n",
       "  2025,\n",
       "  4094,\n",
       "  1012,\n",
       "  9211,\n",
       "  4696,\n",
       "  1024,\n",
       "  2767,\n",
       "  1011,\n",
       "  2109,\n",
       "  2069,\n",
       "  2011,\n",
       "  102],\n",
       " 'dup_id': '[]',\n",
       " 'issue_id': 90566,\n",
       " 'priority': '3\\n',\n",
       " 'product': '26\\n',\n",
       " 'resolution': 'FIXED',\n",
       " 'textual_word': array([  101,  3319,  1037,  2767, 17928,  2426,  1996,  8909,  2063,\n",
       "         1005,  1055,  9262, 21624,  1998,  1996,  1046,  2475,  4168,\n",
       "        17463,  3217,   101,  3531,  3319,  1996,  2767, 17928,  2109,\n",
       "         2011,  1996,  1046,  2475,  4168, 11336,  2000, 17463,  3217,\n",
       "         9623,  2015,  1996,  9262]),\n",
       " 'title': \"[CLS] review a friend api among the id ##e ' s java compiler and the j ##2 ##me prep ##ro ##ces ##sor [SEP]\",\n",
       " 'title_bert': \"[CLS] review a friend api among the id ##e ' s java compiler and the j ##2 ##me prep ##ro ##ces ##sor [SEP]\",\n",
       " 'title_word': array([  101,  3319,  1037,  2767, 17928,  2426,  1996,  8909,  2063,\n",
       "         1005,  1055,  9262, 21624,  1998,  1996,  1046,  2475,  4168,\n",
       "        17463,  3217]),\n",
       " 'title_word_bert': [101,\n",
       "  3319,\n",
       "  1037,\n",
       "  2767,\n",
       "  17928,\n",
       "  2426,\n",
       "  1996,\n",
       "  8909,\n",
       "  2063,\n",
       "  1005,\n",
       "  1055,\n",
       "  9262,\n",
       "  21624,\n",
       "  1998,\n",
       "  1996,\n",
       "  1046,\n",
       "  2475,\n",
       "  4168,\n",
       "  17463,\n",
       "  3217,\n",
       "  9623,\n",
       "  21748,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'version': '7\\n'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 30600)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193512"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(list(issues_by_buckets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "110647 in experiment.baseline.bug_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60 ms, sys: 0 ns, total: 60 ms\n",
      "Wall time: 59.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = experiment.batch_iterator(None, \n",
    "                                                                                          baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train,\n",
    "                                                                                          bug_train_ids,\n",
    "                                                                                          batch_size_test, 1,\n",
    "                                                                                          issues_by_buckets)\n",
    "\n",
    "valid_title_sample_a = np.concatenate([valid_input_sample['title'], valid_input_sample['title']], 0)\n",
    "valid_title_sample_b = np.concatenate([valid_input_pos['title'], valid_input_neg['title']], 0)\n",
    "valid_desc_sample_a = np.concatenate([valid_input_sample['description'], valid_input_sample['description']], 0)\n",
    "valid_desc_sample_b = np.concatenate([valid_input_pos['description'], valid_input_neg['description']], 0)\n",
    "\n",
    "test_gen = ([valid_title_sample_a, valid_title_sample_b, valid_desc_sample_a, valid_desc_sample_b], valid_sim)\n",
    "\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 20), (128, 20), (128,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "#baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 19061'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "\n",
    "# def generating_embed(baseline, EMBED_DIR, EMBEDDING_DIM):\n",
    "#     embeddings_index = {}\n",
    "#     embed_path = os.path.join(EMBED_DIR, 'crawl-300d-2M.vec')\n",
    "#     f = open(embed_path, 'rb')\n",
    "#     f = io.open(embed_path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "#     n, d = map(int, f.readline().split())\n",
    "\n",
    "#     vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed_fasttext.pkl'))\n",
    "#     vocab_size = len(vocab) \n",
    "\n",
    "#     # Initialize uniform the vector considering the Tanh activation\n",
    "#     embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "#     embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "#     loop = tqdm(f)\n",
    "#     loop.set_description(\"Loading FastText\")\n",
    "#     for line in loop:\n",
    "#         tokens = line.rstrip().split(' ')\n",
    "#         embed = list(map(float, tokens[1:]))\n",
    "#         word = tokens[0]\n",
    "#         embeddings_index[word] = np.asarray(embed, dtype='float32')\n",
    "#         loop.update(1)\n",
    "#     f.close()\n",
    "#     loop.close()\n",
    "\n",
    "#     print('Total %s word vectors in FastText 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "#     loop = tqdm(total=vocab_size)\n",
    "#     loop.set_description('Loading embedding from dataset pretrained')\n",
    "#     i = 0\n",
    "#     for word, embed in vocab.items():\n",
    "#         if word in embeddings_index:\n",
    "#             embedding_matrix[i] = embeddings_index[word]\n",
    "#         else:\n",
    "#             embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "#         loop.update(1)\n",
    "#         i+=1\n",
    "#     loop.close()\n",
    "#     baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, EMBED_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(EMBED_DIR, 'glove.42B.300d.txt')\n",
    "    f = open(embed_path, 'rb')\n",
    "    #num_lines = sum(1 for line in open(embed_path, 'rb'))\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(tokens[1:], dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ef6d65816f428ea1326d69174955f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eaefe0a266c4603990004971b25bfea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19061), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 21s, sys: 2.96 s, total: 1min 24s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, EMBED_DIR=EMBED_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Propose\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomUniform, RandomNormal, Ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable, name):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer_{}'.format(name),\n",
    "                                  weights=[embeddings],\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### DWEN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum, Subtract, \\\n",
    "    Average, GlobalAveragePooling1D, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam, Nadam\n",
    "import keras.backend as K\n",
    "\n",
    "def dwen_feature(title_feature_model, desc_feature_model, \\\n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    \n",
    "    # Embedding feature\n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    \n",
    "    bug_t_feat = GlobalAveragePooling1D()(bug_t_feat)\n",
    "    bug_d_feat = GlobalAveragePooling1D()(bug_d_feat)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = Average(name = 'merge_features_{}'.format(name))([bug_t_feat, bug_d_feat])\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model\n",
    "\n",
    "def dwen_model(bug_feature_output_a, bug_feature_output_b, name):\n",
    "    \n",
    "    inputs = np.concatenate([bug_feature_output_a.input, bug_feature_output_b.input], -1).tolist()\n",
    "    \n",
    "    bug_feature_output_a = bug_feature_output_a.output\n",
    "    bug_feature_output_b = bug_feature_output_b.output\n",
    "    \n",
    "    # 2D concatenate feature\n",
    "    bug_feature_output = concatenate([bug_feature_output_a, bug_feature_output_b])\n",
    "    \n",
    "    hidden_layers = 2\n",
    "    \n",
    "    # Deep Hidden MLPs\n",
    "    for _ in range(hidden_layers):\n",
    "        number_of_units = K.int_shape(bug_feature_output)[1]\n",
    "        bug_feature_output = Dense(number_of_units // 2)(bug_feature_output)\n",
    "#         bug_feature_output = BatchNormalization()(bug_feature_output)\n",
    "        bug_feature_output = Activation('relu')(bug_feature_output)\n",
    "        #bug_feature_output = Dropout(.5)(bug_feature_output)\n",
    "    \n",
    "     # Sigmoid\n",
    "    output = Dense(1, activation='sigmoid')(bug_feature_output)\n",
    "\n",
    "    similarity_model = Model(inputs=inputs, outputs=[output], name = 'dwen_output')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title_dwen_a (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_dwen_a (InputLayer)        (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_dwen_b (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_dwen_b (InputLayer)        (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_title (Embeddin (None, 20, 300)      5718300     title_dwen_a[0][0]               \n",
      "                                                                 title_dwen_b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_desc (Embedding (None, 20, 300)      5718300     desc_dwen_a[0][0]                \n",
      "                                                                 desc_dwen_b[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 300)          0           embedding_layer_title[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 300)          0           embedding_layer_desc[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 300)          0           embedding_layer_title[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 300)          0           embedding_layer_desc[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_dwen_a (Average) (None, 300)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_dwen_b (Average) (None, 300)          0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 600)          0           merge_features_dwen_a[0][0]      \n",
      "                                                                 merge_features_dwen_b[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          180300      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 150)          45150       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 150)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            151         activation_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 11,662,201\n",
      "Trainable params: 225,601\n",
      "Non-trainable params: 11,436,600\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 0.69, acc: 0.49\n",
      "Epoch: 2 Loss: 0.69, acc: 0.52\n",
      "Epoch: 3 Loss: 0.69, acc: 0.56\n",
      "Epoch: 4 Loss: 0.69, acc: 0.51\n",
      "Epoch: 5 Loss: 0.69, acc: 0.51\n",
      "Epoch: 6 Loss: 0.69, acc: 0.59\n",
      "Epoch: 7 Loss: 0.69, acc: 0.49\n",
      "Epoch: 8 Loss: 0.69, acc: 0.59\n",
      "Epoch: 9 Loss: 0.69, acc: 0.60\n",
      "Epoch: 10 Loss: 0.69, acc: 0.55\n",
      "Epoch: 11 Loss: 0.68, acc: 0.58\n",
      "Epoch: 12 Loss: 0.68, acc: 0.62\n",
      "Epoch: 13 Loss: 0.68, acc: 0.60\n",
      "Epoch: 14 Loss: 0.67, acc: 0.59\n",
      "Epoch: 15 Loss: 0.68, acc: 0.48\n",
      "Epoch: 16 Loss: 0.68, acc: 0.63\n",
      "Epoch: 17 Loss: 0.67, acc: 0.60\n",
      "Epoch: 18 Loss: 0.67, acc: 0.54\n",
      "Epoch: 19 Loss: 0.67, acc: 0.55\n",
      "Epoch: 20 Loss: 0.67, acc: 0.60\n",
      "Epoch: 21 Loss: 0.68, acc: 0.54\n",
      "Epoch: 22 Loss: 0.67, acc: 0.57\n",
      "Epoch: 23 Loss: 0.66, acc: 0.61\n",
      "Epoch: 24 Loss: 0.68, acc: 0.59\n",
      "Epoch: 25 Loss: 0.66, acc: 0.62\n",
      "Epoch: 26 Loss: 0.64, acc: 0.66\n",
      "Epoch: 27 Loss: 0.66, acc: 0.63\n",
      "Epoch: 28 Loss: 0.68, acc: 0.53\n",
      "Epoch: 29 Loss: 0.67, acc: 0.58\n",
      "Epoch: 30 Loss: 0.67, acc: 0.64\n",
      "Epoch: 31 Loss: 0.65, acc: 0.59\n",
      "Epoch: 32 Loss: 0.68, acc: 0.52\n",
      "Epoch: 33 Loss: 0.66, acc: 0.62\n",
      "Epoch: 34 Loss: 0.64, acc: 0.62\n",
      "Epoch: 35 Loss: 0.66, acc: 0.59\n",
      "Epoch: 36 Loss: 0.67, acc: 0.63\n",
      "Epoch: 37 Loss: 0.66, acc: 0.57\n",
      "Epoch: 38 Loss: 0.67, acc: 0.62\n",
      "Epoch: 39 Loss: 0.67, acc: 0.55\n",
      "Epoch: 40 Loss: 0.65, acc: 0.59\n",
      "Epoch: 41 Loss: 0.67, acc: 0.59\n",
      "Epoch: 42 Loss: 0.65, acc: 0.59\n",
      "Epoch: 43 Loss: 0.69, acc: 0.60\n",
      "Epoch: 44 Loss: 0.65, acc: 0.59\n",
      "Epoch: 45 Loss: 0.63, acc: 0.66\n",
      "Epoch: 46 Loss: 0.67, acc: 0.59\n",
      "Epoch: 47 Loss: 0.64, acc: 0.60\n",
      "Epoch: 48 Loss: 0.66, acc: 0.61\n",
      "Epoch: 49 Loss: 0.65, acc: 0.66\n",
      "Epoch: 50 Loss: 0.65, acc: 0.55\n",
      "Epoch: 51 Loss: 0.67, acc: 0.58\n",
      "Epoch: 52 Loss: 0.67, acc: 0.59\n",
      "Epoch: 53 Loss: 0.66, acc: 0.62\n",
      "Epoch: 54 Loss: 0.67, acc: 0.55\n",
      "Epoch: 55 Loss: 0.66, acc: 0.64\n",
      "Epoch: 56 Loss: 0.63, acc: 0.66\n",
      "Epoch: 57 Loss: 0.67, acc: 0.58\n",
      "Epoch: 58 Loss: 0.62, acc: 0.66\n",
      "Epoch: 59 Loss: 0.61, acc: 0.63\n",
      "Epoch: 60 Loss: 0.62, acc: 0.64\n",
      "Epoch: 61 Loss: 0.69, acc: 0.57\n",
      "Epoch: 62 Loss: 0.67, acc: 0.60\n",
      "Epoch: 63 Loss: 0.68, acc: 0.59\n",
      "Epoch: 64 Loss: 0.62, acc: 0.66\n",
      "Epoch: 65 Loss: 0.69, acc: 0.56\n",
      "Epoch: 66 Loss: 0.66, acc: 0.61\n",
      "Epoch: 67 Loss: 0.64, acc: 0.63\n",
      "Epoch: 68 Loss: 0.66, acc: 0.59\n",
      "Epoch: 69 Loss: 0.63, acc: 0.65\n",
      "Epoch: 70 Loss: 0.61, acc: 0.68\n",
      "Epoch: 71 Loss: 0.65, acc: 0.62\n",
      "Epoch: 72 Loss: 0.58, acc: 0.72\n",
      "Epoch: 73 Loss: 0.63, acc: 0.64\n",
      "Epoch: 74 Loss: 0.67, acc: 0.56\n",
      "Epoch: 75 Loss: 0.64, acc: 0.60\n",
      "Epoch: 76 Loss: 0.62, acc: 0.68\n",
      "Epoch: 77 Loss: 0.66, acc: 0.59\n",
      "Epoch: 78 Loss: 0.63, acc: 0.65\n",
      "Epoch: 79 Loss: 0.59, acc: 0.70\n",
      "Epoch: 80 Loss: 0.68, acc: 0.59\n",
      "Epoch: 81 Loss: 0.65, acc: 0.62\n",
      "Epoch: 82 Loss: 0.63, acc: 0.67\n",
      "Epoch: 83 Loss: 0.62, acc: 0.65\n",
      "Epoch: 84 Loss: 0.60, acc: 0.62\n",
      "Epoch: 85 Loss: 0.62, acc: 0.66\n",
      "Epoch: 86 Loss: 0.66, acc: 0.59\n",
      "Epoch: 87 Loss: 0.65, acc: 0.58\n",
      "Epoch: 88 Loss: 0.65, acc: 0.62\n",
      "Epoch: 89 Loss: 0.65, acc: 0.59\n",
      "Epoch: 90 Loss: 0.65, acc: 0.62\n",
      "Epoch: 91 Loss: 0.67, acc: 0.62\n",
      "Epoch: 92 Loss: 0.60, acc: 0.65\n",
      "Epoch: 93 Loss: 0.62, acc: 0.67\n",
      "Epoch: 94 Loss: 0.68, acc: 0.56\n",
      "Epoch: 95 Loss: 0.67, acc: 0.57\n",
      "Epoch: 96 Loss: 0.67, acc: 0.58\n",
      "Epoch: 97 Loss: 0.65, acc: 0.60\n",
      "Epoch: 98 Loss: 0.63, acc: 0.62\n",
      "Epoch: 99 Loss: 0.66, acc: 0.57\n",
      "Epoch: 100 Loss: 0.65, acc: 0.59, recall@25: 0.50\n",
      "Saved model 'modelos/model_baseline_dwen_100_feature_100epochs_64batch(netbeans).h5' to disk\n",
      "Best_epoch=72, Best_loss=0.58, Recall@25=0.50\n",
      "CPU times: user 2min 47s, sys: 479 ms, total: 2min 47s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(baseline.embedding_matrix), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False, name='desc')\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(baseline.embedding_matrix), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False, name='title')\n",
    "\n",
    "# Similarity model\n",
    "bug_feature_output_a = dwen_feature(title_embedding_layer, desc_embedding_layer, \n",
    "                                    MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'dwen_a')\n",
    "bug_feature_output_b = dwen_feature(title_embedding_layer, desc_embedding_layer, \n",
    "                                    MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'dwen_b')\n",
    "similarity_model = dwen_model(bug_feature_output_a, bug_feature_output_b, 'dwen')\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = experiment.batch_iterator(None, baseline.train_data, baseline.dup_sets_train, \n",
    "                                                  bug_train_ids, batch_size, 1, issues_by_buckets)\n",
    "    \n",
    "    num_batch = train_input_sample['title'].shape[0]\n",
    "    pos = np.full((1, num_batch), 1)\n",
    "    neg = np.full((1, num_batch), 0)\n",
    "    train_sim = np.concatenate([pos, neg], -1)[0]\n",
    "    \n",
    "    title_sample_a = np.concatenate([train_input_sample['title'], train_input_sample['title']], 0)\n",
    "    title_sample_b = np.concatenate([train_input_pos['title'], train_input_neg['title']], 0)\n",
    "    desc_sample_a = np.concatenate([train_input_sample['description'], train_input_sample['description']], 0)\n",
    "    desc_sample_b = np.concatenate([train_input_pos['description'], train_input_neg['description']], 0)\n",
    "    train_batch = [title_sample_a, desc_sample_a, title_sample_b, desc_sample_b]\n",
    "    \n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, bug_feature_output_a, issues_by_buckets, \n",
    "                                                        bug_train_ids, 'dwen')\n",
    "        print(\"Epoch: {} Loss: {:.2f}, acc: {:.2f}, recall@25: {:.2f}\".format(epoch+1, h[0],  h[1], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, acc: {:.2f}\".format(epoch+1, h[0],  h[1]))\n",
    "    \n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(bug_feature_output_a, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['233472:230872|217660:0.6791145503520966,225692:0.6785111725330353,230822:0.6706644296646118,212084:0.6626127064228058,219514:0.660210907459259,215764:0.6591239273548126,214347:0.6557492613792419,220503:0.6548030376434326,225738:0.6513751447200775,234193:0.6496645212173462,220362:0.6488694846630096,219050:0.6483931541442871,218880:0.6433338522911072,217562:0.640870064496994,228408:0.6341737806797028,223240:0.6332027614116669,212493:0.632919579744339,229521:0.630603164434433,228218:0.629583865404129,237770:0.6288505494594574,212462:0.6281609237194061,231518:0.6270377039909363,214436:0.6267807185649872,227024:0.6256855726242065,226831:0.6254185140132904,221387:0.6252486109733582,236108:0.6246815025806427,229883:0.6245419979095459,224309:0.6234250068664551',\n",
       " '230872:233472|225347:0.28612685203552246,217677:0.27108973264694214,225087:0.26974064111709595,226451:0.26045846939086914,220120:0.25651317834854126,239835:0.24281680583953857,224790:0.23885101079940796,237373:0.23604047298431396,233139:0.2348705530166626,232642:0.23140829801559448,223572:0.23047024011611938,229119:0.22931629419326782,228121:0.22911810874938965,219132:0.22810113430023193,226684:0.22767037153244019,216462:0.2264971137046814,212353:0.22325915098190308,220585:0.22259294986724854,234688:0.22218382358551025,234689:0.22218382358551025,224232:0.2207731008529663,219709:0.21918171644210815,228322:0.21820658445358276,212790:0.21815723180770874,233018:0.21769177913665771,221536:0.21766191720962524,218550:0.21759581565856934,229928:0.2167392373085022,222187:0.2154848575592041',\n",
       " '221186:220416,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '226947:220416,221186,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '220553:220416,221186,226947,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '220554:220416,221186,226947,220553,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '218635:220416,221186,226947,220553,220554,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|217446:0.9410289265215397,217536:0.9410289265215397,217729:0.9410289265215397,218103:0.792343944311142,218475:0.7750345468521118,221016:0.7434657216072083,213363:0.7394883632659912,220799:0.7346875071525574,218383:0.7243930995464325,238283:0.7235192954540253,220552:0.7221529185771942,217939:0.7218574285507202,220578:0.7217870056629181,218324:0.7217669486999512,218325:0.7217669486999512,229736:0.7198438346385956,218624:0.719707727432251,218707:0.7174161076545715,229735:0.714919924736023,229737:0.714919924736023,218214:0.7148034572601318,218223:0.7148034572601318,220515:0.710194319486618,229810:0.7072036862373352,218152:0.7070740461349487,220756:0.7057361602783203,220757:0.7057361602783203,226716:0.7045245468616486,226777:0.7045245468616486',\n",
       " '220432:220416,221186,226947,220553,220554,218635,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '226961:220416,221186,226947,220553,220554,218635,220432,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|236162:0.5486516654491425,215671:0.5466743409633636,217010:0.5466743409633636,213011:0.5347540080547333,218599:0.5347540080547333,225675:0.5273496508598328,216618:0.5156099796295166,220419:0.5156099796295166,215208:0.5136927664279938,233366:0.5123314559459686,222084:0.5121789574623108,220344:0.5118390917778015,223887:0.5067241191864014,232548:0.5067241191864014,223644:0.5017894506454468,223736:0.500115841627121,215147:0.4987190365791321,224452:0.4978363513946533,213725:0.4941597580909729,224044:0.4897812604904175,216681:0.4889891743659973,225699:0.48857659101486206,213380:0.48774242401123047,215817:0.48774242401123047,220560:0.4860929250717163,232512:0.484421968460083,238662:0.4843372106552124,217158:0.48396730422973633,220177:0.48396730422973633',\n",
       " '219028:220416,221186,226947,220553,220554,218635,220432,226961,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|219170:0.9999020508184913,219143:0.758613258600235,234940:0.7585658878087997,232639:0.754366084933281,232045:0.7404658198356628,233118:0.7402018904685974,233598:0.738825261592865,221539:0.7381318211555481,221555:0.7381318211555481,231791:0.7347656190395355,221550:0.7323340177536011,236548:0.7313063144683838,228020:0.7296590805053711,219254:0.7249317169189453,219993:0.7193917036056519,232430:0.7181353271007538,219123:0.7161349058151245,219391:0.7154516279697418,223767:0.7152934670448303,219674:0.7145673632621765,226861:0.7141724824905396,223475:0.7114404141902924,236033:0.7113332748413086,222045:0.7112918496131897,220094:0.7112918496131897,219093:0.7108451426029205,224517:0.7104345858097076,226778:0.7098241746425629,227623:0.7098241746425629',\n",
       " '219412:220416,221186,226947,220553,220554,218635,220432,226961,219028,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '220692:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '220948:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '224412:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '224797:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '219550:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '219170:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|219028:0.9999020508184913,219143:0.758613258600235,234940:0.7585658878087997,232639:0.754366084933281,232045:0.7404658198356628,233118:0.7402018904685974,233598:0.738825261592865,221539:0.7381318211555481,221555:0.7381318211555481,231791:0.7347656190395355,221550:0.7323340177536011,236548:0.7313063144683838,228020:0.7296590805053711,219254:0.7249317169189453,219993:0.7193917036056519,232430:0.7181353271007538,219123:0.7161349058151245,219391:0.7154516279697418,223767:0.7152934670448303,219674:0.7145673632621765,226861:0.7141724824905396,223475:0.7114404141902924,236033:0.7113332748413086,222045:0.7112918496131897,220094:0.7112918496131897,219093:0.7108451426029205,224517:0.7104345858097076,226778:0.7098241746425629,227623:0.7098241746425629',\n",
       " '220452:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '224686:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219311:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172',\n",
       " '219311:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221186:0.9997900319140172,221291:0.9997900319140172,229492:0.9997900319140172,221404:0.9997900319140172,222052:0.9997900319140172,222141:0.9997900319140172,222306:0.9997900319140172,224049:0.9997900319140172,224070:0.9997900319140172,224218:0.9997900319140172,224376:0.9997900319140172,224412:0.9997900319140172,224686:0.9997900319140172,224797:0.9997900319140172,225378:0.9997900319140172,225660:0.9997900319140172,226374:0.9997900319140172,226405:0.9997900319140172,226947:0.9997900319140172,227122:0.9997900319140172,219312:0.9997900319140172,219412:0.9997900319140172,219550:0.9997900319140172,219599:0.9997900319140172,219630:0.9997900319140172,219866:0.9997900319140172,220238:0.9997900319140172,220353:0.9997900319140172,220358:0.9997900319140172']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('recall@25 last epoch:', 0.5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, verbose, bug_feature_output_a, issues_by_buckets, \n",
    "                                                            bug_train_ids, method='dwen')\n",
    "\n",
    "\"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 3162\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_dwen_100_feature_100epochs_64batch(netbeans)'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bug_feature_output_a\n",
    "#model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title_dwen_a (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_dwen_a (InputLayer)        (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_title (Embeddin (None, 20, 300)      5718300     title_dwen_a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_desc (Embedding (None, 20, 300)      5718300     desc_dwen_a[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 300)          0           embedding_layer_title[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 300)          0           embedding_layer_desc[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_dwen_a (Average) (None, 300)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 11,436,600\n",
      "Trainable params: 0\n",
      "Non-trainable params: 11,436,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, \n",
    "                                                                   bug_train_ids, method='dwen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/netbeans/exported_rank_baseline_dwen_100.txt'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.44,\n",
       " '2 - recall_at_10': 0.46,\n",
       " '3 - recall_at_15': 0.48,\n",
       " '4 - recall_at_20': 0.49,\n",
       " '5 - recall_at_25': 0.5}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
