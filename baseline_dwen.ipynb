{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning - DWEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 100 # 40\n",
    "MAX_SEQUENCE_LENGTH_D = 100 # 200\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'openoffice'\n",
    "METHOD = 'baseline_dwen'\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Path embeddings\n",
    "EMBED_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_feature@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_feature_@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7462b8ea33fb4e5185c1bbfc876a31c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=57667), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc92f61edac494bb63cbc4b9c3db1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14567), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4cdd8285604728a0ab87141c09b8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=72234), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3355550841e14432add32366259fa9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11.5 s, sys: 915 ms, total: 12.4 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f473b12c83413ab5be4ba1306026d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58572), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n"
     ]
    }
   ],
   "source": [
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = baseline.batch_iterator(baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train,\n",
    "                                                                                          bug_train_ids,\n",
    "                                                                                          batch_size_test, 1)\n",
    "\n",
    "valid_title_sample_a = np.concatenate([valid_input_sample['title'], valid_input_sample['title']], 0)\n",
    "valid_title_sample_b = np.concatenate([valid_input_pos['title'], valid_input_neg['title']], 0)\n",
    "valid_desc_sample_a = np.concatenate([valid_input_sample['description'], valid_input_sample['description']], 0)\n",
    "valid_desc_sample_b = np.concatenate([valid_input_pos['description'], valid_input_neg['description']], 0)\n",
    "\n",
    "test_gen = ([valid_title_sample_a, valid_title_sample_b, valid_desc_sample_a, valid_desc_sample_b], valid_sim)\n",
    "\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed_fasttext.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "\n",
    "# def generating_embed(baseline, EMBED_DIR, EMBEDDING_DIM):\n",
    "#     embeddings_index = {}\n",
    "#     embed_path = os.path.join(EMBED_DIR, 'crawl-300d-2M.vec')\n",
    "#     f = open(embed_path, 'rb')\n",
    "#     f = io.open(embed_path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "#     n, d = map(int, f.readline().split())\n",
    "\n",
    "#     vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed_fasttext.pkl'))\n",
    "#     vocab_size = len(vocab) \n",
    "\n",
    "#     # Initialize uniform the vector considering the Tanh activation\n",
    "#     embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "#     embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "#     loop = tqdm(f)\n",
    "#     loop.set_description(\"Loading FastText\")\n",
    "#     for line in loop:\n",
    "#         tokens = line.rstrip().split(' ')\n",
    "#         embed = list(map(float, tokens[1:]))\n",
    "#         word = tokens[0]\n",
    "#         embeddings_index[word] = np.asarray(embed, dtype='float32')\n",
    "#         loop.update(1)\n",
    "#     f.close()\n",
    "#     loop.close()\n",
    "\n",
    "#     print('Total %s word vectors in FastText 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "#     loop = tqdm(total=vocab_size)\n",
    "#     loop.set_description('Loading embedding from dataset pretrained')\n",
    "#     i = 0\n",
    "#     for word, embed in vocab.items():\n",
    "#         if word in embeddings_index:\n",
    "#             embedding_matrix[i] = embeddings_index[word]\n",
    "#         else:\n",
    "#             embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "#         loop.update(1)\n",
    "#         i+=1\n",
    "#     loop.close()\n",
    "#     baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, EMBED_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(EMBED_DIR, 'glove.42B.300d.txt')\n",
    "    f = open(embed_path, 'rb')\n",
    "    #num_lines = sum(1 for line in open(embed_path, 'rb'))\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(tokens[1:], dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229d963930e74dcdbec868179bd61621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 24s, sys: 3.34 s, total: 1min 27s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, EMBED_DIR=EMBED_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Propose\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomUniform, RandomNormal, Ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable, name):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer_{}'.format(name),\n",
    "                                  weights=[embeddings],\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### DWEN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum, Subtract, \\\n",
    "    Average, GlobalAveragePooling1D, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam, Nadam\n",
    "import keras.backend as K\n",
    "\n",
    "def dwen_feature(title_feature_model, desc_feature_model, \\\n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    \n",
    "    # Embedding feature\n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    \n",
    "    bug_t_feat = GlobalAveragePooling1D()(bug_t_feat)\n",
    "    bug_d_feat = GlobalAveragePooling1D()(bug_d_feat)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = Average(name = 'merge_features_{}'.format(name))([bug_t_feat, bug_d_feat])\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model\n",
    "\n",
    "def dwen_model(bug_feature_output_a, bug_feature_output_b, name):\n",
    "    \n",
    "    inputs = np.concatenate([bug_feature_output_a.input, bug_feature_output_b.input], -1).tolist()\n",
    "    \n",
    "    bug_feature_output_a = bug_feature_output_a.output\n",
    "    bug_feature_output_b = bug_feature_output_b.output\n",
    "    \n",
    "    # 2D concatenate feature\n",
    "    bug_feature_output = concatenate([bug_feature_output_a, bug_feature_output_b])\n",
    "    \n",
    "    hidden_layers = 2\n",
    "    \n",
    "    # Deep Hidden MLPs\n",
    "    for _ in range(hidden_layers):\n",
    "        number_of_units = K.int_shape(bug_feature_output)[1]\n",
    "        bug_feature_output = Dense(number_of_units // 2)(bug_feature_output)\n",
    "#         bug_feature_output = BatchNormalization()(bug_feature_output)\n",
    "        bug_feature_output = Activation('relu')(bug_feature_output)\n",
    "        #bug_feature_output = Dropout(.5)(bug_feature_output)\n",
    "    \n",
    "     # Sigmoid\n",
    "    output = Dense(1, activation='sigmoid')(bug_feature_output)\n",
    "\n",
    "    similarity_model = Model(inputs=inputs, outputs=[output], name = 'dwen_output')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title_dwen_a (InputLayer)       (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_dwen_a (InputLayer)        (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_dwen_b (InputLayer)       (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_dwen_b (InputLayer)        (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_title (Embeddin (None, 100, 300)     30401400    title_dwen_a[0][0]               \n",
      "                                                                 title_dwen_b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_desc (Embedding (None, 100, 300)     30401400    desc_dwen_a[0][0]                \n",
      "                                                                 desc_dwen_b[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 300)          0           embedding_layer_title[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 300)          0           embedding_layer_desc[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 300)          0           embedding_layer_title[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 300)          0           embedding_layer_desc[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_dwen_a (Average) (None, 300)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_dwen_b (Average) (None, 300)          0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 600)          0           merge_features_dwen_a[0][0]      \n",
      "                                                                 merge_features_dwen_b[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          180300      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 150)          45150       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 150)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            151         activation_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 61,028,401\n",
      "Trainable params: 225,601\n",
      "Non-trainable params: 60,802,800\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 0.69, acc: 0.53\n",
      "Epoch: 2 Loss: 0.69, acc: 0.50\n",
      "Epoch: 3 Loss: 0.69, acc: 0.52\n",
      "Epoch: 4 Loss: 0.69, acc: 0.50\n",
      "Epoch: 5 Loss: 0.69, acc: 0.51\n",
      "Epoch: 6 Loss: 0.69, acc: 0.51\n",
      "Epoch: 7 Loss: 0.69, acc: 0.55\n",
      "Epoch: 8 Loss: 0.69, acc: 0.49\n",
      "Epoch: 9 Loss: 0.69, acc: 0.48\n",
      "Epoch: 10 Loss: 0.69, acc: 0.48\n",
      "Epoch: 11 Loss: 0.69, acc: 0.41\n",
      "Epoch: 12 Loss: 0.69, acc: 0.48\n",
      "Epoch: 13 Loss: 0.69, acc: 0.48\n",
      "Epoch: 14 Loss: 0.69, acc: 0.50\n",
      "Epoch: 15 Loss: 0.69, acc: 0.49\n",
      "Epoch: 16 Loss: 0.69, acc: 0.50\n",
      "Epoch: 17 Loss: 0.69, acc: 0.52\n",
      "Epoch: 18 Loss: 0.69, acc: 0.52\n",
      "Epoch: 19 Loss: 0.69, acc: 0.49\n",
      "Epoch: 20 Loss: 0.69, acc: 0.58\n",
      "Epoch: 21 Loss: 0.69, acc: 0.52\n",
      "Epoch: 22 Loss: 0.69, acc: 0.58\n",
      "Epoch: 23 Loss: 0.69, acc: 0.52\n",
      "Epoch: 24 Loss: 0.69, acc: 0.50\n",
      "Epoch: 25 Loss: 0.69, acc: 0.53\n",
      "Epoch: 26 Loss: 0.69, acc: 0.50\n",
      "Epoch: 27 Loss: 0.69, acc: 0.51\n",
      "Epoch: 28 Loss: 0.69, acc: 0.52\n",
      "Epoch: 29 Loss: 0.69, acc: 0.52\n",
      "Epoch: 30 Loss: 0.69, acc: 0.55\n",
      "Epoch: 31 Loss: 0.69, acc: 0.49\n",
      "Epoch: 32 Loss: 0.69, acc: 0.58\n",
      "Epoch: 33 Loss: 0.69, acc: 0.44\n",
      "Epoch: 34 Loss: 0.69, acc: 0.41\n",
      "Epoch: 35 Loss: 0.69, acc: 0.49\n",
      "Epoch: 36 Loss: 0.69, acc: 0.41\n",
      "Epoch: 37 Loss: 0.69, acc: 0.45\n",
      "Epoch: 38 Loss: 0.69, acc: 0.48\n",
      "Epoch: 39 Loss: 0.69, acc: 0.51\n",
      "Epoch: 40 Loss: 0.69, acc: 0.46\n",
      "Epoch: 41 Loss: 0.69, acc: 0.52\n",
      "Epoch: 42 Loss: 0.69, acc: 0.51\n",
      "Epoch: 43 Loss: 0.69, acc: 0.51\n",
      "Epoch: 44 Loss: 0.69, acc: 0.55\n",
      "Epoch: 45 Loss: 0.69, acc: 0.52\n",
      "Epoch: 46 Loss: 0.69, acc: 0.52\n",
      "Epoch: 47 Loss: 0.69, acc: 0.54\n",
      "Epoch: 48 Loss: 0.69, acc: 0.49\n",
      "Epoch: 49 Loss: 0.69, acc: 0.51\n",
      "Epoch: 50 Loss: 0.69, acc: 0.48\n",
      "Epoch: 51 Loss: 0.69, acc: 0.58\n",
      "Epoch: 52 Loss: 0.69, acc: 0.48\n",
      "Epoch: 53 Loss: 0.69, acc: 0.51\n",
      "Epoch: 54 Loss: 0.69, acc: 0.51\n",
      "Epoch: 55 Loss: 0.69, acc: 0.55\n",
      "Epoch: 56 Loss: 0.69, acc: 0.51\n",
      "Epoch: 57 Loss: 0.69, acc: 0.48\n",
      "Epoch: 58 Loss: 0.69, acc: 0.51\n",
      "Epoch: 59 Loss: 0.69, acc: 0.45\n",
      "Epoch: 60 Loss: 0.69, acc: 0.52\n",
      "Epoch: 61 Loss: 0.69, acc: 0.52\n",
      "Epoch: 62 Loss: 0.69, acc: 0.46\n",
      "Epoch: 63 Loss: 0.69, acc: 0.45\n",
      "Epoch: 64 Loss: 0.69, acc: 0.51\n",
      "Epoch: 65 Loss: 0.69, acc: 0.54\n",
      "Epoch: 66 Loss: 0.69, acc: 0.51\n",
      "Epoch: 67 Loss: 0.69, acc: 0.56\n",
      "Epoch: 68 Loss: 0.69, acc: 0.50\n",
      "Epoch: 69 Loss: 0.69, acc: 0.51\n",
      "Epoch: 70 Loss: 0.69, acc: 0.55\n",
      "Epoch: 71 Loss: 0.69, acc: 0.45\n",
      "Epoch: 72 Loss: 0.69, acc: 0.52\n",
      "Epoch: 73 Loss: 0.69, acc: 0.52\n",
      "Epoch: 74 Loss: 0.69, acc: 0.50\n",
      "Epoch: 75 Loss: 0.69, acc: 0.60\n",
      "Epoch: 76 Loss: 0.69, acc: 0.54\n",
      "Epoch: 77 Loss: 0.69, acc: 0.61\n",
      "Epoch: 78 Loss: 0.69, acc: 0.55\n",
      "Epoch: 79 Loss: 0.69, acc: 0.52\n",
      "Epoch: 80 Loss: 0.69, acc: 0.51\n",
      "Epoch: 81 Loss: 0.69, acc: 0.48\n",
      "Epoch: 82 Loss: 0.69, acc: 0.48\n",
      "Epoch: 83 Loss: 0.69, acc: 0.50\n",
      "Epoch: 84 Loss: 0.69, acc: 0.57\n",
      "Epoch: 85 Loss: 0.69, acc: 0.55\n",
      "Epoch: 86 Loss: 0.69, acc: 0.61\n",
      "Epoch: 87 Loss: 0.69, acc: 0.53\n",
      "Epoch: 88 Loss: 0.69, acc: 0.54\n",
      "Epoch: 89 Loss: 0.69, acc: 0.55\n",
      "Epoch: 90 Loss: 0.69, acc: 0.50\n",
      "Epoch: 91 Loss: 0.69, acc: 0.54\n",
      "Epoch: 92 Loss: 0.69, acc: 0.59\n",
      "Epoch: 93 Loss: 0.69, acc: 0.61\n",
      "Epoch: 94 Loss: 0.69, acc: 0.48\n",
      "Epoch: 95 Loss: 0.69, acc: 0.56\n",
      "Epoch: 96 Loss: 0.69, acc: 0.57\n",
      "Epoch: 97 Loss: 0.69, acc: 0.47\n",
      "Epoch: 98 Loss: 0.69, acc: 0.55\n",
      "Epoch: 99 Loss: 0.69, acc: 0.52\n",
      "Epoch: 100 Loss: 0.69, acc: 0.48, recall@25: 0.33\n",
      "Saved model 'modelos/model_baseline_dwen_feature_100epochs_64batch(openoffice).h5' to disk\n",
      "Best_epoch=93, Best_loss=0.69, Recall@25=0.33\n",
      "CPU times: user 59.4 s, sys: 919 ms, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(baseline.embedding_matrix), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False, name='desc')\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(baseline.embedding_matrix), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False, name='title')\n",
    "\n",
    "# Similarity model\n",
    "bug_feature_output_a = dwen_feature(title_embedding_layer, desc_embedding_layer, \n",
    "                                    MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'dwen_a')\n",
    "bug_feature_output_b = dwen_feature(title_embedding_layer, desc_embedding_layer, \n",
    "                                    MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'dwen_b')\n",
    "similarity_model = dwen_model(bug_feature_output_a, bug_feature_output_b, 'dwen')\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = float('inf')\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 0\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = baseline.batch_iterator(baseline.train_data, baseline.dup_sets_train, bug_train_ids, batch_size, 1)\n",
    "    \n",
    "    num_batch = train_input_sample['title'].shape[0]\n",
    "    pos = np.full((1, num_batch), 1)\n",
    "    neg = np.full((1, num_batch), 0)\n",
    "    train_sim = np.concatenate([pos, neg], -1)[0]\n",
    "    \n",
    "    title_sample_a = np.concatenate([train_input_sample['title'], train_input_sample['title']], 0)\n",
    "    title_sample_b = np.concatenate([train_input_pos['title'], train_input_neg['title']], 0)\n",
    "    desc_sample_a = np.concatenate([train_input_sample['description'], train_input_sample['description']], 0)\n",
    "    desc_sample_b = np.concatenate([train_input_pos['description'], train_input_neg['description']], 0)\n",
    "    train_batch = [title_sample_a, desc_sample_a, title_sample_b, desc_sample_b]\n",
    "    \n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, bug_feature_output_a, issues_by_buckets, \n",
    "                                                        bug_train_ids, 'dwen')\n",
    "        print(\"Epoch: {} Loss: {:.2f}, acc: {:.2f}, recall@25: {:.2f}\".format(epoch+1, h[0],  h[1], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, acc: {:.2f}\".format(epoch+1, h[0],  h[1]))\n",
    "    \n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(bug_feature_output_a, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['108544:111059,109674,108379,109366|118195:0.6321955025196075,108665:0.5872728824615479,103769:0.5804994404315948,104696:0.575334757566452,94517:0.5605842471122742,93288:0.5542609393596649,95007:0.5532093346118927,112672:0.5529458522796631,98451:0.5524548292160034,102023:0.5506249964237213,101863:0.5506115853786469,122048:0.5457785129547119,92277:0.5448226034641266,117681:0.5446268618106842,116770:0.5429587364196777,90878:0.5391987860202789,112337:0.5386967658996582,99812:0.5381569862365723,118879:0.5377841889858246,106695:0.535616010427475,107833:0.5353596806526184,92427:0.5341787934303284,115491:0.5331699848175049,91805:0.5299861431121826,101787:0.5294079780578613,106779:0.5291711986064911,49142:0.5279203355312347,114671:0.5268775224685669,108200:0.5264783501625061',\n",
       " '109674:108544,111059,108379,109366|97216:0.6458178162574768,97135:0.6429239511489868,100123:0.6428479850292206,117607:0.639246016740799,121662:0.630834698677063,113493:0.6304080784320831,123409:0.6301462352275848,119738:0.629024863243103,103396:0.624337911605835,105065:0.6227704286575317,95999:0.6225723028182983,95365:0.6218959987163544,90804:0.621579110622406,110023:0.6208203136920929,107249:0.6184751093387604,114245:0.617992490530014,97862:0.6179654896259308,90653:0.6176390051841736,111648:0.6137093007564545,104782:0.609808623790741,102347:0.6096920073032379,105377:0.6065950989723206,108745:0.6065835058689117,122047:0.606005847454071,109853:0.6056783497333527,79559:0.6047087013721466,77903:0.6046677827835083,101074:0.6039422452449799,101922:0.603782594203949',\n",
       " '111059:108544,109674,108379,109366|104068:0.5235863327980042,94242:0.5177185535430908,95451:0.5113023817539215,106917:0.5096742510795593,110123:0.5088760852813721,109739:0.5017624497413635,91195:0.5000088810920715,98692:0.49573707580566406,98033:0.49407005310058594,102759:0.4911476969718933,101398:0.49069732427597046,95341:0.4850236773490906,96463:0.48448872566223145,113829:0.4830777049064636,95800:0.4799174666404724,112788:0.4793417453765869,98994:0.47810429334640503,90726:0.47702568769454956,12248:0.47548550367355347,95489:0.4745985269546509,103949:0.47300201654434204,95059:0.471640944480896,98673:0.47095978260040283,102645:0.47019243240356445,101845:0.4687310457229614,102065:0.4682866930961609,102333:0.4671025276184082,100295:0.4665430188179016,97619:0.4652853012084961',\n",
       " '108379:108544,111059,109674,109366|102736:0.26675260066986084,92771:0.2117459774017334,100704:0.19392812252044678,122840:0.18809926509857178,110397:0.1767786145210266,110136:0.1669110655784607,90178:0.16496682167053223,108276:0.16113609075546265,94519:0.16109704971313477,118195:0.14893943071365356,119055:0.14541763067245483,100473:0.14299768209457397,116196:0.14271587133407593,90502:0.13892316818237305,102304:0.13849520683288574,90577:0.13393789529800415,95088:0.13020187616348267,105176:0.12884199619293213,106877:0.12804800271987915,92277:0.11987745761871338,113535:0.11937350034713745,99257:0.11864525079727173,98040:0.1175355315208435,123315:0.11667132377624512,111557:0.11568295955657959,110566:0.11321496963500977,104492:0.11088639497756958,108553:0.10795456171035767,96739:0.10693395137786865',\n",
       " '109366:108544,111059,109674,108379|117523:0.5624944865703583,108386:0.5540846288204193,106337:0.5495297014713287,103914:0.536160945892334,100033:0.5308468341827393,111583:0.5254758298397064,22453:0.5217774212360382,118032:0.5168857574462891,105482:0.5150690972805023,103502:0.5113828182220459,114719:0.5100659430027008,101504:0.5021803677082062,111347:0.49619758129119873,102735:0.4940139055252075,122567:0.4917824864387512,102759:0.4882994294166565,99106:0.48791855573654175,114600:0.48566824197769165,110601:0.48364341259002686,90726:0.4825330972671509,90704:0.4815564751625061,90949:0.4809644818305969,110270:0.47881144285202026,96372:0.4785372018814087,93913:0.4767008423805237,113876:0.4743906855583191,100024:0.4731440544128418,104148:0.4727800488471985,112393:0.47203528881073',\n",
       " '110594:107073,108355,108453,109162,111761,111800|119292:0.7781840860843658,115922:0.7185899019241333,102465:0.6939051449298859,117607:0.6931964159011841,105991:0.6902758181095123,101456:0.6817678213119507,96735:0.6761371195316315,110026:0.6757913529872894,101315:0.6740142405033112,94749:0.6726397573947906,106234:0.67149418592453,100271:0.6709482371807098,98890:0.6692328751087189,97845:0.6655206978321075,68248:0.6653257012367249,90324:0.664415180683136,98129:0.6635816693305969,94421:0.6622573435306549,105859:0.6605648398399353,100429:0.659372091293335,109431:0.657657653093338,109748:0.6571739315986633,99420:0.6564064919948578,101030:0.6539866030216217,98766:0.6539848148822784,90792:0.6537742614746094,96344:0.6521095931529999,92453:0.6518762707710266,123293:0.6504763066768646',\n",
       " '111800:107073,110594,108355,108453,109162,111761|97216:0.637020081281662,90653:0.6190299093723297,92090:0.6031991243362427,115068:0.5983805358409882,109674:0.5890726149082184,95489:0.5862826704978943,113010:0.5843117535114288,98546:0.5826083123683929,109853:0.577936053276062,109550:0.5765609741210938,94935:0.5753074884414673,102333:0.5724533796310425,119046:0.5724296569824219,94175:0.5723909139633179,118276:0.5708081424236298,100632:0.5707275867462158,95800:0.5704416334629059,95059:0.5669293701648712,106008:0.5667245984077454,105654:0.5644179284572601,121662:0.5617248117923737,99763:0.5609054565429688,93249:0.5601492524147034,102347:0.5589506924152374,115242:0.5588882863521576,94526:0.5585103332996368,122296:0.558211624622345,112862:0.5569265782833099,97135:0.5559244453907013',\n",
       " '111761:107073,110594,108355,108453,109162,111800|112187:0.6781628429889679,123409:0.6780681610107422,112179:0.6751216053962708,110915:0.6630113124847412,95319:0.6604478061199188,79559:0.6594220101833344,100123:0.6592435538768768,121149:0.6553933024406433,94245:0.652797669172287,116211:0.6518242657184601,116212:0.6515474915504456,121662:0.6509852409362793,97773:0.6506406664848328,96395:0.6483446061611176,98964:0.6440442204475403,95040:0.6435468792915344,98020:0.642815351486206,98023:0.642815351486206,101787:0.6405260860919952,102081:0.6399328112602234,100634:0.6380446553230286,106798:0.632401704788208,100449:0.6266246438026428,110720:0.6264879405498505,116770:0.6203605830669403,93318:0.6199343502521515,122047:0.6199153959751129,95999:0.619277834892273,101852:0.618457555770874',\n",
       " '109162:107073,110594,108355,108453,111761,111800|95999:0.6375506520271301,90804:0.6373304426670074,122047:0.6369021236896515,94526:0.6359208524227142,106252:0.6351758241653442,94033:0.6296641826629639,109550:0.6293570399284363,102081:0.6276487708091736,113138:0.6237952709197998,106568:0.6208474338054657,112862:0.6204288899898529,105880:0.6184271275997162,93249:0.6182982623577118,117798:0.6182776093482971,115543:0.6179915964603424,102347:0.6148580610752106,111514:0.6120577752590179,96167:0.611037403345108,107980:0.6105649173259735,113724:0.6104160249233246,95494:0.6101461052894592,79559:0.608542263507843,95878:0.6076801717281342,101852:0.6074963808059692,112393:0.6068856418132782,108138:0.6065899431705475,109153:0.6061615645885468,81467:0.6054853796958923,100632:0.6053704917430878',\n",
       " '108355:107073,110594,108453,109162,111761,111800|123343:0.44132566452026367,106936:0.4297518730163574,107598:0.3782999515533447,105590:0.37088364362716675,122070:0.36358726024627686,104820:0.3580102324485779,123315:0.35281771421432495,102000:0.34552478790283203,106051:0.34401851892471313,102649:0.3390309810638428,94775:0.3348979949951172,90871:0.33474212884902954,98428:0.3153318166732788,103199:0.31520241498947144,91477:0.31454169750213623,94519:0.31226855516433716,120250:0.306918740272522,104817:0.30510735511779785,94675:0.3045222759246826,103992:0.2993975877761841,113252:0.29839563369750977,89691:0.29540807008743286,89692:0.29540807008743286,102638:0.2893562912940979,105208:0.28875499963760376,100429:0.28558349609375,101131:0.281638503074646,105364:0.28116655349731445,102378:0.2811269164085388',\n",
       " '108453:107073,110594,108355,109162,111761,111800|94884:0.6599059104919434,102435:0.6596534252166748,102915:0.6585681438446045,115922:0.6577440798282623,113082:0.6456731259822845,97350:0.6397075951099396,91479:0.6390076577663422,94415:0.6363236606121063,102495:0.6328029334545135,95341:0.6263481378555298,113915:0.626305341720581,104173:0.6252250075340271,106085:0.6243722438812256,109647:0.6242900192737579,95333:0.6232354938983917,105768:0.621743768453598,96413:0.6181966662406921,93732:0.614582896232605,105461:0.6143762469291687,102802:0.614309549331665,103567:0.6124131977558136,95540:0.6118677854537964,83117:0.6100633144378662,107749:0.6098622381687164,95206:0.6079779863357544,91589:0.6069836318492889,102921:0.6052381694316864,103297:0.6043275594711304,95269:0.603983461856842',\n",
       " '114705:114676|109513:0.6539129912853241,111104:0.6521368324756622,114671:0.6470833718776703,118884:0.6400395333766937,112672:0.6398348212242126,120046:0.6357570886611938,102081:0.6347571611404419,95926:0.6340411007404327,109987:0.6335479319095612,122698:0.6314412951469421,117681:0.6264954507350922,107061:0.6219203472137451,97289:0.6212135851383209,118879:0.6210455000400543,102852:0.6184276044368744,121625:0.6182993948459625,96317:0.6168813705444336,119993:0.6152152419090271,106168:0.6143325567245483,97342:0.6139512956142426,87549:0.6136358082294464,109850:0.6098966598510742,95028:0.6081063747406006,92277:0.6066261827945709,104494:0.6063783764839172,106695:0.6052211225032806,106779:0.6045375764369965,107142:0.6038990318775177,114518:0.603805661201477',\n",
       " '114676:114705|113492:0.6238773465156555,110879:0.5872993171215057,99186:0.583303689956665,105969:0.5381408035755157,92333:0.5265078544616699,96817:0.5186003148555756,101448:0.5158662796020508,91495:0.5152454674243927,99138:0.5108283460140228,117724:0.5105803608894348,112930:0.49739402532577515,112931:0.49739402532577515,96787:0.49693793058395386,102978:0.4959242343902588,102712:0.4942457675933838,104589:0.4924461841583252,93989:0.48156362771987915,98583:0.4782501459121704,110812:0.4775661826133728,102506:0.4774940013885498,117714:0.4768468737602234,113511:0.47317636013031006,93769:0.47089964151382446,94857:0.47077828645706177,95242:0.47046005725860596,93439:0.46815478801727295,111908:0.466325581073761,100962:0.4627687335014343,105175:0.461412250995636',\n",
       " '110593:110618|101570:0.6037043333053589,94622:0.5975789725780487,103951:0.5891300737857819,109513:0.5783343613147736,121594:0.5775881111621857,109630:0.5737544596195221,121551:0.5663717091083527,107764:0.5621973276138306,122345:0.5578910708427429,90273:0.55238476395607,105991:0.5521176755428314,123293:0.5509980916976929,87894:0.5468430817127228,110482:0.542926013469696,122078:0.5420390963554382,105970:0.5411697924137115,102409:0.5404939651489258,81355:0.5366942584514618,109850:0.5361925065517426,102454:0.5359019935131073,120979:0.5340614318847656,98664:0.530771940946579,115895:0.5288916528224945,106168:0.5286104381084442,97736:0.5271421670913696,111502:0.5265444219112396,116007:0.5260020792484283,104698:0.5252035558223724,108081:0.5251873731613159',\n",
       " '110618:110593|110207:0.6179734766483307,116193:0.6163085699081421,92639:0.6033696234226227,117531:0.6004305779933929,105026:0.5946834087371826,117096:0.5925359725952148,123438:0.5842069685459137,116027:0.5819773375988007,100023:0.5741461515426636,107846:0.569598913192749,102803:0.5694983005523682,106903:0.5677286088466644,90892:0.56092169880867,122920:0.548184335231781,105535:0.5436064004898071,109879:0.5420522093772888,96929:0.5346233546733856,110928:0.5143200755119324,112579:0.5105688571929932,90967:0.5097576081752777,102582:0.508647084236145,111065:0.5083883106708527,115520:0.5082668364048004,105961:0.5063314139842987,103861:0.5019086003303528,93689:0.4999169111251831,120130:0.4990466833114624,112788:0.49734431505203247,120613:0.49390387535095215',\n",
       " '102409:102053|109850:0.6785994470119476,106168:0.6722098588943481,91704:0.669496476650238,120046:0.6568741202354431,119409:0.6559203565120697,109630:0.6489031910896301,105991:0.648114025592804,94421:0.645503431558609,109513:0.6416678130626678,112630:0.6407008767127991,109987:0.6378497779369354,91972:0.6355707943439484,102852:0.6352241933345795,120979:0.6345820724964142,112299:0.6341307759284973,101030:0.6303896009922028,120455:0.6300371289253235,105527:0.6293300688266754,103217:0.6288363635540009,118977:0.6271945834159851,114669:0.6271267533302307,107061:0.6270990371704102,109249:0.6261749863624573,109640:0.6251946985721588,83448:0.6246319115161896,98549:0.6226272284984589,120035:0.6224024295806885,117454:0.6197618842124939,111223:0.6194033324718475',\n",
       " '102053:102409|101593:0.6503674685955048,105991:0.6382846832275391,92278:0.6376455724239349,105859:0.6341848373413086,119409:0.6281328201293945,105640:0.6199188232421875,92251:0.6184683442115784,92453:0.6110049188137054,109640:0.6108646392822266,83448:0.6072938740253448,87549:0.6070548295974731,102996:0.6067174971103668,109748:0.6027587056159973,106168:0.6010984182357788,90273:0.597820907831192,93564:0.5944581627845764,113031:0.5930273234844208,101030:0.5921128690242767,100271:0.5903735458850861,96471:0.5878136456012726,68248:0.586534708738327,94349:0.5862204730510712,106779:0.5855936408042908,107061:0.5838348865509033,111223:0.5816024541854858,103757:0.5811041593551636,109249:0.5796917974948883,110972:0.5788357555866241,106710:0.5784932076931',\n",
       " '110604:110612|97804:0.5587051808834076,98234:0.5403761267662048,113511:0.5155593752861023,99962:0.5135661363601685,100204:0.5111926198005676,122928:0.5078020989894867,94948:0.5071642100811005,96277:0.5066637694835663,102506:0.5053071975708008,100678:0.5006664991378784,110812:0.4981251358985901,100840:0.4969336986541748,119108:0.4962349534034729,102489:0.49418163299560547,94420:0.49237966537475586,85559:0.48676079511642456,101451:0.47494620084762573,113492:0.47258079051971436,119185:0.4721028804779053,115369:0.46618568897247314,120554:0.46468061208724976,102785:0.45964401960372925,95309:0.45911645889282227,115908:0.45327943563461304,108431:0.44986510276794434,106143:0.44689130783081055,112606:0.44063615798950195,105175:0.43950605392456055,102436:0.4383665919303894',\n",
       " '110612:110604|101628:0.593178391456604,108675:0.561722993850708,100678:0.5235357880592346,100671:0.522582471370697,108431:0.49869102239608765,115369:0.4917740225791931,104697:0.48558586835861206,100843:0.48517388105392456,91809:0.45546555519104004,113851:0.4461725950241089,110879:0.4373180866241455,107819:0.43610137701034546,107820:0.43610137701034546,97167:0.42001891136169434,121632:0.4125223159790039,93607:0.411506712436676,110604:0.4114232659339905,113511:0.41073548793792725,54535:0.4063241481781006,95960:0.4061397314071655,105176:0.40225523710250854,102085:0.3953314423561096,109662:0.3941168189048767,100674:0.39146101474761963,94634:0.3909232020378113,101458:0.3907897472381592,119185:0.38942116498947144,92024:0.389004647731781,70821:0.388461709022522',\n",
       " '116738:116938,117027|117027:0.5650615692138672,91487:0.5487407445907593,114600:0.4962924122810364,108386:0.49511080980300903,93913:0.4943949580192566,106741:0.4849768877029419,105482:0.48340147733688354,92564:0.4751059412956238,117523:0.4710467457771301,95421:0.46597427129745483,110844:0.4641299843788147,115912:0.4622112512588501,102883:0.4609672427177429,104080:0.4477023482322693,112854:0.43806231021881104,107044:0.43762850761413574,122894:0.43189847469329834,97318:0.4310314655303955,106337:0.42708486318588257,122649:0.42639583349227905,122650:0.42639583349227905,110601:0.42368704080581665,103914:0.4180753827095032,91195:0.41680586338043213,101380:0.4063701033592224,109366:0.39681291580200195,107173:0.3943753242492676,105687:0.39364445209503174,112477:0.3931768536567688']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('recall@25 last epoch:', 0.33)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, verbose, bug_feature_output_a, issues_by_buckets, \n",
    "                                                            bug_train_ids, method='dwen')\n",
    "\n",
    "\"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 2086\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_dwen_feature_100epochs_64batch(openoffice)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title_dwen_a (InputLayer)       (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_dwen_a (InputLayer)        (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_title (Embeddin (None, 100, 300)     30401400    title_dwen_a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_desc (Embedding (None, 100, 300)     30401400    desc_dwen_a[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 300)          0           embedding_layer_title[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 300)          0           embedding_layer_desc[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_dwen_a (Average) (None, 300)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 60,802,800\n",
      "Trainable params: 0\n",
      "Non-trainable params: 60,802,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, \n",
    "                                                                   bug_train_ids, method='dwen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/openoffice/exported_rank_baseline_dwen.txt'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.19,\n",
       " '2 - recall_at_10': 0.25,\n",
       " '3 - recall_at_15': 0.28,\n",
       " '4 - recall_at_20': 0.31,\n",
       " '5 - recall_at_25': 0.33}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
