{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning - DWEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 40\n",
    "MAX_SEQUENCE_LENGTH_D = 150 # 200\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'netbeans'\n",
    "METHOD = 'baseline_dwen'\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Path embeddings\n",
    "EMBED_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_feature@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_feature_@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb5280d34aa49d3907a05a954d481eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=180483), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ad79e70e99427e81a124e7c32a6df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36232), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "216715"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d40962083114e07927d75ea1a733df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=216715), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e797861c004943ea9409663ee5c2587f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 33.6 s, sys: 1.67 s, total: 35.2 s\n",
      "Wall time: 35.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5b61ca6e094c6988ea95a2fe1a4717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=180483), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "experiment.prepare_dataset(issues_by_buckets)\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': '1\\n',\n",
       " 'bug_status': '2\\n',\n",
       " 'component': '104\\n',\n",
       " 'creation_ts': '2003-12-24 22:49:00 +0000',\n",
       " 'delta_ts': '2006-06-05 00:45:51 +0000',\n",
       " 'description': 'description tested env stripes on madhatter stripes build at organization i am trying exercise the the example at http developers sun com tools javatools documentation s s time html followed all the steps and did not see any records in organization my dafult server for web tier apps is organization appserver i installed the organization as root and brought it up as non root user i created an admin domain of the appserver for the non root user so that non root user can deploy the applications a comment',\n",
       " 'description_word': array([  453,  1325,  1779,  9333,    30,     1,  9333,    37,     6,\n",
       "            4,    18,   277,   415,  7375,     9,     9,   408,     6,\n",
       "          151,  2447,    40,    56,    92, 15746,  1177,   132,   132,\n",
       "          180,   163,  2461,   120,     9,   273,    17,   766,    28,\n",
       "          149,   270,  3767,    14,     4,   160,     1,   169,    29,\n",
       "           48, 12049,  1502,    15,     4,  1805,    18,   434,     9,\n",
       "            4,    85,   359,    17,  3968,    31,   222,    85,   611,\n",
       "          359,   114,    18,   233,   142,   981,  1048,    27,     9,\n",
       "         1805,    29,     9,   611,   359,   114,   192,    65,   611,\n",
       "          359,   114,    81,   596,     9,  1114,    16,   654,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0]),\n",
       " 'dup_id': '37411',\n",
       " 'issue_id': 38327,\n",
       " 'priority': '2\\n',\n",
       " 'product': '19\\n',\n",
       " 'resolution': 'DUPLICATE',\n",
       " 'title': 'http monitor does not show any records in organization',\n",
       " 'title_word': array([ 151,  436,  177,   28,  221,  270, 3767,   14,    4,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'version': '2\\n'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 32276)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.2 ms, sys: 15 µs, total: 57.2 ms\n",
      "Wall time: 56.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = baseline.batch_iterator(baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train, \n",
    "                                                                                          batch_size_test, 1)\n",
    "\n",
    "valid_title_sample_a = np.concatenate([valid_input_sample['title'], valid_input_sample['title']], 0)\n",
    "valid_title_sample_b = np.concatenate([valid_input_pos['title'], valid_input_neg['title']], 0)\n",
    "valid_desc_sample_a = np.concatenate([valid_input_sample['description'], valid_input_sample['description']], 0)\n",
    "valid_desc_sample_b = np.concatenate([valid_input_pos['description'], valid_input_neg['description']], 0)\n",
    "\n",
    "test_gen = ([valid_title_sample_a, valid_title_sample_b, valid_desc_sample_a, valid_desc_sample_b], valid_sim)\n",
    "\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 20), (128, 150), (128,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Title***: i can not browse the oracle database\n",
      "***Title***: organization organization error in\n",
      "***Description***: i can not browse the oracle database i can connect to the database the sql queries are running fine but whenever i try to see the tables in the db explorer it shows an error the error in the log file is java lang abstract method error oracle jdbc driver oracle database meta data get database major version i at org netbeans lib ddl adaptors person get database major version person java at org netbeans modules db explorer infos table list node info init children table list node info java at org netbeans modules db explorer infos database node info get children database node info java at org netbeans modules db explorer database node children run database node children java at org openide util request processor task run request processor java catch at org openide util request processor processor run request processor java please help me out\n",
      "***Description***: hello all i require a little help here i have just switched from the product to i am developing a web application using organization and connecting to an product database i in the organization netbeans i manage to connect to product i however when i click on the tables tab it gives me an error unable to refresh children connection is broken unsupported feature after this i can not view the tables but i can view any views i have created however the views are not draggable sic to objects in the web page i am using the product thin driver to connect to the database if it will help using the same driver i can connect and view the tables in product thanks in advance dayvie\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: the cache can not be reliably traversed\n",
      "***Title***: organization get all command doesn t always work reliably\n",
      "***Description***: while traversing through the cache dirs and files structure files and directories can randomly disappear as organization are released from the memory the cache should be able to be traversed without the necessity to hold all file objects\n",
      "***Description***: net beans windows with product build description get all command as well as add all command sometimes do not work reliably especially on complex data structures what happens is that command stays running although nothing happens on disk however organization stays responsive take a look at the thread dump attached made in such a state steps to reproduce prepare empty product repository archive and setup new working directory for purpose of this case copy there whole vcsgeneric module mount this product filesystem and run product add all command on vcsgeneric package if everything was uploaded all right prepare new working directory mount it and try to get all whole module you will either encounter described behaviour or not everything will be downloaded from archive\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: can not drag word line selections\n",
      "***Title***: not possible to control fonts colors for organization files\n",
      "***Description***: if you double click on a word but don t let the button go there is no word selected so you can not initiate a word selection drag to get a word you have to let go of the mouse and then you can not drag extend that because as soon as you click again the selection collapses to nil now substitute line for word it makes it really hard to select multiple lines for moving or deleting this is standard fare in most text tools including this form i m writing into\n",
      "***Description***: not possible to control fonts colors for organization files\n",
      "***similar = 0\n",
      "########################\n",
      "***Title***: pressing next button in new wizard organization fails\n",
      "***Title***: upgrade wizard panels hurt performance\n",
      "***Description***: nationality java product sp organization button in new wizard e g for a new jpanel form fails with the following exception java lang artwork at org openide artwork go to organization step artwork java at org openide artwork access artwork java at org openide artwork listener action perfor med artwork java at javax swing artwork fire action performed artwork java at javax swing artwork forward action events act ion performed artwork java at javax swing product product java at javax swing product set pressed product java at javax swing plaf basic basic button listener mouse re leased basic button listener java at java awt component process mouse organization java at java awt component process organization java at java awt organization process organization java at java awt component dispatch event organization java at java awt organization dispatch event impl organization java at java awt component dispatch organization java at java product retarget mouse organization java at java product process mouse organization java at java product dispatch organization java at java awt organization dispatch event impl organization java at java awt window dispatch event impl window java at java awt component dispatch organization java catch at java awt event queue dispatch event event queue java at organization for hierar chy event dispatch thread java at organizationat organizationat java awt dialog run dialog java at java awt dialog show dialog java at org netbeans core person presenter super show person presenter java at org netbeans core person presenter do show person presenter java at org netbeans core person presenter run person presenter java at org openide util product do product java at org openide util product read access product java at org netbeans core person presenter show person presenter java at org openide loaders artwork instantiate impl artwork java at org openide loaders artwork instantiate artwork java at org openide actions artwork java at org openide actions law access law java at org openide actions law menu with rece nt item action performed law java at javax swing artwork fire action performed artwork java at javax swing artwork forward action events act ion performed artwork java at javax swing product product java at javax swing product set pressed product java at javax swing artwork do click artwork java at javax swing plaf basic product do click product java at javax swing plaf basic product mouse input h andler mouse released product java at java awt component process mouse organization java at java awt component process organization java at java awt organization process organization java at java awt component dispatch event organization java at java awt organization dispatch event impl organization java at java awt component dispatch organization java at java product retarget mouse organization java at java product process mouse organization java at java product dispatch organization java at java awt organization dispatch event impl organization java at java awt window dispatch event impl window java at java awt component dispatch organization java at java awt event queue dispatch event event queue java at organization for hierar chy event dispatch thread java at organizationat organization event dispatch thread java at organization event dispatch thread java at organization run event dispatch thread java the same exception occurs for different organization with back and organization buttons\n",
      "***Description***: upgrade wizard panels hurt performance\n",
      "***similar = 0\n",
      "########################\n",
      "CPU times: user 55.3 ms, sys: 0 ns, total: 55.3 ms\n",
      "Wall time: 54.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "baseline.display_batch(baseline.train_data, baseline.dup_sets_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed_fasttext.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 122604'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def generating_embed(baseline, EMBED_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(EMBED_DIR, 'crawl-300d-2M.vec')\n",
    "    f = open(embed_path, 'rb')\n",
    "    f = io.open(embed_path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, f.readline().split())\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed_fasttext.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading FastText\")\n",
    "    for line in loop:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        embed = list(map(float, tokens[1:]))\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in FastText 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7915fe02e8492abed4488c0c7300e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1999995 word vectors in FastText 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98dcec20c5d413f9870cc1c061a1f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=122604), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 9s, sys: 4.46 s, total: 2min 14s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, EMBED_DIR=EMBED_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Propose\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomUniform, RandomNormal, Ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable, name):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer_{}'.format(name),\n",
    "                                  weights=[embeddings],\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### DWEN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum, Subtract, \\\n",
    "    Average, GlobalAveragePooling1D, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam, Nadam\n",
    "import keras.backend as K\n",
    "\n",
    "def dwen_feature(title_feature_model, desc_feature_model, \\\n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    \n",
    "    # Embedding feature\n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    \n",
    "    bug_t_feat = GlobalAveragePooling1D()(bug_t_feat)\n",
    "    bug_d_feat = GlobalAveragePooling1D()(bug_d_feat)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = Average(name = 'merge_features_{}'.format(name))([bug_t_feat, bug_d_feat])\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model\n",
    "\n",
    "def dwen_model(bug_feature_output_a, bug_feature_output_b, name):\n",
    "    \n",
    "    inputs = np.concatenate([bug_feature_output_a.input, bug_feature_output_b.input], -1).tolist()\n",
    "    \n",
    "    bug_feature_output_a = bug_feature_output_a.output\n",
    "    bug_feature_output_b = bug_feature_output_b.output\n",
    "    \n",
    "    # 2D concatenate feature\n",
    "    bug_feature_output = concatenate([bug_feature_output_a, bug_feature_output_b])\n",
    "    \n",
    "    hidden_layers = 2\n",
    "    \n",
    "    # Deep Hidden MLPs\n",
    "    for _ in range(hidden_layers):\n",
    "        number_of_units = K.int_shape(bug_feature_output)[1]\n",
    "        bug_feature_output = Dense(number_of_units // 2)(bug_feature_output)\n",
    "#         bug_feature_output = BatchNormalization()(bug_feature_output)\n",
    "        bug_feature_output = Activation('relu')(bug_feature_output)\n",
    "        #bug_feature_output = Dropout(.5)(bug_feature_output)\n",
    "    \n",
    "     # Sigmoid\n",
    "    output = Dense(1, activation='sigmoid')(bug_feature_output)\n",
    "\n",
    "    similarity_model = Model(inputs=inputs, outputs=[output], name = 'dwen_output')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title_dwen_a (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_dwen_a (InputLayer)        (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_dwen_b (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_dwen_b (InputLayer)        (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_title (Embeddin (None, 20, 300)      36781200    title_dwen_a[0][0]               \n",
      "                                                                 title_dwen_b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_desc (Embedding (None, 150, 300)     36781200    desc_dwen_a[0][0]                \n",
      "                                                                 desc_dwen_b[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 300)          0           embedding_layer_title[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 300)          0           embedding_layer_desc[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 300)          0           embedding_layer_title[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 300)          0           embedding_layer_desc[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_dwen_a (Average) (None, 300)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_dwen_b (Average) (None, 300)          0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 600)          0           merge_features_dwen_a[0][0]      \n",
      "                                                                 merge_features_dwen_b[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          180300      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 150)          45150       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 150)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            151         activation_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 73,788,001\n",
      "Trainable params: 225,601\n",
      "Non-trainable params: 73,562,400\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 0.72, acc: 0.50\n",
      "Epoch: 2 Loss: 0.70, acc: 0.50\n",
      "Epoch: 3 Loss: 0.70, acc: 0.51\n",
      "Epoch: 4 Loss: 0.69, acc: 0.52\n",
      "Epoch: 5 Loss: 0.68, acc: 0.57\n",
      "Epoch: 6 Loss: 0.69, acc: 0.53\n",
      "Epoch: 7 Loss: 0.69, acc: 0.51\n",
      "Epoch: 8 Loss: 0.69, acc: 0.57\n",
      "Epoch: 9 Loss: 0.69, acc: 0.54\n",
      "Epoch: 10 Loss: 0.67, acc: 0.63\n",
      "Epoch: 11 Loss: 0.68, acc: 0.53\n",
      "Epoch: 12 Loss: 0.67, acc: 0.55\n",
      "Epoch: 13 Loss: 0.67, acc: 0.63\n",
      "Epoch: 14 Loss: 0.66, acc: 0.61\n",
      "Epoch: 15 Loss: 0.66, acc: 0.57\n",
      "Epoch: 16 Loss: 0.67, acc: 0.58\n",
      "Epoch: 17 Loss: 0.68, acc: 0.54\n",
      "Epoch: 18 Loss: 0.68, acc: 0.58\n",
      "Epoch: 19 Loss: 0.65, acc: 0.62\n",
      "Epoch: 20 Loss: 0.66, acc: 0.60\n",
      "Epoch: 21 Loss: 0.66, acc: 0.62\n",
      "Epoch: 22 Loss: 0.66, acc: 0.54\n",
      "Epoch: 23 Loss: 0.64, acc: 0.63\n",
      "Epoch: 24 Loss: 0.65, acc: 0.58\n",
      "Epoch: 25 Loss: 0.69, acc: 0.56\n",
      "Epoch: 26 Loss: 0.65, acc: 0.59\n",
      "Epoch: 27 Loss: 0.64, acc: 0.62\n",
      "Epoch: 28 Loss: 0.66, acc: 0.59\n",
      "Epoch: 29 Loss: 0.64, acc: 0.59\n",
      "Epoch: 30 Loss: 0.62, acc: 0.62\n",
      "Epoch: 31 Loss: 0.64, acc: 0.66\n",
      "Epoch: 32 Loss: 0.64, acc: 0.59\n",
      "Epoch: 33 Loss: 0.65, acc: 0.57\n",
      "Epoch: 34 Loss: 0.62, acc: 0.64\n",
      "Epoch: 35 Loss: 0.68, acc: 0.56\n",
      "Epoch: 36 Loss: 0.61, acc: 0.68\n",
      "Epoch: 37 Loss: 0.65, acc: 0.57\n",
      "Epoch: 38 Loss: 0.65, acc: 0.59\n",
      "Epoch: 39 Loss: 0.64, acc: 0.63\n",
      "Epoch: 40 Loss: 0.65, acc: 0.58\n",
      "Epoch: 41 Loss: 0.66, acc: 0.59\n",
      "Epoch: 42 Loss: 0.66, acc: 0.61\n",
      "Epoch: 43 Loss: 0.62, acc: 0.63\n",
      "Epoch: 44 Loss: 0.63, acc: 0.59\n",
      "Epoch: 45 Loss: 0.64, acc: 0.59\n",
      "Epoch: 46 Loss: 0.67, acc: 0.58\n",
      "Epoch: 47 Loss: 0.66, acc: 0.59\n",
      "Epoch: 48 Loss: 0.67, acc: 0.58\n",
      "Epoch: 49 Loss: 0.65, acc: 0.58\n",
      "Epoch: 50 Loss: 0.65, acc: 0.62\n",
      "Epoch: 51 Loss: 0.63, acc: 0.64\n",
      "Epoch: 52 Loss: 0.59, acc: 0.70\n",
      "Epoch: 53 Loss: 0.64, acc: 0.55\n",
      "Epoch: 54 Loss: 0.62, acc: 0.68\n",
      "Epoch: 55 Loss: 0.62, acc: 0.63\n",
      "Epoch: 56 Loss: 0.65, acc: 0.59\n",
      "Epoch: 57 Loss: 0.64, acc: 0.66\n",
      "Epoch: 58 Loss: 0.64, acc: 0.59\n",
      "Epoch: 59 Loss: 0.63, acc: 0.67\n",
      "Epoch: 60 Loss: 0.63, acc: 0.64\n",
      "Epoch: 61 Loss: 0.68, acc: 0.63\n",
      "Epoch: 62 Loss: 0.62, acc: 0.66\n",
      "Epoch: 63 Loss: 0.65, acc: 0.64\n",
      "Epoch: 64 Loss: 0.57, acc: 0.71\n",
      "Epoch: 65 Loss: 0.65, acc: 0.58\n",
      "Epoch: 66 Loss: 0.62, acc: 0.60\n",
      "Epoch: 67 Loss: 0.66, acc: 0.55\n",
      "Epoch: 68 Loss: 0.65, acc: 0.64\n",
      "Epoch: 69 Loss: 0.63, acc: 0.67\n",
      "Epoch: 70 Loss: 0.66, acc: 0.60\n",
      "Epoch: 71 Loss: 0.63, acc: 0.66\n",
      "Epoch: 72 Loss: 0.70, acc: 0.49\n",
      "Epoch: 73 Loss: 0.64, acc: 0.62\n",
      "Epoch: 74 Loss: 0.63, acc: 0.60\n",
      "Epoch: 75 Loss: 0.62, acc: 0.59\n",
      "Epoch: 76 Loss: 0.61, acc: 0.70\n",
      "Epoch: 77 Loss: 0.62, acc: 0.64\n",
      "Epoch: 78 Loss: 0.66, acc: 0.58\n",
      "Epoch: 79 Loss: 0.64, acc: 0.63\n",
      "Epoch: 80 Loss: 0.65, acc: 0.60\n",
      "Epoch: 81 Loss: 0.64, acc: 0.63\n",
      "Epoch: 82 Loss: 0.64, acc: 0.64\n",
      "Epoch: 83 Loss: 0.67, acc: 0.57\n",
      "Epoch: 84 Loss: 0.58, acc: 0.68\n",
      "Epoch: 85 Loss: 0.61, acc: 0.68\n",
      "Epoch: 86 Loss: 0.72, acc: 0.52\n",
      "Epoch: 87 Loss: 0.63, acc: 0.61\n",
      "Epoch: 88 Loss: 0.65, acc: 0.66\n",
      "Epoch: 89 Loss: 0.70, acc: 0.52\n",
      "Epoch: 90 Loss: 0.61, acc: 0.70\n",
      "Epoch: 91 Loss: 0.59, acc: 0.62\n",
      "Epoch: 92 Loss: 0.61, acc: 0.66\n",
      "Epoch: 93 Loss: 0.58, acc: 0.68\n",
      "Epoch: 94 Loss: 0.71, acc: 0.53\n",
      "Epoch: 95 Loss: 0.62, acc: 0.61\n",
      "Epoch: 96 Loss: 0.67, acc: 0.62\n",
      "Epoch: 97 Loss: 0.66, acc: 0.57\n",
      "Epoch: 98 Loss: 0.62, acc: 0.65\n",
      "Epoch: 99 Loss: 0.65, acc: 0.63\n",
      "Epoch: 100 Loss: 0.63, acc: 0.67, recall@25: 0.09\n",
      "Saved model 'modelos/model_baseline_dwen_feature_100epochs_64batch(netbeans).h5' to disk\n",
      "Best_epoch=64, Best_loss=0.57, Recall@25=0.09\n",
      "CPU times: user 13.4 s, sys: 827 ms, total: 14.2 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(baseline.embedding_matrix), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False, name='desc')\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(baseline.embedding_matrix), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False, name='title')\n",
    "\n",
    "# Similarity model\n",
    "bug_feature_output_a = dwen_feature(title_embedding_layer, desc_embedding_layer, \n",
    "                                    MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'dwen_a')\n",
    "bug_feature_output_b = dwen_feature(title_embedding_layer, desc_embedding_layer, \n",
    "                                    MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'dwen_b')\n",
    "similarity_model = dwen_model(bug_feature_output_a, bug_feature_output_b, 'dwen')\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = float('inf')\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 0\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = baseline.batch_iterator(baseline.train_data, baseline.dup_sets_train, batch_size, 1)\n",
    "    \n",
    "    num_batch = train_input_sample['title'].shape[0]\n",
    "    pos = np.full((1, num_batch), 1)\n",
    "    neg = np.full((1, num_batch), 0)\n",
    "    train_sim = np.concatenate([pos, neg], -1)[0]\n",
    "    \n",
    "    title_sample_a = np.concatenate([train_input_sample['title'], train_input_sample['title']], 0)\n",
    "    title_sample_b = np.concatenate([train_input_pos['title'], train_input_neg['title']], 0)\n",
    "    desc_sample_a = np.concatenate([train_input_sample['description'], train_input_sample['description']], 0)\n",
    "    desc_sample_b = np.concatenate([train_input_pos['description'], train_input_neg['description']], 0)\n",
    "    train_batch = [title_sample_a, desc_sample_a, title_sample_b, desc_sample_b]\n",
    "    \n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _ = experiment.evaluate_validation_test(retrieval, verbose, bug_feature_output_a, issues_by_buckets, 'dwen')\n",
    "        print(\"Epoch: {} Loss: {:.2f}, acc: {:.2f}, recall@25: {:.2f}\".format(epoch+1, h[0],  h[1], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, acc: {:.2f}\".format(epoch+1, h[0],  h[1]))\n",
    "    \n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(bug_feature_output_a, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['198406:196608|172436:0.7830578088760376,62213:0.7765262871980667,195727:0.7691275924444199,123431:0.7655877023935318,17382:0.7655494809150696,209260:0.7642121464014053,140217:0.7640320509672165,220410:0.7619846612215042,174412:0.7592526525259018,184620:0.7578661441802979,24585:0.7546855509281158,112547:0.754297748208046,85978:0.7539859265089035,126989:0.7539338022470474,206567:0.7534202635288239,207991:0.7532514035701752,160794:0.753130629658699,232775:0.7528560906648636,46451:0.7527205497026443,110010:0.7523248493671417,107239:0.7522113770246506,123067:0.7519770413637161,42422:0.7516163140535355,200469:0.749250054359436,205622:0.7490116655826569',\n",
       " '189728:198719|194488:0.7513469457626343,185432:0.7437190413475037,98090:0.7367369532585144,210945:0.733039379119873,49840:0.7319099009037018,72802:0.730250746011734,79296:0.727332204580307,219992:0.7248916923999786,218888:0.724147617816925,63594:0.7219699025154114,193732:0.719864696264267,202588:0.7167925238609314,49705:0.7158420979976654,147651:0.7142517268657684,196734:0.7140456438064575,14035:0.7138694524765015,151921:0.7137424349784851,166703:0.7116981148719788,172605:0.7091400623321533,164896:0.7087168097496033,135968:0.7085189819335938,155969:0.7051309049129486,71391:0.7034391462802887,47617:0.7025895118713379,180164:0.7016438245773315',\n",
       " '196611:198719|183595:0.7871574014425278,200469:0.770154595375061,52890:0.753915473818779,206401:0.7464007139205933,152381:0.7457263767719269,209260:0.7348048090934753,148421:0.7313895225524902,57573:0.7289421260356903,124691:0.7229935824871063,184800:0.7222322523593903,29436:0.7191700041294098,53265:0.7190587222576141,181671:0.7172548174858093,219962:0.7168487906455994,233602:0.7166077196598053,129382:0.7162819504737854,221703:0.7158718705177307,135792:0.713588684797287,228991:0.7127931416034698,78889:0.7126012146472931,181208:0.7122718691825867,108676:0.7122194170951843,93966:0.7105095684528351,185017:0.7100701928138733,175018:0.7098236382007599',\n",
       " '226337:228991|203772:0.7566060870885849,9538:0.7544631212949753,77872:0.747938334941864,145811:0.7434360086917877,71391:0.7423531115055084,112885:0.7410039901733398,63594:0.7408174276351929,134716:0.7399584949016571,103713:0.7397133111953735,101715:0.7367058396339417,215976:0.7327264845371246,200588:0.7323138117790222,73690:0.7320400774478912,221703:0.7315884232521057,148421:0.7302420139312744,227510:0.7261261641979218,80850:0.7259775102138519,57272:0.7256763875484467,129382:0.7202964127063751,151909:0.7201903462409973,177158:0.7198767066001892,210293:0.7198529243469238,221860:0.7192000150680542,114942:0.7186466753482819,79363:0.7177251875400543',\n",
       " '230596:228991|144755:0.8689975738525391,64184:0.8594874888658524,66850:0.8532048314809799,27095:0.8528772592544556,213410:0.8520831167697906,44732:0.8507615774869919,46111:0.8492096960544586,165136:0.8491464555263519,47896:0.8481668382883072,106763:0.8462014049291611,41833:0.8452399373054504,136214:0.843743309378624,103046:0.8436701744794846,95128:0.8424663245677948,19680:0.8416843712329865,232160:0.8404053002595901,194481:0.8400106132030487,16995:0.8393218964338303,114391:0.8390894085168839,192778:0.8382248282432556,237561:0.8377753049135208,11299:0.837635800242424,201743:0.8375490307807922,90373:0.8370718508958817,144383:0.8364120125770569',\n",
       " '229380:228991|159796:0.933206282556057,211165:0.9292067363858223,43143:0.9291372075676918,194481:0.926751896739006,106361:0.9214134365320206,35851:0.9202890843153,236031:0.9200117811560631,13779:0.9157677963376045,182513:0.9143686592578888,9767:0.9143419861793518,121255:0.9135149717330933,53504:0.9128624722361565,36142:0.9126720950007439,86437:0.9109938815236092,130104:0.9099554643034935,61826:0.9097880199551582,46981:0.9088399559259415,116885:0.9079786092042923,163156:0.906902864575386,191786:0.9067539870738983,12793:0.9067191928625107,11660:0.9067097157239914,15663:0.906016081571579,46611:0.904135525226593,47896:0.9034866467118263',\n",
       " '230625:228991|159796:0.9404886700212955,194481:0.9294801726937294,236031:0.928827553987503,130104:0.9235337004065514,144383:0.9199451878666878,35851:0.9178851917386055,211165:0.9165481179952621,47896:0.9156645610928535,116885:0.9131076708436012,43143:0.9112773314118385,13779:0.9105925187468529,115340:0.9098459854722023,46981:0.9097696244716644,165136:0.9084736406803131,190226:0.9075374007225037,31019:0.9074166938662529,38321:0.9064809456467628,121255:0.9064180329442024,12793:0.9062046483159065,14565:0.9052023440599442,106361:0.9051686972379684,15663:0.9049138352274895,182513:0.904894694685936,61826:0.9040316939353943,36142:0.9039784073829651',\n",
       " '229719:228991|66850:0.8886294215917587,218370:0.8726931810379028,9767:0.8721475303173065,102804:0.8706613630056381,36378:0.865771934390068,71450:0.8641657531261444,170486:0.8624611794948578,64166:0.8605678230524063,59325:0.8581044524908066,132721:0.8568975180387497,190409:0.8564134687185287,132328:0.8555831909179688,76431:0.8551627397537231,105616:0.8544171899557114,41341:0.8543994873762131,231782:0.8536934554576874,25457:0.8516487628221512,70094:0.8515712469816208,39015:0.8514327853918076,47896:0.850613996386528,89072:0.8503016382455826,63036:0.8498770743608475,183098:0.849418580532074,157921:0.8491798341274261,194481:0.8490881472826004',\n",
       " '142004:180230|106763:0.8857513964176178,121255:0.8848983719944954,194481:0.8844394162297249,84869:0.8809355571866035,27183:0.880892314016819,211165:0.8807036951184273,11660:0.8799258172512054,35851:0.8788195252418518,47896:0.8787299394607544,38321:0.8783228024840355,106361:0.8774808719754219,46611:0.8767838329076767,130104:0.8757753744721413,13779:0.8757531866431236,12793:0.8756627142429352,43143:0.875067226588726,61826:0.8747781068086624,159796:0.8726624101400375,19680:0.8716855645179749,31019:0.8716115802526474,165136:0.8712370842695236,64166:0.8708534687757492,191786:0.8705972582101822,48427:0.8696487993001938,44732:0.8691805452108383',\n",
       " '223173:180230|166236:0.8566088825464249,136214:0.8468500822782516,178127:0.8433153480291367,137550:0.8316833525896072,134404:0.8272594809532166,68831:0.8239083737134933,83738:0.8225478678941727,63165:0.8221694082021713,59325:0.8184632062911987,193409:0.8177563399076462,144755:0.8141542226076126,132721:0.8136066049337387,140560:0.811455175280571,132328:0.8111899197101593,98622:0.8090189844369888,98646:0.803723081946373,102946:0.8036455810070038,120725:0.8034289479255676,103046:0.8028401583433151,232160:0.8011038303375244,214999:0.8007370978593826,145751:0.7993710786104202,141682:0.7989402413368225,213410:0.7986145168542862,64184:0.797759622335434',\n",
       " '196616:196549|196549:0.7810897976160049,197083:0.26001620292663574,204849:0.2220197319984436,216921:0.21602225303649902,202376:0.2151498794555664,220765:0.20480012893676758,179045:0.2009323239326477,186297:0.19156622886657715,209598:0.1767408847808838,206863:0.16983002424240112,209390:0.14900994300842285,155742:0.1434447169303894,134886:0.13227784633636475,175326:0.12634700536727905,231010:0.12318199872970581,153550:0.11390048265457153,83667:0.11371731758117676,178584:0.11266636848449707,149306:0.10746502876281738,122526:0.10495847463607788,18949:0.102652907371521,199356:0.09528499841690063,184971:0.09213560819625854,214706:0.08891558647155762,135907:0.08636844158172607',\n",
       " '196615:196549|196549:0.7994368523359299,197083:0.267084002494812,204849:0.22207629680633545,216921:0.2106724977493286,202376:0.20736819505691528,179045:0.20527374744415283,220765:0.1995500922203064,186297:0.18571949005126953,209598:0.17746102809906006,206863:0.16888773441314697,209390:0.13725203275680542,155742:0.13369017839431763,134886:0.1283818483352661,175326:0.12069147825241089,83667:0.12024784088134766,231010:0.11418479681015015,178584:0.11220049858093262,149306:0.10599899291992188,18949:0.10402721166610718,122526:0.10346418619155884,199356:0.1029665470123291,153550:0.10274404287338257,135907:0.08572304248809814,184971:0.08291906118392944,214706:0.07812821865081787',\n",
       " '129785:132247|121915:0.9047657698392868,137550:0.8452376574277878,83738:0.8404408097267151,132721:0.8403356075286865,132328:0.8393507748842239,136214:0.838587149977684,59325:0.8350686877965927,66850:0.8329802751541138,47896:0.8266467154026031,90373:0.8253434747457504,191786:0.8253380507230759,107400:0.8251676559448242,46111:0.8250951021909714,98646:0.8241234719753265,106763:0.823795959353447,144755:0.8226431310176849,140560:0.8215120136737823,120725:0.8213938027620316,46611:0.8213874995708466,44732:0.821210503578186,213410:0.8210318833589554,19680:0.820554181933403,41443:0.8201280236244202,27095:0.8200364708900452,12793:0.8200048804283142',\n",
       " '131083:132247|121915:0.9045113399624825,137550:0.8424804508686066,132721:0.8369522839784622,132328:0.8360222280025482,83738:0.835693895816803,136214:0.8350785821676254,59325:0.8305440694093704,66850:0.8295346796512604,90373:0.8233276456594467,47896:0.8227361589670181,191786:0.8215344846248627,46111:0.8215065449476242,107400:0.8205794841051102,98646:0.8201894164085388,106763:0.8199425786733627,120725:0.8198125809431076,140560:0.8194521963596344,144755:0.8192931711673737,142033:0.8180979490280151,213410:0.8178618252277374,46611:0.8178563714027405,44732:0.8174265921115875,170486:0.8170522153377533,19680:0.8166468739509583,27095:0.8166049420833588',\n",
       " '131083:132247|121915:0.9045113399624825,137550:0.8424804508686066,132721:0.8369522839784622,132328:0.8360222280025482,83738:0.835693895816803,136214:0.8350785821676254,59325:0.8305440694093704,66850:0.8295346796512604,90373:0.8233276456594467,47896:0.8227361589670181,191786:0.8215344846248627,46111:0.8215065449476242,107400:0.8205794841051102,98646:0.8201894164085388,106763:0.8199425786733627,120725:0.8198125809431076,140560:0.8194521963596344,144755:0.8192931711673737,142033:0.8180979490280151,213410:0.8178618252277374,46611:0.8178563714027405,44732:0.8174265921115875,170486:0.8170522153377533,19680:0.8166468739509583,27095:0.8166049420833588',\n",
       " '131084:132247|121915:0.9045113399624825,137550:0.8424804508686066,132721:0.8369522839784622,132328:0.8360222280025482,83738:0.835693895816803,136214:0.8350785821676254,59325:0.8305440694093704,66850:0.8295346796512604,90373:0.8233276456594467,47896:0.8227361589670181,191786:0.8215344846248627,46111:0.8215065449476242,107400:0.8205794841051102,98646:0.8201894164085388,106763:0.8199425786733627,120725:0.8198125809431076,140560:0.8194521963596344,144755:0.8192931711673737,142033:0.8180979490280151,213410:0.8178618252277374,46611:0.8178563714027405,44732:0.8174265921115875,170486:0.8170522153377533,19680:0.8166468739509583,27095:0.8166049420833588',\n",
       " '131085:131082|135742:0.7033818960189819,234685:0.6935408711433411,115566:0.6897719204425812,225442:0.6887863576412201,154123:0.6887695789337158,65815:0.6868405342102051,46614:0.686095267534256,16995:0.6859311759471893,58816:0.6852107346057892,70456:0.6850410103797913,74151:0.6840119957923889,20725:0.6836185455322266,76431:0.6832432150840759,157026:0.6819440722465515,35573:0.6814838647842407,5009:0.6814574003219604,147564:0.6814255118370056,118038:0.6810386478900909,84690:0.6809806525707245,194887:0.680922657251358,29030:0.6805363893508911,72693:0.6794284582138062,135475:0.6793416142463684,175093:0.6789776086807251,222360:0.6787635385990143',\n",
       " '65910:63195|116885:0.9187291041016579,115340:0.9164640232920647,163156:0.913079634308815,159796:0.9081736505031586,43143:0.9081536531448364,106361:0.9076477810740471,194481:0.9071017205715179,211165:0.9070827662944794,35851:0.9059001058340073,182513:0.9002636075019836,15663:0.8995542004704475,48427:0.8974490687251091,9767:0.8970426693558693,236031:0.896856278181076,13779:0.8963349908590317,89072:0.8963314667344093,9740:0.8957788720726967,191786:0.8954198658466339,11660:0.8953767344355583,121255:0.8952753692865372,46611:0.8938754573464394,31019:0.8938685432076454,47896:0.8930500000715256,24898:0.8925078436732292,46981:0.8921170234680176',\n",
       " '67772:63195|9538:0.7787354737520218,46466:0.7777387052774429,221703:0.7673886865377426,65354:0.7593707293272018,113172:0.7573170512914658,90424:0.7488379180431366,203772:0.7484589517116547,214439:0.7449073791503906,11020:0.7423945069313049,181394:0.7390868663787842,57272:0.7383957505226135,148421:0.7366020083427429,132028:0.7352932691574097,73690:0.7333299219608307,117509:0.7330566048622131,183595:0.7311013638973236,17644:0.7308894991874695,64941:0.7300513684749603,12924:0.7295077741146088,80676:0.7292976081371307,77872:0.7280511260032654,164277:0.7260392606258392,19608:0.7256641983985901,160273:0.7256192266941071,80850:0.7253378033638',\n",
       " '65550:63195|18909:0.5331573784351349,19559:0.5272116661071777,205241:0.5239096581935883,32162:0.49957650899887085,67094:0.4973682761192322,86903:0.49541646242141724,111610:0.49167317152023315,71744:0.4879513382911682,200280:0.48775219917297363,62919:0.48732060194015503,64283:0.485232412815094,15950:0.48287051916122437,213736:0.48203277587890625,169260:0.48143327236175537,99100:0.48109161853790283,99063:0.4787108302116394,137872:0.47827595472335815,75881:0.4743315577507019,173028:0.4733278155326843,119739:0.4717007875442505,226994:0.4712004065513611,139048:0.4707399010658264,208562:0.47070568799972534,141888:0.470071017742157,49897:0.4698724150657654']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('recall@25 last epoch:', 0.09)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall, exported_rank = experiment.evaluate_validation_test(retrieval, verbose, bug_feature_output_a, issues_by_buckets, 'dwen')\n",
    "\n",
    "\"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 7164\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_dwen_feature_100epochs_64batch(netbeans)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title_dwen_a (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_dwen_a (InputLayer)        (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_title (Embeddin (None, 20, 300)      36781200    title_dwen_a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_desc (Embedding (None, 150, 300)     36781200    desc_dwen_a[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 300)          0           embedding_layer_title[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 300)          0           embedding_layer_desc[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_dwen_a (Average) (None, 300)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 73,562,400\n",
      "Trainable params: 0\n",
      "Non-trainable params: 73,562,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, 'dwen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/netbeans/exported_rank_baseline_dwen.txt'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.08,\n",
       " '2 - recall_at_10': 0.08,\n",
       " '3 - recall_at_15': 0.09,\n",
       " '4 - recall_at_20': 0.09,\n",
       " '5 - recall_at_25': 0.09}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
