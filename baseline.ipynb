{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 100 # 100\n",
    "MAX_SEQUENCE_LENGTH_D = 500 # 500\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'openoffice'\n",
    "METHOD = 'baseline'\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Glove embeddings\n",
    "GLOVE_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = 'baseline_feature@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "SAVE_PATH_FEATURE = 'baseline_feature_@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5270369194499580332a75dfef122b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=57667), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc79d98162d48eab6cff7861b3c892d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14567), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ab66ac7cf1497382c2bb2eddeb594a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=72234), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6384f1ba9f048eda779949c58fb3629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 27.3 s, sys: 1.1 s, total: 28.4 s\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e5e4a524824c6996740544b264f61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58572), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[59, 27],\n",
       " [59, 92],\n",
       " [27, 92],\n",
       " [64, 43],\n",
       " [44, 45],\n",
       " [53, 54],\n",
       " [84, 63],\n",
       " [75, 699],\n",
       " [105, 121],\n",
       " [186, 199]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the corpus train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CORPUS:\n",
    "    corpus = []\n",
    "    export_file = open(os.path.join(DIR, 'corpus_train.txt'), 'w')\n",
    "    for bug_id in tqdm(baseline.bug_set):\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title = bug['title']\n",
    "        desc = bug['description']\n",
    "        export_file.write(\"{}\\n{}\\n\".format(title, desc))\n",
    "    export_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "# Generating tiple of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'opening a file from the file history that has been moved or deleted causes an error dialogue to pop up saying it doesn t exist etc upon clicking ok the dialogue comes up again this continues indefinitely meaning the application has to be terminated', 'title': 'opening a recent doc that has since been moved deleted causes unfulfilled loop', 'description_word': array([ 350,    7,   21,   30,    3,   21, 2479,   26,   85,  212, 1105,\n",
      "         49,  832,  615,   52,   48, 1370,    4, 1401,  125, 1579,   12,\n",
      "        187,   45,  879,  480, 1420,  537,  172,    3, 1370, 1050,  125,\n",
      "        234,   15, 3480, 9171, 2730,    3,  204,   85,    4,   22, 3834,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0]), 'bug_status': '2\\n', 'component': '3\\n', 'title_word': array([ 350,    7, 1595,  154,   26,   85,  346,  212, 1105,  832,  615,\n",
      "          1, 1053,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0]), 'delta_ts': '2003-09-08 16:56:16 +0000', 'version': '527\\n', 'issue_id': 2521, 'dup_id': '2268', 'priority': '2\\n', 'resolution': 'DUPLICATE', 'creation_ts': '2001-12-12 17:00:00 +0000', 'product': '1\\n', 'bug_severity': '5\\n'}\n"
     ]
    }
   ],
   "source": [
    "if 2521 in baseline.bug_set:\n",
    "    print(baseline.bug_set[2521])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 11043)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.6 ms, sys: 0 ns, total: 56.6 ms\n",
      "Wall time: 56.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = baseline.batch_iterator(baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train,\n",
    "                                                                                          bug_train_ids,\n",
    "                                                                                          batch_size_test, 1)\n",
    "test_gen = ([valid_input_sample['title'], valid_input_pos['title'], valid_input_neg['title'], \n",
    "             valid_input_sample['description'], valid_input_pos['description'], valid_input_neg['description'],\n",
    "            valid_input_sample['info'], valid_input_pos['info'], valid_input_neg['info']], valid_sim)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 100), (128, 500), (128, 729), (128,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Title***: please limit the version list at issue submission time currently number versions in version list\n",
      "***Title***: remove obsole target milestones and versions\n",
      "***Description***: there are approx number versions in e g the tools version list this is an unnavigable amount to browse through to select the affected version i propose that we drop all the number and number m where is current milestone number srcnumber today and to then drop all the release candidates e g rc i e leaving just the released versions of ooo and the last number devel milestones ideally to order them with the most recent formal releases of ooo and so the most likely version that a submitter has installed at the top i e number it would be sufficient to just restrict the visually available for selection versions for new bug submission the versions that existing bugs are logged against shouldn t change\n",
      "***Description***: the target milestnumber and the found in version fields in issuetracker list all versions that were ever known that is confusing and doesn t add any value because most entries are obsolete e g number has been obsolete for date now it makes the lists more than x longer than what would be reasonable with issuetracker being number of the number things a new contributor sees and these fields being topmost in an issue that leaves a very bad number impression our project deserves so much pride because of its professional quality doesn t deserve this\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: hyperlinks lost when opening organization document in impress\n",
      "***Title***: product import hyperlink on an object are not working\n",
      "***Description***: there are many issues dealing with hyperlinks in organization but i couldn t find one describing my problem open the attached file product in ms organization sp under product start the presentation click on the image above the word singles the mouse cursor is a hand indicating a link the attached file organization is opened and displayed open the attached file product in ooo product start the presentation click on the image above the word singles the mouse cursor is an arrow indicating no link the presentation is ended if there was a number slide in product the number slide would be displayed the hyperlinks in organization disappear when opening in product this is the opposite of law saving the files in product format doesn t solve the problem because the links have already disappeared we have number of organization presentations with hyperlinks that we need to open in product\n",
      "***Description***: open the attached organization document enter in slideshow mode press keyboard under product you can click on the blue object it will open a number organization file also attached under ooo the link is not detected\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: trouble with spreadsheet as data source\n",
      "***Title***: unable to change default setting for vertical ruler in office writer\n",
      "***Description***: i define a very simple spreadsheet to be used as a data source say customer sxc as customer id customer name organization organization number product organization date person i create a data source using this sheet if i modify the spreadsheet in artwork save and refresh the data source modifications are not reflected in the data source now i close the document in artwork if i ask for a refresh no joy if i try to open again the spreadsheet in artwork i get an error pop up error loading document file read error error in file structure while importing i have to close organization all windows to be able step number to see the changes in the spreadsheet reflected in the data source number to be able to open again the spreadsheet in artwork\n",
      "***Description***: unable to change default setting for vertical ruler in office writer\n",
      "***similar = 0\n",
      "########################\n",
      "***Title***: on import of a large product sheet the calculations stops in the middle of the sheet\n",
      "***Title***: unable to find and replace non printing characters\n",
      "***Description***: at import of a product file the calculated values stop being calculated on saving of the imported file to a native product file format the calculated values are ok i can send you a file which demonstrates the problem i ve also downloaded the product ver and had the same problem regards carrera\n",
      "***Description***: unable to find and replace non printing characters\n",
      "***similar = 0\n",
      "########################\n",
      "CPU times: user 54.9 ms, sys: 0 ns, total: 54.9 ms\n",
      "Wall time: 54.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test ', 2086)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Test \", len(baseline.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 101338'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, GLOVE_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(GLOVE_DIR, 'glove.42B.300d.txt')\n",
    "    f = open(embed_path, 'rb')\n",
    "    #num_lines = sum(1 for line in open(embed_path, 'rb'))\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(tokens[1:], dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400179aa803e4c809b14570a1e29d6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac5e036709a4fcfb50783c7f022535c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101338), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 23s, sys: 3.64 s, total: 2min 27s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, GLOVE_DIR=GLOVE_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer',\n",
    "                                  weights=[embeddings],\n",
    "                                  embeddings_constraint=MaxNorm(max_value=1, axis=0),\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI074wU4Y13y"
   },
   "source": [
    "### CNN with filter 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "h6YJU9GtFTyq",
    "outputId": "f85cf105-1fd6-491d-d969-7e6936f32739",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "\n",
    "def cnn_model(embedding_layer, max_sequence_length):\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length,), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None,), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "    # best combination filter (3, 4, 5) e 128 e 256\n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    n_filters = 64\n",
    "\n",
    "    for index, filter_size in enumerate(filter_sizes):\n",
    "        l_conv = Conv1D(filters=n_filters, kernel_size=filter_size)(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(pool_size=filter_size)(l_conv) # index+1\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "    # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "    #conv = Conv1D(filters=n_filters * 3, kernel_size=3)(l_merge)\n",
    "    layer = GlobalAveragePooling1D()(l_merge)\n",
    "    #layer = Flatten()(l_merge)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "    #layer = LeakyReLU()(layer)\n",
    "\n",
    "    cnn_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureCNNGenerationModel') # inputs=visible\n",
    "\n",
    "    return cnn_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr6ObTXiaALH"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "vC7MQXEsaCeG",
    "outputId": "65e647a9-c5d3-4009-b8a4-2e2d97b52684"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, GRU, Dropout, Bidirectional, GlobalAveragePooling1D, TimeDistributed\n",
    "\n",
    "def lstm_model(embedding_layer, max_sequence_length):\n",
    "    number_lstm_units = 75\n",
    "    rate_drop_lstm = 0\n",
    "    recurrent_dropout = 0\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None, ), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    left_layer = LSTM(number_lstm_units, return_sequences=True)(embedded_sequences)\n",
    "    right_layer = LSTM(number_lstm_units, return_sequences=True, go_backwards=True)(left_layer)\n",
    "    \n",
    "    lstm_layer = Concatenate()([left_layer, right_layer])\n",
    "    \n",
    "    #lstm_layer = TimeDistributed(Dense(50))(lstm_layer)\n",
    "    #layer = Flatten()(lstm_layer)\n",
    "    layer = GlobalAveragePooling1D()(lstm_layer)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "\n",
    "    lstm_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureLstmGenerationModel') # inputs=visible\n",
    "\n",
    "    return lstm_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    for units in [64, 32]:\n",
    "        layer = Dense(units, activation='tanh', kernel_initializer='random_uniform')(info_input)\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.sum(K.maximum(0.0, margin - pos + neg))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "  \n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    #     bug_feature_output = Activation('tanh')(bug_feature_output)\n",
    "    \n",
    "    # Bug representation layer\n",
    "    # bug_feature_output = Dense(300, activation='tanh')(bug_feature_output)\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    \n",
    "    # Cosine\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3 * decay_lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer=optimizer, loss=custom_margin_loss, metrics=[pos_distance, neg_distance, custom_margin_loss])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_pos (InputLayer)          (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_pos (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_neg (InputLayer)          (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_neg (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          219000      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          30604800    title_in[0][0]                   \n",
      "                                                                 title_pos[0][0]                  \n",
      "                                                                 title_neg[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          30651492    desc_in[0][0]                    \n",
      "                                                                 desc_pos[0][0]                   \n",
      "                                                                 desc_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 900)          0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureLstmGenerationModel[2][0] \n",
      "                                                                 FeatureCNNGenerationModel[2][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 900)          0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureLstmGenerationModel[3][0] \n",
      "                                                                 FeatureCNNGenerationModel[3][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances (Lambda)        (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 61,475,292\n",
      "Trainable params: 672,492\n",
      "Non-trainable params: 60,802,800\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 0.90, MarginLoss: 0.90, pos_cosine: 0.85, neg_cosine: 0.74\n",
      "Epoch: 2 Loss: 0.91, MarginLoss: 0.91, pos_cosine: 0.83, neg_cosine: 0.73\n",
      "Epoch: 3 Loss: 0.91, MarginLoss: 0.91, pos_cosine: 0.81, neg_cosine: 0.72\n",
      "Epoch: 4 Loss: 0.91, MarginLoss: 0.91, pos_cosine: 0.81, neg_cosine: 0.72\n",
      "Epoch: 5 Loss: 0.93, MarginLoss: 0.93, pos_cosine: 0.79, neg_cosine: 0.72\n",
      "Epoch: 6 Loss: 0.87, MarginLoss: 0.87, pos_cosine: 0.83, neg_cosine: 0.71\n",
      "Epoch: 7 Loss: 0.87, MarginLoss: 0.87, pos_cosine: 0.82, neg_cosine: 0.69\n",
      "Epoch: 8 Loss: 0.86, MarginLoss: 0.86, pos_cosine: 0.81, neg_cosine: 0.68\n",
      "Epoch: 9 Loss: 0.88, MarginLoss: 0.88, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 10 Loss: 0.85, MarginLoss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 11 Loss: 0.88, MarginLoss: 0.88, pos_cosine: 0.76, neg_cosine: 0.64\n",
      "Epoch: 12 Loss: 0.86, MarginLoss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 13 Loss: 0.87, MarginLoss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 14 Loss: 0.85, MarginLoss: 0.85, pos_cosine: 0.75, neg_cosine: 0.60\n",
      "Epoch: 15 Loss: 0.85, MarginLoss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 16 Loss: 0.84, MarginLoss: 0.84, pos_cosine: 0.73, neg_cosine: 0.57\n",
      "Epoch: 17 Loss: 0.80, MarginLoss: 0.80, pos_cosine: 0.77, neg_cosine: 0.57\n",
      "Epoch: 18 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.79, neg_cosine: 0.54\n",
      "Epoch: 19 Loss: 0.81, MarginLoss: 0.81, pos_cosine: 0.73, neg_cosine: 0.54\n",
      "Epoch: 20 Loss: 0.84, MarginLoss: 0.84, pos_cosine: 0.73, neg_cosine: 0.57\n",
      "Epoch: 21 Loss: 0.79, MarginLoss: 0.79, pos_cosine: 0.74, neg_cosine: 0.53\n",
      "Epoch: 22 Loss: 0.82, MarginLoss: 0.82, pos_cosine: 0.70, neg_cosine: 0.52\n",
      "Epoch: 23 Loss: 0.77, MarginLoss: 0.77, pos_cosine: 0.75, neg_cosine: 0.52\n",
      "Epoch: 24 Loss: 0.80, MarginLoss: 0.80, pos_cosine: 0.74, neg_cosine: 0.54\n",
      "Epoch: 25 Loss: 0.84, MarginLoss: 0.84, pos_cosine: 0.70, neg_cosine: 0.54\n",
      "Epoch: 26 Loss: 0.81, MarginLoss: 0.81, pos_cosine: 0.74, neg_cosine: 0.55\n",
      "Epoch: 27 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.74, neg_cosine: 0.49\n",
      "Epoch: 28 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.75, neg_cosine: 0.52\n",
      "Epoch: 29 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.72, neg_cosine: 0.46\n",
      "Epoch: 30 Loss: 0.77, MarginLoss: 0.77, pos_cosine: 0.75, neg_cosine: 0.52\n",
      "Epoch: 31 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.75, neg_cosine: 0.50\n",
      "Epoch: 32 Loss: 0.78, MarginLoss: 0.78, pos_cosine: 0.73, neg_cosine: 0.50\n",
      "Epoch: 33 Loss: 0.78, MarginLoss: 0.78, pos_cosine: 0.73, neg_cosine: 0.51\n",
      "Epoch: 34 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.77, neg_cosine: 0.53\n",
      "Epoch: 35 Loss: 0.73, MarginLoss: 0.73, pos_cosine: 0.75, neg_cosine: 0.48\n",
      "Epoch: 36 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.76, neg_cosine: 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.78, neg_cosine: 0.49\n",
      "Epoch: 38 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.78, neg_cosine: 0.50\n",
      "Epoch: 39 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.76, neg_cosine: 0.48\n",
      "Epoch: 40 Loss: 0.74, MarginLoss: 0.74, pos_cosine: 0.75, neg_cosine: 0.49\n",
      "Epoch: 41 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.74, neg_cosine: 0.49\n",
      "Epoch: 42 Loss: 0.73, MarginLoss: 0.73, pos_cosine: 0.77, neg_cosine: 0.50\n",
      "Epoch: 43 Loss: 0.78, MarginLoss: 0.78, pos_cosine: 0.75, neg_cosine: 0.54\n",
      "Epoch: 44 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.80, neg_cosine: 0.50\n",
      "Epoch: 45 Loss: 0.73, MarginLoss: 0.73, pos_cosine: 0.78, neg_cosine: 0.51\n",
      "Epoch: 46 Loss: 0.74, MarginLoss: 0.74, pos_cosine: 0.76, neg_cosine: 0.51\n",
      "Epoch: 47 Loss: 0.74, MarginLoss: 0.74, pos_cosine: 0.77, neg_cosine: 0.51\n",
      "Epoch: 48 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.79, neg_cosine: 0.50\n",
      "Epoch: 49 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.78, neg_cosine: 0.47\n",
      "Epoch: 50 Loss: 0.74, MarginLoss: 0.74, pos_cosine: 0.77, neg_cosine: 0.51\n",
      "Epoch: 51 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.82, neg_cosine: 0.48\n",
      "Epoch: 52 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.77, neg_cosine: 0.53\n",
      "Epoch: 53 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.81, neg_cosine: 0.50\n",
      "Epoch: 54 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.82, neg_cosine: 0.51\n",
      "Epoch: 55 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.80, neg_cosine: 0.50\n",
      "Epoch: 56 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.79, neg_cosine: 0.55\n",
      "Epoch: 57 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.84, neg_cosine: 0.48\n",
      "Epoch: 58 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.79, neg_cosine: 0.49\n",
      "Epoch: 59 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.78, neg_cosine: 0.44\n",
      "Epoch: 60 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.85, neg_cosine: 0.50\n",
      "Epoch: 61 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.82, neg_cosine: 0.49\n",
      "Epoch: 62 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.80, neg_cosine: 0.48\n",
      "Epoch: 63 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.79, neg_cosine: 0.50\n",
      "Epoch: 64 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.81, neg_cosine: 0.47\n",
      "Epoch: 65 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.83, neg_cosine: 0.48\n",
      "Epoch: 66 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.84, neg_cosine: 0.50\n",
      "Epoch: 67 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.84, neg_cosine: 0.51\n",
      "Epoch: 68 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.79, neg_cosine: 0.49\n",
      "Epoch: 69 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.83, neg_cosine: 0.49\n",
      "Epoch: 70 Loss: 0.74, MarginLoss: 0.74, pos_cosine: 0.77, neg_cosine: 0.51\n",
      "Epoch: 71 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.84, neg_cosine: 0.55\n",
      "Epoch: 72 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.81, neg_cosine: 0.52\n",
      "Epoch: 73 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.76, neg_cosine: 0.52\n",
      "Epoch: 74 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.86, neg_cosine: 0.50\n",
      "Epoch: 75 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.87, neg_cosine: 0.45\n",
      "Epoch: 76 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.86, neg_cosine: 0.49\n",
      "Epoch: 77 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.81, neg_cosine: 0.46\n",
      "Epoch: 78 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.82, neg_cosine: 0.51\n",
      "Epoch: 79 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.82, neg_cosine: 0.50\n",
      "Epoch: 80 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.89, neg_cosine: 0.48\n",
      "Epoch: 81 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.82, neg_cosine: 0.49\n",
      "Epoch: 82 Loss: 0.73, MarginLoss: 0.73, pos_cosine: 0.83, neg_cosine: 0.56\n",
      "Epoch: 83 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.85, neg_cosine: 0.49\n",
      "Epoch: 84 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.82, neg_cosine: 0.51\n",
      "Epoch: 85 Loss: 0.74, MarginLoss: 0.74, pos_cosine: 0.78, neg_cosine: 0.53\n",
      "Epoch: 86 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.83, neg_cosine: 0.51\n",
      "Epoch: 87 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.86, neg_cosine: 0.53\n",
      "Epoch: 88 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.84, neg_cosine: 0.54\n",
      "Epoch: 89 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.83, neg_cosine: 0.48\n",
      "Epoch: 90 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.81, neg_cosine: 0.49\n",
      "Epoch: 91 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.80, neg_cosine: 0.49\n",
      "Epoch: 92 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.85, neg_cosine: 0.53\n",
      "Epoch: 93 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.84, neg_cosine: 0.53\n",
      "Epoch: 94 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.86, neg_cosine: 0.45\n",
      "Epoch: 95 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.87, neg_cosine: 0.45\n",
      "Epoch: 96 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.84, neg_cosine: 0.55\n",
      "Epoch: 97 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.85, neg_cosine: 0.50\n",
      "Epoch: 98 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.85, neg_cosine: 0.44\n",
      "Epoch: 99 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.86, neg_cosine: 0.51\n",
      "Epoch: 100 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.85, neg_cosine: 0.43, recall@25: 0.59\n",
      "Saved model 'modelos/model_baseline_feature_100epochs_64batch(openoffice).h5' to disk\n",
      "Best_epoch=100, Best_loss=0.58, Recall@25=0.59\n",
      "CPU times: user 5min 8s, sys: 13.8 s, total: 5min 22s\n",
      "Wall time: 4min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False)\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False)\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    mlp_model\n",
    "'''\n",
    "desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "title_feature_model = lstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = baseline.batch_iterator(baseline.train_data, baseline.dup_sets_train, bug_train_ids, batch_size, 1)\n",
    "    train_batch = [train_input_sample['title'], train_input_sample['description'], train_input_sample['info'],\n",
    "                   train_input_pos['title'], train_input_pos['description'], train_input_pos['info'], \n",
    "                   train_input_neg['title'], train_input_neg['description'], train_input_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[3]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['108544:111059,109674,108379,109366|108529:0.7890812456607819,115421:0.3693650960922241,115634:0.3693578243255615,102470:0.3693546652793884,115569:0.369335412979126,115100:0.36930233240127563,95460:0.3692981004714966,92541:0.3599584102630615,92188:0.35995519161224365,92613:0.35995352268218994,115895:0.3578541874885559,110322:0.35782498121261597,110323:0.3578176498413086,14454:0.35456031560897827,89620:0.34550631046295166,89456:0.3454993963241577,98212:0.34477484226226807,108390:0.3428518772125244,46957:0.3396211862564087,92543:0.3393595814704895,94815:0.33861976861953735,112693:0.338323712348938,92690:0.3360458016395569,92117:0.33603334426879883,92348:0.33593863248825073,92020:0.3330014944076538,91999:0.33259373903274536,92540:0.3252970576286316,111593:0.32409727573394775',\n",
       " '109674:108544,111059,108379,109366|94815:0.8102591633796692,112693:0.8088679015636444,102682:0.4886932373046875,14454:0.4847095012664795,46957:0.4728817343711853,92543:0.4601345658302307,108390:0.4589328169822693,115421:0.44172757863998413,115634:0.4417102336883545,102470:0.4416947364807129,115100:0.44169026613235474,115569:0.4416840076446533,95460:0.44162875413894653,108377:0.4314003586769104,113509:0.42947232723236084,112299:0.4294602870941162,107845:0.4225054979324341,92541:0.4180048108100891,92188:0.4180009365081787,92613:0.41799044609069824,98212:0.41463834047317505,95277:0.41344112157821655,107267:0.40826094150543213,115895:0.40820038318634033,110322:0.4081565737724304,110323:0.40815573930740356,94421:0.40173280239105225,105082:0.40118396282196045,105511:0.39997023344039917',\n",
       " '111059:108544,109674,108379,109366|110555:0.9919131984934211,111297:0.989438634365797,110274:0.9829943142831326,14454:0.41090255975723267,94815:0.40288424491882324,46957:0.4028237462043762,112693:0.40258514881134033,98212:0.3850995898246765,109674:0.3756183385848999,115895:0.37295639514923096,110322:0.3729342818260193,110323:0.3729236125946045,115421:0.3707030415534973,115634:0.37069886922836304,102470:0.37068819999694824,115569:0.37068212032318115,115100:0.3706509470939636,95460:0.3706238269805908,102557:0.36795902252197266,104173:0.36795443296432495,102003:0.3679516911506653,102471:0.36794495582580566,104267:0.3679397702217102,102398:0.3679320812225342,106543:0.3600730895996094,109862:0.3600713610649109,92690:0.3582720160484314,92117:0.35826432704925537,92348:0.3581671714782715',\n",
       " '108379:108544,111059,109674,109366|108492:0.9947878331877291,14454:0.4262274503707886,92690:0.3995392918586731,92117:0.39951419830322266,92348:0.39941662549972534,115895:0.39167261123657227,110322:0.3916517496109009,110323:0.3916396498680115,92188:0.3897268772125244,92613:0.3897259831428528,92541:0.38972264528274536,109862:0.38472360372543335,106543:0.3847106695175171,89620:0.38091856241226196,89456:0.38091737031936646,98212:0.37871938943862915,94909:0.3784022927284241,94815:0.37475311756134033,102557:0.37467294931411743,115262:0.3746640086174011,102003:0.37466394901275635,104173:0.3746609687805176,104267:0.3746578097343445,102398:0.374655544757843,102471:0.37465548515319824,112693:0.37441790103912354,105907:0.37155836820602417,97026:0.3692728281021118,95800:0.36925143003463745',\n",
       " '109366:108544,111059,109674,108379|110044:0.9919922417029738,109298:0.5057627260684967,91310:0.49654829502105713,105235:0.4773162007331848,92537:0.4628216028213501,104266:0.43158233165740967,102497:0.43157947063446045,108311:0.4265609383583069,104956:0.42389094829559326,99191:0.4191443920135498,109431:0.4162258505821228,112617:0.41603517532348633,115491:0.41597867012023926,105086:0.414323627948761,98821:0.4071783423423767,106574:0.4044930338859558,103056:0.4037129282951355,105482:0.4031500220298767,101622:0.39514732360839844,102082:0.3950900435447693,114671:0.39351916313171387,114719:0.39350050687789917,114770:0.3934630751609802,111295:0.3920269012451172,109081:0.3910861015319824,105993:0.3906923532485962,107044:0.3906739354133606,106191:0.3906683921813965,115579:0.38137704133987427',\n",
       " '110594:107073,108355,108453,109162,111761,111800|109162:0.9949158579111099,95494:0.4617709517478943,103827:0.4427313804626465,107073:0.42095834016799927,108084:0.4209534525871277,108240:0.420951783657074,108439:0.42094719409942627,96633:0.41572171449661255,111761:0.4132978916168213,106479:0.40776193141937256,101462:0.40530771017074585,98331:0.4024708867073059,103471:0.3881184458732605,98310:0.386605441570282,108453:0.3789033889770508,101545:0.36830395460128784,108355:0.2653666138648987,104620:0.2579251527786255,95007:0.25703221559524536,94775:0.25697630643844604,103282:0.25567615032196045,98480:0.2532351016998291,98554:0.2511747479438782,93569:0.2454046607017517,99298:0.24537205696105957,100327:0.24463796615600586,96871:0.24083399772644043,95055:0.240827739238739,105251:0.23925888538360596',\n",
       " '111800:107073,110594,108355,108453,109162,111761|78260:0.44234853982925415,57538:0.4355769753456116,56891:0.4355199337005615,76670:0.4184897541999817,111833:0.41290146112442017,108513:0.4128772020339966,97681:0.40708309412002563,98278:0.4070785641670227,98948:0.4070650339126587,94707:0.4056793451309204,102865:0.4018439054489136,98966:0.4015176296234131,102298:0.39583367109298706,106252:0.3954318165779114,95903:0.39110320806503296,96736:0.3911001682281494,96117:0.3910977840423584,98022:0.39109641313552856,95999:0.3910900354385376,98770:0.3878093957901001,96929:0.38574808835983276,100537:0.3810083270072937,98967:0.38069844245910645,100029:0.37939053773880005,102068:0.3782656192779541,91324:0.37209397554397583,96212:0.3604445457458496,92385:0.3575267195701599,112809:0.3575037717819214',\n",
       " '111761:107073,110594,108355,108453,109162,111800|95494:0.5072910487651825,111758:0.5005874931812286,103827:0.4517472982406616,106479:0.4373428225517273,107073:0.4336654543876648,108084:0.43366074562072754,108240:0.433657169342041,108439:0.4336497187614441,101545:0.43174344301223755,96633:0.42982929944992065,108453:0.4275650978088379,101462:0.41424882411956787,110594:0.4132978916168213,109162:0.4132876396179199,103471:0.41025567054748535,110992:0.40818220376968384,110712:0.40817534923553467,98331:0.4016095995903015,98310:0.39133644104003906,108355:0.28551387786865234,93258:0.2590012550354004,95269:0.2576637268066406,93569:0.25247371196746826,98480:0.2498011589050293,93989:0.24726927280426025,95750:0.24605649709701538,109909:0.24566948413848877,95853:0.24530929327011108,97736:0.24519282579421997',\n",
       " '109162:107073,110594,108355,108453,111761,111800|110594:0.9949158579111099,95494:0.4617607593536377,103827:0.44274240732192993,107073:0.4209521412849426,108084:0.4209499955177307,108240:0.4209434986114502,108439:0.4209347367286682,96633:0.41572922468185425,111761:0.4132876396179199,106479:0.4077538251876831,101462:0.4053053855895996,98331:0.4024696946144104,103471:0.38810962438583374,98310:0.3865981698036194,108453:0.3789137601852417,101545:0.36829614639282227,108355:0.26536697149276733,104620:0.25792086124420166,95007:0.2570306062698364,94775:0.25698333978652954,103282:0.25567376613616943,98480:0.2532302737236023,98554:0.2511689066886902,93569:0.24539870023727417,99298:0.24536347389221191,100327:0.24463552236557007,96871:0.2408342957496643,95055:0.2408263087272644,105251:0.23925894498825073',\n",
       " '108355:107073,110594,108453,109162,111761,111800|95494:0.31905418634414673,101462:0.3136690855026245,101545:0.29339146614074707,106479:0.2903822064399719,98331:0.2858927249908447,111761:0.28551387786865234,108240:0.2836627960205078,108084:0.28365790843963623,107073:0.2836434245109558,108439:0.2836429476737976,108453:0.2831535339355469,103827:0.26969635486602783,109162:0.26536697149276733,110594:0.2653666138648987,114123:0.26153016090393066,103471:0.25919777154922485,96633:0.25898969173431396,115456:0.25103116035461426,114938:0.24471449851989746,98310:0.24224883317947388,103278:0.23394858837127686,111521:0.23381811380386353,99423:0.23175889253616333,106817:0.2287914752960205,90800:0.21830999851226807,110861:0.20525234937667847,109909:0.19821780920028687,110938:0.18693071603775024,115898:0.18637925386428833',\n",
       " '108453:107073,110594,108355,109162,111761,111800|95494:0.4629777669906616,103827:0.4551474452018738,107073:0.44703924655914307,108084:0.44703274965286255,108240:0.44702303409576416,108439:0.4470164179801941,111761:0.4275650978088379,103471:0.4227259159088135,106479:0.4224455952644348,96633:0.42095446586608887,101462:0.4097864627838135,98310:0.40383607149124146,98331:0.4012868404388428,109162:0.3789137601852417,110594:0.3789033889770508,101545:0.3574153184890747,108355:0.2831535339355469,90612:0.2781965732574463,95968:0.269161581993103,98554:0.26452475786209106,95269:0.2588244080543518,93569:0.25873810052871704,93258:0.2576780915260315,98480:0.25518691539764404,111235:0.25356191396713257,97880:0.25263071060180664,95750:0.2515307664871216,115849:0.24873167276382446,104278:0.24364984035491943',\n",
       " '114705:114676|99254:0.4020150303840637,112218:0.40201258659362793,108423:0.384516179561615,113313:0.3795546889305115,116991:0.377872109413147,105047:0.3738054037094116,102518:0.373653769493103,95152:0.3680446147918701,106591:0.36183470487594604,98659:0.3600471019744873,105747:0.36002951860427856,105727:0.3581565022468567,105368:0.35802119970321655,113535:0.35233235359191895,113470:0.35233163833618164,89587:0.3508020043373108,105822:0.3469010591506958,96918:0.34546488523483276,103423:0.3448086380958557,100282:0.3445051908493042,109640:0.3420933485031128,104587:0.33945298194885254,98753:0.3354809284210205,110687:0.3354487419128418,113097:0.33298373222351074,112783:0.3329108953475952,116750:0.33261722326278687,105295:0.32925814390182495,112187:0.3246440887451172',\n",
       " '114676:114705|106269:0.32753610610961914,106268:0.3275027275085449,108401:0.32318150997161865,103513:0.29745644330978394,103562:0.2974085807800293,91458:0.29321229457855225,99186:0.2932089567184448,91245:0.2927438020706177,115237:0.28885579109191895,115350:0.28883564472198486,102648:0.2862613797187805,110879:0.2782229781150818,110900:0.27821797132492065,104359:0.27303779125213623,104360:0.27303779125213623,96817:0.27298760414123535,111908:0.2710740566253662,101867:0.26389938592910767,107893:0.2569400668144226,101522:0.2562790513038635,101448:0.25616466999053955,110866:0.25550591945648193,112843:0.24302595853805542,112844:0.24302595853805542,112930:0.24300992488861084,112931:0.24300992488861084,113669:0.24299323558807373,111881:0.2366843819618225,108061:0.23238903284072876',\n",
       " '110593:110618|110397:0.9901874884963036,111172:0.9896110892295837,111286:0.8130932450294495,110346:0.7050548791885376,110374:0.7050467729568481,109486:0.7050391733646393,110329:0.7050323486328125,110366:0.7050315737724304,110343:0.7050138115882874,110485:0.704971432685852,110026:0.7048428058624268,114133:0.6373360455036163,110375:0.6372901201248169,109880:0.6372466385364532,110392:0.6274233758449554,111389:0.601222038269043,109568:0.5869198441505432,111651:0.5869185328483582,111681:0.5500507950782776,109951:0.5479289591312408,109435:0.5318227410316467,110956:0.5317803621292114,109950:0.5317689180374146,115496:0.5175109505653381,110241:0.5157761573791504,111054:0.49681758880615234,110657:0.4966864585876465,110012:0.4966506361961365,110005:0.49663805961608887',\n",
       " '110618:110593|110922:0.5160068273544312,91809:0.49220705032348633,112099:0.4922030568122864,100801:0.4757552146911621,100033:0.4757426977157593,104013:0.47574061155319214,98867:0.4757261872291565,99504:0.4756978154182434,99133:0.47521108388900757,108780:0.4742633104324341,110306:0.4646297097206116,105638:0.4621535539627075,106695:0.46214914321899414,109368:0.4621286392211914,116000:0.4620785713195801,91606:0.4515438675880432,112234:0.45090746879577637,96115:0.44618844985961914,95207:0.4461875557899475,90892:0.4461745619773865,94253:0.4461745619773865,98768:0.44369858503341675,95031:0.44369715452194214,95667:0.44369006156921387,96142:0.44368839263916016,97523:0.4436753988265991,96395:0.44365352392196655,99270:0.4436262249946594,99452:0.4400287866592407',\n",
       " '102409:102053|102106:0.9667156115174294,104447:0.5097663402557373,90949:0.46977609395980835,95237:0.4578278064727783,96947:0.45781034231185913,96471:0.45779234170913696,96945:0.45779216289520264,97350:0.4577661156654358,102003:0.45178061723709106,102557:0.45177900791168213,102471:0.4517630338668823,104173:0.4517611265182495,102398:0.4517527222633362,104267:0.45175105333328247,95413:0.4472947120666504,96124:0.44727903604507446,102495:0.4336230158805847,110764:0.4272726774215698,95414:0.42386674880981445,106171:0.41985607147216797,102682:0.4189218282699585,91703:0.4145495295524597,94569:0.4069932699203491,106072:0.4062510132789612,101652:0.4062042236328125,104460:0.40476757287979126,99306:0.4001758098602295,101124:0.3958098888397217,93443:0.39329028129577637',\n",
       " '102053:102409|116288:0.29768306016921997,107236:0.2976587414741516,107101:0.27929145097732544,114049:0.2009226679801941,107778:0.20088964700698853,90840:0.15971159934997559,95114:0.05111974477767944,96739:0.03860396146774292,111603:0.038599371910095215,109864:0.027981281280517578,109794:0.027970731258392334,91542:0.02768230438232422,95975:0.027668476104736328,98546:0.023786723613739014,93913:0.022547423839569092,97095:0.020174384117126465,105631:0.019762158393859863,109067:0.01885443925857544,111354:0.018786251544952393,91543:0.013814926147460938,103541:0.008285820484161377,91126:0.00791257619857788,115335:-0.0003114938735961914,96732:-0.0003249645233154297,101932:-0.002744317054748535,103145:-0.0068024396896362305,97710:-0.006806015968322754,85559:-0.006807088851928711,90307:-0.006815671920776367',\n",
       " '110604:110612|110612:0.6431160569190979,109067:0.15870070457458496,97095:-0.029944777488708496,95768:-0.05140519142150879,105631:-0.06394553184509277,122655:-0.07317829132080078,95114:-0.07360613346099854,107061:-0.08338332176208496,107058:-0.08338594436645508,100327:-0.08782839775085449,100031:-0.08786261081695557,100567:-0.08825051784515381,85559:-0.08916163444519043,103145:-0.08917152881622314,90307:-0.08917236328125,97710:-0.08917379379272461,115871:-0.08920574188232422,114669:-0.08945214748382568,98289:-0.09131157398223877,113114:-0.09355485439300537,100204:-0.09430408477783203,99167:-0.09451234340667725,90697:-0.09595251083374023,114322:-0.0969243049621582,96739:-0.09730792045593262,111603:-0.09730887413024902,110594:-0.09745872020721436,109162:-0.09745907783508301,109864:-0.09888505935668945',\n",
       " '110612:110604|110604:0.6431160569190979,109067:0.10285162925720215,94947:-0.046610236167907715,92890:-0.058965086936950684,111354:-0.06907641887664795,100327:-0.07322454452514648,114322:-0.07603275775909424,100204:-0.07862639427185059,94366:-0.07944214344024658,110594:-0.08149516582489014,109162:-0.0814967155456543,95309:-0.08179175853729248,95114:-0.08294546604156494,100567:-0.08396279811859131,99648:-0.08799660205841064,99498:-0.08800697326660156,98546:-0.08858978748321533,105682:-0.0890054702758789,106067:-0.09051454067230225,90697:-0.09279739856719971,92951:-0.09488880634307861,92387:-0.09490346908569336,96099:-0.09551990032196045,109864:-0.09586489200592041,109794:-0.0958702564239502,102724:-0.09737002849578857,90086:-0.09743070602416992,90085:-0.09743177890777588,108018:-0.09812748432159424',\n",
       " '116738:116938,117027|115793:0.9627991169691086,113225:0.9626421555876732,113106:0.8408355861902237,114018:0.45693016052246094,98664:0.40584832429885864,104697:0.37911564111709595,113395:0.37031495571136475,105337:0.36837244033813477,103944:0.36834126710891724,103945:0.36834126710891724,107999:0.36828839778900146,102288:0.3660537600517273,95130:0.3634529709815979,99469:0.3624221086502075,110740:0.362185537815094,100846:0.3545013666152954,116938:0.3529740571975708,116944:0.3487733006477356,117027:0.348707377910614,109937:0.3464895486831665,93192:0.3451899290084839,96218:0.3428143858909607,96594:0.34258174896240234,105084:0.34226280450820923,100713:0.33440303802490234,100714:0.33440303802490234,100715:0.33440303802490234,100716:0.33440303802490234,92713:0.3340368866920471']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "#     Between 0-10 epochs recall@25 = 0.28\n",
    "#     Between 0-20 epochs recall@25 = 0.32\n",
    "#     Between 0-70 epochs recall@25 = ?\n",
    "#     Between 0-100 epochs recall@25 = ?\n",
    "# '''\n",
    "# recall, exported_rank = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 2086\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_feature_100epochs_64batch(openoffice)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          219000      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          30604800    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          30651492    desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "==================================================================================================\n",
      "Total params: 61,475,292\n",
      "Trainable params: 672,492\n",
      "Non-trainable params: 60,802,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, bug_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/openoffice/exported_rank_baseline.txt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.42,\n",
       " '2 - recall_at_10': 0.49,\n",
       " '3 - recall_at_15': 0.53,\n",
       " '4 - recall_at_20': 0.56,\n",
       " '5 - recall_at_25': 0.59}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some ideas to visualizate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
