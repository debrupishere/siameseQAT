{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 100 # 40\n",
    "MAX_SEQUENCE_LENGTH_D = 500 # 200\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'netbeans'\n",
    "METHOD = 'baseline'\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Glove embeddings\n",
    "GLOVE_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = 'baseline_feature@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "SAVE_PATH_FEATURE = 'baseline_feature_@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1dd3b253e840f1b6d2eba40da143ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83503), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22abcd9308234e3397101683a6f8c641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14567), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98070"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63df9accd8e645819711c51fb128e589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=98070), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c29a46a7924b3c97368c8747ebec58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 1s, sys: 1.09 s, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b1b6be6045415a86b9716ac339dce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=83503), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "experiment.prepare_dataset(issues_by_buckets)\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the corpus train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CORPUS:\n",
    "    corpus = []\n",
    "    export_file = open(os.path.join(DIR, 'corpus_train.txt'), 'w')\n",
    "    for bug_id in tqdm(baseline.bug_set):\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title = bug['title']\n",
    "        desc = bug['description']\n",
    "        export_file.write(\"{}\\n{}\\n\".format(title, desc))\n",
    "    export_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "# Generating tiple of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'opening a recent doc that has since been moved deleted causes unfulfilled loop', 'bug_severity': '4\\n', 'creation_ts': '2001-12-12 17:00:00 +0000', 'dup_id': '2268', 'description_word': array([ 334,    4,   24,   36,    2,   24, 3000,   29,   88,  204, 1136,\n",
      "         51,  816,  601,   54,   52, 1263,    5, 1277,  117, 1458,   15,\n",
      "        187,   43,  880,  439, 1267,  500,  135,    2, 1263,  979,  117,\n",
      "        225,   17, 3082, 8390, 2729,    2,  213,   88,    5,   25, 3617,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0]), 'issue_id': 2521, 'version': '11\\n', 'component': '129\\n', 'delta_ts': '2003-09-08 16:56:16 +0000', 'resolution': 'DUPLICATE', 'title_word': array([ 334,    4, 1535,  163,   29,   88,  363,  204, 1136,  816,  601,\n",
      "          1, 1140,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0]), 'product': '0\\n', 'priority': '3\\n', 'description': 'opening a file from the file history that has been moved or deleted causes an error dialogue to pop up saying it doesn t exist etc upon clicking ok the dialogue comes up again this continues indefinitely meaning the application has to be terminated', 'bug_status': '2\\n'}\n"
     ]
    }
   ],
   "source": [
    "if 2521 in baseline.bug_set:\n",
    "    print(baseline.bug_set[2521])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 13904)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59 ms, sys: 0 ns, total: 59 ms\n",
      "Wall time: 58.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = baseline.batch_iterator(baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train, \n",
    "                                                                                          batch_size_test, 1)\n",
    "test_gen = ([valid_input_sample['title'], valid_input_pos['title'], valid_input_neg['title'], \n",
    "             valid_input_sample['description'], valid_input_pos['description'], valid_input_neg['description'],\n",
    "            valid_input_sample['info'], valid_input_pos['info'], valid_input_neg['info']], valid_sim)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 90), (128, 500), (128, 738), (128,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Title***: curved connector views as straight line\n",
      "***Title***: assertion when displaying certain product object\n",
      "***Description***: open a blank presentation insert a curved connector make sure it is bent not straight ie the number handles number end handles and number middle handle are not on a line press f for viewing the curved connector appears on screen but is superimposed with a straight line joining both end handles this straight line is not wanted note when exporting the presentation eg to bmp organization product the connector draws fine\n",
      "***Description***: open document from issue error ungueltiger index bei const organization auf xpolygon from file o src src svx source xoutdev xpoly cxx at line\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: on organization headings do not transfer to product\n",
      "***Title***: style information does not persist\n",
      "***Description***: in every time you re load a file the heading information is missing in the product panel this does not happen in earlier versions\n",
      "***Description***: i m writing a bit longer document about pages in length and am using headings and numberings once i associate a numbering to a heading anything is alright but once i quit ooo and then re open the document the numbering is no longer assigned to that heading usually a outline gets assigned instead this is really annoying for i have to re apply these numberings every time i re open the document\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: crash during number start on organization\n",
      "***Title***: character in user dir gets lost\n",
      "***Description***: after workstation installation and before completely showing the registration dialogue oo person crashes on organization gcc version prerelease organization glibc\n",
      "***Description***: character in user dir gets lost\n",
      "***similar = 0\n",
      "########################\n",
      "***Title***: import from some ms word documents lacks tables\n",
      "***Title***: organization missing organization to suppress update of all defined names\n",
      "***Description***: there is a short discussion on the issue in the ooo forums http user services openoffice org en forum viewtopic php f t this acts only on productplatforms organization are shifted to the left side by number the example of the document is http www intaer ru files d d d d a d d a d doc\n",
      "***Description***: organization missing organization to suppress update of all defined names\n",
      "***similar = 0\n",
      "########################\n",
      "CPU times: user 59.4 ms, sys: 0 ns, total: 59.4 ms\n",
      "Wall time: 59.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "baseline.display_batch(baseline.train_data, baseline.dup_sets_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test ', 3861)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Test \", len(baseline.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 113140'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, GLOVE_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(GLOVE_DIR, 'glove.42B.300d.txt')\n",
    "    f = open(embed_path, 'rb')\n",
    "    #num_lines = sum(1 for line in open(embed_path, 'rb'))\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(tokens[1:], dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15c9ce8a25c45e68322575bf67cde80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db20684f65544fc897726a99fd943c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113140), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 24s, sys: 3.55 s, total: 2min 28s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, GLOVE_DIR=GLOVE_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer',\n",
    "                                  weights=[embeddings],\n",
    "                                  embeddings_constraint=MaxNorm(max_value=1, axis=0),\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI074wU4Y13y"
   },
   "source": [
    "### CNN with filter 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "h6YJU9GtFTyq",
    "outputId": "f85cf105-1fd6-491d-d969-7e6936f32739",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "\n",
    "def cnn_model(embedding_layer, max_sequence_length):\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length,), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None,), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "    # best combination filter (3, 4, 5) e 128 e 256\n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    n_filters = 64\n",
    "\n",
    "    for index, filter_size in enumerate(filter_sizes):\n",
    "        l_conv = Conv1D(filters=n_filters, kernel_size=filter_size)(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(pool_size=filter_size)(l_conv) # index+1\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "    # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "    #conv = Conv1D(filters=n_filters * 3, kernel_size=3)(l_merge)\n",
    "    layer = GlobalAveragePooling1D()(l_merge)\n",
    "    #layer = Flatten()(l_merge)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "    #layer = LeakyReLU()(layer)\n",
    "\n",
    "    cnn_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureCNNGenerationModel') # inputs=visible\n",
    "\n",
    "    return cnn_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr6ObTXiaALH"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "vC7MQXEsaCeG",
    "outputId": "65e647a9-c5d3-4009-b8a4-2e2d97b52684"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, GRU, Dropout, Bidirectional, GlobalAveragePooling1D\n",
    "\n",
    "def lstm_model(embedding_layer, max_sequence_length):\n",
    "    number_lstm_units = 50\n",
    "    rate_drop_lstm = 0\n",
    "    recurrent_dropout = 0\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None, ), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Creating LSTM Encoder\n",
    "#     lstm_layer = Bidirectional(LSTM(number_lstm_units, return_sequences=True), # dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm \n",
    "#                                merge_mode='ave')\n",
    "\n",
    "    lstm_layer = LSTM(number_lstm_units, return_sequences=True)(embedded_sequences)\n",
    "    layer = LSTM(number_lstm_units)(lstm_layer)\n",
    "\n",
    "    #layer = lstm_layer(embedded_sequences)\n",
    "    #layer = GlobalAveragePooling1D()(layer)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "\n",
    "    lstm_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureLstmGenerationModel') # inputs=visible\n",
    "\n",
    "    return lstm_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.sum(K.maximum(0.0, margin - pos + neg))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "  \n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    #     bug_feature_output = Activation('tanh')(bug_feature_output)\n",
    "    \n",
    "    # Bug representation layer\n",
    "    # bug_feature_output = Dense(300, activation='tanh')(bug_feature_output)\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    \n",
    "    # Cosine\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3 * decay_lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer=optimizer, loss=custom_margin_loss, metrics=[pos_distance, neg_distance, custom_margin_loss])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 738)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 90)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 738)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_pos (InputLayer)          (None, 90)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_pos (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 738)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_neg (InputLayer)          (None, 90)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_neg (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          221700      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          34047700    title_in[0][0]                   \n",
      "                                                                 title_pos[0][0]                  \n",
      "                                                                 title_neg[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          34192092    desc_in[0][0]                    \n",
      "                                                                 desc_pos[0][0]                   \n",
      "                                                                 desc_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 900)          0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureLstmGenerationModel[2][0] \n",
      "                                                                 FeatureCNNGenerationModel[2][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 900)          0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureLstmGenerationModel[3][0] \n",
      "                                                                 FeatureCNNGenerationModel[3][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances (Lambda)        (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 68,461,492\n",
      "Trainable params: 577,492\n",
      "Non-trainable params: 67,884,000\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 0.89, MarginLoss: 0.89, pos_cosine: 0.86, neg_cosine: 0.75\n",
      "Epoch: 2 Loss: 0.91, MarginLoss: 0.91, pos_cosine: 0.83, neg_cosine: 0.73\n",
      "Epoch: 3 Loss: 0.89, MarginLoss: 0.89, pos_cosine: 0.84, neg_cosine: 0.73\n",
      "Epoch: 4 Loss: 0.87, MarginLoss: 0.87, pos_cosine: 0.82, neg_cosine: 0.69\n",
      "Epoch: 5 Loss: 0.87, MarginLoss: 0.87, pos_cosine: 0.81, neg_cosine: 0.68\n",
      "Epoch: 6 Loss: 0.87, MarginLoss: 0.87, pos_cosine: 0.82, neg_cosine: 0.69\n",
      "Epoch: 7 Loss: 0.88, MarginLoss: 0.88, pos_cosine: 0.79, neg_cosine: 0.68\n",
      "Epoch: 8 Loss: 0.87, MarginLoss: 0.87, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 9 Loss: 0.85, MarginLoss: 0.85, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 10 Loss: 0.84, MarginLoss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 11 Loss: 0.82, MarginLoss: 0.82, pos_cosine: 0.80, neg_cosine: 0.62\n",
      "Epoch: 12 Loss: 0.80, MarginLoss: 0.80, pos_cosine: 0.79, neg_cosine: 0.59\n",
      "Epoch: 13 Loss: 0.82, MarginLoss: 0.82, pos_cosine: 0.77, neg_cosine: 0.59\n",
      "Epoch: 14 Loss: 0.78, MarginLoss: 0.78, pos_cosine: 0.80, neg_cosine: 0.58\n",
      "Epoch: 15 Loss: 0.77, MarginLoss: 0.77, pos_cosine: 0.80, neg_cosine: 0.56\n",
      "Epoch: 16 Loss: 0.81, MarginLoss: 0.81, pos_cosine: 0.75, neg_cosine: 0.56\n",
      "Epoch: 17 Loss: 0.82, MarginLoss: 0.82, pos_cosine: 0.74, neg_cosine: 0.57\n",
      "Epoch: 18 Loss: 0.78, MarginLoss: 0.78, pos_cosine: 0.78, neg_cosine: 0.56\n",
      "Epoch: 19 Loss: 0.78, MarginLoss: 0.78, pos_cosine: 0.76, neg_cosine: 0.54\n",
      "Epoch: 20 Loss: 0.81, MarginLoss: 0.81, pos_cosine: 0.74, neg_cosine: 0.55\n",
      "Epoch: 21 Loss: 0.79, MarginLoss: 0.79, pos_cosine: 0.76, neg_cosine: 0.55\n",
      "Epoch: 22 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.77, neg_cosine: 0.53\n",
      "Epoch: 23 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.78, neg_cosine: 0.53\n",
      "Epoch: 24 Loss: 0.74, MarginLoss: 0.74, pos_cosine: 0.77, neg_cosine: 0.51\n",
      "Epoch: 25 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.80, neg_cosine: 0.49\n",
      "Epoch: 26 Loss: 0.77, MarginLoss: 0.77, pos_cosine: 0.74, neg_cosine: 0.51\n",
      "Epoch: 27 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.75, neg_cosine: 0.51\n",
      "Epoch: 28 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.76, neg_cosine: 0.52\n",
      "Epoch: 29 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.75, neg_cosine: 0.51\n",
      "Epoch: 30 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.77, neg_cosine: 0.52\n",
      "Epoch: 31 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.79, neg_cosine: 0.55\n",
      "Epoch: 32 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.78, neg_cosine: 0.49\n",
      "Epoch: 33 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.78, neg_cosine: 0.50\n",
      "Epoch: 34 Loss: 0.77, MarginLoss: 0.77, pos_cosine: 0.76, neg_cosine: 0.54\n",
      "Epoch: 35 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.78, neg_cosine: 0.48\n",
      "Epoch: 36 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.79, neg_cosine: 0.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.80, neg_cosine: 0.51\n",
      "Epoch: 38 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.75, neg_cosine: 0.50\n",
      "Epoch: 39 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.79, neg_cosine: 0.49\n",
      "Epoch: 40 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.81, neg_cosine: 0.47\n",
      "Epoch: 41 Loss: 0.73, MarginLoss: 0.73, pos_cosine: 0.78, neg_cosine: 0.51\n",
      "Epoch: 42 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.78, neg_cosine: 0.50\n",
      "Epoch: 43 Loss: 0.74, MarginLoss: 0.74, pos_cosine: 0.77, neg_cosine: 0.51\n",
      "Epoch: 44 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.80, neg_cosine: 0.50\n",
      "Epoch: 45 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.75, neg_cosine: 0.47\n",
      "Epoch: 46 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.82, neg_cosine: 0.49\n",
      "Epoch: 47 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.79, neg_cosine: 0.51\n",
      "Epoch: 48 Loss: 0.73, MarginLoss: 0.73, pos_cosine: 0.80, neg_cosine: 0.53\n",
      "Epoch: 49 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.81, neg_cosine: 0.50\n",
      "Epoch: 50 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.76, neg_cosine: 0.51\n",
      "Epoch: 51 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.81, neg_cosine: 0.47\n",
      "Epoch: 52 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.80, neg_cosine: 0.47\n",
      "Epoch: 53 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.81, neg_cosine: 0.50\n",
      "Epoch: 54 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.82, neg_cosine: 0.51\n",
      "Epoch: 55 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.81, neg_cosine: 0.51\n",
      "Epoch: 56 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.82, neg_cosine: 0.48\n",
      "Epoch: 57 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.82, neg_cosine: 0.48\n",
      "Epoch: 58 Loss: 0.73, MarginLoss: 0.73, pos_cosine: 0.80, neg_cosine: 0.53\n",
      "Epoch: 59 Loss: 0.80, MarginLoss: 0.80, pos_cosine: 0.77, neg_cosine: 0.57\n",
      "Epoch: 60 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.82, neg_cosine: 0.49\n",
      "Epoch: 61 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.82, neg_cosine: 0.51\n",
      "Epoch: 62 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.82, neg_cosine: 0.49\n",
      "Epoch: 63 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.81, neg_cosine: 0.52\n",
      "Epoch: 64 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.78, neg_cosine: 0.53\n",
      "Epoch: 65 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.81, neg_cosine: 0.48\n",
      "Epoch: 66 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.80, neg_cosine: 0.50\n",
      "Epoch: 67 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.81, neg_cosine: 0.52\n",
      "Epoch: 68 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.81, neg_cosine: 0.49\n",
      "Epoch: 69 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.83, neg_cosine: 0.48\n",
      "Epoch: 70 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.82, neg_cosine: 0.49\n",
      "Epoch: 71 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.84, neg_cosine: 0.49\n",
      "Epoch: 72 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.86, neg_cosine: 0.48\n",
      "Epoch: 73 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.85, neg_cosine: 0.44\n",
      "Epoch: 74 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.81, neg_cosine: 0.51\n",
      "Epoch: 75 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.84, neg_cosine: 0.49\n",
      "Epoch: 76 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.82, neg_cosine: 0.48\n",
      "Epoch: 77 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.84, neg_cosine: 0.49\n",
      "Epoch: 78 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.82, neg_cosine: 0.46\n",
      "Epoch: 79 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.82, neg_cosine: 0.50\n",
      "Epoch: 80 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.85, neg_cosine: 0.45\n",
      "Epoch: 81 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.86, neg_cosine: 0.45\n",
      "Epoch: 82 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.79, neg_cosine: 0.47\n",
      "Epoch: 83 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.82, neg_cosine: 0.49\n",
      "Epoch: 84 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.82, neg_cosine: 0.46\n",
      "Epoch: 85 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.84, neg_cosine: 0.48\n",
      "Epoch: 86 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.82, neg_cosine: 0.49\n",
      "Epoch: 87 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.82, neg_cosine: 0.51\n",
      "Epoch: 88 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.85, neg_cosine: 0.46\n",
      "Epoch: 89 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.80, neg_cosine: 0.50\n",
      "Epoch: 90 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.83, neg_cosine: 0.49\n",
      "Epoch: 91 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.84, neg_cosine: 0.51\n",
      "Epoch: 92 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.84, neg_cosine: 0.48\n",
      "Epoch: 93 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.83, neg_cosine: 0.49\n",
      "Epoch: 94 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.84, neg_cosine: 0.49\n",
      "Epoch: 95 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.84, neg_cosine: 0.47\n",
      "Epoch: 96 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.83, neg_cosine: 0.48\n",
      "Epoch: 97 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.89, neg_cosine: 0.45\n",
      "Epoch: 98 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.87, neg_cosine: 0.48\n",
      "Epoch: 99 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.86, neg_cosine: 0.48\n",
      "Epoch: 100 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.86, neg_cosine: 0.47, recall@25: 0.30\n",
      "Saved model 'modelos/model_baseline_feature_100epochs_64batch(openoffice).h5' to disk\n",
      "Best_epoch=97, Best_loss=0.57, Recall@25=0.30\n",
      "CPU times: user 2min 58s, sys: 11.4 s, total: 3min 9s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False)\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False)\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    mlp_model\n",
    "'''\n",
    "desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "title_feature_model = lstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = baseline.batch_iterator(baseline.train_data, baseline.dup_sets_train, batch_size, 1)\n",
    "    train_batch = [train_input_sample['title'], train_input_sample['description'], train_input_sample['info'],\n",
    "                   train_input_pos['title'], train_input_pos['description'], train_input_pos['info'], \n",
    "                   train_input_neg['title'], train_input_neg['description'], train_input_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _ = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets)\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[3]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16384:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '14604:15363|7213:0.48789507150650024,21034:0.47433000802993774,23220:0.47429412603378296,28625:0.4737488627433777,19906:0.4448719620704651,12626:0.43176043033599854,5149:0.3985724449157715,5091:0.39849716424942017,5362:0.39847201108932495,20352:0.39846372604370117,20485:0.3984569311141968,20883:0.39844775199890137,6263:0.3984338045120239,20119:0.3984309434890747,6431:0.39793020486831665,32062:0.39416611194610596,8567:0.3800280690193176,6541:0.3739650249481201,14775:0.372206449508667,14729:0.3721933960914612,41992:0.36958181858062744,42950:0.3695588707923889,41469:0.36954647302627563,41864:0.3695110082626343,29640:0.363764226436615',\n",
       " '16388:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '16389:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '14054:15363|14156:0.6772976219654083,23251:0.5748790204524994,4700:0.5745701491832733,33449:0.5624824166297913,78756:0.5544387996196747,4397:0.5544214248657227,4477:0.5536214113235474,14647:0.5473522543907166,13824:0.5223752856254578,9278:0.5086086392402649,8698:0.5085655152797699,12207:0.5082470178604126,2574:0.49553799629211426,19911:0.48979365825653076,13015:0.486639142036438,5011:0.48002690076828003,15220:0.47956788539886475,31735:0.47772759199142456,15006:0.4745514988899231,16120:0.46195781230926514,16805:0.46195536851882935,12788:0.46194833517074585,3930:0.44856399297714233,56638:0.44255316257476807,255:0.40689653158187866',\n",
       " '16385:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '16386:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '39820:32772|49301:0.6985204219818115,51258:0.687159925699234,13592:0.6564901769161224,21359:0.6564756035804749,23728:0.6562930345535278,5991:0.6436318755149841,25072:0.6435240507125854,3910:0.6435132920742035,34343:0.6406092941761017,24755:0.6371569633483887,35959:0.6242118775844574,53885:0.6225932836532593,45952:0.6225460469722748,44924:0.6224976480007172,56806:0.6130838692188263,22575:0.6064389646053314,21299:0.6064269542694092,32175:0.6063448786735535,24525:0.6063134074211121,21290:0.6063050925731659,22196:0.6062650680541992,25140:0.6061247289180756,13507:0.6060605347156525,46062:0.6047437787055969,48748:0.6043537557125092',\n",
       " '14604:15363|7213:0.48789507150650024,21034:0.47433000802993774,23220:0.47429412603378296,28625:0.4737488627433777,19906:0.4448719620704651,12626:0.43176043033599854,5149:0.3985724449157715,5091:0.39849716424942017,5362:0.39847201108932495,20352:0.39846372604370117,20485:0.3984569311141968,20883:0.39844775199890137,6263:0.3984338045120239,20119:0.3984309434890747,6431:0.39793020486831665,32062:0.39416611194610596,8567:0.3800280690193176,6541:0.3739650249481201,14775:0.372206449508667,14729:0.3721933960914612,41992:0.36958181858062744,42950:0.3695588707923889,41469:0.36954647302627563,41864:0.3695110082626343,29640:0.363764226436615',\n",
       " '16390:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '12274:31697|11371:0.8150249570608139,11040:0.8149605840444565,12228:0.8149395883083344,11493:0.7863152623176575,11491:0.7599960714578629,4508:0.7319278419017792,4568:0.7318868935108185,33307:0.7318633198738098,13592:0.7291500270366669,23728:0.7290506064891815,21359:0.7290070056915283,6836:0.7219065725803375,14387:0.6965360343456268,6843:0.6949344575405121,7280:0.6949262022972107,19323:0.6892611086368561,21423:0.6887242794036865,4686:0.6872671544551849,24755:0.6835035383701324,7311:0.6735664904117584,23286:0.6735546290874481,2109:0.6708491742610931,6455:0.67083540558815,14822:0.6708303689956665,81146:0.6708216965198517',\n",
       " '12275:31697|11371:0.8150249570608139,11040:0.8149605840444565,12228:0.8149395883083344,11493:0.7863152623176575,11491:0.7599960714578629,4508:0.7319278419017792,4568:0.7318868935108185,33307:0.7318633198738098,13592:0.7291500270366669,23728:0.7290506064891815,21359:0.7290070056915283,6836:0.7219065725803375,14387:0.6965360343456268,6843:0.6949344575405121,7280:0.6949262022972107,19323:0.6892611086368561,21423:0.6887242794036865,4686:0.6872671544551849,24755:0.6835035383701324,7311:0.6735664904117584,23286:0.6735546290874481,2109:0.6708491742610931,6455:0.67083540558815,14822:0.6708303689956665,81146:0.6708216965198517',\n",
       " '16393:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '14054:15363|14156:0.6772976219654083,23251:0.5748790204524994,4700:0.5745701491832733,33449:0.5624824166297913,78756:0.5544387996196747,4397:0.5544214248657227,4477:0.5536214113235474,14647:0.5473522543907166,13824:0.5223752856254578,9278:0.5086086392402649,8698:0.5085655152797699,12207:0.5082470178604126,2574:0.49553799629211426,19911:0.48979365825653076,13015:0.486639142036438,5011:0.48002690076828003,15220:0.47956788539886475,31735:0.47772759199142456,15006:0.4745514988899231,16120:0.46195781230926514,16805:0.46195536851882935,12788:0.46194833517074585,3930:0.44856399297714233,56638:0.44255316257476807,255:0.40689653158187866',\n",
       " '16394:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '16379:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '14604:15363|7213:0.48789507150650024,21034:0.47433000802993774,23220:0.47429412603378296,28625:0.4737488627433777,19906:0.4448719620704651,12626:0.43176043033599854,5149:0.3985724449157715,5091:0.39849716424942017,5362:0.39847201108932495,20352:0.39846372604370117,20485:0.3984569311141968,20883:0.39844775199890137,6263:0.3984338045120239,20119:0.3984309434890747,6431:0.39793020486831665,32062:0.39416611194610596,8567:0.3800280690193176,6541:0.3739650249481201,14775:0.372206449508667,14729:0.3721933960914612,41992:0.36958181858062744,42950:0.3695588707923889,41469:0.36954647302627563,41864:0.3695110082626343,29640:0.363764226436615',\n",
       " '16395:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '16390:15363|13015:0.726079672574997,23251:0.6441001892089844,4700:0.6051553189754486,14647:0.6049550771713257,33449:0.5864703953266144,13824:0.5831818580627441,78756:0.5629229247570038,4397:0.5628447532653809,4477:0.5620640516281128,9278:0.5484780073165894,8698:0.5484072268009186,12207:0.5479196310043335,19911:0.53129443526268,15006:0.5293072164058685,15220:0.49851900339126587,16120:0.49127525091171265,12788:0.49127399921417236,16805:0.4912490248680115,31735:0.48122018575668335,56638:0.4810744524002075,2574:0.45890742540359497,5011:0.4499360918998718,42871:0.44436830282211304,19339:0.42830514907836914,43032:0.427470326423645',\n",
       " '8184:3724|14658:0.9933975948952138,14718:0.993179835844785,7180:0.989032925106585,8808:0.9762715566903353,10621:0.7854288667440414,7560:0.7854159772396088,8302:0.785370483994484,12129:0.7596995681524277,19079:0.7596532851457596,12710:0.7595301270484924,22811:0.7488754093647003,6705:0.7488752603530884,33851:0.7488256692886353,6087:0.748735249042511,9709:0.7482506930828094,21716:0.7476856708526611,23476:0.7425516545772552,7020:0.7425506114959717,22306:0.7425373792648315,4874:0.7425097525119781,18735:0.7425066530704498,4904:0.7425033152103424,4925:0.7420768141746521,4695:0.7417021095752716,17222:0.7278591990470886']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('recall@25 last epoch:', 0.3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Between 0-10 epochs recall@25 = 0.28\n",
    "    Between 0-20 epochs recall@25 = 0.32\n",
    "    Between 0-70 epochs recall@25 = ?\n",
    "    Between 0-100 epochs recall@25 = ?\n",
    "'''\n",
    "recall, exported_rank = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets)\n",
    "\n",
    "\"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loss=h.history['loss']\n",
    "# val_loss=h.history['val_loss']\n",
    "\n",
    "# plt.plot(loss, label='loss')\n",
    "# plt.plot(val_loss, label='val_loss')\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 3861\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_feature_100epochs_64batch(openoffice)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 738)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 90)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          221700      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          34047700    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          34192092    desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "==================================================================================================\n",
      "Total params: 68,461,492\n",
      "Trainable params: 577,492\n",
      "Non-trainable params: 67,884,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/openoffice/exported_rank_baseline.txt'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.15,\n",
       " '2 - recall_at_10': 0.19,\n",
       " '3 - recall_at_15': 0.22,\n",
       " '4 - recall_at_20': 0.26,\n",
       " '5 - recall_at_25': 0.3}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
