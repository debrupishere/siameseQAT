{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 100 # 40\n",
    "MAX_SEQUENCE_LENGTH_D = 500 # 200\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'eclipse'\n",
    "METHOD = 'baseline'\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Glove embeddings\n",
    "GLOVE_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = 'baseline_feature@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "SAVE_PATH_FEATURE = 'baseline_feature_@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "212512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4f58d6feec45b1bd433d402bd1e21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=212512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b79542c917a422b98e39a2880aa832b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 27s, sys: 3.43 s, total: 1min 30s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the corpus train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CORPUS:\n",
    "    corpus = []\n",
    "    export_file = open(os.path.join(DIR, 'corpus_train.txt'), 'w')\n",
    "    for bug_id in tqdm(baseline.bug_set):\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title = bug['title']\n",
    "        desc = bug['description']\n",
    "        export_file.write(\"{}\\n{}\\n\".format(title, desc))\n",
    "    export_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0WZNngemNM8"
   },
   "source": [
    "## Geração de batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "# Generating tiple of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "CPU times: user 619 ms, sys: 3.97 ms, total: 623 ms\n",
      "Wall time: 620 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "experiment.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dup_id': '[]', 'bug_status': '0\\n', 'resolution': 'FIXED', 'title': 'selecting window in the window menu does not maximize window gfitic', 'title_word': array([1036,   95,   11,    8,   95,  213,  101,   20, 3086,   95,    1,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0]), 'description': 'steps minimize all your windows go to any window and select the nationality menu pick any window organization that it only gets selected and not maximized this happens in country as well organization', 'version': '522\\n', 'product': '125\\n', 'description_word': array([ 241, 3070,   86,  548,  297,  394,    9,  196,   95,   16,  131,\n",
      "          8,   17,  213, 1931,  196,   95,    2,   27,   22,  130,  783,\n",
      "        276,   16,   20, 3484,   23,  610,   11,   28,   44,  563,    2,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0]), 'bug_severity': '4\\n', 'creation_ts': '2001-10-10 22:38:00 -0400', 'component': '566\\n', 'delta_ts': '2005-05-10 14:55:51 -0400', 'issue_id': 2521, 'priority': '0\\n'}\n"
     ]
    }
   ],
   "source": [
    "if 2521 in baseline.bug_set:\n",
    "    print(baseline.bug_set[2521])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87.2 ms, sys: 3.97 ms, total: 91.1 ms\n",
      "Wall time: 90.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "train_gen = baseline.siam_gen(baseline.train_data, baseline.dup_sets_train, batch_size, 1)\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = baseline.batch_iterator(baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train, \n",
    "                                                                                          batch_size_test, 1)\n",
    "test_gen = ([valid_input_sample['title'], valid_input_pos['title'], valid_input_neg['title'], \n",
    "             valid_input_sample['description'], valid_input_pos['description'], valid_input_neg['description'],\n",
    "            valid_input_sample['info'], valid_input_pos['info'], valid_input_neg['info']], valid_sim)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 43), (128, 500), (128, 1682), (128,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Title***: exception causing eclipse crash\n",
      "***Title***: very frequent crashing in person\n",
      "***Description***: senario unpack eclipse organization linux motif zip run eclipse not as root expand project exist in eclipse opne file exist in the project by double click on it in this case an xml cdtbuild file see step the installation does not contains cdt file open an externl file window is open with several gui drawings and then comes the crush this is not happend if you do not open file number see crahs log below have fun an unexpected exception has been detected in native code outside the facility occurred at pc organization product pthread mutex lock product lib libpthread so current java thread at org eclipse swt internal motif os person values person at org eclipse swt widgets person set text person java at org eclipse jface action organization update organization java at org eclipse jface action person update person java at org eclipse jface action person update person java at org eclipse jface action person update person java at org eclipse ui internal nationality update active nationality window person nationality java at org eclipse ui internal nationality access nationality java at org eclipse ui internal nationality window deactivated nationality java at org eclipse ui internal nationality run nationality java at org eclipse core internal runtime organization run organization java at org eclipse core runtime organization java at org eclipse ui internal nationality fire window deactivated nationality java at org eclipse ui internal nationality window shell deactivated nationality window java at org eclipse swt widgets person handle event person java at org eclipse swt widgets artwork send event artwork java at org eclipse swt widgets person send event person java at org eclipse swt widgets person run deferred events person java at org eclipse swt widgets person read and dispatch person java at org eclipse swt widgets organization open organization java at org eclipse ui internal editors text organization query file organization java at org eclipse ui internal editors text organization run organization java at org eclipse ui internal editors text organization run organization java at org eclipse ui internal organization run with event organization java at org eclipse ui internal wwin organization run with event wwin organization java at org eclipse jface action organization handle person selection organization java at org eclipse jface action organization access organization java at org eclipse jface action organization handle event organization java at org eclipse swt widgets artwork send event artwork java at org eclipse swt widgets person send event person java at org eclipse swt widgets person run deferred events person java at org eclipse swt widgets person read and dispatch person java at org eclipse ui internal nationality run event loop nationality java at org eclipse ui internal nationality run organization nationality java at org eclipse ui internal nationality create and run nationality nationality java at org eclipse ui platform organization create and run nationality platform organization java at org eclipse ui internal ide product run product java at org eclipse core internal runtime organization run organization java at org eclipse core runtime adaptor organization run organization java at org eclipse core runtime adaptor organization run organization java at sun reflect person person invoke person at sun reflect person person invoke unknown source at sun reflect delegating person person invoke unknown source at java lang reflect person invoke unknown source at org eclipse core launcher person basic run person java at org eclipse core launcher person run person java at org eclipse core launcher person main person java dynamic libraries xp usr java re bin java rw usr java re bin java xp lib ld so rw lib ld so xp usr java re lib native threads libhpi so rw usr java re lib native threads libhpi so xp lib libnss files so rw lib libnss files so usr eclipse simple plugins org eclipse ui workbench ompatibility compatibility jar xp lib libpthread so rw lib libpthread so xp lib libdl so rw lib libdl so xp lib libc so rw lib libc so xp usr java re lib client libjvm so rw fa usr java re lib client libjvm so xp lib libnsl so ba rw lib libnsl so bc dd xp lib libm so dd de rw lib libm so de rw tmp hsperfdata ykuck usr java re lib jce jar fd xp lib libnss nisplus so fd fe rw lib libnss nisplus so ff xp lib libnss nis so rw lib libnss nis so xp usr java re lib libverify so rw usr java re lib libverify so xp usr java re lib libjava so rw usr java re lib libjava so xp usr java re lib libzip so rw usr java re lib libzip so usr java re lib rt jar usr java re lib sunrsasign jar usr java re lib jsse jar ba usr java re lib charsets jar usr java re lib ext dnsns jar usr eclipse simple startup jar usr eclipse simple plugins org eclipse osgi util util jar usr eclipse simple plugins org eclipse swt motif ws motif swt gtk jar usr eclipse simple plugins org eclipse ui ui ja fd usr java re lib ext ldapsec jar fd usr java re lib ext localedata jar usr java re lib ext sunjce provider jar usr eclipse simple plugins org eclipse osgi cor jar usr eclipse simple plugins org eclipse osgi con sole jar usr eclipse simple plugins org eclipse osgi osg jar usr eclipse simple plugins org eclipse osgi res olver jar usr eclipse simple plugins org eclipse osgi def ault person jar usr eclipse simple plugins org eclipse osgi ecl ipse person jar usr eclipse simple plugins org eclipse update configu rator configurator jar usr eclipse simple plugins org eclipse core runtime runtime jar ca usr eclipse simple plugins org eclipse osgi services services jar ca usr eclipse simple plugins org eclipse ui ide de jar usr eclipse simple plugins org eclipse core runtime ompatibility compatibility jar ca usr eclipse simple plugins org eclipse ui workbench workbench jar ca cab usr eclipse simple plugins org eclipse jface jf ace jar cab cac usr eclipse simple plugins org eclipse swt motif ws motif swt mozilla jar cac cbc usr eclipse simple plugins org eclipse swt motif ws motif swt jar cbc cc xp usr eclipse simple plugins org eclipse swt motif os linux libswt motif so cc cc rw usr eclipse simple plugins org eclipse swt motif os linux libswt motif so cc cd xp usr eclipse simple lib xm so cd cda rw usr eclipse simple lib xm so cda cdb xp usr java re lib libnet so cdb cdb rw usr java re lib libnet so cdb cdb usr eclipse simple plugins org eclipse core resources linux resources linux jar cdb ce xp usr lib lib so ce ce rw usr lib lib so ce cea xp usr lib lib person so cea cea rw usr lib lib person so cea ceea xp usr lib lib person so ceea ceee rw usr lib lib person so ceee cef xp usr lib lib person so cef cef rw usr lib lib person so cef cefa xp usr lib lib personst so cefa cefc rw usr lib lib personst so cefc cf xp usr lib lib country so cf cf rw usr lib lib country so cf cf xp usr lib lib organization so cf cf rw usr lib lib organization so cf cf xp usr java re lib libnio so cf cf rw usr java re lib libnio so usr eclipse simple plugins org eclipse osgi console jar usr eclipse simple plugins org eclipse osgi osgi jar usr eclipse simple plugins org eclipse osgi resolver jar usr eclipse simple plugins org eclipse osgi default person jar usr eclipse simple plugins org eclipse osgi eclipse person jar usr eclipse simple plugins org eclipse update configurator configurator jar usr eclipse simple plugins org eclipse core runtime runtim jar ca usr eclipse simple plugins org eclipse osgi services servi ces jar ca usr eclipse simple plugins org eclipse ui ide ide jar usr eclipse simple plugins org eclipse core runtime compatibilit compatibility jar ca usr eclipse simple plugins org eclipse ui workbench workbe nch jar ca cab usr eclipse simple plugins org eclipse jface jface jar cab cac usr eclipse simple plugins org eclipse swt motif ws motif swt mozilla jar cac cbc usr eclipse simple plugins org eclipse swt motif ws motif swt jar cbc cc xp usr eclipse simple plugins org eclipse swt motif os linux libswt motif so cc cc rw usr eclipse simple plugins org eclipse swt motif os linux libswt motif so cc cd xp usr eclipse simple lib xm so cd cda rw usr eclipse simple lib xm so cda cdb xp usr java re lib libnet so cdb cdb rw usr java re lib libnet so cdb cdb usr eclipse simple plugins org eclipse core resources linux resources linux jar cdb ce xp usr lib lib so ce ce rw usr lib lib so ce cea xp usr lib lib person so cea cea rw usr lib lib person so cea ceea xp usr lib lib person so ceea ceee rw usr lib lib person so ceee cef xp usr lib lib person so cef cef rw usr lib lib person so cef cefa xp usr lib lib personst so cefa cefc rw usr lib lib personst so cefc cf xp usr lib lib country so cf cf rw usr lib lib country so cf cf xp usr lib lib organization so cf cf rw usr lib lib organization so cf cf xp usr java re lib libnio so cf cf rw usr java re lib libnio so cf cfbb usr eclipse simple plugins org eclipse core resources reso urces jar cfbb cfbc xp usr eclipse simple plugins org eclipse core resources linux os linux libcore so cfbc cfbd rw usr eclipse simple plugins org eclipse core resources linux os linux libcore so cfbd cfcc usr eclipse simple plugins org eclipse help help jar cfcc cfda usr eclipse simple plugins org eclipse ui views views jar cfda be usr eclipse simple plugins org eclipse team cvs ui teamcvs ui jar be ea usr eclipse simple plugins org eclipse team core team jar ea usr eclipse simple plugins org eclipse team cvs core cvs ar usr eclipse simple plugins org eclipse team ui teamui jar usr eclipse simple plugins org eclipse ui console console jar usr eclipse simple plugins org eclipse text text jar usr eclipse simple plugins org eclipse update scheduler sc heduler jar ff usr eclipse simple plugins org eclipse core filebuffers fi lebuffers jar usr eclipse simple plugins org eclipse compare compare jar usr eclipse simple plugins org eclipse ui externaltools ex ternaltools jar usr eclipse simple plugins org eclipse debug ui dtui jar usr eclipse simple plugins org eclipse debug core dtcore ar usr eclipse simple plugins org eclipse ui intro intro jar usr eclipse simple plugins org eclipse ui forms forms jar usr eclipse simple plugins org eclipse update core updatec ore jar usr eclipse simple plugins org eclipse jface text jfacetex jar usr eclipse simple plugins org eclipse ui editors editors jar usr eclipse simple plugins org eclipse ui workbench texteditor texteditor jar heap at facility def new generation total used eden space used fe from space used to space used tenured generation total used the space used compacting perm gen total used the space used local time wed mar elapsed time the exception above was detected in native code outside the vm person person spot tm client vm mixed mode\n",
      "***Description***: get very frequent crash with and always in the same place usually when opening dialog at the moment thats after time of using eclipse so its unusable to me organization is country jdk dual processor its not always in libc sometimes its in pthread but its always in person sometimes it knows which library function have read bug which is now closed but none of the fixes there work have tried in vain to upgrade to organization but will have to replace the whole of to do it so am stuck with organization bit of trace is organization occurred at pc bf function null bf product lib libc so note we are unable to locate the function name symbol for the error just occurred please refer to release documentation for possible reason and solutions current person thread at org eclipse swt internal motif organization person person at org eclipse swt widgets person set text person java\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: bundles could not be found in rt ws\n",
      "***Title***: possibility to specify dependencies to plugins in the development workspace\n",
      "***Description***: hi have some plugin projects in my workspace now start new runtime ws in this new workspace tried to create new organization with dependencies to the projects in my workspace organization told me that it is not able to find them the functionality provided by the ws plugins is available\n",
      "***Description***: when developing plugin that consists of several projects with dependencies between these projects it is kind of cumbersome to launch or debug this plugin because when launching or debugging the plugin as an organization application the dependencies to other plugins that reside in the development workspace will not be resolved the best workaround is to import the other projects on which the plugin depends into the organization application runtime workspace without physically copying the project files this is somewhat inconvenient though\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: person report id exp\n",
      "***Title***: aioobe on compare with another branch or version\n",
      "***Description***: version svn client org eclipse team svn connector svnkit svn svnkit http svnkit com jvm properties java vendor organization sun java launcher organization org osgi supports framework extension true sun management compiler organization https proxy host samba osgi framework beginningstartlevel https proxy organization true os name product osgi ws win sun desktop windows java vm specification vendor organization java runtime version org apache commons logging simplelog log httpclient wire header off osgi instance area file workspace http proxy facilityuser name darren hodges org osgi framework language en user language en org osgi framework processor osgi syspath product eclipse plugins sun boot library path organization java jdk jre bin osgi manifest cache organization eclipse configuration org eclipse osgi manifests osgi compatibility bootdelegation true eof eof java version org osgi framework os name product user timezone organization sun arch data model http non person localhost samba samba mionegroup com au svn svn mionegroup com au java endorsed dirs organization java jdk jre lib endorsed sun cpu isalist pentium pro mmx pentium pro pentium mmx pentium sun jnu encoding organizationfile encoding pkg sun io org osgi framework vendor organization file separator java specification name person java class version user country organization org eclipse equinox launcher splash location product eclipse plugins org eclipse platform splash bmp java home organization java jdk jre osgi os win eclipse commands os win ws win arch showsplash launcher organization eclipse eclipse exe name organization launcher library organization eclipse plugins org eclipse equinox launcher win win eclipse dll startup organization eclipse plugins org eclipse equinox launcher jar exitdata df vm organization java jdk bin javaw exe java vm info mixed mode osgi splash organization eclipse plugins org eclipse platform splash bmp os version https proxy facilityosgi arch https non person localhost samba samba mionegroup com au svn svn mionegroup com au path separator java vm version org osgi supports framework fragment true user variant osgi framework shape jar http proxy organization true osgi instance area default file organization and organizationtings darren hodges workspace java awt printerjob sun awt windows organization sun io unicode encoding organization org osgi framework version awt toolkit sun awt windows organization osgi install area file organization eclipse osgi framework file product eclipse plugins org eclipse osgi jar user home organization and organizationtings darren hodges osgi bundlestore organization eclipse configuration org eclipse osgi bundles osgi splash country platform base plugins org eclipse platform osgi nl en organization java specification vendor organization java library path organization java jdk bin windows sun person windows system windows windows system windows windows system wbem organization intel dmix organization ati technologies ati ace organization common files roxio shared dllshared organization slik svn bin organization quick organization qtsystem organization tortoise svn bin java vendor url http java sun com org osgi framework os version eclipse start organization java vm vendor organization java runtime name organization java class path organization eclipse plugins org eclipse equinox launcher jar org apache commons logging simplelog log org apache commons httpclient off eclipse vm organization java jdk bin javaw exe java vm specification name person java vm specification version sun cpu endian little sun os patch level organization org apache commons logging simplelog defaultlog off java io tmpdir docume darren hod locals temp java vendor url bug http java sun com cgi bin bugreport cgi http proxy host samba eclipse product org eclipse platform ide os arch java awt graphicsenv sun awt organization java ext dirs organization java jdk jre lib ext windows sun java lib ext user dir organization eclipse org osgi supports framework requirebundle true line separator java vm name person vm org apache commons logging person org apache commons logging impl simple person eclipse ee install verify false file encoding organizationosgi framework version eclipse build id eclipse vmargs person use parallel gc xx perm size xx person size xx cmsclass unloading enabled xx cmsperm gen sweeping enabled jar organization eclipse plugins org eclipse equinox launcher jar java specification version org osgi framework executionenvironment osgi personosgi personjre se se se se java se osgi logfile workspace metadata log osgi configuration area file organization eclipse configuration java lang no such person error org eclipse team svn core connector svnchange organization init ljava lang person lang string ijjjljava lang string iiiizzljava lang person lang person lang person lang string jzljava lang person lang person lang string product eclipse team svn core connector person jjiljava lang string java lang no such person error org eclipse team svn core connector svnchange organization init ljava lang person lang string ijjjljava lang string iiiizzljava lang person lang person lang person lang string jzljava lang person lang person lang string product eclipse team svn core connector person jjiljava lang string at org tigris subversion javahl organization convert organization java at org tigris subversion javahl organization do organization organization java at org tmatesoft svn core javahl svnclient impl handle organization svnclient impl java at org tmatesoft svn core internal wc svnorganization editor get dir organization svnorganization editor java at org tmatesoft svn core internal wc svnorganization editor close edit svnorganization editor java at org tmatesoft svn core wc svnorganization client do organization svnorganization client java at org tmatesoft svn core javahl svnclient impl status svnclient impl java at org tmatesoft svn core javahl svnclient impl status svnclient impl java at org polarion team svn connector svnkit svnkit connector status svnkit connector java at org eclipse team svn core extension factory thread name modifier status thread name modifier java at org eclipse team svn core utility organization status organization java at org eclipse team svn core utility organization get svninfo for not connected organization java at org eclipse team svn core organization upload repository resource organization java at org eclipse team svn core organization connect to project organization java at org eclipse team svn core organization get repository resource organization java at org eclipse team svn core svnstorage organization repository resource svnremote storage java at org eclipse team svn ui history nationality page show history nationality page java at org eclipse team svn ui history nationality page input organization nationality page java at org eclipse team ui history organization set input organization java at org eclipse team internal ui history organization organization for generic history view java at org eclipse team internal ui history organization history for generic history view java at org eclipse team internal ui history organization history for generic history view java at org eclipse team svn ui operation organization run organization java at org eclipse swt widgets organization sync exec organization java at org eclipse ui internal organizationorganization sync exec organizationorganization java at org eclipse swt widgets person sync exec person java at org eclipse team svn ui operation organization run impl organization java at org eclipse team svn core operation organization run organization java at org eclipse team svn core operation personged operation run personged operation java at org eclipse team svn core utility organization do task organization java at org eclipse team svn core utility organization do task external organization java at org eclipse team svn ui utility organization cancellable operation wrapper run organization cancellable operation wrapper java at org eclipse team svn ui utility organization run organization java at org eclipse swt custom organization show while organization java at org eclipse team svn ui utility organization do task busy organization java at org eclipse team svn ui action organization run busy organization java at org eclipse team svn ui action local organization run impl organization java at org eclipse team svn ui action organization run impl organization java at org eclipse team svn core operation organization run organization java at org eclipse team svn core operation personged operation run personged operation java at org eclipse team svn core utility organization do task organization java at org eclipse team svn core utility organization do task external organization java at org eclipse team svn core utility organization do task external organization java at org eclipse team svn ui action organization execute organization java at org eclipse team internal ui actions organization run organization java at org eclipse team internal ui actions organization run with event organization java at org eclipse ui internal organization run with event organization java at org eclipse jface action action contribution item handle person selection action contribution item java at org eclipse jface action action contribution item access action contribution item java at org eclipse jface action action contribution item handle event action contribution item java at org eclipse swt widgets organization send event organization java at org eclipse swt widgets person send event person java at org eclipse swt widgets person run deferred events person java at org eclipse swt widgets person read and dispatch person java at org eclipse ui internal nationality run event loop nationality java at org eclipse ui internal nationality run organization nationality java at org eclipse ui internal nationality access nationality java at org eclipse ui internal nationality run nationality java at org eclipse core databinding observable country run with organization country java at org eclipse ui internal nationality create and run nationality nationality java at org eclipse ui platform organization create and run nationality platform organization java at org eclipse ui internal ide application ideapplication start ideapplication java at org eclipse equinox internal app organization app handle run organization app handle java at org eclipse core runtime internal adaptor organization app launcher run application organization app launcher java at org eclipse core runtime internal adaptor organization app launcher start organization app launcher java at org eclipse core runtime adaptor organization starter run organization starter java at org eclipse core runtime adaptor organization starter run organization starter java at sun reflect nationality person person invoke nationality person at sun reflect nationality person person invoke nationality person person java at sun reflect delegating person person invoke delegating person person java at java lang reflect person invoke person java at org eclipse equinox launcher person invoke framework person java at org eclipse equinox launcher person basic run person java at org eclipse equinox launcher person run person java at org eclipse equinox launcher person main person java\n",
      "***Description***: aioobe on compare with another branch or version\n",
      "***similar = 0\n",
      "########################\n",
      "***Title***: person project imported from organization compiles with generated makefiles but shows lots of errors in organization\n",
      "***Title***: objectivity develop objectivity store\n",
      "***Description***: apologize ahead of time if this is known problem may be similar to but found way to reliably reproduce symptoms environment juno cdt organization create simple executable hello world project person gcc organization shows project with standard organization and src sub directory add project to organization artifacts checked in hello src hello cproject hello project and hello src hello cpp delete project from local workspace import project back from organization nb used find projects in the children option hello project appears in organization but the organization section is missing project compiles and executes fine but the organization shows lot of errors due to missing includes note repeated this exact procedure using indigo cdt organization and the organization appeared correctly in the imported project so far have been unable to find suitable workaround for juno any suggestions would be welcome idmc\n",
      "***Description***: objectivity develop objectivity store\n",
      "***similar = 0\n",
      "########################\n",
      "CPU times: user 89.3 ms, sys: 0 ns, total: 89.3 ms\n",
      "Wall time: 88.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "baseline.display_batch(baseline.train_data, baseline.dup_sets_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 113554'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, GLOVE_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(GLOVE_DIR, 'glove.42B.300d.txt')\n",
    "    f = open(embed_path, 'rb')\n",
    "    #num_lines = sum(1 for line in open(embed_path, 'rb'))\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(tokens[1:], dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab098182f3a24e5182a7fd3a451354ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285bc26db3904add9e520d72b3b96f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113554), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 43s, sys: 4.57 s, total: 1min 48s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, GLOVE_DIR=GLOVE_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating for each epoch at same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods train experiment siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.retrieval import Retrieval\n",
    "from annoy import AnnoyIndex\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f517bb01ec1450594208eb2908b49b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=321483), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbe99ed22864a1f8886758f5b8b143c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39523), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "retrieval = Retrieval()\n",
    "\n",
    "path = 'data/processed/{}'.format(DOMAIN)\n",
    "path_buckets = 'data/normalized/{}/{}.csv'.format(DOMAIN, DOMAIN)\n",
    "path_train = 'data/processed/{}/train.txt'.format(DOMAIN)\n",
    "path_test = 'data/processed/{}/test.txt'.format(DOMAIN)\n",
    "\n",
    "experiment.retrieval(retrieval, baseline, number_of_columns_info, DOMAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a555a64b48433d8cb7c55772ad436c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read and create the test queries duplicate\n",
    "experiment.create_queries(path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795de7bd29e44b3b8983f5daa8d44255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=321483), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer',\n",
    "                                  weights=[embeddings],\n",
    "                                  embeddings_constraint=MaxNorm(max_value=1, axis=0),\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI074wU4Y13y"
   },
   "source": [
    "### CNN with filter 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "h6YJU9GtFTyq",
    "outputId": "f85cf105-1fd6-491d-d969-7e6936f32739",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "\n",
    "def cnn_model(embedding_layer, max_sequence_length):\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length,), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None,), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "    # best combination filter (3, 4, 5) e 128 e 256\n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    n_filters = 64\n",
    "\n",
    "    for index, filter_size in enumerate(filter_sizes):\n",
    "        l_conv = Conv1D(filters=n_filters, kernel_size=filter_size)(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(pool_size=filter_size)(l_conv) # index+1\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "    # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "    #conv = Conv1D(filters=n_filters * 3, kernel_size=3)(l_merge)\n",
    "    layer = GlobalAveragePooling1D()(l_merge)\n",
    "    #layer = Flatten()(l_merge)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "    #layer = LeakyReLU()(layer)\n",
    "\n",
    "    cnn_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureCNNGenerationModel') # inputs=visible\n",
    "\n",
    "    return cnn_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr6ObTXiaALH"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "vC7MQXEsaCeG",
    "outputId": "65e647a9-c5d3-4009-b8a4-2e2d97b52684"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, GRU, Dropout, Bidirectional, GlobalAveragePooling1D\n",
    "\n",
    "def lstm_model(embedding_layer, max_sequence_length):\n",
    "    number_lstm_units = 50\n",
    "    rate_drop_lstm = 0\n",
    "    recurrent_dropout = 0\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None, ), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Creating LSTM Encoder\n",
    "#     lstm_layer = Bidirectional(LSTM(number_lstm_units, return_sequences=True), # dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm \n",
    "#                                merge_mode='ave')\n",
    "\n",
    "    lstm_layer = LSTM(number_lstm_units, return_sequences=True)(embedded_sequences)\n",
    "    layer = LSTM(number_lstm_units)(lstm_layer)\n",
    "\n",
    "    #layer = lstm_layer(embedded_sequences)\n",
    "    #layer = GlobalAveragePooling1D()(layer)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "\n",
    "    lstm_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureLstmGenerationModel') # inputs=visible\n",
    "\n",
    "    return lstm_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "    \n",
    "class MarginLoss(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        pos = inputs[0]\n",
    "        neg = inputs[1]\n",
    "        loss = self.margin_loss(pos, neg)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        return inputs\n",
    "        \n",
    "    def margin_loss(self, pos, neg):\n",
    "        margin = K.constant(1.0)\n",
    "        return K.sum(K.maximum(0.0, margin - pos + neg))\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.sum(K.maximum(0.0, margin - pos + neg))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "  \n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    #     bug_feature_output = Activation('tanh')(bug_feature_output)\n",
    "    \n",
    "    # Bug representation layer\n",
    "    # bug_feature_output = Dense(300, activation='tanh')(bug_feature_output)\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    \n",
    "    # Cosine\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3 * decay_lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer=optimizer, loss=custom_margin_loss, metrics=[pos_distance, neg_distance, custom_margin_loss])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 43)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_pos (InputLayer)          (None, 43)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_pos (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_neg (InputLayer)          (None, 43)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_neg (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          34171900    title_in[0][0]                   \n",
      "                                                                 title_pos[0][0]                  \n",
      "                                                                 title_neg[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          34316292    desc_in[0][0]                    \n",
      "                                                                 desc_pos[0][0]                   \n",
      "                                                                 desc_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 900)          0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureLstmGenerationModel[2][0] \n",
      "                                                                 FeatureCNNGenerationModel[2][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 900)          0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureLstmGenerationModel[3][0] \n",
      "                                                                 FeatureCNNGenerationModel[3][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances (Lambda)        (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 68,993,092\n",
      "Trainable params: 860,692\n",
      "Non-trainable params: 68,132,400\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 0.81, MarginLoss: 0.81, pos_cosine: 0.86, neg_cosine: 0.67\n",
      "Epoch: 2 Loss: 0.83, MarginLoss: 0.83, pos_cosine: 0.84, neg_cosine: 0.67\n",
      "Epoch: 3 Loss: 0.79, MarginLoss: 0.79, pos_cosine: 0.84, neg_cosine: 0.63\n",
      "Epoch: 4 Loss: 0.79, MarginLoss: 0.79, pos_cosine: 0.85, neg_cosine: 0.64\n",
      "Epoch: 5 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.85, neg_cosine: 0.61\n",
      "Epoch: 6 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.87, neg_cosine: 0.58\n",
      "Epoch: 7 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.82, neg_cosine: 0.58\n",
      "Epoch: 8 Loss: 0.73, MarginLoss: 0.73, pos_cosine: 0.82, neg_cosine: 0.55\n",
      "Epoch: 9 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.82, neg_cosine: 0.54\n",
      "Epoch: 10 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.85, neg_cosine: 0.53\n",
      "Epoch: 11 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.82, neg_cosine: 0.54\n",
      "Epoch: 12 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.82, neg_cosine: 0.53\n",
      "Epoch: 13 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.84, neg_cosine: 0.50\n",
      "Epoch: 14 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.84, neg_cosine: 0.51\n",
      "Epoch: 15 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.84, neg_cosine: 0.51\n",
      "Epoch: 16 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.84, neg_cosine: 0.54\n",
      "Epoch: 17 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.84, neg_cosine: 0.51\n",
      "Epoch: 18 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.79, neg_cosine: 0.51\n",
      "Epoch: 19 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.85, neg_cosine: 0.50\n",
      "Epoch: 20 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.83, neg_cosine: 0.51\n",
      "Epoch: 21 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.85, neg_cosine: 0.52\n",
      "Epoch: 22 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.83, neg_cosine: 0.49\n",
      "Epoch: 23 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.85, neg_cosine: 0.52\n",
      "Epoch: 24 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.88, neg_cosine: 0.48\n",
      "Epoch: 25 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.86, neg_cosine: 0.52\n",
      "Epoch: 26 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.87, neg_cosine: 0.51\n",
      "Epoch: 27 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.86, neg_cosine: 0.51\n",
      "Epoch: 28 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.85, neg_cosine: 0.50\n",
      "Epoch: 29 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.85, neg_cosine: 0.49\n",
      "Epoch: 30 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.87, neg_cosine: 0.51\n",
      "Epoch: 31 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.85, neg_cosine: 0.45\n",
      "Epoch: 32 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.83, neg_cosine: 0.49\n",
      "Epoch: 33 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.86, neg_cosine: 0.48\n",
      "Epoch: 34 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.87, neg_cosine: 0.48\n",
      "Epoch: 35 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.87, neg_cosine: 0.49\n",
      "Epoch: 36 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.85, neg_cosine: 0.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.88, neg_cosine: 0.52\n",
      "Epoch: 38 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.87, neg_cosine: 0.51\n",
      "Epoch: 39 Loss: 0.73, MarginLoss: 0.73, pos_cosine: 0.80, neg_cosine: 0.53\n",
      "Epoch: 40 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.87, neg_cosine: 0.50\n",
      "Epoch: 41 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.89, neg_cosine: 0.49\n",
      "Epoch: 42 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.86, neg_cosine: 0.49\n",
      "Epoch: 43 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.86, neg_cosine: 0.50\n",
      "Epoch: 44 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.89, neg_cosine: 0.49\n",
      "Epoch: 45 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.87, neg_cosine: 0.51\n",
      "Epoch: 46 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.88, neg_cosine: 0.49\n",
      "Epoch: 47 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.89, neg_cosine: 0.49\n",
      "Epoch: 48 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.87, neg_cosine: 0.51\n",
      "Epoch: 49 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.86, neg_cosine: 0.49\n",
      "Epoch: 50 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.88, neg_cosine: 0.53\n",
      "Epoch: 51 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.85, neg_cosine: 0.48\n",
      "Epoch: 52 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.90, neg_cosine: 0.51\n",
      "Epoch: 53 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.89, neg_cosine: 0.47\n",
      "Epoch: 54 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.90, neg_cosine: 0.47\n",
      "Epoch: 55 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.84, neg_cosine: 0.49\n",
      "Epoch: 56 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.86, neg_cosine: 0.51\n",
      "Epoch: 57 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.90, neg_cosine: 0.50\n",
      "Epoch: 58 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.89, neg_cosine: 0.54\n",
      "Epoch: 59 Loss: 0.55, MarginLoss: 0.55, pos_cosine: 0.93, neg_cosine: 0.48\n",
      "Epoch: 60 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.91, neg_cosine: 0.49\n",
      "Epoch: 61 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.86, neg_cosine: 0.47\n",
      "Epoch: 62 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.90, neg_cosine: 0.48\n",
      "Epoch: 63 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.89, neg_cosine: 0.47\n",
      "Epoch: 64 Loss: 0.54, MarginLoss: 0.54, pos_cosine: 0.90, neg_cosine: 0.44\n",
      "Epoch: 65 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.92, neg_cosine: 0.51\n",
      "Epoch: 66 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.89, neg_cosine: 0.51\n",
      "Epoch: 67 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.89, neg_cosine: 0.49\n",
      "Epoch: 68 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.91, neg_cosine: 0.55\n",
      "Epoch: 69 Loss: 0.55, MarginLoss: 0.55, pos_cosine: 0.92, neg_cosine: 0.47\n",
      "Epoch: 70 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.88, neg_cosine: 0.55\n",
      "Epoch: 71 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.91, neg_cosine: 0.48\n",
      "Epoch: 72 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.89, neg_cosine: 0.52\n",
      "Epoch: 73 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.91, neg_cosine: 0.50\n",
      "Epoch: 74 Loss: 0.54, MarginLoss: 0.54, pos_cosine: 0.91, neg_cosine: 0.44\n",
      "Epoch: 75 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.92, neg_cosine: 0.52\n",
      "Epoch: 76 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.89, neg_cosine: 0.52\n",
      "Epoch: 77 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.92, neg_cosine: 0.52\n",
      "Epoch: 78 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.92, neg_cosine: 0.50\n",
      "Epoch: 79 Loss: 0.55, MarginLoss: 0.55, pos_cosine: 0.92, neg_cosine: 0.47\n",
      "Epoch: 80 Loss: 0.53, MarginLoss: 0.53, pos_cosine: 0.92, neg_cosine: 0.45\n",
      "Epoch: 81 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.92, neg_cosine: 0.52\n",
      "Epoch: 82 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.93, neg_cosine: 0.51\n",
      "Epoch: 83 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.91, neg_cosine: 0.50\n",
      "Epoch: 84 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.92, neg_cosine: 0.50\n",
      "Epoch: 85 Loss: 0.55, MarginLoss: 0.55, pos_cosine: 0.92, neg_cosine: 0.47\n",
      "Epoch: 86 Loss: 0.50, MarginLoss: 0.50, pos_cosine: 0.93, neg_cosine: 0.42\n",
      "Epoch: 87 Loss: 0.56, MarginLoss: 0.56, pos_cosine: 0.91, neg_cosine: 0.46\n",
      "Epoch: 88 Loss: 0.52, MarginLoss: 0.52, pos_cosine: 0.95, neg_cosine: 0.47\n",
      "Epoch: 89 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.92, neg_cosine: 0.50\n",
      "Epoch: 90 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.90, neg_cosine: 0.49\n",
      "Epoch: 91 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.88, neg_cosine: 0.49\n",
      "Epoch: 92 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.91, neg_cosine: 0.55\n",
      "Epoch: 93 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.94, neg_cosine: 0.50\n",
      "Epoch: 94 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.90, neg_cosine: 0.49\n",
      "Epoch: 95 Loss: 0.52, MarginLoss: 0.52, pos_cosine: 0.92, neg_cosine: 0.45\n",
      "Epoch: 96 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.92, neg_cosine: 0.50\n",
      "Epoch: 97 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.91, neg_cosine: 0.50\n",
      "Epoch: 98 Loss: 0.56, MarginLoss: 0.56, pos_cosine: 0.93, neg_cosine: 0.49\n",
      "Epoch: 99 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.93, neg_cosine: 0.52\n",
      "Epoch: 100 Loss: 0.55, MarginLoss: 0.55, pos_cosine: 0.93, neg_cosine: 0.48, recall@25: 0.43\n",
      "Saved model 'modelos/model_baseline_feature_100epochs_64batch(eclipse).h5' to disk\n",
      "Best_epoch=86, Best_loss=0.50, Recall@25=0.43\n",
      "CPU times: user 1min 47s, sys: 9.55 s, total: 1min 57s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False)\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False)\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    mlp_model\n",
    "'''\n",
    "desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "title_feature_model = lstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = baseline.batch_iterator(baseline.train_data, baseline.dup_sets_train, batch_size, 1)\n",
    "    train_batch = [train_input_sample['title'], train_input_sample['description'], train_input_sample['info'],\n",
    "                   train_input_pos['title'], train_input_pos['description'], train_input_pos['info'], \n",
    "                   train_input_neg['title'], train_input_neg['description'], train_input_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _ = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets)\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[3]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['278531:273691|42957:0.2278715968132019,374789:-0.06542181968688965,399000:-0.07143187522888184,331485:-0.07776987552642822,336080:-0.07781922817230225,44512:-0.08853280544281006,342193:-0.09060001373291016,209474:-0.1034008264541626,218120:-0.11373674869537354,222610:-0.11375200748443604,309100:-0.11530506610870361,259990:-0.11662638187408447,260043:-0.11678850650787354,249310:-0.11685335636138916,246226:-0.11685991287231445,268387:-0.11686825752258301,278598:-0.11687815189361572,256910:-0.11688601970672607,268159:-0.11689376831054688,269615:-0.11699354648590088,280259:-0.11707520484924316,293474:-0.11807286739349365,305429:-0.11940789222717285,365799:-0.12011206150054932,57174:-0.12328386306762695',\n",
       " '62806:58722|69626:0.9915389027446508,49179:0.9910320397466421,89739:0.9897751901298761,45206:0.9870161172002554,70398:0.9845137167721987,65098:0.9777631647884846,41231:0.9762147311121225,58722:0.9728733766824007,73226:0.9050467610359192,66836:0.9000180140137672,59638:0.856286346912384,53095:0.8405398726463318,40322:0.8405216187238693,50989:0.8404744118452072,57743:0.8403951972723007,43842:0.8402725160121918,61872:0.8395599722862244,56870:0.8210323750972748,53727:0.8153755515813828,51075:0.8153498619794846,68838:0.8153447508811951,62854:0.8153398782014847,49896:0.8153331577777863,70827:0.815325990319252,52921:0.8153136372566223',\n",
       " '151116:147467|148706:0.9930058210156858,193981:0.9926035683602095,160967:0.9925790322013199,142538:0.9924836191348732,108556:0.9921380989253521,146099:0.9919407311826944,142204:0.9909451119601727,156357:0.9419071599841118,153766:0.9402544349431992,151743:0.9397098869085312,124281:0.8922104686498642,124138:0.8920796290040016,157506:0.8920549675822258,122639:0.8916594162583351,107377:0.8910274356603622,124953:0.8810307905077934,127658:0.8796040192246437,135088:0.8778003603219986,137614:0.8773491978645325,141387:0.8772507384419441,134690:0.8771300092339516,144225:0.8768889158964157,132158:0.8645704090595245,147846:0.8645675331354141,115061:0.8645669519901276',\n",
       " '90114:5337|86493:0.9892124589532614,102785:0.9889314025640488,82483:0.9876389037817717,109039:0.8512607663869858,98515:0.8306441307067871,125043:0.7850132882595062,63547:0.75503970682621,64611:0.7550365030765533,42847:0.7473224997520447,40333:0.747314989566803,41475:0.7472938299179077,65302:0.7472911477088928,43840:0.7472793757915497,45692:0.747276782989502,46122:0.7472676932811737,52475:0.7472590208053589,41738:0.7472555637359619,40929:0.7472502887248993,62407:0.7472443282604218,67540:0.7472303807735443,47006:0.7472159564495087,75717:0.7466203570365906,53579:0.7392055988311768,55062:0.7293829321861267,55029:0.7293668687343597',\n",
       " '90212:5337|84689:0.992500162217766,87829:0.9911390468478203,78551:0.988907715305686,75828:0.8417229503393173,78064:0.7898923754692078,87236:0.7475003004074097,67878:0.7473248839378357,134967:0.7452537417411804,74655:0.7447800636291504,76423:0.744772732257843,62749:0.7447557151317596,59839:0.7447358667850494,38970:0.7447343170642853,53399:0.7447293698787689,63002:0.7446809709072113,74566:0.744649201631546,48467:0.7446421682834625,57452:0.7445221841335297,141234:0.73650723695755,63753:0.7351101636886597,51473:0.7316990494728088,65952:0.7285511791706085,127279:0.7274191975593567,140490:0.7274044454097748,119056:0.7273882329463959',\n",
       " '114702:182662|78500:0.5640389621257782,113477:0.5574896037578583,50867:0.5290175378322601,136985:0.4619767665863037,173504:0.4401760697364807,184039:0.41592055559158325,158091:0.4158664345741272,243213:0.4142693281173706,147730:0.40879595279693604,159179:0.40745091438293457,108874:0.40734320878982544,240677:0.40631103515625,104615:0.4054902195930481,117152:0.39290040731430054,74802:0.3927012085914612,214788:0.3782072067260742,162624:0.37504446506500244,88960:0.3693990111351013,87335:0.36810189485549927,82697:0.3678992986679077,82700:0.3678487539291382,198413:0.3669508695602417,104130:0.3641258478164673,79114:0.36172693967819214,227779:0.3590434193611145',\n",
       " '49168:51735|46934:0.9951521372422576,41295:0.9950505904853344,61658:0.9950186004862189,70711:0.9947711750864983,50420:0.9947683825157583,57469:0.9946857988834381,62474:0.9946420639753342,59873:0.9945933949202299,52581:0.9942163554951549,92976:0.9941765004768968,50918:0.9939728565514088,64598:0.9938332196325064,46468:0.9938017805106938,53617:0.993442187551409,49999:0.9934161119163036,53425:0.9930661637336016,55651:0.9912266479805112,52720:0.9807640668004751,55657:0.9790155831724405,54928:0.975945333018899,77696:0.9413205310702324,55537:0.9412497766315937,50312:0.9412221275269985,43157:0.9411383047699928,53605:0.9394596442580223',\n",
       " '50950:51735|68026:0.9960532221011817,42080:0.9943826864473522,42511:0.9930114499293268,61592:0.9930092627182603,62293:0.9922532010823488,58586:0.9919114131480455,62586:0.9913787441328168,68702:0.9897321676835418,47267:0.9830645862966776,98080:0.9826556462794542,68129:0.9730114806443453,49576:0.943636704236269,44578:0.9403553828597069,57746:0.900026448071003,68696:0.8998518288135529,47525:0.880108155310154,59899:0.8792004287242889,57656:0.8788372352719307,49416:0.8773410245776176,65675:0.8548899739980698,70226:0.8539159595966339,49979:0.8291990011930466,46894:0.827519029378891,60114:0.8136208653450012,107252:0.779847040772438',\n",
       " '98399:98321|98321:0.8691795617341995,118891:0.6447206139564514,106295:0.5737748146057129,101262:0.573268860578537,115326:0.5676991939544678,91294:0.5578425526618958,97756:0.5301242768764496,102467:0.5298570096492767,104153:0.517824649810791,100441:0.5177536606788635,91857:0.5001565515995026,156346:0.5000854730606079,143246:0.4928860664367676,93535:0.4928281903266907,92426:0.48956799507141113,136954:0.48647648096084595,91740:0.4830321669578552,126755:0.4829863905906677,120018:0.4631519317626953,121305:0.46313393115997314,116398:0.46081990003585815,87474:0.4529740810394287,113886:0.44664132595062256,205004:0.4393746852874756,88135:0.4362460970878601',\n",
       " '16405:18748|12757:0.9949771827086806,16092:0.9949388145469129,5975:0.9947542268782854,8459:0.9942786958999932,7235:0.9938020734116435,12984:0.9931770851835608,12970:0.9926611962728202,8043:0.991076648235321,2882:0.9909883346408606,10949:0.9894451387226582,6926:0.9872434362769127,11116:0.985731846652925,25548:0.9851840641349554,6855:0.9747349806129932,19152:0.8857284486293793,19165:0.8855205774307251,6513:0.8773780912160873,2051:0.8773624300956726,16391:0.8773496150970459,8822:0.8773273080587387,18821:0.8773170337080956,16962:0.8772544488310814,19651:0.8769988492131233,16170:0.8769067898392677,2497:0.8739809542894363',\n",
       " '245784:214092|170890:0.6622198522090912,93343:0.6379742324352264,90255:0.626768559217453,89428:0.6262700259685516,82146:0.6262542307376862,232823:0.625982403755188,79808:0.6249556243419647,88824:0.6243813335895538,87604:0.6243803203105927,94087:0.6243487298488617,88883:0.6243423223495483,111106:0.624333918094635,82068:0.6242692172527313,162097:0.6242378950119019,76767:0.6240979731082916,79964:0.6231490969657898,92250:0.6162995100021362,311863:0.6081052720546722,133912:0.6022675037384033,150012:0.6021301746368408,77039:0.5846255421638489,77640:0.5774813294410706,123075:0.57479527592659,244536:0.567471832036972,70454:0.5635844767093658',\n",
       " '243073:214092|90255:0.6520142257213593,170890:0.6463800072669983,232823:0.6159532964229584,93343:0.6060392558574677,82146:0.6048794090747833,89428:0.6048722863197327,79808:0.6036801338195801,87604:0.6002203524112701,88824:0.6002129316329956,88883:0.6001900732517242,94087:0.6001840233802795,111106:0.6001788079738617,82068:0.6001090109348297,76767:0.5999780893325806,79964:0.5990307927131653,162097:0.5964804887771606,92250:0.5869918763637543,133912:0.5800317227840424,150012:0.5798743069171906,311863:0.5741674602031708,244536:0.5696817934513092,77640:0.5683744549751282,77039:0.5661620199680328,123075:0.545508474111557,149121:0.5453253984451294',\n",
       " '238522:214092|213139:0.9900046177208424,232823:0.8565839678049088,223481:0.8461028635501862,331621:0.8269511461257935,212565:0.6743936836719513,210304:0.614528626203537,243347:0.6111316680908203,164695:0.6104774475097656,186370:0.6104294657707214,160959:0.6099990606307983,235020:0.5900070369243622,213305:0.5900008678436279,160098:0.5899941027164459,239477:0.5899922847747803,230940:0.5899864137172699,268651:0.5899684429168701,240817:0.5899535119533539,231776:0.5897936820983887,236524:0.5841643512248993,240033:0.5768666565418243,233598:0.5768562853336334,236513:0.5768134891986847,245367:0.5764822065830231,236724:0.5764223635196686,207827:0.576115220785141',\n",
       " '273940:214092|213194:0.979623993858695,262651:0.9761570766568184,283503:0.9018504843115807,242388:0.9002641066908836,253060:0.875046618282795,260585:0.8750450313091278,256919:0.8750432208180428,267405:0.8750432059168816,260123:0.8750350549817085,255403:0.875021830201149,251605:0.8750175014138222,252232:0.8750055655837059,278886:0.8750023543834686,274385:0.8750020265579224,277714:0.8749694228172302,277193:0.8749588131904602,248758:0.8749570697546005,277314:0.8749481737613678,252714:0.8749262988567352,264553:0.8748941719532013,294986:0.8748874515295029,270280:0.8748539984226227,279671:0.8748332113027573,256169:0.8744582235813141,287234:0.8740614205598831',\n",
       " '260566:214092|232823:0.7298691272735596,243347:0.717056542634964,213139:0.6973423361778259,223481:0.663576066493988,331621:0.6393492519855499,213194:0.6306133270263672,262651:0.6306031048297882,348346:0.6204708516597748,279671:0.6068871319293976,294986:0.6068717837333679,278886:0.6068654656410217,252232:0.6068562567234039,277314:0.6068409979343414,264553:0.6068380773067474,260585:0.6068379282951355,260123:0.6068327724933624,274385:0.6068294644355774,251605:0.6068292558193207,256919:0.6068228185176849,256169:0.606820821762085,253060:0.6068204641342163,248758:0.6068117916584015,267405:0.6068108081817627,255403:0.6068066656589508,259687:0.6068019866943359',\n",
       " '32793:32633|33733:0.926656998693943,38016:0.9261877611279488,30971:0.8583724349737167,28818:0.8583085089921951,29923:0.8558174222707748,25382:0.8437431305646896,32206:0.843662217259407,32633:0.8413489162921906,38370:0.8041954636573792,28796:0.8041452318429947,32829:0.8010355979204178,32494:0.8010291308164597,28627:0.801016628742218,42703:0.8010075241327286,33452:0.8009115755558014,31899:0.8008052706718445,47995:0.7723062038421631,46418:0.7272185981273651,55374:0.7270092666149139,63374:0.7266721129417419,33936:0.7265740931034088,34297:0.7163966298103333,16036:0.7157835066318512,43285:0.7116878926753998,79706:0.7116568386554718',\n",
       " '33446:32633|38016:0.9237714186310768,33733:0.9234721139073372,30971:0.8568564504384995,28818:0.8566938787698746,29923:0.8539958894252777,32206:0.8424854427576065,25382:0.8422281295061111,32633:0.8399460017681122,28796:0.8033730536699295,38370:0.8029628545045853,42703:0.7998966127634048,32829:0.7998594790697098,33452:0.7998450249433517,28627:0.7998290956020355,32494:0.7998057454824448,31899:0.7996545881032944,47995:0.7712738513946533,46418:0.7264816462993622,55374:0.7261627018451691,63374:0.7257764935493469,33936:0.725724071264267,34297:0.7157592475414276,16036:0.7150262296199799,64951:0.7110050320625305,79706:0.710974782705307',\n",
       " '33526:32633|33733:0.9954091287218034,38016:0.99170296266675,30971:0.8884338885545731,28818:0.8883747607469559,29923:0.8697178214788437,25382:0.8676043599843979,32206:0.8675907403230667,28796:0.8582931309938431,38370:0.8582715690135956,32633:0.8580156117677689,32829:0.8495066165924072,28627:0.8494808673858643,32494:0.8494629561901093,42703:0.8494580239057541,33452:0.8492913544178009,31899:0.849285289645195,47995:0.7659794688224792,34297:0.7649804800748825,16036:0.7642617076635361,37862:0.7514213174581528,46418:0.7453375458717346,63374:0.7447921931743622,33936:0.7343983948230743,43285:0.7259645164012909,64951:0.72592893242836',\n",
       " '84509:81947|108074:0.9972974741831422,85833:0.9485732838511467,95317:0.9001093730330467,192530:0.8896649181842804,371292:0.7823968678712845,100464:0.7704888582229614,92891:0.7704198360443115,106101:0.7536426335573196,104413:0.7480949461460114,318108:0.6957185864448547,103070:0.6945143043994904,104001:0.6939413249492645,102822:0.6936383247375488,284272:0.6707642376422882,206680:0.6555226743221283,178598:0.6518295109272003,143553:0.6372546255588531,81751:0.6372539103031158,86337:0.6272924542427063,145590:0.6272924542427063,111279:0.6171181201934814,101860:0.6171064972877502,118330:0.5827701389789581,100667:0.5822741389274597,85296:0.5822597742080688',\n",
       " '355472:173732|147885:0.6206209361553192,178601:0.6130817830562592,171387:0.6130801737308502,178386:0.6130769550800323,167551:0.6130650341510773,177018:0.6130227148532867,159812:0.6107411086559296,87542:0.6094735264778137,113568:0.6058427393436432,165636:0.6030234396457672,333227:0.5867078900337219,351399:0.5846551954746246,36045:0.576027899980545,172436:0.5676043927669525,186533:0.5676020979881287,196479:0.5675998628139496,194395:0.5675908923149109,206776:0.5675769746303558,195040:0.5675519704818726,180305:0.5675384402275085,193030:0.5674863159656525,177431:0.5674210786819458,246693:0.5640130043029785,252744:0.5639791488647461,247838:0.5639320611953735']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('recall@25 last epoch:', 0.43)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Between 0-10 epochs recall@25 = 0.28\n",
    "    Between 0-20 epochs recall@25 = 0.32\n",
    "    Between 0-70 epochs recall@25 = ?\n",
    "    Between 0-100 epochs recall@25 = ?\n",
    "'''\n",
    "recall, exported_rank = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets)\n",
    "\n",
    "\"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loss=h.history['loss']\n",
    "# val_loss=h.history['val_loss']\n",
    "\n",
    "# plt.plot(loss, label='loss')\n",
    "# plt.plot(val_loss, label='val_loss')\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 7260\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_feature_100epochs_64batch(eclipse)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 43)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          34171900    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          34316292    desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "==================================================================================================\n",
      "Total params: 68,993,092\n",
      "Trainable params: 860,692\n",
      "Non-trainable params: 68,132,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/eclipse/exported_rank_baseline.txt'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.23,\n",
       " '2 - recall_at_10': 0.31,\n",
       " '3 - recall_at_15': 0.36,\n",
       " '4 - recall_at_20': 0.4,\n",
       " '5 - recall_at_25': 0.43}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Eclipse\n",
    "    With CNN print all embeddings zero and 2 epochs\n",
    "    {'1 - recall_at_5': 0.13,\n",
    "     '2 - recall_at_10': 0.18,\n",
    "     '3 - recall_at_15': 0.22,\n",
    "     '4 - recall_at_20': 0.24}\n",
    "     Without relu activation for each feature siamese in 100 epochs\n",
    "     {'1 - recall_at_5': 0.16,\n",
    "     '2 - recall_at_10': 0.23,\n",
    "     '3 - recall_at_15': 0.27,\n",
    "     '4 - recall_at_20': 0.31}\n",
    "     Without dense in the last layer with 100 epochs with embed trainable\n",
    "     {'1 - recall_at_5': 0.16,\n",
    "     '2 - recall_at_10': 0.22,\n",
    "     '3 - recall_at_15': 0.26,\n",
    "     '4 - recall_at_20': 0.3}\n",
    "      \n",
    "      {'1 - recall_at_5': 0.16,\n",
    "         '2 - recall_at_10': 0.22,\n",
    "         '3 - recall_at_15': 0.26,\n",
    "         '4 - recall_at_20': 0.29,\n",
    "         '5 - recall_at_25': 0.29}\n",
    "    With title (100 padding) and desc (500 padding) and batch refactored\n",
    "        {'1 - recall_at_5': 0.2,\n",
    "         '2 - recall_at_10': 0.26,\n",
    "         '3 - recall_at_15': 0.3,\n",
    "         '4 - recall_at_20': 0.33,\n",
    "         '5 - recall_at_25': 0.33}\n",
    "         \n",
    "         {'1 - recall_at_5': 0.2,\n",
    "         '2 - recall_at_10': 0.27,\n",
    "         '3 - recall_at_15': 0.31,\n",
    "         '4 - recall_at_20': 0.34,\n",
    "         '5 - recall_at_25': 0.34}\n",
    "         With recall in validation step and split 90 train 10 to test\n",
    "         {'1 - recall_at_5': 0.25,\n",
    "         '2 - recall_at_10': 0.32,\n",
    "         '3 - recall_at_15': 0.37,\n",
    "         '4 - recall_at_20': 0.4,\n",
    "         '5 - recall_at_25': 0.4}\n",
    "         With 200 epochs validation_recall@25 = 58, optimizer=Nadam\n",
    "         {'1 - recall_at_5': 0.26,\n",
    "         '2 - recall_at_10': 0.34,\n",
    "         '3 - recall_at_15': 0.39,\n",
    "         '4 - recall_at_20': 0.42,\n",
    "         '5 - recall_at_25': 0.42}\n",
    "         With 100 epochs validation_recall@25 = 52, optimizer=Adam\n",
    "         {'1 - recall_at_5': 0.23,\n",
    "         '2 - recall_at_10': 0.3,\n",
    "         '3 - recall_at_15': 0.34,\n",
    "         '4 - recall_at_20': 0.37,\n",
    "         '5 - recall_at_25': 0.37}\n",
    "        With 1000 epochs validation_recall@25=60, optimizer=Nadam\n",
    "        {'1 - recall_at_5': 0.24,\n",
    "         '2 - recall_at_10': 0.32,\n",
    "         '3 - recall_at_15': 0.37,\n",
    "         '4 - recall_at_20': 0.41,\n",
    "         '5 - recall_at_25': 0.41}\n",
    "         With 1000 epochs validation_recall@25=64, optimizer=Nadam\n",
    "         {'1 - recall_at_5': 0.28,\n",
    "         '2 - recall_at_10': 0.36,\n",
    "         '3 - recall_at_15': 0.41,\n",
    "         '4 - recall_at_20': 0.45,\n",
    "         '5 - recall_at_25': 0.45}\n",
    "         Withou change the distance x when calculate the cosine\n",
    "         {'1 - recall_at_5': 0.18,\n",
    "         '2 - recall_at_10': 0.24,\n",
    "         '3 - recall_at_15': 0.28,\n",
    "         '4 - recall_at_20': 0.31,\n",
    "         '5 - recall_at_25': 0.31}\n",
    "         With concatenation\n",
    "         {'1 - recall_at_5': 0.23,\n",
    "         '2 - recall_at_10': 0.31,\n",
    "         '3 - recall_at_15': 0.36,\n",
    "         '4 - recall_at_20': 0.4,\n",
    "         '5 - recall_at_25': 0.43}\n",
    "             \n",
    "    # Open Office\n",
    "    {'1 - recall_at_5': 0.2,\n",
    "     '2 - recall_at_10': 0.27,\n",
    "     '3 - recall_at_15': 0.31,\n",
    "     '4 - recall_at_20': 0.34,\n",
    "     '5 - recall_at_25': 0.34}\n",
    "'''\n",
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
