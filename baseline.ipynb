{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 40\n",
    "MAX_SEQUENCE_LENGTH_D = 100 # 200\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'netbeans'\n",
    "METHOD = 'baseline'\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Glove embeddings\n",
    "GLOVE_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = 'baseline_feature@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "SAVE_PATH_FEATURE = 'baseline_feature_@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9870ed019bec46e79df5ef07bf2456af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=180483), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc1dd443b4844c7a5fda9df5821c54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36232), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "216715"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9155fa39239149f18d33b5ccb54c7014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=216715), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ec9fd22e024074b3f41f4c8731d004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 21s, sys: 2.39 s, total: 1min 24s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c3aaa22daf4aeca9d0027f9ad3a979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=180483), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[90024, 1289],\n",
       " [1408, 6256],\n",
       " [1787, 14975],\n",
       " [166804, 2020],\n",
       " [2337, 31362],\n",
       " [2337, 46020],\n",
       " [2337, 15205],\n",
       " [2337, 32942],\n",
       " [2337, 35023],\n",
       " [2337, 57495]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the corpus train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CORPUS:\n",
    "    corpus = []\n",
    "    export_file = open(os.path.join(DIR, 'corpus_train.txt'), 'w')\n",
    "    for bug_id in tqdm(baseline.bug_set):\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title = bug['title']\n",
    "        desc = bug['description']\n",
    "        export_file.write(\"{}\\n{}\\n\".format(title, desc))\n",
    "    export_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "# Generating tiple of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dup_id': '[]', 'bug_status': '1\\n', 'issue_id': 2521, 'priority': '3\\n', 'title': 'when opended number edited file save is not available onlu save all when opened more then number file save is available but organization s save non actual file', 'component': '103\\n', 'description': 'priority is changed to p normal', 'delta_ts': '2008-12-23 10:55:57 +0000', 'creation_ts': '1999-07-16 03:55:00 +0000', 'resolution': 'FIXED', 'product': '9\\n', 'description_word': array([1351,   15,  292,   11,  421, 1348,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0]), 'title_word': array([  66,    1,   46, 1919,   35,  364,   15,   28,  607,    1,  364,\n",
      "        120,   66,  295,  278,  210,   46,   35,  364,   15,  607,   89,\n",
      "          4,  132,  364,  611, 1291,   35,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0]), 'bug_severity': '2\\n', 'version': '1\\n'}\n"
     ]
    }
   ],
   "source": [
    "if 2521 in baseline.bug_set:\n",
    "    print(baseline.bug_set[2521])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 30600)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 ms, sys: 0 ns, total: 52 ms\n",
      "Wall time: 51.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = baseline.batch_iterator(baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train,\n",
    "                                                                                          bug_train_ids,\n",
    "                                                                                          batch_size_test, 1)\n",
    "test_gen = ([valid_input_sample['title'], valid_input_pos['title'], valid_input_neg['title'], \n",
    "             valid_input_sample['description'], valid_input_pos['description'], valid_input_neg['description'],\n",
    "            valid_input_sample['info'], valid_input_pos['info'], valid_input_neg['info']], valid_sim)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 100), (128, 500), (128, 544), (128,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Title***: cat assertion error child organization reciete organization src utils moms java folder organization reciete organization src utils\n",
      "***Title***: assertion error file name users ryanmauger projects i i local application modules slideshows models slideshows php be d fo organization users ryanmauger projects i i local application module\n",
      "***Description***: this bug was originally marked as duplicate of bug that is already resolved this bug is still valid so this seems to be another bug but it might be related build net beans ide dev build vm java hot spot tm client vm b organization runtime environment b organization product carlo salinari checking issues from exception reporter person to rename a package stacktrace java lang assertion error child organization reciete person src utils moms java folder organization reciete person src utils at org netbeans modules masterfs filebasedfs children organization add child organization java at org netbeans modules masterfs filebasedfs children organization rescan children organization java at org netbeans modules masterfs filebasedfs children organization get children organization java at org netbeans modules masterfs filebasedfs fileobjects product get children product java at org netbeans modules masterfs filebasedfs fileobjects product get children product java at org openide filesystems organization get children organization java\n",
      "***Description***: build net beans ide beta build vm java hot spot tm organization b organization runtime environment b m organization x user comments bittarman alt clicked in project pane guest expanding files tree in location view coops artwork a file in the projects pane guest i was unfolding a folder from location tab guest i clicked a folder in my projects list product java lang artwork ryanmauger location i i local application modules slideshows models slideshows php be d fo artwork users ryanmauger location i i local application modules slideshows models slideshows php f ea c c valid true at org netbeans modules masterfs filebasedfs fileobjects product get children product java at org openide loaders artwork r run artwork java at org openide product run request processor java at org openide util request processor processor run request processor java\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: s in invocations of collect children\n",
      "***Title***: assertion error child organization net beans projects tools src org netbeans javafx folder organization net beans projects tools src org netbeans\n",
      "***Description***: build net beans ide build vm java hot spot tm client vm b organization runtime environment b organization product maximum slowness yet reported was ms average is\n",
      "***Description***: this bug was originally marked as duplicate of bug that is already resolved this bug is still valid so this seems to be another bug but it might be related build net beans ide dev build vm java hot spot tm organization b organization runtime environment b organization product user comments bobw performed a person with refactor option on a folder in a organization project michaeljohnmcginley renaming a project product java lang assertion error child organization net beans projects tools src org netbeans javafx folder organization net beans projects tools src org netbeans at org netbeans modules masterfs filebasedfs children organization add child organization java at org netbeans modules masterfs filebasedfs children organization rescan children organization java at org netbeans modules masterfs filebasedfs children organization get children organization java at org netbeans modules masterfs filebasedfs fileobjects product get children product java at org netbeans modules masterfs filebasedfs fileobjects product get children product java at org netbeans modules parsing impl indexing organization collect organization java\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: reflect undeclared throwable exception at proxy property change\n",
      "***Title***: organization exception on change order for organization schemas\n",
      "***Description***: build net beans ide dev build vm java hot spot tm organization b organization environment standard edition b organization product generic amd product when closing a organization project product java lang reflect product property change java at org openide nodes location fire own property change location java at org openide nodes filter location location adapter property change filter location java at org openide nodes filter location location adapter property change filter location java at org openide nodes location fire own property change location java at org openide nodes location fire short description change location java\n",
      "***Description***: organization exception on change order for organization schemas\n",
      "***similar = 0\n",
      "########################\n",
      "***Title***: show annotations revision numbers not displayed\n",
      "***Title***: java lang exception can not find correct line\n",
      "***Description***: product version net beans ide dev build java java hot spot tm client vm b system organization organization version running on x organization country en nb on organization i can not see revision numbers for source code lines in the left column after i select show annotations for that file on the other hand in the right column there are version stripes related to different versions of this file please is there any way how to get revision numbers to the annotations column on other platforms revision numbers are displayed implicitly after show annotations i think\n",
      "***Description***: java lang exception can not find correct line\n",
      "***similar = 0\n",
      "########################\n",
      "CPU times: user 50.7 ms, sys: 0 ns, total: 50.7 ms\n",
      "Wall time: 49.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test ', 3162)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Test \", len(baseline.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 102875'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, GLOVE_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(GLOVE_DIR, 'glove.42B.300d.txt')\n",
    "    f = open(embed_path, 'rb')\n",
    "    #num_lines = sum(1 for line in open(embed_path, 'rb'))\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(tokens[1:], dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea00a9617e2649dab8cfd02ccb6d8a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29979ff7e8b4e4b97456157985a4204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=102875), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 28s, sys: 3.62 s, total: 1min 32s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, GLOVE_DIR=GLOVE_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer',\n",
    "                                  weights=[embeddings],\n",
    "                                  embeddings_constraint=MaxNorm(max_value=1, axis=0),\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI074wU4Y13y"
   },
   "source": [
    "### CNN with filter 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "h6YJU9GtFTyq",
    "outputId": "f85cf105-1fd6-491d-d969-7e6936f32739",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "\n",
    "def cnn_model(embedding_layer, max_sequence_length):\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length,), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None,), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "    # best combination filter (3, 4, 5) e 128 e 256\n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    n_filters = 64\n",
    "\n",
    "    for index, filter_size in enumerate(filter_sizes):\n",
    "        l_conv = Conv1D(filters=n_filters, kernel_size=filter_size)(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(pool_size=filter_size)(l_conv) # index+1\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "    # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "    #conv = Conv1D(filters=n_filters * 3, kernel_size=3)(l_merge)\n",
    "    layer = GlobalAveragePooling1D()(l_merge)\n",
    "    #layer = Flatten()(l_merge)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "    #layer = LeakyReLU()(layer)\n",
    "\n",
    "    cnn_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureCNNGenerationModel') # inputs=visible\n",
    "\n",
    "    return cnn_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr6ObTXiaALH"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "vC7MQXEsaCeG",
    "outputId": "65e647a9-c5d3-4009-b8a4-2e2d97b52684"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, GRU, Dropout, Bidirectional, GlobalAveragePooling1D\n",
    "\n",
    "def lstm_model(embedding_layer, max_sequence_length):\n",
    "    number_lstm_units = 50\n",
    "    rate_drop_lstm = 0\n",
    "    recurrent_dropout = 0\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None, ), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Creating LSTM Encoder\n",
    "#     lstm_layer = Bidirectional(LSTM(number_lstm_units, return_sequences=True), # dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm \n",
    "#                                merge_mode='ave')\n",
    "\n",
    "    lstm_layer = LSTM(number_lstm_units, return_sequences=True)(embedded_sequences)\n",
    "    layer = LSTM(number_lstm_units)(lstm_layer)\n",
    "\n",
    "    #layer = lstm_layer(embedded_sequences)\n",
    "    #layer = GlobalAveragePooling1D()(layer)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "\n",
    "    lstm_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureLstmGenerationModel') # inputs=visible\n",
    "\n",
    "    return lstm_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.sum(K.maximum(0.0, margin - pos + neg))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "  \n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    #     bug_feature_output = Activation('tanh')(bug_feature_output)\n",
    "    \n",
    "    # Bug representation layer\n",
    "    # bug_feature_output = Dense(300, activation='tanh')(bug_feature_output)\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    \n",
    "    # Cosine\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3 * decay_lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer=optimizer, loss=custom_margin_loss, metrics=[pos_distance, neg_distance, custom_margin_loss])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 544)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 544)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_pos (InputLayer)          (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_pos (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 544)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_neg (InputLayer)          (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_neg (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          163500      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          30968200    title_in[0][0]                   \n",
      "                                                                 title_pos[0][0]                  \n",
      "                                                                 title_neg[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          31112592    desc_in[0][0]                    \n",
      "                                                                 desc_pos[0][0]                   \n",
      "                                                                 desc_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 900)          0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureLstmGenerationModel[2][0] \n",
      "                                                                 FeatureCNNGenerationModel[2][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 900)          0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureLstmGenerationModel[3][0] \n",
      "                                                                 FeatureCNNGenerationModel[3][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances (Lambda)        (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 62,244,292\n",
      "Trainable params: 519,292\n",
      "Non-trainable params: 61,725,000\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 0.80, MarginLoss: 0.80, pos_cosine: 0.89, neg_cosine: 0.69\n",
      "Epoch: 2 Loss: 0.81, MarginLoss: 0.81, pos_cosine: 0.86, neg_cosine: 0.68\n",
      "Epoch: 3 Loss: 0.78, MarginLoss: 0.78, pos_cosine: 0.87, neg_cosine: 0.65\n",
      "Epoch: 4 Loss: 0.79, MarginLoss: 0.79, pos_cosine: 0.87, neg_cosine: 0.66\n",
      "Epoch: 5 Loss: 0.79, MarginLoss: 0.79, pos_cosine: 0.85, neg_cosine: 0.64\n",
      "Epoch: 6 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.87, neg_cosine: 0.61\n",
      "Epoch: 7 Loss: 0.76, MarginLoss: 0.76, pos_cosine: 0.84, neg_cosine: 0.60\n",
      "Epoch: 8 Loss: 0.73, MarginLoss: 0.73, pos_cosine: 0.87, neg_cosine: 0.60\n",
      "Epoch: 9 Loss: 0.75, MarginLoss: 0.75, pos_cosine: 0.82, neg_cosine: 0.57\n",
      "Epoch: 10 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.85, neg_cosine: 0.56\n",
      "Epoch: 11 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.85, neg_cosine: 0.54\n",
      "Epoch: 12 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.84, neg_cosine: 0.55\n",
      "Epoch: 13 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.83, neg_cosine: 0.54\n",
      "Epoch: 14 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.85, neg_cosine: 0.55\n",
      "Epoch: 15 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.82, neg_cosine: 0.51\n",
      "Epoch: 16 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.84, neg_cosine: 0.53\n",
      "Epoch: 17 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.85, neg_cosine: 0.51\n",
      "Epoch: 18 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.86, neg_cosine: 0.50\n",
      "Epoch: 19 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.83, neg_cosine: 0.50\n",
      "Epoch: 20 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.84, neg_cosine: 0.50\n",
      "Epoch: 21 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.82, neg_cosine: 0.53\n",
      "Epoch: 22 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.83, neg_cosine: 0.50\n",
      "Epoch: 23 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.82, neg_cosine: 0.50\n",
      "Epoch: 24 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.83, neg_cosine: 0.48\n",
      "Epoch: 25 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.84, neg_cosine: 0.49\n",
      "Epoch: 26 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.83, neg_cosine: 0.49\n",
      "Epoch: 27 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.85, neg_cosine: 0.51\n",
      "Epoch: 28 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.82, neg_cosine: 0.50\n",
      "Epoch: 29 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.86, neg_cosine: 0.50\n",
      "Epoch: 30 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.87, neg_cosine: 0.52\n",
      "Epoch: 31 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.84, neg_cosine: 0.51\n",
      "Epoch: 32 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.84, neg_cosine: 0.50\n",
      "Epoch: 33 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.85, neg_cosine: 0.51\n",
      "Epoch: 34 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.83, neg_cosine: 0.51\n",
      "Epoch: 35 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.83, neg_cosine: 0.47\n",
      "Epoch: 36 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.89, neg_cosine: 0.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.86, neg_cosine: 0.48\n",
      "Epoch: 38 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.86, neg_cosine: 0.50\n",
      "Epoch: 39 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.87, neg_cosine: 0.55\n",
      "Epoch: 40 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.85, neg_cosine: 0.51\n",
      "Epoch: 41 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.87, neg_cosine: 0.50\n",
      "Epoch: 42 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.84, neg_cosine: 0.50\n",
      "Epoch: 43 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.88, neg_cosine: 0.47\n",
      "Epoch: 44 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.87, neg_cosine: 0.48\n",
      "Epoch: 45 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.86, neg_cosine: 0.52\n",
      "Epoch: 46 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.88, neg_cosine: 0.48\n",
      "Epoch: 47 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.88, neg_cosine: 0.49\n",
      "Epoch: 48 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.87, neg_cosine: 0.51\n",
      "Epoch: 49 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.88, neg_cosine: 0.48\n",
      "Epoch: 50 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.87, neg_cosine: 0.53\n",
      "Epoch: 51 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.88, neg_cosine: 0.52\n",
      "Epoch: 52 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.90, neg_cosine: 0.52\n",
      "Epoch: 53 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.87, neg_cosine: 0.48\n",
      "Epoch: 54 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.85, neg_cosine: 0.52\n",
      "Epoch: 55 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.88, neg_cosine: 0.50\n",
      "Epoch: 56 Loss: 0.55, MarginLoss: 0.55, pos_cosine: 0.87, neg_cosine: 0.43\n",
      "Epoch: 57 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.85, neg_cosine: 0.48\n",
      "Epoch: 58 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.87, neg_cosine: 0.49\n",
      "Epoch: 59 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.89, neg_cosine: 0.52\n",
      "Epoch: 60 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.88, neg_cosine: 0.47\n",
      "Epoch: 61 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.87, neg_cosine: 0.51\n",
      "Epoch: 62 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.88, neg_cosine: 0.50\n",
      "Epoch: 63 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.89, neg_cosine: 0.49\n",
      "Epoch: 64 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.89, neg_cosine: 0.53\n",
      "Epoch: 65 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.90, neg_cosine: 0.47\n",
      "Epoch: 66 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.90, neg_cosine: 0.52\n",
      "Epoch: 67 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.91, neg_cosine: 0.49\n",
      "Epoch: 68 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.87, neg_cosine: 0.51\n",
      "Epoch: 69 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.90, neg_cosine: 0.53\n",
      "Epoch: 70 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.88, neg_cosine: 0.51\n",
      "Epoch: 71 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.91, neg_cosine: 0.54\n",
      "Epoch: 72 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.90, neg_cosine: 0.49\n",
      "Epoch: 73 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.90, neg_cosine: 0.48\n",
      "Epoch: 74 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.91, neg_cosine: 0.50\n",
      "Epoch: 75 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.89, neg_cosine: 0.51\n",
      "Epoch: 76 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.92, neg_cosine: 0.51\n",
      "Epoch: 77 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.88, neg_cosine: 0.47\n",
      "Epoch: 78 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.87, neg_cosine: 0.50\n",
      "Epoch: 79 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.89, neg_cosine: 0.46\n",
      "Epoch: 80 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.87, neg_cosine: 0.51\n",
      "Epoch: 81 Loss: 0.56, MarginLoss: 0.56, pos_cosine: 0.92, neg_cosine: 0.47\n",
      "Epoch: 82 Loss: 0.55, MarginLoss: 0.55, pos_cosine: 0.91, neg_cosine: 0.46\n",
      "Epoch: 83 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.88, neg_cosine: 0.49\n",
      "Epoch: 84 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.90, neg_cosine: 0.49\n",
      "Epoch: 85 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.88, neg_cosine: 0.51\n",
      "Epoch: 86 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.91, neg_cosine: 0.51\n",
      "Epoch: 87 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.90, neg_cosine: 0.50\n",
      "Epoch: 88 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.90, neg_cosine: 0.47\n",
      "Epoch: 89 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.89, neg_cosine: 0.46\n",
      "Epoch: 90 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.89, neg_cosine: 0.53\n",
      "Epoch: 91 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.88, neg_cosine: 0.52\n",
      "Epoch: 92 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.88, neg_cosine: 0.46\n",
      "Epoch: 93 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.88, neg_cosine: 0.53\n",
      "Epoch: 94 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.89, neg_cosine: 0.52\n",
      "Epoch: 95 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.88, neg_cosine: 0.51\n",
      "Epoch: 96 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.91, neg_cosine: 0.53\n",
      "Epoch: 97 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.89, neg_cosine: 0.49\n",
      "Epoch: 98 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.89, neg_cosine: 0.50\n",
      "Epoch: 99 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.90, neg_cosine: 0.50\n",
      "Epoch: 100 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.91, neg_cosine: 0.49, recall@25: 0.74\n",
      "Saved model 'modelos/model_baseline_feature_100epochs_64batch(netbeans).h5' to disk\n",
      "Best_epoch=82, Best_loss=0.55, Recall@25=0.74\n",
      "CPU times: user 5min 52s, sys: 18.5 s, total: 6min 10s\n",
      "Wall time: 4min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False)\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False)\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    mlp_model\n",
    "'''\n",
    "desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "title_feature_model = lstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = baseline.batch_iterator(baseline.train_data, baseline.dup_sets_train, bug_train_ids, batch_size, 1)\n",
    "    train_batch = [train_input_sample['title'], train_input_sample['description'], train_input_sample['info'],\n",
    "                   train_input_pos['title'], train_input_pos['description'], train_input_pos['info'], \n",
    "                   train_input_neg['title'], train_input_neg['description'], train_input_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[3]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['233472:230872|234329:0.9974548863247037,230092:0.9969204270746559,234917:0.9967435547150671,234918:0.9967435547150671,230090:0.995780489873141,231856:0.9957241797819734,231804:0.9931402602232993,229428:0.9864214025437832,237668:0.5490624308586121,236741:0.5489483177661896,233727:0.5397214591503143,237097:0.5397157371044159,236879:0.5397125780582428,236839:0.5397065579891205,234948:0.5103350281715393,234962:0.5044711232185364,231238:0.5044639408588409,235127:0.5044516324996948,235129:0.5043337345123291,234216:0.5005126595497131,234214:0.5005110502243042,234218:0.4993858337402344,232621:0.49730223417282104,232615:0.4973018765449524,233709:0.49729180335998535,232720:0.49728816747665405,229528:0.4913507103919983,235293:0.4910625219345093,229581:0.49105578660964966',\n",
       " '230872:233472|235293:0.9948847237974405,229581:0.993970044888556,236775:0.9050537645816803,235670:0.9050142765045166,234120:0.9050001576542854,229419:0.9049997180700302,237324:0.9049843028187752,237294:0.9049826413393021,237323:0.9049634709954262,237173:0.9049443602561951,229528:0.8588946610689163,235463:0.766347199678421,238523:0.5876889526844025,237668:0.5435285866260529,236741:0.5434321165084839,231238:0.530333012342453,234962:0.530333012342453,235127:0.5302966833114624,235129:0.5302076637744904,235128:0.5197586119174957,233727:0.5166841745376587,237097:0.5166793465614319,236879:0.5166776180267334,236839:0.5166735649108887,234948:0.5115004777908325,232615:0.4915493130683899,232621:0.4915485978126526,233709:0.4915400743484497,232720:0.4915273189544678',\n",
       " '221186:220416,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|225378:0.9984676109161228,219220:0.99840154487174,220987:0.99840154487174,221121:0.99840154487174,219599:0.9983193336520344,219412:0.9982293203938752,222306:0.9981710163410753,220472:0.9981657135067508,221404:0.9980993330245838,226405:0.9980868083657697,220432:0.9980598645051941,220553:0.9980598645051941,220618:0.9980598645051941,220647:0.9980598645051941,220465:0.9980321573093534,229492:0.9980247670318931,220358:0.9980181681457907,219630:0.9979701400734484,220353:0.9979571204166859,224218:0.9978682093787938,221021:0.9978575543500483,222052:0.9977544229477644,222141:0.9977544229477644,226947:0.9977544229477644,227122:0.9977544229477644,220416:0.9977544229477644,220238:0.9977462834212929,224412:0.9977034498006105,220692:0.9976537534967065',\n",
       " '226947:220416,221186,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|222052:1.0,222141:1.0,227122:1.0,220416:1.0,221291:0.9998931208610884,220692:0.9993456710362807,224218:0.9988181412918493,222306:0.9987820460228249,220648:0.9987811333267018,221021:0.998675993992947,226374:0.9985051163239405,220497:0.9984574094414711,226405:0.9984374654013664,219630:0.9982348157791421,220353:0.9982198590878397,220465:0.9981843432178721,219599:0.9981777791399509,224412:0.9981527382042259,221138:0.9981468858895823,229492:0.9980623694136739,219220:0.9979988590348512,220987:0.9979988590348512,221121:0.9979988590348512,220432:0.9979886198416352,220553:0.9979886198416352,220618:0.9979886198416352,220647:0.9979886198416352,219412:0.997985101537779,220238:0.9979813885875046',\n",
       " '220553:220416,221186,226947,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|220432:1.0,220618:1.0,220647:1.0,219220:0.9987137534189969,220987:0.9987137534189969,221121:0.9987137534189969,224797:0.9985226878197864,225378:0.9985138747142628,226405:0.9985051163239405,221291:0.9984583940822631,220353:0.9984083331655711,220452:0.9983767328085378,219599:0.998361405567266,224218:0.998295717057772,222306:0.9981507131597027,229492:0.9981165012577549,220692:0.9980893490137532,221186:0.9980598645051941,221021:0.9980242028832436,219312:0.9980174053926021,222052:0.9979886198416352,222141:0.9979886198416352,226947:0.9979886198416352,227122:0.9979886198416352,220416:0.9979886198416352,220472:0.997927175136283,220358:0.9979232223704457,220465:0.9979081719648093,219630:0.9978004544973373',\n",
       " '220554:220416,221186,226947,220553,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|224070:0.9977519209496677,226374:0.9976183609105647,220648:0.9975081845186651,219599:0.9974419337231666,222052:0.9974273783154786,222141:0.9974273783154786,226947:0.9974273783154786,227122:0.9974273783154786,220416:0.9974273783154786,220497:0.9973348460625857,222306:0.9973021219484508,224376:0.997243664925918,219630:0.9972386497538537,224412:0.9972238151822239,221021:0.9972138800658286,219550:0.9972094628028572,220465:0.9972061177249998,219220:0.9971945143770427,220987:0.9971945143770427,221121:0.9971945143770427,220472:0.9971442562527955,221186:0.9971249694935977,220238:0.9971069737803191,225378:0.9970974382013083,220452:0.9970611312892288,229492:0.997051744023338,221291:0.9970323040615767,220692:0.9969629077240825,226405:0.9969490463845432',\n",
       " '218635:220416,221186,226947,220553,220554,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221021:0.8261634260416031,219220:0.82616026699543,220987:0.82616026699543,221121:0.82616026699543,220692:0.8261599987745285,229492:0.8261594474315643,222306:0.8261581659317017,220497:0.8261577636003494,221404:0.8261572271585464,219599:0.8261562585830688,220384:0.8261553943157196,220358:0.8261551707983017,219170:0.8261551409959793,219412:0.826154813170433,224412:0.8261545896530151,224218:0.8261540830135345,220648:0.8261539787054062,221186:0.8261537253856659,225378:0.826153576374054,220432:0.8261533081531525,220553:0.8261533081531525,220618:0.8261533081531525,220647:0.8261533081531525,220238:0.8261530697345734,220472:0.8261530697345734,220353:0.8261527866125107,220465:0.8261525332927704,226405:0.8261525183916092,226374:0.8261523693799973',\n",
       " '220432:220416,221186,226947,220553,220554,218635,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|220553:1.0,220618:1.0,220647:1.0,219220:0.9987137534189969,220987:0.9987137534189969,221121:0.9987137534189969,224797:0.9985226878197864,225378:0.9985138747142628,226405:0.9985051163239405,221291:0.9984583940822631,220353:0.9984083331655711,220452:0.9983767328085378,219599:0.998361405567266,224218:0.998295717057772,222306:0.9981507131597027,229492:0.9981165012577549,220692:0.9980893490137532,221186:0.9980598645051941,221021:0.9980242028832436,219312:0.9980174053926021,222052:0.9979886198416352,222141:0.9979886198416352,226947:0.9979886198416352,227122:0.9979886198416352,220416:0.9979886198416352,220472:0.997927175136283,220358:0.9979232223704457,220465:0.9979081719648093,219630:0.9978004544973373',\n",
       " '226961:220416,221186,226947,220553,220554,218635,220432,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|214389:0.9953986597247422,212461:0.9944261922501028,214050:0.9933704868890345,213329:0.9903955487534404,213379:0.9899402922019362,215671:0.9869348220527172,217010:0.9862225418910384,214382:0.8317762017250061,209343:0.6591955423355103,210444:0.5740876793861389,218638:0.5740830600261688,213630:0.5740819275379181,220677:0.5740781426429749,215382:0.5740760862827301,215647:0.5740747153759003,214646:0.5740723609924316,214706:0.5740565657615662,212620:0.5740533769130707,225268:0.5740359127521515,213389:0.5740248560905457,218202:0.5740171074867249,216036:0.5739035308361053,214462:0.5738505423069,212024:0.5646440982818604,214068:0.5646394193172455,214538:0.564600944519043,215561:0.5623434782028198,207558:0.5594442188739777,210956:0.5594442188739777',\n",
       " '219028:220416,221186,226947,220553,220554,218635,220432,226961,219412,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|219412:0.9980656644329429,222052:0.9975785748101771,222141:0.9975785748101771,226947:0.9975785748101771,227122:0.9975785748101771,220416:0.9975785748101771,221021:0.997520063072443,221404:0.997501160716638,226405:0.9974682114552706,220353:0.9974515985231847,229492:0.9974210076034069,220692:0.9973199113737792,221291:0.9972780256066471,224218:0.997259832220152,219630:0.9972590196412057,219170:0.9972582084592432,225378:0.9971921264659613,220452:0.9971754183061421,219312:0.9971155077219009,220648:0.9970923049841076,220465:0.9970757861156017,222306:0.9970560586079955,220358:0.9970138741191477,219599:0.9969994050916284,219220:0.9969571421388537,220987:0.9969571421388537,221121:0.9969571421388537,224797:0.996871581999585,221186:0.9968246724456549',\n",
       " '219412:220416,221186,226947,220553,220554,218635,220432,226961,219028,220692,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|219220:0.998511629877612,220987:0.998511629877612,221121:0.998511629877612,229492:0.9984914369415492,225378:0.9983716893475503,222306:0.9983293582918122,221186:0.9982293203938752,220692:0.9982010863022879,226405:0.9981777791399509,221021:0.99815800471697,219028:0.9980656644329429,224218:0.9980024022515863,222052:0.997985101537779,222141:0.997985101537779,226947:0.997985101537779,227122:0.997985101537779,220416:0.997985101537779,220358:0.9979719857219607,220452:0.9979110285639763,219312:0.9979087049141526,219599:0.9978990969248116,221404:0.9978927003685385,220353:0.9978842176496983,219630:0.9977972363121808,220465:0.9977565871085972,220648:0.9977304418571293,221291:0.997724698157981,224686:0.9977098028175533,220238:0.9976799951400608',\n",
       " '220692:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220948,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|220465:0.9994259016239084,222052:0.9993456710362807,222141:0.9993456710362807,226947:0.9993456710362807,227122:0.9993456710362807,220416:0.9993456710362807,221021:0.9990873497445136,221291:0.9990500871208496,222306:0.9988586510298774,220358:0.9984788802685216,220353:0.9984686028910801,219220:0.9984374654013664,220987:0.9984374654013664,221121:0.9984374654013664,226405:0.9983600494451821,219599:0.9982896132860333,219630:0.9982867750804871,224412:0.9982629583682865,220238:0.9982573746237904,221138:0.9982567360857502,221404:0.9982477615121752,219412:0.9982010863022879,229492:0.9981671469286084,224218:0.9981671469286084,220648:0.9981430676998571,220432:0.9980893490137532,220553:0.9980893490137532,220618:0.9980893490137532,220647:0.9980893490137532',\n",
       " '220948:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,224412,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|222052:0.9969412246719003,222141:0.9969412246719003,226947:0.9969412246719003,227122:0.9969412246719003,220416:0.9969412246719003,219630:0.9968978299293667,220358:0.996810938930139,220692:0.996714626904577,220353:0.9966424531303346,221291:0.9965848952997476,220465:0.9965295807924122,220648:0.9965264620259404,219599:0.9964786327909678,224218:0.9964778907597065,224412:0.9964656142983586,226405:0.9964378329459578,219412:0.9964347942732275,220432:0.9963934549596161,220553:0.9963934549596161,220618:0.9963934549596161,220647:0.9963934549596161,225378:0.9963230160064995,222306:0.9963171309791505,221138:0.996314191725105,220497:0.9963118636514992,221021:0.99630963569507,226374:0.99630245892331,221404:0.9962969091720879,221186:0.9962420584633946',\n",
       " '224412:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224797,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221021:0.9985499938484281,221138:0.998528518830426,219630:0.9984219974139705,220238:0.9983248841017485,220692:0.9982629583682865,219599:0.9982326953904703,220353:0.9982150334399194,222052:0.9981527382042259,222141:0.9981527382042259,226947:0.9981527382042259,227122:0.9981527382042259,220416:0.9981527382042259,221404:0.9981081923469901,220648:0.998090514796786,221291:0.9980836902977899,219220:0.9980187301989645,220987:0.9980187301989645,221121:0.9980187301989645,222306:0.9979295190423727,229492:0.9978989062365144,224218:0.9978485065512359,224070:0.997847288614139,220452:0.9978118508588523,225378:0.9977629128843546,220432:0.9977340577170253,220553:0.9977340577170253,220618:0.9977340577170253,220647:0.9977340577170253,221186:0.9977034498006105',\n",
       " '224797:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,219550,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|220432:0.9985226878197864,220553:0.9985226878197864,220618:0.9985226878197864,220647:0.9985226878197864,219220:0.9979017504956573,220987:0.9979017504956573,221121:0.9979017504956573,225378:0.9978495449759066,222052:0.9978212579153478,222141:0.9978212579153478,226947:0.9978212579153478,227122:0.9978212579153478,220416:0.9978212579153478,219599:0.997811340726912,226405:0.9977943459525704,224686:0.9977001959923655,220353:0.9975903078448027,224218:0.9975777873769403,224070:0.9975767082069069,221404:0.9975733212195337,222306:0.9975599711760879,219412:0.9975590554531664,220472:0.9975559953600168,220465:0.997520353179425,220692:0.9975131377577782,220497:0.9975086338818073,219312:0.9974807631224394,229492:0.9974485102575272,221186:0.9974064184352756',\n",
       " '219550:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219170,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|219599:0.9979324054438621,229492:0.997781177284196,219220:0.9976331458892673,220987:0.9976331458892673,221121:0.9976331458892673,221186:0.9975077356211841,220472:0.99748699599877,221021:0.9973553796298802,224070:0.9973007389344275,225378:0.997293692547828,220452:0.9972547881770879,219412:0.9972456912510097,224797:0.9972377037629485,224376:0.997227588435635,220554:0.9972094628028572,220497:0.9971628834027797,220238:0.9971287385560572,224686:0.9971153747756034,224412:0.9970949946437031,220692:0.9970921697095037,220358:0.9970888320822269,222306:0.997058336623013,226405:0.9970412508118898,220648:0.9969859858974814,221138:0.9969827665481716,219630:0.9969645065721124,219312:0.996956889750436,220432:0.9969525975175202,220553:0.9969525975175202',\n",
       " '219170:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,220452,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|222306:0.9976105466485023,220648:0.99752202257514,222052:0.9974830036517233,222141:0.9974830036517233,226947:0.9974830036517233,227122:0.9974830036517233,220416:0.9974830036517233,220465:0.9974182622972876,220353:0.9973606211133301,219220:0.9973024106584489,220987:0.9973024106584489,221121:0.9973024106584489,219412:0.9972744586411864,219028:0.9972582084592432,221404:0.9972266482654959,224412:0.9971597334370017,224218:0.9971542165149003,219599:0.9971010535955429,220238:0.9970984722021967,220497:0.9970584667753428,220692:0.9970459355972707,221291:0.9969882296863943,220472:0.9969543174374849,221138:0.9969189707189798,221021:0.9969135231804103,229492:0.9969018083065748,219630:0.9969010890927166,225378:0.996826553484425,219312:0.9968253751285374',\n",
       " '220452:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,224686,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|219220:0.9986032438464463,220987:0.9986032438464463,221121:0.9986032438464463,220432:0.9983767328085378,220553:0.9983767328085378,220618:0.9983767328085378,220647:0.9983767328085378,224218:0.9983349435497075,225378:0.9981987830251455,219599:0.998153341235593,221291:0.9981210724217817,226405:0.9980462468229234,220353:0.99800052982755,219412:0.9979110285639763,221021:0.9978485065512359,224070:0.9978305283002555,219312:0.9978200553450733,224412:0.9978118508588523,219630:0.997781855519861,221404:0.9977779837790877,222052:0.9977457884233445,222141:0.9977457884233445,226947:0.9977457884233445,227122:0.9977457884233445,220416:0.9977457884233445,220648:0.9976690739858896,229492:0.9975530952215195,222306:0.9975354576017708,220692:0.9975321306847036',\n",
       " '224686:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,219311,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|224218:0.9981454684166238,222306:0.9979063840582967,221138:0.9978014682419598,225378:0.9977894423063844,219599:0.9977309324312955,219412:0.9977098028175533,224797:0.9977001959923655,221404:0.9976783832535148,219630:0.9976363081950694,219220:0.997629681834951,220987:0.997629681834951,221121:0.997629681834951,220353:0.9976251181215048,220472:0.9976149164140224,220497:0.9975664073135704,220432:0.9975325828418136,220553:0.9975325828418136,220618:0.9975325828418136,220647:0.9975325828418136,229492:0.9975048920605332,221186:0.9975044447928667,219312:0.9974712959956378,220465:0.9974680528976023,224412:0.997445295099169,226405:0.9973843458574265,220692:0.9973596248310059,220238:0.9973590539302677,222052:0.9973256192170084,222141:0.9973256192170084',\n",
       " '219311:220416,221186,226947,220553,220554,218635,220432,226961,219028,219412,220692,220948,224412,224797,219550,219170,220452,224686,219312,220465,224049,227122,220472,220987,222141,220353,221121,220358,224070,226374,220618,220238,219599,220497,221138,219220,219866,220379,221404,221021,224218,220384,222306,225378,222052,226405,220647,220648,218475,221291,220653,219630,229492,224376,225660|221404:0.9973613165784627,219412:0.9973481914494187,219599:0.9972862552385777,221291:0.9972641940694302,221021:0.9972592818085104,220692:0.9972274524625391,224218:0.9972074548713863,219220:0.9972010452765971,220987:0.9972010452765971,221121:0.9972010452765971,220432:0.9971766048111022,220553:0.9971766048111022,220618:0.9971766048111022,220647:0.9971766048111022,225378:0.9971616994589567,222052:0.9971402073279023,222141:0.9971402073279023,226947:0.9971402073279023,227122:0.9971402073279023,220416:0.9971402073279023,229492:0.9971317311283201,220452:0.9971245799679309,220353:0.9970682552084327,221186:0.9969856147654355,219630:0.9969852438662201,226405:0.9969744880218059,224412:0.9969364667776972,224070:0.9969148482196033,219312:0.9969074735417962']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "#     Between 0-10 epochs recall@25 = 0.28\n",
    "#     Between 0-20 epochs recall@25 = 0.32\n",
    "#     Between 0-70 epochs recall@25 = ?\n",
    "#     Between 0-100 epochs recall@25 = ?\n",
    "# '''\n",
    "# recall, exported_rank = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 3162\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_feature_100epochs_64batch(netbeans)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 544)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          163500      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          30968200    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          31112592    desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "==================================================================================================\n",
      "Total params: 62,244,292\n",
      "Trainable params: 519,292\n",
      "Non-trainable params: 61,725,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, bug_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/netbeans/exported_rank_baseline.txt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.6,\n",
       " '2 - recall_at_10': 0.66,\n",
       " '3 - recall_at_15': 0.69,\n",
       " '4 - recall_at_20': 0.72,\n",
       " '5 - recall_at_25': 0.74}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some ideas to visualizate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
