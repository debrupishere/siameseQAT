{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 100\n",
    "MAX_SEQUENCE_LENGTH_D = 20 # 500\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'openoffice'\n",
    "METHOD = 'baseline_{}'.format(epochs)\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Glove embeddings\n",
    "GLOVE_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_feature@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_feature_@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec1108cc2d6419eaae061473c8d6df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=57667), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dce98ca80544b0bd36db72ae59660f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14567), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4160732abbb4e588d76bb458d1c140a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=72234), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed42a42c364048d5aa953c32e284fbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 5.13 s, sys: 620 ms, total: 5.75 s\n",
      "Wall time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702fb78826c448aca95fb4321401757d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58572), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[59, 27],\n",
       " [59, 92],\n",
       " [27, 92],\n",
       " [64, 43],\n",
       " [44, 45],\n",
       " [53, 54],\n",
       " [84, 63],\n",
       " [75, 699],\n",
       " [105, 121],\n",
       " [186, 199]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the corpus train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CORPUS:\n",
    "    corpus = []\n",
    "    export_file = open(os.path.join(DIR, 'corpus_train.txt'), 'w')\n",
    "    for bug_id in tqdm(baseline.bug_set):\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title = bug['title']\n",
    "        desc = bug['description']\n",
    "        export_file.write(\"{}\\n{}\\n\".format(title, desc))\n",
    "    export_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "# Generating tiple of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': '4\\n',\n",
       " 'bug_status': '1\\n',\n",
       " 'component': '121\\n',\n",
       " 'creation_ts': '2003-05-05 09:46:00 +0000',\n",
       " 'delta_ts': '2003-05-06 20:38:08 +0000',\n",
       " 'description': '[CLS] open office has always had this defect : when the processor is loaded , it runs slow . but with the new os that i have installed ( su ##se linux 8 . 2 ) , and with versions of open ##off ##ice 1 . 0 . 2 from 1 . 1 . beta , this becomes unacceptable . when a program occupies 85 - 97 % of the cpu ( no matter what % of memory ) , the open ##off ##ice is extremely slow and , generally , un ##usa ##ble . i wonder whether there is a solution . the problem seems to become more and more serious as the os - s and g ##cc versions progress . other similar applications , like ko ##ffi ##ce , nets ##cape do not display noticeable slow ##down . [SEP]',\n",
       " 'description_bert': '[CLS] open office has always had this defect : when the processor is loaded , it runs slow . but with the new os that i have installed ( su ##se linux 8 . 2 ) , and with versions of open ##off ##ice 1 . 0 . 2 from 1 . 1 . beta , this becomes unacceptable . when a program occupies 85 - 97 % of the cpu ( no matter what % of memory ) , the open ##off ##ice is extremely slow and , generally , un ##usa ##ble . i wonder whether there is a solution . the problem seems to become more and more serious as the os - s and g ##cc versions progress . other similar applications , like ko ##ffi ##ce , nets ##cape do not display noticeable slow ##down . [SEP]',\n",
       " 'description_word': array([  101,  2330,  2436,  2038,  2467,  2018,  2023, 21262,  1024,\n",
       "         2043,  1996, 13151,  2003,  8209,  1010,  2009,  3216,  4030,\n",
       "         1012,  2021]),\n",
       " 'description_word_bert': [101,\n",
       "  2330,\n",
       "  2436,\n",
       "  2038,\n",
       "  2467,\n",
       "  2018,\n",
       "  2023,\n",
       "  21262,\n",
       "  1024,\n",
       "  2043,\n",
       "  1996,\n",
       "  13151,\n",
       "  2003,\n",
       "  8209,\n",
       "  1010,\n",
       "  2009,\n",
       "  3216,\n",
       "  4030,\n",
       "  1012,\n",
       "  2021,\n",
       "  2007,\n",
       "  1996,\n",
       "  2047,\n",
       "  9808,\n",
       "  2008,\n",
       "  1045,\n",
       "  2031,\n",
       "  5361,\n",
       "  1006,\n",
       "  10514,\n",
       "  3366,\n",
       "  11603,\n",
       "  1022,\n",
       "  1012,\n",
       "  1016,\n",
       "  1007,\n",
       "  1010,\n",
       "  1998,\n",
       "  2007,\n",
       "  4617,\n",
       "  1997,\n",
       "  2330,\n",
       "  7245,\n",
       "  6610,\n",
       "  1015,\n",
       "  1012,\n",
       "  1014,\n",
       "  1012,\n",
       "  1016,\n",
       "  2013,\n",
       "  1015,\n",
       "  1012,\n",
       "  1015,\n",
       "  1012,\n",
       "  8247,\n",
       "  1010,\n",
       "  2023,\n",
       "  4150,\n",
       "  21873,\n",
       "  1012,\n",
       "  2043,\n",
       "  1037,\n",
       "  2565,\n",
       "  14133,\n",
       "  5594,\n",
       "  1011,\n",
       "  5989,\n",
       "  1003,\n",
       "  1997,\n",
       "  1996,\n",
       "  17368,\n",
       "  1006,\n",
       "  2053,\n",
       "  3043,\n",
       "  2054,\n",
       "  1003,\n",
       "  1997,\n",
       "  3638,\n",
       "  1007,\n",
       "  1010,\n",
       "  1996,\n",
       "  2330,\n",
       "  7245,\n",
       "  6610,\n",
       "  2003,\n",
       "  5186,\n",
       "  4030,\n",
       "  1998,\n",
       "  1010,\n",
       "  3227,\n",
       "  1010,\n",
       "  4895,\n",
       "  10383,\n",
       "  3468,\n",
       "  1012,\n",
       "  1045,\n",
       "  4687,\n",
       "  3251,\n",
       "  2045,\n",
       "  2003,\n",
       "  1037,\n",
       "  5576,\n",
       "  1012,\n",
       "  1996,\n",
       "  3291,\n",
       "  3849,\n",
       "  2000,\n",
       "  2468,\n",
       "  2062,\n",
       "  1998,\n",
       "  2062,\n",
       "  3809,\n",
       "  2004,\n",
       "  1996,\n",
       "  9808,\n",
       "  1011,\n",
       "  1055,\n",
       "  1998,\n",
       "  1043,\n",
       "  9468,\n",
       "  4617,\n",
       "  5082,\n",
       "  1012,\n",
       "  2060,\n",
       "  2714,\n",
       "  5097,\n",
       "  1010,\n",
       "  2066,\n",
       "  12849,\n",
       "  26989,\n",
       "  3401,\n",
       "  1010,\n",
       "  16996,\n",
       "  19464,\n",
       "  2079,\n",
       "  2025,\n",
       "  4653,\n",
       "  17725,\n",
       "  4030,\n",
       "  7698,\n",
       "  1012,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'dup_id': '9277',\n",
       " 'issue_id': 14104,\n",
       " 'priority': '1\\n',\n",
       " 'product': '38\\n',\n",
       " 'resolution': 'DUPLICATE',\n",
       " 'textual_word': array([  101,  2330,  7245,  6610,  2003,  2200,  4030,  1006,  7687,\n",
       "         1010, 11809,  1007,  1999,  1037,  3811,  8209,  7473,   102,\n",
       "            0,     0,   101,  2330,  2436,  2038,  2467,  2018,  2023,\n",
       "        21262,  1024,  2043,  1996, 13151,  2003,  8209,  1010,  2009,\n",
       "         3216,  4030,  1012,  2021]),\n",
       " 'title': '[CLS] open ##off ##ice is very slow ( essentially , useless ) in a highly loaded pc [SEP]',\n",
       " 'title_bert': '[CLS] open ##off ##ice is very slow ( essentially , useless ) in a highly loaded pc [SEP]',\n",
       " 'title_word': array([  101,  2330,  7245,  6610,  2003,  2200,  4030,  1006,  7687,\n",
       "         1010, 11809,  1007,  1999,  1037,  3811,  8209,  7473,   102,\n",
       "            0,     0]),\n",
       " 'title_word_bert': [101,\n",
       "  2330,\n",
       "  7245,\n",
       "  6610,\n",
       "  2003,\n",
       "  2200,\n",
       "  4030,\n",
       "  1006,\n",
       "  7687,\n",
       "  1010,\n",
       "  11809,\n",
       "  1007,\n",
       "  1999,\n",
       "  1037,\n",
       "  3811,\n",
       "  8209,\n",
       "  7473,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'version': '47\\n'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 11043)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 123 ms, sys: 151 µs, total: 123 ms\n",
      "Wall time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = experiment.batch_iterator(None, \n",
    "                                                                                                      baseline.train_data, \n",
    "                                                                                                      baseline.dup_sets_train,\n",
    "                                                                                                      bug_train_ids,\n",
    "                                                                                                      batch_size_test, 1,\n",
    "                                                                                                      issues_by_buckets)\n",
    "test_gen = ([valid_input_sample['title'], valid_input_pos['title'], valid_input_neg['title'], \n",
    "             valid_input_sample['description'], valid_input_pos['description'], valid_input_neg['description'],\n",
    "            valid_input_sample['info'], valid_input_pos['info'], valid_input_neg['info']], valid_sim)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 20), (128, 20), (128, 729), (128,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "#baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test ', 2086)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Test \", len(baseline.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 18562'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, GLOVE_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(GLOVE_DIR, 'glove.42B.300d.txt')\n",
    "    f = open(embed_path, 'rb')\n",
    "    #num_lines = sum(1 for line in open(embed_path, 'rb'))\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(tokens[1:], dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f63ca24d434d28a9d0ae26202099d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a92d98f25b462c982009f80eab8390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18562), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 21s, sys: 3.48 s, total: 1min 24s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, GLOVE_DIR=GLOVE_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer',\n",
    "                                  weights=[embeddings],\n",
    "                                  embeddings_constraint=MaxNorm(max_value=1, axis=0),\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI074wU4Y13y"
   },
   "source": [
    "### CNN with filter 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "h6YJU9GtFTyq",
    "outputId": "f85cf105-1fd6-491d-d969-7e6936f32739",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "\n",
    "def cnn_model(embedding_layer, max_sequence_length):\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length,), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None,), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "    # best combination filter (3, 4, 5) e 128 e 256\n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    n_filters = 64\n",
    "\n",
    "    for index, filter_size in enumerate(filter_sizes):\n",
    "        l_conv = Conv1D(filters=n_filters, kernel_size=filter_size)(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(pool_size=filter_size)(l_conv) # index+1\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "    # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "    #conv = Conv1D(filters=n_filters * 3, kernel_size=3)(l_merge)\n",
    "    layer = GlobalAveragePooling1D()(l_merge)\n",
    "    #layer = Flatten()(l_merge)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "    #layer = LeakyReLU()(layer)\n",
    "\n",
    "    cnn_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureCNNGenerationModel') # inputs=visible\n",
    "\n",
    "    return cnn_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr6ObTXiaALH"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "vC7MQXEsaCeG",
    "outputId": "65e647a9-c5d3-4009-b8a4-2e2d97b52684"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, GRU, Dropout, Bidirectional, GlobalAveragePooling1D, TimeDistributed\n",
    "\n",
    "def lstm_model(embedding_layer, max_sequence_length):\n",
    "    number_lstm_units = 75\n",
    "    rate_drop_lstm = 0\n",
    "    recurrent_dropout = 0\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None, ), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    left_layer = LSTM(number_lstm_units, return_sequences=True)(embedded_sequences)\n",
    "    right_layer = LSTM(number_lstm_units, return_sequences=True, go_backwards=True)(left_layer)\n",
    "    \n",
    "    lstm_layer = Concatenate()([left_layer, right_layer])\n",
    "    \n",
    "    #lstm_layer = TimeDistributed(Dense(50))(lstm_layer)\n",
    "    #layer = Flatten()(lstm_layer)\n",
    "    layer = GlobalAveragePooling1D()(lstm_layer)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "\n",
    "    lstm_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureLstmGenerationModel') # inputs=visible\n",
    "\n",
    "    return lstm_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    for units in [64, 32]:\n",
    "        layer = Dense(units, activation='tanh', kernel_initializer='random_uniform')(info_input)\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.sum(K.maximum(0.0, margin - pos + neg))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "  \n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    #     bug_feature_output = Activation('tanh')(bug_feature_output)\n",
    "    \n",
    "    # Bug representation layer\n",
    "    # bug_feature_output = Dense(300, activation='tanh')(bug_feature_output)\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    \n",
    "    # Cosine\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3 * decay_lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer=optimizer, loss=custom_margin_loss, metrics=[pos_distance, neg_distance, custom_margin_loss])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_pos (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_pos (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_neg (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_neg (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          219000      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          5772000     title_in[0][0]                   \n",
      "                                                                 title_pos[0][0]                  \n",
      "                                                                 title_neg[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          5818692     desc_in[0][0]                    \n",
      "                                                                 desc_pos[0][0]                   \n",
      "                                                                 desc_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 900)          0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureLstmGenerationModel[2][0] \n",
      "                                                                 FeatureCNNGenerationModel[2][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 900)          0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureLstmGenerationModel[3][0] \n",
      "                                                                 FeatureCNNGenerationModel[3][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances (Lambda)        (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 11,809,692\n",
      "Trainable params: 672,492\n",
      "Non-trainable params: 11,137,200\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 1.08, MarginLoss: 1.08, pos_cosine: 0.88, neg_cosine: 0.96\n",
      "Epoch: 2 Loss: 1.07, MarginLoss: 1.07, pos_cosine: 0.90, neg_cosine: 0.96\n",
      "Epoch: 3 Loss: 1.06, MarginLoss: 1.06, pos_cosine: 0.92, neg_cosine: 0.97\n",
      "Epoch: 4 Loss: 1.03, MarginLoss: 1.03, pos_cosine: 0.94, neg_cosine: 0.98\n",
      "Epoch: 5 Loss: 1.03, MarginLoss: 1.03, pos_cosine: 0.95, neg_cosine: 0.98\n",
      "Epoch: 6 Loss: 1.02, MarginLoss: 1.02, pos_cosine: 0.97, neg_cosine: 0.98\n",
      "Epoch: 7 Loss: 1.02, MarginLoss: 1.02, pos_cosine: 0.97, neg_cosine: 0.99\n",
      "Epoch: 8 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.98, neg_cosine: 0.99\n",
      "Epoch: 9 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.98, neg_cosine: 0.99\n",
      "Epoch: 10 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 11 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 12 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 13 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 14 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 15 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 16 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 17 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 18 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 19 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 20 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 21 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 22 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 23 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 24 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 25 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 26 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 27 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 28 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 29 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 30 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 31 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 32 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 33 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 34 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 35 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 36 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 38 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 39 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 40 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 41 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 42 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 43 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 44 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 45 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 46 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 47 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 48 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 49 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 50 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 51 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 52 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 53 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 54 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 55 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 56 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 57 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 58 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 59 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 60 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 61 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 62 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 63 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 64 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 65 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 66 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 67 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 68 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 69 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 70 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 71 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 72 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 73 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 74 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 75 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 76 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 77 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 78 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 79 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 80 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 81 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 82 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 83 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 84 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 85 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 86 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 87 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 88 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 89 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 90 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 91 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 92 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 93 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 94 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 95 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 96 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 97 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 98 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 99 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 100 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00, recall@25: 0.55\n",
      "Saved model 'modelos/model_baseline_100_feature_100epochs_64batch(openoffice).h5' to disk\n",
      "Best_epoch=0, Best_loss=1.00, Recall@25=0.55\n",
      "CPU times: user 1h 18s, sys: 16min 29s, total: 1h 16min 47s\n",
      "Wall time: 47min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False)\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False)\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    mlp_model\n",
    "'''\n",
    "desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "title_feature_model = lstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = experiment.batch_iterator(encoded_anchor, baseline.train_data, baseline.dup_sets_train, bug_train_ids, \n",
    "                                       batch_size, 1, issues_by_buckets)\n",
    "    train_batch = [train_input_sample['title'], train_input_sample['description'], train_input_sample['info'],\n",
    "                   train_input_pos['title'], train_input_pos['description'], train_input_pos['info'], \n",
    "                   train_input_neg['title'], train_input_neg['description'], train_input_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[3]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['108544:111059,109674,108379,109366|108529:0.9626346789300442,115634:0.9557104967534542,115421:0.9555168636143208,115569:0.9542703852057457,92348:0.9535358771681786,111593:0.9535335339605808,108492:0.9533993266522884,105757:0.9533493258059025,95460:0.9532226622104645,109298:0.9531769417226315,115557:0.9527512155473232,115100:0.9526020474731922,92690:0.9525536634027958,101398:0.952545702457428,92613:0.9521787203848362,98212:0.9518547542393208,105671:0.9516589269042015,93177:0.9516127668321133,92365:0.9515058882534504,92541:0.9513933062553406,102470:0.9513736180961132,65064:0.9513263925909996,98647:0.9511205591261387,105166:0.9510599225759506,106337:0.950668103992939,82495:0.9505720771849155,115072:0.9503335207700729,97168:0.9502439275383949,96429:0.9501969143748283',\n",
       " '109674:108544,111059,108379,109366|94815:0.9624805934727192,108390:0.9508225806057453,107845:0.9498982727527618,90533:0.9497983232140541,105511:0.9493419639766216,93055:0.948128342628479,95277:0.9478422738611698,108529:0.9473443031311035,102682:0.9470536299049854,113509:0.9461973197758198,108377:0.9460068196058273,105082:0.945921503007412,114153:0.9452823400497437,93288:0.9447534158825874,94421:0.9445281215012074,92543:0.9441403485834599,112299:0.9434390068054199,105671:0.9425536058843136,108544:0.9422409981489182,100665:0.9419513233006,89620:0.9419160299003124,111593:0.9418132901191711,92202:0.9418117366731167,93177:0.9417816884815693,109298:0.9417198151350021,116199:0.9415537640452385,101398:0.9413352683186531,98647:0.9413194470107555,105272:0.9412417896091938',\n",
       " '111059:108544,109674,108379,109366|110274:0.9920026334002614,110555:0.9898035116493702,111297:0.965644583106041,102470:0.9522907584905624,115569:0.9516074433922768,105907:0.9504573121666908,115421:0.9501628242433071,115634:0.9496256224811077,107267:0.9496245048940182,93169:0.9495494440197945,92541:0.9495251141488552,114022:0.9494389668107033,110843:0.9493759796023369,93318:0.9493062905967236,109862:0.9490553140640259,109298:0.9489329606294632,108918:0.9488426707684994,110889:0.94872235506773,106543:0.94866156950593,82495:0.9486545100808144,92613:0.9486000388860703,110322:0.948559895157814,110323:0.948559895157814,115557:0.9485374726355076,101398:0.9485099390149117,104267:0.9483580961823463,102712:0.9480140097439289,113630:0.9472995661199093,115068:0.9472681544721127',\n",
       " '108379:108544,111059,109674,109366|104574:0.9473079890012741,104576:0.9473079890012741,92188:0.9471917040646076,93295:0.9466937109827995,115888:0.9466776140034199,112693:0.9466493912041187,92117:0.9452387429773808,104173:0.9451734758913517,101268:0.944837398827076,106168:0.944755457341671,89456:0.9444011300802231,102471:0.943807803094387,97026:0.94374630600214,102003:0.9434971436858177,105961:0.9430825673043728,99982:0.94305220246315,108276:0.9430120699107647,99981:0.9430088326334953,107794:0.9428599365055561,116229:0.9427901729941368,97860:0.9416333362460136,106462:0.9413887485861778,93171:0.9410170465707779,106234:0.9409397765994072,115100:0.9407311752438545,94815:0.94060492888093,95460:0.9396998770534992,94033:0.9388625025749207,95800:0.9384460635483265',\n",
       " '109366:108544,111059,109674,108379|110044:0.9847926311194897,98821:0.952065970748663,105086:0.951464369893074,108311:0.9503871090710163,111295:0.9500490911304951,109431:0.9494610652327538,109535:0.9491983242332935,114719:0.9486369900405407,106574:0.948635883629322,105993:0.9483805149793625,115491:0.9482683092355728,104266:0.9482650049030781,102082:0.9482508450746536,102497:0.9481644555926323,114671:0.9475202932953835,92537:0.9474633224308491,105482:0.9460891745984554,91310:0.9452988803386688,99191:0.9448016434907913,100666:0.9431427642703056,106191:0.9425801560282707,101622:0.942379429936409,114770:0.9422781206667423,109363:0.9422738067805767,109081:0.940330009907484,112617:0.9401499927043915,107044:0.9398919902741909,109909:0.9390957690775394,104956:0.938806377351284',\n",
       " '110594:107073,108355,108453,109162,111761,111800|109162:0.9888514745980501,111761:0.9498472437262535,106479:0.949441023170948,107073:0.9478575401008129,108439:0.9474584572017193,98331:0.9469534903764725,108240:0.946443472057581,103827:0.9457026831805706,108918:0.9432005658745766,109198:0.9428389891982079,110843:0.9412004202604294,104278:0.9404731765389442,101545:0.9399791732430458,110889:0.9396539516746998,110274:0.9391885362565517,111059:0.9391608908772469,110555:0.9390709437429905,98394:0.9385362938046455,114077:0.9379589036107063,102251:0.9377633668482304,91605:0.9377536997199059,110445:0.9377282187342644,110712:0.9374861940741539,106207:0.93740464001894,109165:0.9371592998504639,95269:0.9370303228497505,103810:0.936939612030983,107319:0.9366165548563004,114227:0.9365088269114494',\n",
       " '111800:107073,110594,108355,108453,109162,111761|56891:0.9534984640777111,111833:0.9529997743666172,76670:0.9505252279341221,91324:0.9501503705978394,96212:0.9488974325358868,81539:0.9487534314393997,96736:0.9480007775127888,108569:0.9479150548577309,94719:0.9476623609662056,105931:0.9474498182535172,78260:0.9471161775290966,102068:0.9469727464020252,96117:0.946759570389986,92385:0.9466640241444111,108513:0.9466436356306076,102865:0.9458450339734554,95999:0.9458317048847675,102556:0.9456773847341537,98966:0.9456576034426689,94707:0.9454618133604527,112864:0.9453557021915913,106252:0.9451482370495796,102522:0.9444023594260216,90449:0.9442410841584206,100179:0.9425567165017128,112809:0.9423960261046886,85170:0.9407144822180271,102298:0.9398606233298779,105594:0.9397783055901527',\n",
       " '111761:107073,110594,108355,108453,109162,111800|111758:0.9613168314099312,110992:0.9577242061495781,110712:0.957448024302721,107073:0.9536082446575165,106479:0.9521616064012051,108240:0.9520145691931248,98331:0.9513329863548279,109162:0.9511009678244591,110594:0.9498472437262535,98310:0.9496851563453674,101462:0.9488362818956375,108084:0.9485911317169666,108439:0.9482027478516102,103827:0.94801801815629,103471:0.9469184540212154,95494:0.9442270547151566,95269:0.9422835186123848,93569:0.9411933869123459,106207:0.940662395209074,98394:0.9404396861791611,104278:0.9403953738510609,105251:0.9403053671121597,101545:0.9402506314218044,103810:0.9399878233671188,110482:0.939824428409338,91337:0.9397223107516766,99842:0.9392092041671276,95448:0.9388213120400906,91605:0.9385870285332203',\n",
       " '109162:107073,110594,108355,108453,111761,111800|110594:0.9888514745980501,111761:0.9511009678244591,106479:0.950976736843586,107073:0.9489072151482105,108240:0.9481220133602619,98331:0.948046587407589,103827:0.9472858719527721,101462:0.9470237232744694,98310:0.9465382322669029,108439:0.9458042755723,103471:0.9450974613428116,108084:0.9437554851174355,95494:0.9421709068119526,104278:0.9404007941484451,98394:0.939226221293211,101545:0.9388357624411583,91605:0.9386125355958939,111758:0.9386083483695984,102251:0.9381676837801933,95269:0.9381562881171703,114227:0.937935583293438,103810:0.9374641478061676,110712:0.9373256117105484,91931:0.9372470825910568,106207:0.9372453838586807,100234:0.9372311979532242,108126:0.9370179623365402,107319:0.9369437173008919,91337:0.9367617964744568',\n",
       " '108355:107073,110594,108453,109162,111761,111800|110230:0.9394090138375759,109909:0.9355764538049698,114938:0.9338611587882042,115898:0.9330025687813759,91166:0.9326241686940193,107049:0.9317044988274574,104333:0.9315603673458099,106083:0.9315420240163803,97135:0.9315204098820686,105243:0.9308144301176071,107439:0.9299599006772041,110692:0.929029107093811,108426:0.9279714226722717,90800:0.9275988414883614,99423:0.9274895042181015,105368:0.9274810031056404,110861:0.9271801337599754,106581:0.9271241575479507,109535:0.9269271716475487,103278:0.9268613681197166,112187:0.9266384243965149,108439:0.9261750876903534,109103:0.9257779344916344,114202:0.9254102408885956,105377:0.9252929612994194,102921:0.9252552390098572,106710:0.9251892119646072,91534:0.9249521493911743,99254:0.924949623644352',\n",
       " '108453:107073,110594,108355,109162,111761,111800|95494:0.948394425213337,108084:0.9474306255578995,103471:0.9461395628750324,101462:0.9460814520716667,98310:0.944499034434557,108240:0.94386375695467,103827:0.9433707147836685,106479:0.9431604072451591,100158:0.942658681422472,111761:0.9422212354838848,98331:0.9422035850584507,107073:0.9413896948099136,114811:0.9407976754009724,102023:0.940352775156498,104620:0.9395082034170628,98244:0.9394810274243355,91931:0.939458142966032,109162:0.9394493512809277,93419:0.9393603764474392,97821:0.9381396435201168,115849:0.937972966581583,107139:0.9373329505324364,99672:0.9373316094279289,95448:0.9369766935706139,108018:0.9369246736168861,95269:0.936901181936264,92902:0.9367848336696625,101051:0.93659508228302,93952:0.9365224540233612',\n",
       " '114705:114676|105368:0.9541390873491764,108423:0.9528214037418365,98659:0.9514101594686508,113470:0.9511216469109058,105822:0.9505662433803082,105047:0.9498870633542538,113535:0.9496264234185219,116991:0.9494567178189754,110915:0.9486447423696518,116139:0.9479544200003147,105747:0.9474081322550774,95152:0.9470821283757687,112187:0.9457223117351532,116457:0.9453340508043766,106523:0.9452153258025646,106591:0.9433683529496193,113313:0.9424825422465801,115048:0.9422318898141384,110230:0.9419720694422722,115404:0.9418742880225182,111191:0.9418349862098694,100282:0.9417870417237282,113097:0.941453792154789,104587:0.9410433433949947,112218:0.9408142752945423,98753:0.9407164044678211,102735:0.9404902122914791,103423:0.9403705857694149,100351:0.9402729086577892',\n",
       " '114676:114705|91245:0.9501240514218807,111881:0.9498261399567127,104359:0.9488819129765034,104360:0.9488819129765034,96817:0.9486207813024521,101522:0.9485183916985989,102648:0.9483028277754784,101448:0.9474561028182507,110900:0.9472173862159252,112843:0.947127815335989,112844:0.947127815335989,108401:0.9469515457749367,107893:0.9468601979315281,115237:0.9465688243508339,103513:0.9464643709361553,113669:0.945829551666975,106268:0.9447531998157501,106269:0.9447305798530579,115350:0.9436898678541183,110866:0.9410671852529049,108061:0.9380955249071121,121279:0.9324674680829048,108191:0.9308906570076942,108190:0.9282075613737106,90896:0.9277369230985641,99163:0.9276537373661995,97978:0.9275316074490547,108431:0.9271868467330933,112684:0.9268687814474106',\n",
       " '110593:110618|110397:0.9807796310633421,111172:0.9723912458866835,110485:0.9638575576245785,110374:0.9633640348911285,110343:0.9632076136767864,110026:0.9626796022057533,110005:0.962450560182333,110657:0.9618297405540943,110375:0.9618211984634399,111651:0.9605889357626438,109568:0.9602580852806568,109950:0.9598672948777676,110346:0.959488894790411,110012:0.9593215137720108,110392:0.9588944278657436,109880:0.9584055580198765,115496:0.9554140828549862,109435:0.9545764103531837,110956:0.954203400760889,102304:0.953398335725069,106085:0.952305618673563,98276:0.9520335718989372,98675:0.9515941739082336,116347:0.9514698795974255,92311:0.9513838700950146,110351:0.9512469880282879,96092:0.95105816796422,105687:0.9508831351995468,114881:0.9508009068667889',\n",
       " '110618:110593|110922:0.9596413858234882,112234:0.9591102078557014,110306:0.9568833597004414,90892:0.9541639797389507,96115:0.9538983330130577,94253:0.9538454785943031,91809:0.9533381722867489,90511:0.9526325054466724,94884:0.9524470791220665,105817:0.952173613011837,105290:0.9519368335604668,101648:0.9517987221479416,109221:0.9515636749565601,105396:0.951525654643774,110485:0.9512890391051769,110343:0.9510088004171848,110374:0.9509518705308437,113831:0.950762901455164,109422:0.9507484547793865,96142:0.9506745263934135,105276:0.950672097504139,89188:0.9505672007799149,97263:0.950563095510006,110026:0.9505294002592564,105640:0.950437918305397,99270:0.9504367485642433,104162:0.9497944116592407,106046:0.9495991729199886,97523:0.9494470991194248',\n",
       " '102409:102053|102106:0.9852072391659021,96124:0.9547942467033863,102557:0.9530632458627224,106171:0.9518062993884087,99306:0.9508473537862301,106072:0.95084098726511,102398:0.9501907117664814,101124:0.9490015879273415,110764:0.9484305717051029,96945:0.9480426833033562,96471:0.9475112073123455,104044:0.9474581182003021,104267:0.9470253325998783,92348:0.935241125524044,92690:0.9347537532448769,105272:0.9342914298176765,65064:0.9338965937495232,115634:0.9336647242307663,115421:0.9335199594497681,95460:0.9334592297673225,93296:0.9334375858306885,46957:0.9333582073450089,104409:0.9332624152302742,102638:0.9331901744008064,103357:0.9331094548106194,98647:0.9330310747027397,102973:0.9329875260591507,103136:0.9329522401094437,103459:0.9329310357570648',\n",
       " '102053:102409|107236:0.9452610798180103,116288:0.9428670704364777,98569:0.9384058751165867,90473:0.9383899979293346,103145:0.9365679919719696,90307:0.936133548617363,107101:0.935759574174881,97710:0.9357129856944084,85559:0.9349134489893913,91791:0.9328751638531685,107778:0.9325898960232735,109067:0.9311593994498253,99167:0.9302036464214325,99163:0.9286385625600815,109794:0.9284388050436974,108431:0.9284347742795944,97978:0.9284123331308365,108665:0.9282092675566673,101249:0.9281904101371765,96390:0.9280734583735466,90896:0.9278906583786011,90096:0.9276002869009972,109550:0.9274289011955261,107712:0.9273182600736618,112276:0.9273155182600021,111165:0.9272626414895058,113653:0.9271364286541939,71112:0.9270751103758812,106090:0.9270501211285591',\n",
       " '110604:110612|81355:0.9234379082918167,99626:0.9233478531241417,92672:0.9232689663767815,115300:0.923042893409729,103504:0.9212957620620728,91477:0.9210784956812859,108002:0.9208102822303772,101955:0.9204305559396744,100721:0.9200143292546272,100722:0.9200143292546272,106005:0.9196914806962013,113532:0.9195167273283005,102023:0.9194689616560936,102450:0.9192963987588882,107466:0.9192492440342903,102978:0.9192099124193192,108045:0.9191195219755173,104050:0.9191072210669518,111673:0.919050931930542,102471:0.9189435914158821,103210:0.9188774153590202,112371:0.91881462931633,112313:0.9187775328755379,92117:0.9187216237187386,97809:0.9187149405479431,111277:0.9186913967132568,112103:0.9186470359563828,105176:0.9186263531446457,106950:0.9186125174164772',\n",
       " '110612:110604|104153:0.9281469956040382,109067:0.9252985790371895,94780:0.9220304191112518,102701:0.921143926680088,101569:0.9210351407527924,112039:0.920821875333786,98005:0.9204390421509743,108840:0.9201554208993912,93289:0.920123778283596,93607:0.9191202819347382,89528:0.9190662726759911,91479:0.918714128434658,92679:0.9186791703104973,94226:0.918510690331459,93364:0.9178358092904091,100676:0.9175329506397247,113579:0.9173809438943863,30870:0.9173800349235535,107712:0.9172667115926743,114310:0.9172211289405823,96390:0.9170543849468231,102712:0.9170165956020355,101249:0.9168998748064041,113652:0.9168190583586693,112690:0.9167600199580193,91279:0.9167517051100731,108665:0.9167292192578316,94385:0.9166866391897202,113653:0.916524663567543',\n",
       " '116738:116938,117027|113225:0.9753791745752096,115793:0.9743968546390533,115201:0.9531884789466858,115228:0.9518244490027428,100846:0.950721975415945,116938:0.950176790356636,95130:0.9495299383997917,112680:0.9494129940867424,99737:0.948846310377121,90796:0.9486260265111923,115444:0.9485674425959587,93220:0.9483903907239437,86455:0.948308926075697,96218:0.948102068156004,100713:0.9478996209800243,100714:0.9478996209800243,100715:0.9478996209800243,100716:0.9478996209800243,105862:0.9478455632925034,108414:0.9477730430662632,92002:0.94768425822258,112379:0.9476634375751019,98664:0.9475970976054668,109937:0.9475163780152798,100511:0.9472710862755775,111617:0.9469743110239506,99106:0.9464428387582302,107833:0.9456498883664608,113395:0.9455834962427616']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "#     Between 0-10 epochs recall@25 = 0.28\n",
    "#     Between 0-20 epochs recall@25 = 0.32\n",
    "#     Between 0-70 epochs recall@25 = ?\n",
    "#     Between 0-100 epochs recall@25 = ?\n",
    "# '''\n",
    "# recall, exported_rank = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 2086\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_100_feature_100epochs_64batch(openoffice)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoded_anchor\n",
    "# model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          219000      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          5772000     title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          5818692     desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "==================================================================================================\n",
      "Total params: 11,809,692\n",
      "Trainable params: 672,492\n",
      "Non-trainable params: 11,137,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, bug_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/openoffice/exported_rank_baseline_100.txt'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in _:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.39,\n",
       " '2 - recall_at_10': 0.45,\n",
       " '3 - recall_at_15': 0.49,\n",
       " '4 - recall_at_20': 0.52,\n",
       " '5 - recall_at_25': 0.55}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some ideas to visualizate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
