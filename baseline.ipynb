{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 100 # 100\n",
    "MAX_SEQUENCE_LENGTH_D = 500 # 500\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'eclipse'\n",
    "METHOD = 'baseline'\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Glove embeddings\n",
    "GLOVE_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = 'baseline_feature@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "SAVE_PATH_FEATURE = 'baseline_feature_@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4a4425dfd74446beac6aa74af5a409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322339), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e307e3b3ac452da84147bfacac19c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39545), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "361006"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d89c311d8845b8bee7a54b7f86a587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=361006), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90becd983a7541ce86cfee9d73271693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 16s, sys: 5.22 s, total: 2min 21s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2301fd0f2c00442e92930655902c84c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=321536), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 183],\n",
       " [15392, 2],\n",
       " [15392, 9779],\n",
       " [15392, 94],\n",
       " [2, 9779],\n",
       " [2, 94],\n",
       " [9779, 94],\n",
       " [42962, 7],\n",
       " [10, 121067],\n",
       " [40, 20]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the corpus train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CORPUS:\n",
    "    corpus = []\n",
    "    export_file = open(os.path.join(DIR, 'corpus_train.txt'), 'w')\n",
    "    for bug_id in tqdm(baseline.bug_set):\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title = bug['title']\n",
    "        desc = bug['description']\n",
    "        export_file.write(\"{}\\n{}\\n\".format(title, desc))\n",
    "    export_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "# Generating tiple of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bug_status': '0\\n', 'priority': '2\\n', 'delta_ts': '2005-05-10 14:55:51 -0400', 'component': '724\\n', 'version': '151\\n', 'description': 'steps step index minimize all your windows step index go to any window and select the window menu step index pick any window notice that it only gets selected and not maximized this happens in os as well notes', 'resolution': 'FIXED', 'creation_ts': '2001-10-10 22:38:00 -0400', 'title_word': array([1132,   11,   79,   12,    6,   79,  212,   91,   19, 3149,   79,\n",
      "          1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0]), 'dup_id': '[]', 'bug_severity': '1\\n', 'title': 'selecting a window in the window menu does not maximize window gfitic', 'description_word': array([ 179,   28,   26, 3135,  109,  658,  386,   28,   26,  469,    8,\n",
      "        243,   79,   17,  168,    6,   79,  212,   28,   26, 2053,  243,\n",
      "         79,  967,   33,   24,  189,  874,  307,   17,   19, 3495,   25,\n",
      "        709,   12,  166,   57,  665, 1299,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0]), 'issue_id': 2521, 'product': '173\\n'}\n"
     ]
    }
   ],
   "source": [
    "if 2521 in baseline.bug_set:\n",
    "    print(baseline.bug_set[2521])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 34882)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_neg_bug(invalid_bugs, bug_ids, issues_by_buckets):\n",
    "    neg_bug = random.choice(list(issues_by_buckets.keys()))\n",
    "    try:\n",
    "        while neg_bug in invalid_bugs or neg_bug not in issues_by_buckets:\n",
    "            neg_bug = random.choice(bug_ids)\n",
    "    except:\n",
    "        invalid_bugs = [invalid_bugs]\n",
    "        while neg_bug in invalid_bugs or neg_bug not in issues_by_buckets:\n",
    "            neg_bug = random.choice(bug_ids)\n",
    "    return neg_bug\n",
    "\n",
    "def get_neg_bug_semihard(baseline, model, batch_bugs, anchor, invalid_bugs):\n",
    "    vector = model.predict([ np.array([baseline.bug_set[anchor]['title_word']]), \n",
    "                            np.array([baseline.bug_set[anchor]['description_word']]), \n",
    "                            np.array([retrieval.get_info(baseline.bug_set[anchor])]) ])\n",
    "    annoy = AnnoyIndex(vector.shape[1])\n",
    "    embeds = []\n",
    "    title_data, desc_data, info_data = [], [], []\n",
    "    batch_bugs_wo_positives = list(set(batch_bugs) - set(invalid_bugs)) \n",
    "    for bug_id in batch_bugs_wo_positives:\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title_data.append(bug['title_word'])\n",
    "        desc_data.append(bug['description_word'])\n",
    "        info_data.append(retrieval.get_info(bug))\n",
    "    embeds = model.predict([ np.array(title_data), np.array(desc_data), np.array(info_data) ])\n",
    "    for bug_id, embed in zip(batch_bugs_wo_positives, embeds):\n",
    "        annoy.add_item(bug_id, embed)\n",
    "    annoy.build(10) # 10 trees\n",
    "    rank = annoy.get_nns_by_vector(vector[0], 20, include_distances=False)\n",
    "    neg_bug = rank[0]\n",
    "    return neg_bug\n",
    "\n",
    "def batch_iterator(baseline, model, data, dup_sets, bug_ids, batch_size, n_neg, issues_by_buckets):\n",
    "    # global train_data\n",
    "    # global self.dup_sets\n",
    "    # global self.bug_ids\n",
    "    # global self.bug_set\n",
    "\n",
    "    random.shuffle(data)\n",
    "\n",
    "    batch_input, batch_pos, batch_neg = {'title' : [], 'desc' : [], 'info' : []}, \\\n",
    "                                            {'title' : [], 'desc' : [], 'info' : []}, \\\n",
    "                                                {'title' : [], 'desc' : [], 'info' : []}\n",
    "\n",
    "    n_train = len(data)\n",
    "\n",
    "    batch_triplets = []\n",
    "\n",
    "    batch_triplets, batch_bugs_anchor, batch_bugs_pos, batch_bugs_neg, batch_bugs = [], [], [], [], []\n",
    "\n",
    "    for offset in range(batch_size):\n",
    "        #neg_bug = Baseline.get_neg_bug(dup_sets[data[offset][0]], bug_train_ids)\n",
    "        #neg_bug = get_neg_bug_semihard(baseline, data[offset][0], dup_sets[data[offset][0]])\n",
    "#         pos_bug = get_pos_bug_semihard(baseline, data[offset][0], dup_sets[data[offset][0]])\n",
    "        anchor, pos = data[offset][0], data[offset][1]\n",
    "        batch_bugs_anchor.append(anchor)\n",
    "        batch_bugs_pos.append(pos)\n",
    "        batch_bugs += dup_sets[anchor]\n",
    "    \n",
    "    for anchor, pos in zip(batch_bugs_anchor, batch_bugs_pos):\n",
    "        if model == None:\n",
    "            neg = get_neg_bug(anchor, dup_sets[anchor], issues_by_buckets)\n",
    "        else:\n",
    "            neg = get_neg_bug_semihard(baseline, model, batch_bugs, anchor, dup_sets[anchor])\n",
    "        bug_anchor = baseline.bug_set[anchor]\n",
    "        bug_pos = baseline.bug_set[pos]\n",
    "        bug_neg = baseline.bug_set[neg]\n",
    "        \n",
    "        baseline.read_batch_bugs(batch_input, bug_anchor)\n",
    "        baseline.read_batch_bugs(batch_pos, bug_pos)\n",
    "        baseline.read_batch_bugs(batch_neg, bug_neg)\n",
    "        # triplet bug and master\n",
    "        batch_triplets.append([anchor, pos, neg])\n",
    "\n",
    "    batch_input['title'] = np.array(batch_input['title'])\n",
    "    batch_input['desc'] = np.array(batch_input['desc'])\n",
    "    batch_input['info'] = np.array(batch_input['info'])\n",
    "    batch_pos['title'] = np.array(batch_pos['title'])\n",
    "    batch_pos['desc'] = np.array(batch_pos['desc'])\n",
    "    batch_pos['info'] = np.array(batch_pos['info'])\n",
    "    batch_neg['title'] = np.array(batch_neg['title'])\n",
    "    batch_neg['desc'] = np.array(batch_neg['desc'])\n",
    "    batch_neg['info'] = np.array(batch_neg['info'])\n",
    "\n",
    "    n_half = len(batch_triplets) // 2\n",
    "    if n_half > 0:\n",
    "        pos = np.full((1, n_half), 1)\n",
    "        neg = np.full((1, n_half), 0)\n",
    "        sim = np.concatenate([pos, neg], -1)[0]\n",
    "    else:\n",
    "        sim = np.array([np.random.choice([1, 0])])\n",
    "\n",
    "    input_sample, input_pos, input_neg = {}, {}, {}\n",
    "\n",
    "    input_sample = { 'title' : batch_input['title'], 'description' : batch_input['desc'], 'info' : batch_input['info'] }\n",
    "    input_pos = { 'title' : batch_pos['title'], 'description' : batch_pos['desc'], 'info': batch_pos['info'] }\n",
    "    input_neg = { 'title' : batch_neg['title'], 'description' : batch_neg['desc'], 'info': batch_neg['info'] }\n",
    "\n",
    "    return batch_triplets, input_sample, input_pos, input_neg, sim #sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 452 ms, sys: 0 ns, total: 452 ms\n",
      "Wall time: 450 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = batch_iterator(baseline, None, \n",
    "                                                                                                       baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train,\n",
    "                                                                                          bug_train_ids,\n",
    "                                                                                          batch_size_test, 1,\n",
    "                                                                                          issues_by_buckets)\n",
    "test_gen = ([valid_input_sample['title'], valid_input_pos['title'], valid_input_neg['title'], \n",
    "             valid_input_sample['description'], valid_input_pos['description'], valid_input_neg['description'],\n",
    "            valid_input_sample['info'], valid_input_pos['info'], valid_input_neg['info']], valid_sim)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 100), (128, 500), (128, 1682), (128,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "display_batch() missing 2 required positional arguments: 'batch_iterator' and 'issues_by_buckets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: display_batch() missing 2 required positional arguments: 'batch_iterator' and 'issues_by_buckets'"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test ', 4641)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Test \", len(baseline.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 149145'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, GLOVE_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(GLOVE_DIR, 'glove.42B.300d.txt')\n",
    "    f = open(embed_path, 'rb')\n",
    "    #num_lines = sum(1 for line in open(embed_path, 'rb'))\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(tokens[1:], dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a9a998035d4984a322d80fc55ee52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fe8286660f4ad4a7b4586e7d77af20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=149145), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 43s, sys: 7.67 s, total: 2min 51s\n",
      "Wall time: 5min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, GLOVE_DIR=GLOVE_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer',\n",
    "                                  weights=[embeddings],\n",
    "                                  embeddings_constraint=MaxNorm(max_value=1, axis=0),\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI074wU4Y13y"
   },
   "source": [
    "### CNN with filter 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "h6YJU9GtFTyq",
    "outputId": "f85cf105-1fd6-491d-d969-7e6936f32739",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "\n",
    "def cnn_model(embedding_layer, max_sequence_length):\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length,), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None,), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "    # best combination filter (3, 4, 5) e 128 e 256\n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    n_filters = 64\n",
    "\n",
    "    for index, filter_size in enumerate(filter_sizes):\n",
    "        l_conv = Conv1D(filters=n_filters, kernel_size=filter_size)(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(pool_size=filter_size)(l_conv) # index+1\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "    # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "    #conv = Conv1D(filters=n_filters * 3, kernel_size=3)(l_merge)\n",
    "    layer = GlobalAveragePooling1D()(l_merge)\n",
    "    #layer = Flatten()(l_merge)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "    #layer = LeakyReLU()(layer)\n",
    "\n",
    "    cnn_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureCNNGenerationModel') # inputs=visible\n",
    "\n",
    "    return cnn_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr6ObTXiaALH"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "vC7MQXEsaCeG",
    "outputId": "65e647a9-c5d3-4009-b8a4-2e2d97b52684"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, GRU, Dropout, Bidirectional, GlobalAveragePooling1D, TimeDistributed\n",
    "\n",
    "def lstm_model(embedding_layer, max_sequence_length):\n",
    "    number_lstm_units = 75\n",
    "    rate_drop_lstm = 0\n",
    "    recurrent_dropout = 0\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None, ), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    left_layer = LSTM(number_lstm_units, return_sequences=True)(embedded_sequences)\n",
    "    right_layer = LSTM(number_lstm_units, return_sequences=True, go_backwards=True)(left_layer)\n",
    "    \n",
    "    lstm_layer = Concatenate()([left_layer, right_layer])\n",
    "    \n",
    "    #lstm_layer = TimeDistributed(Dense(50))(lstm_layer)\n",
    "    #layer = Flatten()(lstm_layer)\n",
    "    layer = GlobalAveragePooling1D()(lstm_layer)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "\n",
    "    lstm_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureLstmGenerationModel') # inputs=visible\n",
    "\n",
    "    return lstm_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    for units in [64, 32]:\n",
    "        layer = Dense(units, activation='tanh', kernel_initializer='random_uniform')(info_input)\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.sum(K.maximum(0.0, margin - pos + neg))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "  \n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    #     bug_feature_output = Activation('tanh')(bug_feature_output)\n",
    "    \n",
    "    # Bug representation layer\n",
    "    # bug_feature_output = Dense(300, activation='tanh')(bug_feature_output)\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    \n",
    "    # Cosine\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3 * decay_lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer=optimizer, loss=custom_margin_loss, metrics=[pos_distance, neg_distance, custom_margin_loss])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_pos (InputLayer)          (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_pos (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_neg (InputLayer)          (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_neg (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          44946900    title_in[0][0]                   \n",
      "                                                                 title_pos[0][0]                  \n",
      "                                                                 title_neg[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          44993592    desc_in[0][0]                    \n",
      "                                                                 desc_pos[0][0]                   \n",
      "                                                                 desc_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 900)          0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureLstmGenerationModel[2][0] \n",
      "                                                                 FeatureCNNGenerationModel[2][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 900)          0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureLstmGenerationModel[3][0] \n",
      "                                                                 FeatureCNNGenerationModel[3][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances (Lambda)        (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 90,445,392\n",
      "Trainable params: 958,392\n",
      "Non-trainable params: 89,487,000\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 1.04, MarginLoss: 1.04, pos_cosine: 0.87, neg_cosine: 0.91\n",
      "Epoch: 2 Loss: 1.03, MarginLoss: 1.03, pos_cosine: 0.87, neg_cosine: 0.90\n",
      "Epoch: 3 Loss: 1.02, MarginLoss: 1.02, pos_cosine: 0.89, neg_cosine: 0.91\n",
      "Epoch: 4 Loss: 1.04, MarginLoss: 1.04, pos_cosine: 0.88, neg_cosine: 0.92\n",
      "Epoch: 5 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.90, neg_cosine: 0.91\n",
      "Epoch: 6 Loss: 1.02, MarginLoss: 1.02, pos_cosine: 0.90, neg_cosine: 0.92\n",
      "Epoch: 7 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.91, neg_cosine: 0.92\n",
      "Epoch: 8 Loss: 1.03, MarginLoss: 1.03, pos_cosine: 0.90, neg_cosine: 0.93\n",
      "Epoch: 9 Loss: 1.02, MarginLoss: 1.02, pos_cosine: 0.92, neg_cosine: 0.93\n",
      "Epoch: 10 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.93, neg_cosine: 0.92\n",
      "Epoch: 11 Loss: 1.02, MarginLoss: 1.02, pos_cosine: 0.92, neg_cosine: 0.94\n",
      "Epoch: 12 Loss: 1.03, MarginLoss: 1.03, pos_cosine: 0.92, neg_cosine: 0.95\n",
      "Epoch: 13 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.94, neg_cosine: 0.95\n",
      "Epoch: 14 Loss: 1.02, MarginLoss: 1.02, pos_cosine: 0.94, neg_cosine: 0.96\n",
      "Epoch: 15 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.95, neg_cosine: 0.96\n",
      "Epoch: 16 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.96, neg_cosine: 0.97\n",
      "Epoch: 17 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.97, neg_cosine: 0.98\n",
      "Epoch: 18 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.98, neg_cosine: 0.98\n",
      "Epoch: 19 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 20 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 21 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 22 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 23 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 24 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 25 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 26 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 27 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 28 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 29 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 30 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 31 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 32 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 33 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 34 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 35 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 36 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 38 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 39 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 40 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 41 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 42 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 43 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 44 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 45 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 46 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 47 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 48 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 49 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 50 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 51 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 52 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 53 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 54 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 55 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 56 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 57 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 58 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 59 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 60 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 61 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 62 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 63 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 64 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 65 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 66 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 67 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 68 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 69 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 70 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 71 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 72 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 73 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 74 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 75 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 76 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 77 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 78 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 79 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 80 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 81 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 82 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 83 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 84 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 85 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 86 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 87 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 88 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 89 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 90 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 91 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 92 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 93 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 94 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 95 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 96 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 97 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 98 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 99 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 100 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00, recall@25: 0.52\n",
      "Saved model 'modelos/model_baseline_feature_100epochs_64batch(eclipse).h5' to disk\n",
      "Best_epoch=10, Best_loss=1.00, Recall@25=0.52\n",
      "CPU times: user 2h 36min 41s, sys: 50min 29s, total: 3h 27min 11s\n",
      "Wall time: 2h 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False)\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False)\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    mlp_model\n",
    "'''\n",
    "desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "title_feature_model = lstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 300\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = batch_iterator(baseline, encoded_anchor, baseline.train_data, baseline.dup_sets_train, bug_train_ids, \n",
    "                                       batch_size, 1, issues_by_buckets)\n",
    "    train_batch = [train_input_sample['title'], train_input_sample['description'], train_input_sample['info'],\n",
    "                   train_input_pos['title'], train_input_pos['description'], train_input_pos['info'], \n",
    "                   train_input_neg['title'], train_input_neg['description'], train_input_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[3]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['327681:324658|355330:0.9267133623361588,412728:0.926476001739502,402273:0.9260732382535934,376838:0.9257475435733795,376841:0.9257475435733795,347642:0.9256748110055923,398578:0.9252976775169373,327528:0.9252941831946373,406047:0.9252534955739975,413111:0.9251361414790154,316218:0.9251253828406334,344993:0.9250642210245132,393933:0.925028033554554,319622:0.9250030815601349,379377:0.9249824732542038,333341:0.9249795153737068,351328:0.9245840311050415,369157:0.9245734959840775,371466:0.924544520676136,367477:0.9245422333478928,377553:0.9245322942733765,394186:0.924505889415741,339619:0.924440398812294,328530:0.9244069159030914,384962:0.9244030490517616,367643:0.9243293777108192,377477:0.9242998287081718,367642:0.9242889285087585,390765:0.9242689236998558',\n",
       " '324658:327681|326293:0.9224240481853485,351536:0.9207181036472321,395181:0.9187239781022072,350379:0.9173689633607864,374073:0.9162716418504715,327514:0.9161949828267097,322720:0.9161906018853188,327511:0.9160611853003502,347384:0.9151782616972923,386774:0.9151746034622192,345577:0.9150315895676613,326250:0.9149040505290031,378700:0.914271168410778,318639:0.9139535799622536,320688:0.9136450663208961,372249:0.913632407784462,380433:0.9134445488452911,348162:0.9129968583583832,390320:0.912989541888237,387094:0.9129603505134583,369267:0.9129510894417763,359259:0.9129410684108734,382534:0.9129212275147438,374398:0.912912093102932,339046:0.9129035994410515,330409:0.9128689467906952,366094:0.912780299782753,321841:0.9127074033021927,321847:0.9126871526241302',\n",
       " '417795:417796,403749|417796:0.9987661140039563,422902:0.9640818908810616,412623:0.9581217169761658,350396:0.9542203173041344,350323:0.9542085528373718,348435:0.95419130474329,350521:0.9541645646095276,334455:0.9531485699117184,409086:0.9521290063858032,406277:0.9520633555948734,368390:0.9515141844749451,421260:0.9494141675531864,421292:0.9493599645793438,421574:0.9492956809699535,420245:0.9492767453193665,94152:0.9470270499587059,87239:0.9470051266252995,106371:0.9469549171626568,94755:0.9468875750899315,417122:0.945187795907259,419767:0.9451482221484184,391433:0.9450772069394588,411794:0.9449024684727192,349798:0.9444012567400932,396681:0.944118045270443,398995:0.9439987242221832,403749:0.9439555406570435,271551:0.9438964277505875,398965:0.9438793919980526',\n",
       " '417796:417795,403749|417795:0.9987661140039563,422902:0.9640893191099167,412623:0.9583072438836098,350323:0.9542366452515125,350396:0.9542259089648724,348435:0.9541970565915108,350521:0.9541250020265579,334455:0.9531592726707458,409086:0.9521273449063301,406277:0.9521008655428886,368390:0.9515015929937363,421260:0.949401468038559,421574:0.9493322484195232,421292:0.9493268430233002,420245:0.9492748081684113,94152:0.9469883851706982,87239:0.9469778761267662,106371:0.9469471089541912,94755:0.9468808174133301,417122:0.9451999366283417,419767:0.9451131373643875,391433:0.9450900852680206,411794:0.9449160881340504,349798:0.9443659260869026,396681:0.9440812133252621,398995:0.9439731277525425,403749:0.9439320005476475,271551:0.9438964501023293,390915:0.9438639879226685',\n",
       " '403749:417795,417796|398995:0.999298534123227,390915:0.9983990165637806,398965:0.9973037850577384,411794:0.9732836410403252,409086:0.9683603942394257,406277:0.9682864136993885,418692:0.9649539515376091,403927:0.964892815798521,397464:0.9648036025464535,394467:0.9609881341457367,406463:0.9554894641041756,423214:0.9552238397300243,104395:0.9530952833592892,393621:0.953026071190834,409520:0.9515179097652435,364815:0.949712336063385,402530:0.9496020600199699,350323:0.9459987506270409,350396:0.945974737405777,350521:0.9459724053740501,348435:0.9459686428308487,416295:0.945259653031826,334455:0.9450978450477123,406676:0.9447328113019466,410309:0.944527167826891,417795:0.9439555406570435,417796:0.9439320005476475,391433:0.9431202635169029,408203:0.9421345703303814',\n",
       " '417796:417795,403749|417795:0.9987661140039563,422902:0.9640893191099167,412623:0.9583072438836098,350323:0.9542366452515125,350396:0.9542259089648724,348435:0.9541970565915108,350521:0.9541250020265579,334455:0.9531592726707458,409086:0.9521273449063301,406277:0.9521008655428886,368390:0.9515015929937363,421260:0.949401468038559,421574:0.9493322484195232,421292:0.9493268430233002,420245:0.9492748081684113,94152:0.9469883851706982,87239:0.9469778761267662,106371:0.9469471089541912,94755:0.9468808174133301,417122:0.9451999366283417,419767:0.9451131373643875,391433:0.9450900852680206,411794:0.9449160881340504,349798:0.9443659260869026,396681:0.9440812133252621,398995:0.9439731277525425,403749:0.9439320005476475,271551:0.9438964501023293,390915:0.9438639879226685',\n",
       " '403749:417795,417796|398995:0.999298534123227,390915:0.9983990165637806,398965:0.9973037850577384,411794:0.9732836410403252,409086:0.9683603942394257,406277:0.9682864136993885,418692:0.9649539515376091,403927:0.964892815798521,397464:0.9648036025464535,394467:0.9609881341457367,406463:0.9554894641041756,423214:0.9552238397300243,104395:0.9530952833592892,393621:0.953026071190834,409520:0.9515179097652435,364815:0.949712336063385,402530:0.9496020600199699,350323:0.9459987506270409,350396:0.945974737405777,350521:0.9459724053740501,348435:0.9459686428308487,416295:0.945259653031826,334455:0.9450978450477123,406676:0.9447328113019466,410309:0.944527167826891,417795:0.9439555406570435,417796:0.9439320005476475,391433:0.9431202635169029,408203:0.9421345703303814',\n",
       " '319495:319752,319435,319915,319471,319895,318297,319514,319515,319517,319551|336302:0.9720314703881741,319515:0.963009886443615,303746:0.9602753520011902,324470:0.9602559581398964,293689:0.9596924632787704,316183:0.9596055187284946,320758:0.9595901556313038,310082:0.9595766998827457,303904:0.9595705531537533,310675:0.9595398753881454,323107:0.9594885408878326,301871:0.959463320672512,324056:0.9593511298298836,316710:0.9592948481440544,304857:0.9588576965034008,323255:0.9566437900066376,411745:0.9547513984143734,353765:0.9546811617910862,337670:0.9544758647680283,323601:0.9541248083114624,352801:0.9541175030171871,317862:0.9540835507214069,361844:0.9535141065716743,321669:0.9533315412700176,327985:0.9529933370649815,309465:0.9528441540896893,319438:0.9528179951012135,319119:0.9527914635837078,317763:0.9527756869792938',\n",
       " '319752:319495,319435,319915,319471,319895,318297,319514,319515,319517,319551|323459:0.9796425607055426,304678:0.9794401004910469,348966:0.9705495182424784,304215:0.9685985408723354,344849:0.9595533795654774,318297:0.9591156281530857,348346:0.9585009180009365,319131:0.9552937000989914,406926:0.9551607258617878,305468:0.9542365856468678,351957:0.9541656412184238,396128:0.9511904269456863,405707:0.9509794488549232,320931:0.9509388394653797,417542:0.9507362991571426,329650:0.9506548345088959,411482:0.9500723369419575,424671:0.9500698894262314,405341:0.9491324312984943,421946:0.9490924887359142,420310:0.9490003362298012,408088:0.9489864185452461,409977:0.9489189721643925,403428:0.9487798810005188,311065:0.9487347267568111,411745:0.9476617053151131,361844:0.9474657326936722,353765:0.9474430233240128,225780:0.9474233724176884',\n",
       " '319435:319495,319752,319915,319471,319895,318297,319514,319515,319517,319551|336302:0.9332201927900314,319495:0.9275634288787842,378102:0.924225889146328,347887:0.9218680709600449,390395:0.9201477393507957,411034:0.9201274812221527,322312:0.9191487655043602,319915:0.9186381921172142,319515:0.9183926582336426,348966:0.9174501001834869,337670:0.9153679236769676,406736:0.9149870350956917,364824:0.9148368760943413,321205:0.9147116467356682,340402:0.9146285355091095,394378:0.9138883948326111,420259:0.9136966839432716,323459:0.9132712781429291,405707:0.9132711440324783,361844:0.9131646975874901,421387:0.9130444750189781,304678:0.912988618016243,225780:0.9127722010016441,403411:0.9126311391592026,417542:0.9126280695199966,403428:0.9125931113958359,327985:0.9124889820814133,421391:0.9122443720698357,420310:0.9120807349681854',\n",
       " '319915:319495,319752,319435,319471,319895,318297,319514,319515,319517,319551|348966:0.9544512741267681,340402:0.9529543407261372,336302:0.9525637179613113,406736:0.9521180205047131,390395:0.9507217593491077,364824:0.9493908882141113,225780:0.9493801482021809,403428:0.9490978457033634,304678:0.9490757174789906,409977:0.9489739835262299,420310:0.9489535056054592,323459:0.9489128254354,408088:0.9487378187477589,421946:0.9486547857522964,421391:0.9485693722963333,405341:0.9485553875565529,409513:0.9482515938580036,406926:0.9479869268834591,337670:0.947577852755785,394378:0.947294320911169,421387:0.9464963190257549,421474:0.9464567452669144,361844:0.9463021084666252,396128:0.9461365081369877,355950:0.9459586888551712,347854:0.9458745643496513,319752:0.945819154381752,405707:0.9457508474588394,411034:0.9457490220665932',\n",
       " '319471:319495,319752,319435,319915,319895,318297,319514,319515,319517,319551|319517:0.9869558131322265,348377:0.9718257896602154,333365:0.9711602814495564,340629:0.9707890450954437,354108:0.9692231137305498,343947:0.9619142636656761,350559:0.9588596299290657,320802:0.958844430744648,318020:0.958826519548893,330765:0.958770040422678,319342:0.9587499164044857,317762:0.9587169326841831,333360:0.9586231522262096,332311:0.9581214301288128,353535:0.958049513399601,329588:0.9577662274241447,329589:0.9577658325433731,341296:0.957763560116291,351498:0.9577606543898582,330347:0.9577577896416187,331632:0.9577530398964882,352026:0.9577401727437973,344673:0.9577365443110466,339250:0.9577346742153168,353553:0.9577323757112026,346026:0.9577279575169086,341333:0.9577152356505394,340608:0.9577128030359745,335751:0.9577100947499275',\n",
       " '319895:319495,319752,319435,319915,319471,318297,319514,319515,319517,319551|418266:0.9570078402757645,401550:0.9517323412001133,312784:0.9459744840860367,321044:0.9459539763629436,323511:0.9458992257714272,319345:0.9451032318174839,328765:0.9447004795074463,323322:0.9445661827921867,320383:0.9420288689434528,317757:0.9418660700321198,321239:0.9418174587190151,336894:0.9418103881180286,317896:0.9417965561151505,322158:0.9416905120015144,315120:0.9416802264750004,291696:0.941637434065342,323333:0.9415999390184879,328587:0.9404640905559063,322056:0.939926091581583,374621:0.9359384924173355,321210:0.9350408613681793,350225:0.9337485730648041,352455:0.9328217729926109,359661:0.9311597570776939,327172:0.9311083257198334,355922:0.930983304977417,357286:0.930927075445652,339788:0.9308035150170326,363185:0.9297328293323517',\n",
       " '318297:319495,319752,319435,319915,319471,319895,319514,319515,319517,319551|344849:0.9949223925359547,319131:0.9798646606504917,325607:0.9683926962316036,320403:0.9681646898388863,320931:0.9648784846067429,320590:0.9619201384484768,324347:0.9619182981550694,321929:0.9618896059691906,359779:0.9617740549147129,325402:0.9617309607565403,319752:0.9591156281530857,311766:0.9588741697371006,323812:0.9587794281542301,340956:0.956335037946701,422384:0.9553490616381168,405723:0.954370204359293,304678:0.9540862441062927,323459:0.9539534151554108,332088:0.9537499845027924,367675:0.9536836929619312,353905:0.9536706916987896,353907:0.9536541514098644,360623:0.9534084610641003,406748:0.9533878602087498,361513:0.9530258774757385,352801:0.9515290595591068,323601:0.9514997154474258,317862:0.9514370523393154,324497:0.951422031968832',\n",
       " '319514:319495,319752,319435,319915,319471,319895,318297,319515,319517,319551|324473:0.9822495188564062,320546:0.97197100892663,325294:0.9719413872808218,312784:0.9594732001423836,321044:0.9594535902142525,322917:0.9589659087359905,323511:0.9583103694021702,347183:0.9549496211111546,319123:0.9543847106397152,344696:0.9529734812676907,365722:0.9464442320168018,402343:0.9461330026388168,328795:0.9457064978778362,329375:0.9456226192414761,342114:0.9456096366047859,344833:0.9455934464931488,351083:0.9455703347921371,348806:0.9455246292054653,348805:0.9454642534255981,288063:0.9454020820558071,327772:0.9450254514813423,418266:0.9447189308702946,317929:0.9440926015377045,393787:0.942640658468008,358923:0.942595586180687,322477:0.9408596605062485,314129:0.940820712596178,332039:0.9406730197370052,388299:0.9402702115476131',\n",
       " '319515:319495,319752,319435,319915,319471,319895,318297,319514,319517,319551|347887:0.9713571164757013,319495:0.963009886443615,316183:0.9618518315255642,303904:0.9618338793516159,320758:0.9618231244385242,323107:0.9617716558277607,310082:0.9617516696453094,301871:0.9617499560117722,310675:0.9617427736520767,324056:0.9616515934467316,316710:0.9616385996341705,304857:0.9612120315432549,303746:0.9590837024152279,324470:0.9590633921325207,323255:0.9588602185249329,293689:0.9586165845394135,327985:0.9574647881090641,323601:0.9569243602454662,352801:0.9569086395204067,317862:0.9568143598735332,321669:0.9562377147376537,400084:0.9555368795990944,309465:0.9551956728100777,319438:0.9551460668444633,317763:0.9551382772624493,319119:0.9551027119159698,323913:0.9550944902002811,322143:0.9550381936132908,336302:0.9539876505732536',\n",
       " '319517:319495,319752,319435,319915,319471,319895,318297,319514,319515,319551|319471:0.9869558131322265,340629:0.9714640285819769,333365:0.9702244997024536,354108:0.9698558244854212,348377:0.9694434721022844,343947:0.9657680690288544,325940:0.9587842896580696,353535:0.9583430550992489,332311:0.9583265669643879,333360:0.9578870795667171,350559:0.9576449654996395,348507:0.9575275741517544,317762:0.9575219564139843,342819:0.9574960134923458,319342:0.9574367254972458,346051:0.9573888033628464,327881:0.9573795460164547,318020:0.9573450982570648,330264:0.9573197178542614,322371:0.9572729803621769,320046:0.9572402387857437,334306:0.9571392089128494,338402:0.9570759497582912,342757:0.9570445530116558,320802:0.9570351727306843,323855:0.9570053406059742,322545:0.9569663293659687,330765:0.9569482803344727,337415:0.9569327123463154',\n",
       " '319551:319495,319752,319435,319915,319471,319895,318297,319514,319515,319517|351172:0.9555951245129108,397264:0.9500889517366886,320027:0.9485404379665852,373494:0.9478060640394688,398766:0.9477664567530155,406207:0.9464586265385151,413761:0.9460301883518696,326746:0.9453011229634285,358138:0.944545604288578,410005:0.9445261657238007,390314:0.9445213153958321,329739:0.9440417550504208,333456:0.943945873528719,368548:0.9436939097940922,249938:0.943576417863369,381476:0.9434694312512875,361910:0.9433484822511673,348431:0.943248562514782,348533:0.9432198442518711,403554:0.9428374022245407,330530:0.9427603483200073,331901:0.9427563287317753,329383:0.9427511505782604,359760:0.9427432678639889,323715:0.9426733329892159,328072:0.9426537901163101,328133:0.9426049217581749,350698:0.9425867721438408,346906:0.9425772055983543',\n",
       " '401416:401362,401363,401461,401023|374895:0.9919770574197173,333434:0.9910614071413875,380606:0.9782983604818583,411599:0.9778595399111509,387214:0.977660421282053,333397:0.9668208360671997,376887:0.9621354639530182,333392:0.9585410840809345,350644:0.9546241536736488,331284:0.9544791355729103,354805:0.9524574801325798,354984:0.9520637467503548,343150:0.9509278014302254,359128:0.9509210884571075,411799:0.9506859444081783,401023:0.9505653120577335,360970:0.9505220465362072,381661:0.9503480307757854,357301:0.9503255523741245,397300:0.9502236843109131,400428:0.9501917958259583,368943:0.9501495286822319,417885:0.9501115046441555,362358:0.950097281485796,343563:0.9500649198889732,333779:0.9500310868024826,350336:0.9500050470232964,355235:0.9499942995607853,422595:0.9499941021203995',\n",
       " '401362:401416,401363,401461,401023|412266:0.9629628248512745,411482:0.955222349613905,403605:0.9539330117404461,406503:0.9535885341465473,403313:0.9517745450139046,405714:0.9509487710893154,395752:0.9508562833070755,424679:0.9508520215749741,407863:0.9507936462759972,399608:0.9507615640759468,411847:0.9503471627831459,382829:0.9496971070766449,392494:0.94943056255579,421072:0.9490885213017464,408678:0.9490664675831795,405563:0.9490649923682213,412105:0.9490572400391102,406941:0.9490566290915012,421036:0.9490559138357639,410705:0.9490446001291275,395005:0.9490445517003536,403900:0.9490325823426247,410744:0.9490163885056973,407375:0.949015811085701,408203:0.9490104764699936,405416:0.9489912576973438,396494:0.9489862844347954,401108:0.9489810094237328,411120:0.948945514857769']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "#     Between 0-10 epochs recall@25 = 0.28\n",
    "#     Between 0-20 epochs recall@25 = 0.32\n",
    "#     Between 0-70 epochs recall@25 = ?\n",
    "#     Between 0-100 epochs recall@25 = ?\n",
    "# '''\n",
    "# recall, exported_rank = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 4641\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_feature_100epochs_64batch(eclipse)'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          44946900    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          44993592    desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "==================================================================================================\n",
      "Total params: 90,445,392\n",
      "Trainable params: 958,392\n",
      "Non-trainable params: 89,487,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, bug_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/eclipse/exported_rank_baseline.txt'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.35,\n",
       " '2 - recall_at_10': 0.42,\n",
       " '3 - recall_at_15': 0.46,\n",
       " '4 - recall_at_20': 0.5,\n",
       " '5 - recall_at_25': 0.52}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some ideas to visualizate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
