{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 100 # 100\n",
    "MAX_SEQUENCE_LENGTH_D = 500 # 500\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'eclipse'\n",
    "METHOD = 'baseline'\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Glove embeddings\n",
    "GLOVE_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = 'baseline_feature@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "SAVE_PATH_FEATURE = 'baseline_feature_@number_of_epochs@epochs_64batch({})'.format(DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce76a362e7f745e888e97bb12192032b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322339), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657d8adb5e854ee68d318c4d0ae6e18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39545), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "361006"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42da45b2c525475981a0d264bd908d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=361006), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650608dc5e7041a8b54e3a936d3f78d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 18s, sys: 4.21 s, total: 2min 22s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d23761db744a3383d811621ae3bd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=321536), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 183],\n",
       " [15392, 2],\n",
       " [15392, 9779],\n",
       " [15392, 94],\n",
       " [2, 9779],\n",
       " [2, 94],\n",
       " [9779, 94],\n",
       " [42962, 7],\n",
       " [10, 121067],\n",
       " [40, 20]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the corpus train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CORPUS:\n",
    "    corpus = []\n",
    "    export_file = open(os.path.join(DIR, 'corpus_train.txt'), 'w')\n",
    "    for bug_id in tqdm(baseline.bug_set):\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title = bug['title']\n",
    "        desc = bug['description']\n",
    "        export_file.write(\"{}\\n{}\\n\".format(title, desc))\n",
    "    export_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "# Generating tiple of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bug_severity': '2\\n', 'priority': '4\\n', 'creation_ts': '2001-10-10 22:38:00 -0400', 'resolution': 'FIXED', 'title_word': array([1173,   11,   83,   12,    7,   83,  213,  101,   19, 3141,   83,\n",
      "          1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0]), 'dup_id': '[]', 'issue_id': 2521, 'description_word': array([ 189,   10, 3187,  116,  662,  378,   31,   28,  483,    8,  255,\n",
      "         83,   17,  167,    7,   83,  213,   31,   28, 2096,  255,   83,\n",
      "        993,   35,   25,  196,  900,  320,   17,   19, 3603,   26,  730,\n",
      "         12,   27,   61,  675, 1339,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0]), 'description': 'steps number minimize all your windows step index go to any window and select the window menu step index pick any window notice that it only gets selected and not maximized this happens in product as well notes', 'delta_ts': '2005-05-10 14:55:51 -0400', 'title': 'selecting a window in the window menu does not maximize window gfitic', 'version': '291\\n', 'component': '437\\n', 'product': '130\\n', 'bug_status': '2\\n'}\n"
     ]
    }
   ],
   "source": [
    "if 2521 in baseline.bug_set:\n",
    "    print(baseline.bug_set[2521])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 34882)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57 ms, sys: 0 ns, total: 57 ms\n",
      "Wall time: 55.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = baseline.batch_iterator(baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train,\n",
    "                                                                                          bug_train_ids,\n",
    "                                                                                          batch_size_test, 1)\n",
    "test_gen = ([valid_input_sample['title'], valid_input_pos['title'], valid_input_neg['title'], \n",
    "             valid_input_sample['description'], valid_input_pos['description'], valid_input_neg['description'],\n",
    "            valid_input_sample['info'], valid_input_pos['info'], valid_input_neg['info']], valid_sim)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 100), (128, 500), (128, 1682), (128,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Title***: use the new classpath container initializer language for the jre\n",
      "***Title***: use new classpath container initialization language for jre container\n",
      "***Description***: the following patch uses the new language in classpath container initializer to signal the ui that access rules can not be modified but source attachment javadoc and native lib can all other user provided attributes are not supported and not shown in the ui i updated the ui to use the new apis and removed the hard coded behavior for the jre container can you release for i otherwise user will be able to modify the access rules again\n",
      "***Description***: for m launching should override the new apis from classpath container initialization to specify which classpath container children attributes are modifiable and which are read only\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: organize import deletes text sandwiched between import statements code manipulation\n",
      "***Title***: organise imports deletes comments\n",
      "***Description***: the easiest way to dkeyboardribe this bug is by asking you to reproduce it i guess please paste this into a extension file file and do an organize import note that the comment will be gone after eclipses done reorganizing the imports code snippet package com acme ames activision rule import extension file util hashtable import com acme common log import com acme be exception import com acme be rule import com acme common p title rule extension file p author blah version product import com acme my biz event import extension file util map public class rule code snippet\n",
      "***Description***: build id m steps to reproduce step index add import statements step index put a comment between import statements step index keyboard shift o the comments are removed along with any incorrect import statements this can not be right i want to add comments to the import section but they disappear when i organise imports xd more information\n",
      "***similar = 1\n",
      "########################\n",
      "***Title***: docs core runtime applications and core runtime products ext pts missing\n",
      "***Title***: jvirtual machine does not die after exiting eclipse potentially due to display async exec\n",
      "***Description***: i the following help files are missing from the build help topic org eclipse platform doc isv reference extension points org eclipse core runtime applications extension file help topic org eclipse platform doc isv reference extension points number extension file these extension points moved from the org eclipse core runtime bundle to the org eclipse equinox app bundle from the instructions at http wiki eclipse org index php how to add things to the eclipse doc it is unclear that anything needed to be updated in the org eclipse platform doc isv to pick up the the moved extension point documentation i do not see any place that associates extension point documentation with the plugin which provides the extension point\n",
      "***Description***: jvirtual machine does not die after exiting eclipse potentially due to display async exec\n",
      "***similar = 0\n",
      "########################\n",
      "***Title***: null pointer exception unhandled event loop exception\n",
      "***Title***: persists sashes locations\n",
      "***Description***: not sure what triggered it but all of a sudden typing in a extension file editor does not move the cursor forward i get a stack trace on the console and a bunch of these java lang null pointer exception unhandled event loop exception reason debian testing ibm jdk\n",
      "***Description***: persists sashes locations\n",
      "***similar = 0\n",
      "########################\n",
      "CPU times: user 44.8 ms, sys: 0 ns, total: 44.8 ms\n",
      "Wall time: 44.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test ', 4641)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Test \", len(baseline.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 113554'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, GLOVE_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(GLOVE_DIR, 'glove.42B.300d.txt')\n",
    "    f = open(embed_path, 'rb')\n",
    "    #num_lines = sum(1 for line in open(embed_path, 'rb'))\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(tokens[1:], dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69dd54a4c644e5dbfc64450610a03d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101430ce168d4110a84f4f424fbbf008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=113554), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 20s, sys: 4.92 s, total: 2min 25s\n",
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, GLOVE_DIR=GLOVE_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer',\n",
    "                                  weights=[embeddings],\n",
    "                                  embeddings_constraint=MaxNorm(max_value=1, axis=0),\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI074wU4Y13y"
   },
   "source": [
    "### CNN with filter 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "h6YJU9GtFTyq",
    "outputId": "f85cf105-1fd6-491d-d969-7e6936f32739",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "\n",
    "def cnn_model(embedding_layer, max_sequence_length):\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length,), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None,), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "    # best combination filter (3, 4, 5) e 128 e 256\n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    n_filters = 64\n",
    "\n",
    "    for index, filter_size in enumerate(filter_sizes):\n",
    "        l_conv = Conv1D(filters=n_filters, kernel_size=filter_size)(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(pool_size=filter_size)(l_conv) # index+1\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "    # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "    #conv = Conv1D(filters=n_filters * 3, kernel_size=3)(l_merge)\n",
    "    layer = GlobalAveragePooling1D()(l_merge)\n",
    "    #layer = Flatten()(l_merge)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "    #layer = LeakyReLU()(layer)\n",
    "\n",
    "    cnn_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureCNNGenerationModel') # inputs=visible\n",
    "\n",
    "    return cnn_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr6ObTXiaALH"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "vC7MQXEsaCeG",
    "outputId": "65e647a9-c5d3-4009-b8a4-2e2d97b52684"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, GRU, Dropout, Bidirectional, GlobalAveragePooling1D, TimeDistributed\n",
    "\n",
    "def lstm_model(embedding_layer, max_sequence_length):\n",
    "    number_lstm_units = 75\n",
    "    rate_drop_lstm = 0\n",
    "    recurrent_dropout = 0\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None, ), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    left_layer = LSTM(number_lstm_units, return_sequences=True)(embedded_sequences)\n",
    "    right_layer = LSTM(number_lstm_units, return_sequences=True, go_backwards=True)(left_layer)\n",
    "    \n",
    "    lstm_layer = Concatenate()([left_layer, right_layer])\n",
    "    \n",
    "    #lstm_layer = TimeDistributed(Dense(50))(lstm_layer)\n",
    "    #layer = Flatten()(lstm_layer)\n",
    "    layer = GlobalAveragePooling1D()(lstm_layer)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "\n",
    "    lstm_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureLstmGenerationModel') # inputs=visible\n",
    "\n",
    "    return lstm_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    for units in [64, 32]:\n",
    "        layer = Dense(units, activation='tanh', kernel_initializer='random_uniform')(info_input)\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.sum(K.maximum(0.0, margin - pos + neg))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "  \n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    #     bug_feature_output = Activation('tanh')(bug_feature_output)\n",
    "    \n",
    "    # Bug representation layer\n",
    "    # bug_feature_output = Dense(300, activation='tanh')(bug_feature_output)\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    \n",
    "    # Cosine\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3 * decay_lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer=optimizer, loss=custom_margin_loss, metrics=[pos_distance, neg_distance, custom_margin_loss])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_pos (InputLayer)          (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_pos (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_neg (InputLayer)          (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_neg (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          34269600    title_in[0][0]                   \n",
      "                                                                 title_pos[0][0]                  \n",
      "                                                                 title_neg[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          34316292    desc_in[0][0]                    \n",
      "                                                                 desc_pos[0][0]                   \n",
      "                                                                 desc_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 900)          0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureLstmGenerationModel[2][0] \n",
      "                                                                 FeatureCNNGenerationModel[2][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 900)          0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureLstmGenerationModel[3][0] \n",
      "                                                                 FeatureCNNGenerationModel[3][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances (Lambda)        (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 69,090,792\n",
      "Trainable params: 958,392\n",
      "Non-trainable params: 68,132,400\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 0.84, MarginLoss: 0.84, pos_cosine: 0.87, neg_cosine: 0.71\n",
      "Epoch: 2 Loss: 0.82, MarginLoss: 0.82, pos_cosine: 0.85, neg_cosine: 0.67\n",
      "Epoch: 3 Loss: 0.79, MarginLoss: 0.79, pos_cosine: 0.86, neg_cosine: 0.65\n",
      "Epoch: 4 Loss: 0.77, MarginLoss: 0.77, pos_cosine: 0.88, neg_cosine: 0.65\n",
      "Epoch: 5 Loss: 0.78, MarginLoss: 0.78, pos_cosine: 0.83, neg_cosine: 0.62\n",
      "Epoch: 6 Loss: 0.78, MarginLoss: 0.78, pos_cosine: 0.84, neg_cosine: 0.61\n",
      "Epoch: 7 Loss: 0.78, MarginLoss: 0.78, pos_cosine: 0.81, neg_cosine: 0.59\n",
      "Epoch: 8 Loss: 0.74, MarginLoss: 0.74, pos_cosine: 0.83, neg_cosine: 0.57\n",
      "Epoch: 9 Loss: 0.74, MarginLoss: 0.74, pos_cosine: 0.83, neg_cosine: 0.57\n",
      "Epoch: 10 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.82, neg_cosine: 0.54\n",
      "Epoch: 11 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.80, neg_cosine: 0.53\n",
      "Epoch: 12 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.82, neg_cosine: 0.51\n",
      "Epoch: 13 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.81, neg_cosine: 0.53\n",
      "Epoch: 14 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.81, neg_cosine: 0.50\n",
      "Epoch: 15 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.82, neg_cosine: 0.48\n",
      "Epoch: 16 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.81, neg_cosine: 0.52\n",
      "Epoch: 17 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.79, neg_cosine: 0.51\n",
      "Epoch: 18 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.81, neg_cosine: 0.49\n",
      "Epoch: 19 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.80, neg_cosine: 0.49\n",
      "Epoch: 20 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.83, neg_cosine: 0.50\n",
      "Epoch: 21 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.82, neg_cosine: 0.51\n",
      "Epoch: 22 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.80, neg_cosine: 0.52\n",
      "Epoch: 23 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.82, neg_cosine: 0.50\n",
      "Epoch: 24 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.85, neg_cosine: 0.52\n",
      "Epoch: 25 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.84, neg_cosine: 0.52\n",
      "Epoch: 26 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.83, neg_cosine: 0.51\n",
      "Epoch: 27 Loss: 0.71, MarginLoss: 0.71, pos_cosine: 0.84, neg_cosine: 0.55\n",
      "Epoch: 28 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.80, neg_cosine: 0.48\n",
      "Epoch: 29 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.85, neg_cosine: 0.51\n",
      "Epoch: 30 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.83, neg_cosine: 0.49\n",
      "Epoch: 31 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.84, neg_cosine: 0.52\n",
      "Epoch: 32 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.83, neg_cosine: 0.53\n",
      "Epoch: 33 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.84, neg_cosine: 0.51\n",
      "Epoch: 34 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.85, neg_cosine: 0.51\n",
      "Epoch: 35 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.86, neg_cosine: 0.54\n",
      "Epoch: 36 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.85, neg_cosine: 0.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.84, neg_cosine: 0.49\n",
      "Epoch: 38 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.85, neg_cosine: 0.49\n",
      "Epoch: 39 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.83, neg_cosine: 0.46\n",
      "Epoch: 40 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.86, neg_cosine: 0.49\n",
      "Epoch: 41 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.82, neg_cosine: 0.48\n",
      "Epoch: 42 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.83, neg_cosine: 0.49\n",
      "Epoch: 43 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.87, neg_cosine: 0.54\n",
      "Epoch: 44 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.85, neg_cosine: 0.47\n",
      "Epoch: 45 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.86, neg_cosine: 0.48\n",
      "Epoch: 46 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.87, neg_cosine: 0.55\n",
      "Epoch: 47 Loss: 0.72, MarginLoss: 0.72, pos_cosine: 0.82, neg_cosine: 0.54\n",
      "Epoch: 48 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.86, neg_cosine: 0.50\n",
      "Epoch: 49 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.88, neg_cosine: 0.50\n",
      "Epoch: 50 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.86, neg_cosine: 0.46\n",
      "Epoch: 51 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.85, neg_cosine: 0.51\n",
      "Epoch: 52 Loss: 0.70, MarginLoss: 0.70, pos_cosine: 0.84, neg_cosine: 0.54\n",
      "Epoch: 53 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.89, neg_cosine: 0.48\n",
      "Epoch: 54 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.89, neg_cosine: 0.53\n",
      "Epoch: 55 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.90, neg_cosine: 0.52\n",
      "Epoch: 56 Loss: 0.65, MarginLoss: 0.65, pos_cosine: 0.85, neg_cosine: 0.51\n",
      "Epoch: 57 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.88, neg_cosine: 0.51\n",
      "Epoch: 58 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.88, neg_cosine: 0.52\n",
      "Epoch: 59 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.87, neg_cosine: 0.45\n",
      "Epoch: 60 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.84, neg_cosine: 0.51\n",
      "Epoch: 61 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.86, neg_cosine: 0.48\n",
      "Epoch: 62 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.86, neg_cosine: 0.50\n",
      "Epoch: 63 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.90, neg_cosine: 0.48\n",
      "Epoch: 64 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.88, neg_cosine: 0.49\n",
      "Epoch: 65 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.87, neg_cosine: 0.48\n",
      "Epoch: 66 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.87, neg_cosine: 0.48\n",
      "Epoch: 67 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.89, neg_cosine: 0.53\n",
      "Epoch: 68 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.88, neg_cosine: 0.54\n",
      "Epoch: 69 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.88, neg_cosine: 0.48\n",
      "Epoch: 70 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.90, neg_cosine: 0.50\n",
      "Epoch: 71 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.86, neg_cosine: 0.49\n",
      "Epoch: 72 Loss: 0.66, MarginLoss: 0.66, pos_cosine: 0.87, neg_cosine: 0.53\n",
      "Epoch: 73 Loss: 0.69, MarginLoss: 0.69, pos_cosine: 0.83, neg_cosine: 0.52\n",
      "Epoch: 74 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.82, neg_cosine: 0.50\n",
      "Epoch: 75 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.90, neg_cosine: 0.48\n",
      "Epoch: 76 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.89, neg_cosine: 0.46\n",
      "Epoch: 77 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.90, neg_cosine: 0.54\n",
      "Epoch: 78 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.88, neg_cosine: 0.48\n",
      "Epoch: 79 Loss: 0.68, MarginLoss: 0.68, pos_cosine: 0.84, neg_cosine: 0.52\n",
      "Epoch: 80 Loss: 0.63, MarginLoss: 0.63, pos_cosine: 0.85, neg_cosine: 0.48\n",
      "Epoch: 81 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.89, neg_cosine: 0.53\n",
      "Epoch: 82 Loss: 0.58, MarginLoss: 0.58, pos_cosine: 0.88, neg_cosine: 0.46\n",
      "Epoch: 83 Loss: 0.57, MarginLoss: 0.57, pos_cosine: 0.90, neg_cosine: 0.47\n",
      "Epoch: 84 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.89, neg_cosine: 0.51\n",
      "Epoch: 85 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.87, neg_cosine: 0.46\n",
      "Epoch: 86 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.88, neg_cosine: 0.50\n",
      "Epoch: 87 Loss: 0.64, MarginLoss: 0.64, pos_cosine: 0.88, neg_cosine: 0.52\n",
      "Epoch: 88 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.88, neg_cosine: 0.49\n",
      "Epoch: 89 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.87, neg_cosine: 0.46\n",
      "Epoch: 90 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.87, neg_cosine: 0.47\n",
      "Epoch: 91 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.89, neg_cosine: 0.48\n",
      "Epoch: 92 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.90, neg_cosine: 0.49\n",
      "Epoch: 93 Loss: 0.67, MarginLoss: 0.67, pos_cosine: 0.93, neg_cosine: 0.60\n",
      "Epoch: 94 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.91, neg_cosine: 0.51\n",
      "Epoch: 95 Loss: 0.61, MarginLoss: 0.61, pos_cosine: 0.88, neg_cosine: 0.49\n",
      "Epoch: 96 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.90, neg_cosine: 0.52\n",
      "Epoch: 97 Loss: 0.59, MarginLoss: 0.59, pos_cosine: 0.89, neg_cosine: 0.48\n",
      "Epoch: 98 Loss: 0.60, MarginLoss: 0.60, pos_cosine: 0.89, neg_cosine: 0.49\n",
      "Epoch: 99 Loss: 0.55, MarginLoss: 0.55, pos_cosine: 0.91, neg_cosine: 0.47\n",
      "Epoch: 100 Loss: 0.62, MarginLoss: 0.62, pos_cosine: 0.89, neg_cosine: 0.51, recall@25: 0.50\n",
      "Saved model 'modelos/model_baseline_feature_100epochs_64batch(eclipse).h5' to disk\n",
      "Best_epoch=99, Best_loss=0.55, Recall@25=0.50\n",
      "CPU times: user 9min 23s, sys: 17.9 s, total: 9min 41s\n",
      "Wall time: 9min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False)\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False)\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    mlp_model\n",
    "'''\n",
    "desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "title_feature_model = lstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = baseline.batch_iterator(baseline.train_data, baseline.dup_sets_train, bug_train_ids, batch_size, 1)\n",
    "    train_batch = [train_input_sample['title'], train_input_sample['description'], train_input_sample['info'],\n",
    "                   train_input_pos['title'], train_input_pos['description'], train_input_pos['info'], \n",
    "                   train_input_neg['title'], train_input_neg['description'], train_input_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[3]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['327681:324658|424407:0.22079259157180786,414325:0.19946640729904175,401398:0.1990208625793457,351415:0.19478857517242432,298577:0.19477510452270508,386322:0.19477427005767822,339927:0.19477075338363647,325112:0.19476449489593506,357457:0.1947624683380127,353198:0.19475364685058594,350693:0.19471079111099243,343328:0.19471067190170288,350590:0.1946849822998047,320203:0.1945807933807373,313327:0.19454294443130493,360224:0.19447612762451172,319958:0.19445723295211792,378585:0.19432282447814941,366428:0.19430428743362427,405534:0.19423329830169678,401877:0.19309639930725098,401390:0.19309335947036743,367268:0.19308847188949585,337781:0.1930662989616394,359809:0.19305986166000366,325519:0.19292670488357544,380478:0.1928272843360901,377486:0.19274210929870605,324814:0.19266647100448608',\n",
       " '324658:327681|338198:0.18723970651626587,387076:0.18723785877227783,407978:0.1872326135635376,393981:0.18722689151763916,402041:0.18716710805892944,319932:0.1868758201599121,340676:0.1862843632698059,341146:0.1862536072731018,343989:0.18623864650726318,369026:0.17267197370529175,305914:0.17265605926513672,321759:0.172349750995636,389320:0.16459691524505615,400354:0.1627650260925293,397146:0.16209590435028076,363830:0.15906763076782227,412376:0.15492498874664307,368216:0.15327084064483643,391329:0.14918136596679688,326131:0.14551198482513428,331092:0.14550387859344482,321412:0.1444852352142334,320094:0.14399808645248413,391487:0.14316099882125854,370035:0.14296412467956543,362471:0.1428079605102539,324217:0.1424729824066162,400371:0.14235270023345947,400372:0.14235270023345947',\n",
       " '417795:417796,403749|417796:0.9944928772747517,422902:0.6616610586643219,412623:0.6590143442153931,409086:0.5604976713657379,406277:0.5603004097938538,348435:0.5411400496959686,350323:0.5411249101161957,350521:0.5411092936992645,334455:0.540758341550827,350396:0.5407207310199738,368390:0.5130293071269989,393621:0.48459506034851074,406676:0.48205918073654175,94152:0.4767875671386719,87239:0.47676974534988403,94755:0.4766830801963806,106371:0.4766514301300049,355329:0.4524765610694885,393359:0.45067620277404785,390196:0.4506646990776062,391117:0.44979536533355713,336390:0.4401012659072876,341209:0.44008052349090576,344729:0.4400627017021179,348867:0.44004714488983154,352547:0.440044105052948,346872:0.43997740745544434,341717:0.43997395038604736,343645:0.43995189666748047',\n",
       " '417796:417795,403749|417795:0.9944928772747517,422902:0.661602795124054,412623:0.6591230630874634,409086:0.5604908168315887,406277:0.5602961778640747,348435:0.541156142950058,350323:0.5411410331726074,350521:0.5410995483398438,334455:0.5407839417457581,350396:0.5407081842422485,368390:0.5130363702774048,393621:0.4845985174179077,406676:0.4820908308029175,94152:0.47679901123046875,87239:0.47679126262664795,94755:0.47666943073272705,106371:0.47663986682891846,355329:0.4524906873703003,393359:0.45066410303115845,390196:0.4506300687789917,391117:0.4497426152229309,336390:0.4401189088821411,341209:0.44008970260620117,344729:0.44006192684173584,348867:0.4400554895401001,352547:0.44004905223846436,346872:0.43998146057128906,341717:0.43997883796691895,343645:0.4399678707122803',\n",
       " '403749:417795,417796|398965:0.9839884471148252,390915:0.9816369339823723,398995:0.9805523343384266,411794:0.8675249367952347,418692:0.6224382221698761,403927:0.6224317252635956,397464:0.6221344470977783,409520:0.5983901619911194,394467:0.5727495551109314,104395:0.5543128848075867,409086:0.5108836591243744,406277:0.510714054107666,391433:0.4979560375213623,349798:0.49652934074401855,411636:0.49172598123550415,364815:0.48040300607681274,366014:0.4606367349624634,406463:0.417086660861969,407864:0.39706528186798096,418000:0.39704978466033936,386410:0.38103044033050537,416911:0.37704670429229736,394692:0.36206114292144775,393621:0.3518073558807373,406676:0.34986329078674316,397455:0.34307557344436646,385642:0.34272831678390503,368390:0.33366847038269043,348435:0.32233232259750366',\n",
       " '417796:417795,403749|417795:0.9944928772747517,422902:0.661602795124054,412623:0.6591230630874634,409086:0.5604908168315887,406277:0.5602961778640747,348435:0.541156142950058,350323:0.5411410331726074,350521:0.5410995483398438,334455:0.5407839417457581,350396:0.5407081842422485,368390:0.5130363702774048,393621:0.4845985174179077,406676:0.4820908308029175,94152:0.47679901123046875,87239:0.47679126262664795,94755:0.47666943073272705,106371:0.47663986682891846,355329:0.4524906873703003,393359:0.45066410303115845,390196:0.4506300687789917,391117:0.4497426152229309,336390:0.4401189088821411,341209:0.44008970260620117,344729:0.44006192684173584,348867:0.4400554895401001,352547:0.44004905223846436,346872:0.43998146057128906,341717:0.43997883796691895,343645:0.4399678707122803',\n",
       " '403749:417795,417796|398965:0.9839884471148252,390915:0.9816369339823723,398995:0.9805523343384266,411794:0.8675249367952347,418692:0.6224382221698761,403927:0.6224317252635956,397464:0.6221344470977783,409520:0.5983901619911194,394467:0.5727495551109314,104395:0.5543128848075867,409086:0.5108836591243744,406277:0.510714054107666,391433:0.4979560375213623,349798:0.49652934074401855,411636:0.49172598123550415,364815:0.48040300607681274,366014:0.4606367349624634,406463:0.417086660861969,407864:0.39706528186798096,418000:0.39704978466033936,386410:0.38103044033050537,416911:0.37704670429229736,394692:0.36206114292144775,393621:0.3518073558807373,406676:0.34986329078674316,397455:0.34307557344436646,385642:0.34272831678390503,368390:0.33366847038269043,348435:0.32233232259750366',\n",
       " '319495:319752,319435,319915,319471,319895,318297,319514,319515,319517,319551|336302:0.8485512286424637,319435:0.8441836833953857,319915:0.6436697542667389,304678:0.6158550083637238,323459:0.6157695055007935,319752:0.6057775318622589,225780:0.5856092870235443,348966:0.5839146077632904,319515:0.5800995528697968,304215:0.5791851878166199,353765:0.5709381997585297,411745:0.5708597600460052,337670:0.5523960292339325,347887:0.5420864522457123,379465:0.5372384190559387,389108:0.5371905267238617,382974:0.5371850430965424,392674:0.5371573269367218,376562:0.5279584527015686,404182:0.5279316604137421,389594:0.5279204249382019,392061:0.5279178619384766,373174:0.5279148519039154,384676:0.5278852880001068,394104:0.5278548300266266,390153:0.5278485119342804,376232:0.5278342366218567,372230:0.527827799320221,402592:0.5278030633926392',\n",
       " '319752:319495,319435,319915,319471,319895,318297,319514,319515,319517,319551|323459:0.9021580293774605,304678:0.9018349722027779,348966:0.8777929022908211,304215:0.7943355739116669,319915:0.6495746374130249,336302:0.6234565675258636,319435:0.6217791736125946,225780:0.6156451404094696,319495:0.6057775318622589,396128:0.5739124119281769,340402:0.5571206510066986,424671:0.5558051764965057,347854:0.5536521077156067,355950:0.5536287128925323,340374:0.5529783070087433,394378:0.5426529347896576,337670:0.541948527097702,353765:0.5416242182254791,411745:0.54152050614357,406736:0.5370205640792847,405707:0.5369940996170044,411482:0.5367572009563446,390395:0.5361119210720062,389738:0.5359367430210114,411034:0.5354179441928864,421387:0.534482330083847,421474:0.5344284176826477,417542:0.5341270565986633,404435:0.5323688387870789',\n",
       " '319435:319495,319752,319915,319471,319895,318297,319514,319515,319517,319551|336302:0.9612494930624962,319495:0.8441836833953857,319915:0.6650314331054688,348966:0.6352291405200958,319752:0.6217791736125946,323459:0.6102198362350464,304678:0.6099102795124054,347887:0.6006343960762024,225780:0.58554807305336,319515:0.5804269015789032,304215:0.5611071288585663,353765:0.5583899617195129,411745:0.5581085979938507,323601:0.5534559190273285,317862:0.5534498691558838,352801:0.5533596277236938,321669:0.5531521439552307,358891:0.5525958240032196,364824:0.5522954165935516,337670:0.5484587252140045,316183:0.545825719833374,324056:0.5457606315612793,310082:0.5457172989845276,320758:0.5457090437412262,303904:0.5456801056861877,301871:0.5456676781177521,310675:0.5456219613552094,323107:0.5455959737300873,316710:0.5455082654953003',\n",
       " '319915:319495,319752,319435,319471,319895,318297,319514,319515,319517,319551|336302:0.6669560968875885,319435:0.6650314331054688,319752:0.6495746374130249,348966:0.6447078883647919,319495:0.6436697542667389,323459:0.636783629655838,304678:0.6367742717266083,225780:0.6300092041492462,304215:0.5809074640274048,271291:0.5747198462486267,258182:0.574676513671875,337670:0.5548111498355865,406736:0.545252650976181,390395:0.5442695915699005,389738:0.5441274642944336,411034:0.5434817969799042,353765:0.5406768620014191,411745:0.5405563116073608,404435:0.5362628698348999,389805:0.535876989364624,411482:0.5334703326225281,405707:0.532885730266571,340402:0.5294905006885529,379465:0.5283285677433014,392674:0.5282515287399292,382974:0.5282416045665741,389108:0.52823206782341,390758:0.5261004865169525,364824:0.5215577185153961',\n",
       " '319471:319495,319752,319435,319915,319895,318297,319514,319515,319517,319551|319517:0.9836958944797516,333365:0.8990141227841377,348377:0.8730337172746658,340629:0.8721457272768021,343947:0.8640724867582321,330765:0.8592256158590317,330428:0.8174251466989517,350559:0.6731655299663544,326517:0.6520705819129944,320633:0.6509468853473663,391025:0.6355403959751129,203725:0.6307965815067291,198044:0.6269572377204895,416180:0.6233721375465393,424320:0.6233318448066711,423070:0.6231572329998016,401951:0.6227090656757355,417662:0.6225417256355286,404003:0.6225374042987823,354108:0.6216491758823395,325755:0.6207560300827026,419506:0.6193369030952454,389248:0.6179781556129456,422879:0.6168932914733887,410295:0.6133324205875397,390916:0.6132770478725433,415396:0.6132499575614929,409673:0.6131153404712677,405691:0.6129180788993835',\n",
       " '319895:319495,319752,319435,319915,319471,318297,319514,319515,319517,319551|401550:0.5508066713809967,418266:0.5156154930591583,321044:0.4750601053237915,312784:0.4749738574028015,323511:0.4746648669242859,319345:0.4741870164871216,328765:0.47391849756240845,317896:0.44579046964645386,317757:0.4457877278327942,321239:0.4457077383995056,322158:0.44568151235580444,322056:0.4452604651451111,323333:0.4410492777824402,291696:0.4410487413406372,315120:0.44103050231933594,336894:0.4410242438316345,320383:0.44094669818878174,328587:0.4407680034637451,321210:0.43934446573257446,323322:0.4310537576675415,243893:0.39103490114212036,352049:0.3839474320411682,277265:0.37608397006988525,409153:0.35422319173812866,397698:0.3542173504829407,423947:0.3538573980331421,352455:0.3445711135864258,383361:0.3434068560600281,409838:0.3395237326622009',\n",
       " '318297:319495,319752,319435,319915,319471,319895,319514,319515,319517,319551|344849:0.9875021148473024,319131:0.9096337184309959,320931:0.8703598082065582,317862:0.6516493260860443,323601:0.6516305804252625,352801:0.6516286134719849,321669:0.6515002250671387,350988:0.6514526307582855,358891:0.6507672369480133,319438:0.6475968360900879,309465:0.6475656032562256,319119:0.647555410861969,323913:0.6475510895252228,317763:0.6475003957748413,322143:0.6474220752716064,315906:0.6472914814949036,323416:0.6463989317417145,235090:0.6432439386844635,354057:0.6337383687496185,318655:0.6335886418819427,204709:0.6331555843353271,271291:0.6277757585048676,258182:0.6276862323284149,320758:0.6264757812023163,310082:0.6264635026454926,316183:0.6264413595199585,303904:0.6264339089393616,310675:0.6264290809631348,324056:0.626403421163559',\n",
       " '319514:319495,319752,319435,319915,319471,319895,318297,319515,319517,319551|324473:0.9592992179095745,325294:0.8356964588165283,320546:0.8354874700307846,388299:0.6033775210380554,317929:0.5910220146179199,347183:0.5721561312675476,328795:0.5367828607559204,319123:0.5360720157623291,344833:0.530017077922821,342114:0.5300134718418121,348805:0.5299892723560333,329375:0.5299350619316101,348806:0.5297853350639343,351083:0.5296847224235535,332039:0.5174620151519775,349105:0.517076164484024,327772:0.5145474374294281,322917:0.5017265975475311,393612:0.4949445128440857,378155:0.4742191433906555,321044:0.4723304510116577,312784:0.4722077250480652,323511:0.4720394015312195,402343:0.4646907448768616,358923:0.4526885747909546,393787:0.4526411294937134,369880:0.4519100785255432,320005:0.4495816230773926,387699:0.44954168796539307',\n",
       " '319515:319495,319752,319435,319915,319471,319895,318297,319514,319517,319551|347887:0.832210510969162,336302:0.5821039378643036,319435:0.5804269015789032,319495:0.5800995528697968,349603:0.5100721716880798,334632:0.5093388855457306,375166:0.4891480803489685,377960:0.47145068645477295,319915:0.46335285902023315,374411:0.4597800374031067,359660:0.45972687005996704,368706:0.45902520418167114,380041:0.4582616090774536,378421:0.4579521417617798,403398:0.45748549699783325,385129:0.4560718536376953,390896:0.454765260219574,382829:0.4487723708152771,411847:0.4482557773590088,380681:0.44626468420028687,395577:0.44462651014328003,319752:0.44168412685394287,357211:0.4385567903518677,396548:0.43829435110092163,413106:0.4373546838760376,304678:0.430919349193573,323459:0.43086105585098267,348966:0.43073374032974243,391573:0.42680054903030396',\n",
       " '319517:319495,319752,319435,319915,319471,319895,318297,319514,319515,319551|319471:0.9836958944797516,333365:0.8981679156422615,340629:0.8723208457231522,348377:0.8719346672296524,343947:0.8622084558010101,330765:0.8583356142044067,330428:0.8160041570663452,350559:0.6728755831718445,326517:0.6517628133296967,320633:0.6506195068359375,391025:0.6351958513259888,203725:0.6302009522914886,198044:0.6266516745090485,416180:0.6230431497097015,424320:0.623035341501236,423070:0.6227158308029175,401951:0.6224949359893799,404003:0.6222020089626312,417662:0.6219306886196136,354108:0.6214143335819244,325755:0.6201811730861664,419506:0.6194757223129272,389248:0.6176206767559052,422879:0.6165450811386108,410295:0.6130054891109467,390916:0.6129952669143677,415396:0.6129559874534607,409673:0.6128316223621368,399571:0.6123683154582977',\n",
       " '319551:319495,319752,319435,319915,319471,319895,318297,319514,319515,319517|351172:0.6561107039451599,373117:0.5973538160324097,351018:0.5973246693611145,397264:0.5972074568271637,322882:0.5941416025161743,350326:0.5937376022338867,381476:0.5935448706150055,329495:0.5906650424003601,412314:0.5906491875648499,342281:0.5904749631881714,417287:0.5904506146907806,382968:0.5897295475006104,379908:0.5897181332111359,422930:0.5897103846073151,314785:0.58936408162117,318262:0.5892629623413086,249938:0.5891854763031006,373494:0.5887451767921448,371901:0.5875792503356934,359044:0.5875248610973358,367118:0.5874350965023041,361875:0.5874195396900177,401910:0.5873799920082092,326746:0.586322158575058,320027:0.5863021910190582,386394:0.5838073194026947,343754:0.5837946832180023,373743:0.5837811827659607,321001:0.5836382210254669',\n",
       " '401416:401362,401363,401461,401023|333434:0.9874487686902285,374895:0.9870185144245625,387214:0.8937135338783264,411599:0.893597811460495,380606:0.8935443684458733,333392:0.8561865389347076,354805:0.4895665645599365,397004:0.48381030559539795,330712:0.4837532043457031,418278:0.48372775316238403,385334:0.48371201753616333,310045:0.4836437702178955,378497:0.48304474353790283,355235:0.4826357960700989,357301:0.4826356768608093,350336:0.48262304067611694,417885:0.4826177954673767,368943:0.4826018214225769,397300:0.4825981855392456,400428:0.4825674891471863,422595:0.48253822326660156,381661:0.4824938178062439,345078:0.4821687936782837,401008:0.47584599256515503,350031:0.47147905826568604,347448:0.4714481830596924,347882:0.47137898206710815,370643:0.47127676010131836,313873:0.47125518321990967',\n",
       " '401362:401416,401363,401461,401023|412266:0.62359419465065,419841:0.5906222462654114,392494:0.5477797985076904,199110:0.4748842716217041,382112:0.43175333738327026,321166:0.4215521216392517,408099:0.39702796936035156,383614:0.3598663806915283,420259:0.32836848497390747,357669:0.3248041272163391,327073:0.32321953773498535,412583:0.31613630056381226,343413:0.3127583861351013,396548:0.3101915717124939,382829:0.3063173294067383,411847:0.3059943914413452,411482:0.30506956577301025,424679:0.30137205123901367,407863:0.30133843421936035,395752:0.3013277053833008,399608:0.30128926038742065,400886:0.300601065158844,403339:0.3001367449760437,406736:0.2917824387550354,389738:0.2912408709526062,390395:0.2911303639411926,411034:0.2909198999404907,395577:0.28964608907699585,404435:0.2863542437553406']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "#     Between 0-10 epochs recall@25 = 0.28\n",
    "#     Between 0-20 epochs recall@25 = 0.32\n",
    "#     Between 0-70 epochs recall@25 = ?\n",
    "#     Between 0-100 epochs recall@25 = ?\n",
    "# '''\n",
    "# recall, exported_rank = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 4641\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_feature_100epochs_64batch(eclipse)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          34269600    title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          34316292    desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "==================================================================================================\n",
      "Total params: 69,090,792\n",
      "Trainable params: 958,392\n",
      "Non-trainable params: 68,132,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, bug_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/eclipse/exported_rank_baseline.txt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.35,\n",
       " '2 - recall_at_10': 0.42,\n",
       " '3 - recall_at_15': 0.45,\n",
       " '4 - recall_at_20': 0.48,\n",
       " '5 - recall_at_25': 0.5}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some ideas to visualizate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
