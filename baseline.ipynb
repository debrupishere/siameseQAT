{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 100\n",
    "MAX_SEQUENCE_LENGTH_D = 20 # 500\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 1000\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'openoffice'\n",
    "METHOD = 'baseline_{}'.format(epochs)\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Glove embeddings\n",
    "GLOVE_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_feature@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_feature_@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a058da112af0488584c930bf62bdac8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=57667), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0e63bce2ec43d5bb50c31764c87679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14567), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c815f0b9814870a91a47eb2846f326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=72234), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca3dd6b9b5b43068e1a60ca636453de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 5.39 s, sys: 661 ms, total: 6.05 s\n",
      "Wall time: 6.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27867f5cf54a4488a8cfc114809c318c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58572), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[59, 27],\n",
       " [59, 92],\n",
       " [27, 92],\n",
       " [64, 43],\n",
       " [44, 45],\n",
       " [53, 54],\n",
       " [84, 63],\n",
       " [75, 699],\n",
       " [105, 121],\n",
       " [186, 199]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the corpus train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CORPUS:\n",
    "    corpus = []\n",
    "    export_file = open(os.path.join(DIR, 'corpus_train.txt'), 'w')\n",
    "    for bug_id in tqdm(baseline.bug_set):\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title = bug['title']\n",
    "        desc = bug['description']\n",
    "        export_file.write(\"{}\\n{}\\n\".format(title, desc))\n",
    "    export_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "# Generating tiple of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': '4\\n',\n",
       " 'bug_status': '1\\n',\n",
       " 'component': '117\\n',\n",
       " 'creation_ts': '2006-07-28 15:20:00 +0000',\n",
       " 'delta_ts': '2013-02-24 21:09:32 +0000',\n",
       " 'description': '[CLS] i have got a book ##mark that en ##cl ##oses a text ##field . trying to access this text ##field using the create ##con ##ten ##ten ##ume ##ration ( ) - method of the book ##mark . anchor does not work though book ##mark . anchor . get ##ava ##ila ##bles ##er ##vic ##ena ##mes ( ) tells that the required \" com . sun . star . text . text ##con ##ten ##t \" is available . regarding the specified behaviour of get ##ava ##ila ##bles ##er ##vic ##ena ##mes ( ) , the create ##con ##ten ##ten ##ume ##ration - method is not allowed to return an empty content ##en ##ume ##ration ( see http : / / api . open ##off ##ice . org / doc ##s / common / ref / com / sun / star / container / x ##con ##ten ##ten ##ume ##ration ##ac ##ces ##s . html # get ##ava ##ila ##bles ##er ##vic ##ena ##mes ) the following code demonstrates this behaviour . the sub \" prepare \" creates a text ##field that is enclosed by the book ##mark test . the get ##ava ##ila ##bles ##er ##vic ##ena ##mes ( ) - method tells that com . sun . star . text . text ##con ##ten ##t is available , but counting the elements of the created content ##en ##ume ##ration shows that this en ##ume ##ration is empty . sub content ##en ##ume ##ration ##ise ##mpt ##y ##bu ##g prepare doc = this ##com ##pone ##nt book ##mark = doc . get ##book ##marks ( ) . get ##by ##name ( \" test \" ) anchor = book ##mark . anchor avail = anchor . get ##ava ##ila ##bles ##er ##vic ##ena ##mes ( ) print avail ( 0 ) en ##u = anchor . create ##con ##ten ##ten ##ume ##ration ( \" com . sun . star . text . text ##con ##ten ##t \" ) count = 0 do while ( en ##u . has ##more ##ele ##ments ( ) ) count = count + 1 loop print count \\' this should be at least 1 end sub sub prepare doc = this ##com ##pone ##nt my ##text = doc . text field = doc . create ##ins ##tance ( \" com . sun . star . text . text ##field . input \" ) field . content = \" test ##con ##ten ##t ##1 \" my ##text . insert ##text ##con ##ten ##t ( my ##text . start , field , false ) cu ##rso ##r = my ##text . create ##text ##cu ##rso ##rb ##yra ##nge ( field . anchor ) book ##mark = doc . create ##ins ##tance ( \" com . sun . star . text . book ##mark \" ) book ##mark . set ##name ( \" test \" ) cu ##rso ##r . text . insert ##text ##con ##ten ##t ( cu ##rso ##r , book ##mark , true ) end sub [SEP]',\n",
       " 'description_bert': '[CLS] i have got a book ##mark that en ##cl ##oses a text ##field . trying to access this text ##field using the create ##con ##ten ##ten ##ume ##ration ( ) - method of the book ##mark . anchor does not work though book ##mark . anchor . get ##ava ##ila ##bles ##er ##vic ##ena ##mes ( ) tells that the required \" com . sun . star . text . text ##con ##ten ##t \" is available . regarding the specified behaviour of get ##ava ##ila ##bles ##er ##vic ##ena ##mes ( ) , the create ##con ##ten ##ten ##ume ##ration - method is not allowed to return an empty content ##en ##ume ##ration ( see http : / / api . open ##off ##ice . org / doc ##s / common / ref / com / sun / star / container / x ##con ##ten ##ten ##ume ##ration ##ac ##ces ##s . html # get ##ava ##ila ##bles ##er ##vic ##ena ##mes ) the following code demonstrates this behaviour . the sub \" prepare \" creates a text ##field that is enclosed by the book ##mark test . the get ##ava ##ila ##bles ##er ##vic ##ena ##mes ( ) - method tells that com . sun . star . text . text ##con ##ten ##t is available , but counting the elements of the created content ##en ##ume ##ration shows that this en ##ume ##ration is empty . sub content ##en ##ume ##ration ##ise ##mpt ##y ##bu ##g prepare doc = this ##com ##pone ##nt book ##mark = doc . get ##book ##marks ( ) . get ##by ##name ( \" test \" ) anchor = book ##mark . anchor avail = anchor . get ##ava ##ila ##bles ##er ##vic ##ena ##mes ( ) print avail ( 0 ) en ##u = anchor . create ##con ##ten ##ten ##ume ##ration ( \" com . sun . star . text . text ##con ##ten ##t \" ) count = 0 do while ( en ##u . has ##more ##ele ##ments ( ) ) count = count + 1 loop print count \\' this should be at least 1 end sub sub prepare doc = this ##com ##pone ##nt my ##text = doc . text field = doc . create ##ins ##tance ( \" com . sun . star . text . text ##field . input \" ) field . content = \" test ##con ##ten ##t ##1 \" my ##text . insert ##text ##con ##ten ##t ( my ##text . start , field , false ) cu ##rso ##r = my ##text . create ##text ##cu ##rso ##rb ##yra ##nge ( field . anchor ) book ##mark = doc . create ##ins ##tance ( \" com . sun . star . text . book ##mark \" ) book ##mark . set ##name ( \" test \" ) cu ##rso ##r . text . insert ##text ##con ##ten ##t ( cu ##rso ##r , book ##mark , true ) end sub [SEP]',\n",
       " 'description_word': array([  101,  1045,  2031,  2288,  1037,  2338, 10665,  2008,  4372,\n",
       "        20464, 27465,  1037,  3793,  3790,  1012,  2667,  2000,  3229,\n",
       "         2023,  3793]),\n",
       " 'description_word_bert': [101,\n",
       "  1045,\n",
       "  2031,\n",
       "  2288,\n",
       "  1037,\n",
       "  2338,\n",
       "  10665,\n",
       "  2008,\n",
       "  4372,\n",
       "  20464,\n",
       "  27465,\n",
       "  1037,\n",
       "  3793,\n",
       "  3790,\n",
       "  1012,\n",
       "  2667,\n",
       "  2000,\n",
       "  3229,\n",
       "  2023,\n",
       "  3793,\n",
       "  3790,\n",
       "  2478,\n",
       "  1996,\n",
       "  3443,\n",
       "  8663,\n",
       "  6528,\n",
       "  6528,\n",
       "  17897,\n",
       "  8156,\n",
       "  1006,\n",
       "  1007,\n",
       "  1011,\n",
       "  4118,\n",
       "  1997,\n",
       "  1996,\n",
       "  2338,\n",
       "  10665,\n",
       "  1012,\n",
       "  8133,\n",
       "  2515,\n",
       "  2025,\n",
       "  2147,\n",
       "  2295,\n",
       "  2338,\n",
       "  10665,\n",
       "  1012,\n",
       "  8133,\n",
       "  1012,\n",
       "  2131,\n",
       "  12462,\n",
       "  11733,\n",
       "  13510,\n",
       "  2121,\n",
       "  7903,\n",
       "  8189,\n",
       "  7834,\n",
       "  1006,\n",
       "  1007,\n",
       "  4136,\n",
       "  2008,\n",
       "  1996,\n",
       "  3223,\n",
       "  1000,\n",
       "  4012,\n",
       "  1012,\n",
       "  3103,\n",
       "  1012,\n",
       "  2732,\n",
       "  1012,\n",
       "  3793,\n",
       "  1012,\n",
       "  3793,\n",
       "  8663,\n",
       "  6528,\n",
       "  2102,\n",
       "  1000,\n",
       "  2003,\n",
       "  2800,\n",
       "  1012,\n",
       "  4953,\n",
       "  1996,\n",
       "  9675,\n",
       "  9164,\n",
       "  1997,\n",
       "  2131,\n",
       "  12462,\n",
       "  11733,\n",
       "  13510,\n",
       "  2121,\n",
       "  7903,\n",
       "  8189,\n",
       "  7834,\n",
       "  1006,\n",
       "  1007,\n",
       "  1010,\n",
       "  1996,\n",
       "  3443,\n",
       "  8663,\n",
       "  6528,\n",
       "  6528,\n",
       "  17897,\n",
       "  8156,\n",
       "  1011,\n",
       "  4118,\n",
       "  2003,\n",
       "  2025,\n",
       "  3039,\n",
       "  2000,\n",
       "  2709,\n",
       "  2019,\n",
       "  4064,\n",
       "  4180,\n",
       "  2368,\n",
       "  17897,\n",
       "  8156,\n",
       "  1006,\n",
       "  2156,\n",
       "  8299,\n",
       "  1024,\n",
       "  1013,\n",
       "  1013,\n",
       "  17928,\n",
       "  1012,\n",
       "  2330,\n",
       "  7245,\n",
       "  6610,\n",
       "  1012,\n",
       "  8917,\n",
       "  1013,\n",
       "  9986,\n",
       "  2015,\n",
       "  1013,\n",
       "  2691,\n",
       "  1013,\n",
       "  25416,\n",
       "  1013,\n",
       "  4012,\n",
       "  1013,\n",
       "  3103,\n",
       "  1013,\n",
       "  2732,\n",
       "  1013,\n",
       "  11661,\n",
       "  1013,\n",
       "  1060,\n",
       "  8663,\n",
       "  6528,\n",
       "  6528,\n",
       "  17897,\n",
       "  102],\n",
       " 'dup_id': '[]',\n",
       " 'issue_id': 67883,\n",
       " 'priority': '3\\n',\n",
       " 'product': '19\\n',\n",
       " 'resolution': 'FIXED',\n",
       " 'textual_word': array([  101,  3443,  8663,  6528,  6528, 17897,  8156,  2006,  2338,\n",
       "        10665,  1012,  8133,  9005,  2019,  4064,  4372, 17897,  8156,\n",
       "          102,     0,   101,  1045,  2031,  2288,  1037,  2338, 10665,\n",
       "         2008,  4372, 20464, 27465,  1037,  3793,  3790,  1012,  2667,\n",
       "         2000,  3229,  2023,  3793]),\n",
       " 'title': '[CLS] create ##con ##ten ##ten ##ume ##ration on book ##mark . anchor creates an empty en ##ume ##ration [SEP]',\n",
       " 'title_bert': '[CLS] create ##con ##ten ##ten ##ume ##ration on book ##mark . anchor creates an empty en ##ume ##ration [SEP]',\n",
       " 'title_word': array([  101,  3443,  8663,  6528,  6528, 17897,  8156,  2006,  2338,\n",
       "        10665,  1012,  8133,  9005,  2019,  4064,  4372, 17897,  8156,\n",
       "          102,     0]),\n",
       " 'title_word_bert': [101,\n",
       "  3443,\n",
       "  8663,\n",
       "  6528,\n",
       "  6528,\n",
       "  17897,\n",
       "  8156,\n",
       "  2006,\n",
       "  2338,\n",
       "  10665,\n",
       "  1012,\n",
       "  8133,\n",
       "  9005,\n",
       "  2019,\n",
       "  4064,\n",
       "  4372,\n",
       "  17897,\n",
       "  8156,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'version': '327\\n'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 11043)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.9 ms, sys: 0 ns, total: 31.9 ms\n",
      "Wall time: 31.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = experiment.batch_iterator(None, \n",
    "                                                                                                      baseline.train_data, \n",
    "                                                                                                      baseline.dup_sets_train,\n",
    "                                                                                                      bug_train_ids,\n",
    "                                                                                                      batch_size_test, 1,\n",
    "                                                                                                      issues_by_buckets)\n",
    "test_gen = ([valid_input_sample['title'], valid_input_pos['title'], valid_input_neg['title'], \n",
    "             valid_input_sample['description'], valid_input_pos['description'], valid_input_neg['description'],\n",
    "            valid_input_sample['info'], valid_input_pos['info'], valid_input_neg['info']], valid_sim)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 20), (128, 20), (128, 729), (128,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "#baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test ', 2086)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Test \", len(baseline.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 18562'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, GLOVE_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(GLOVE_DIR, 'glove.42B.300d.txt')\n",
    "    f = open(embed_path, 'rb')\n",
    "    #num_lines = sum(1 for line in open(embed_path, 'rb'))\n",
    "\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embeddings_index[word] = np.asarray(tokens[1:], dtype='float32')\n",
    "        loop.update(1)\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    i = 0\n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2216c5dc32ec41eb966096ea7816564a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80affd66bf854a4ab8efe2a72d1fafdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18562), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 22s, sys: 3.65 s, total: 1min 25s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, GLOVE_DIR=GLOVE_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "\n",
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer',\n",
    "                                  weights=[embeddings],\n",
    "                                  embeddings_constraint=MaxNorm(max_value=1, axis=0),\n",
    "                                  #input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI074wU4Y13y"
   },
   "source": [
    "### CNN with filter 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "h6YJU9GtFTyq",
    "outputId": "f85cf105-1fd6-491d-d969-7e6936f32739",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "\n",
    "def cnn_model(embedding_layer, max_sequence_length):\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length,), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None,), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "    # best combination filter (3, 4, 5) e 128 e 256\n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    n_filters = 64\n",
    "\n",
    "    for index, filter_size in enumerate(filter_sizes):\n",
    "        l_conv = Conv1D(filters=n_filters, kernel_size=filter_size)(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(pool_size=filter_size)(l_conv) # index+1\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "    # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "    #conv = Conv1D(filters=n_filters * 3, kernel_size=3)(l_merge)\n",
    "    layer = GlobalAveragePooling1D()(l_merge)\n",
    "    #layer = Flatten()(l_merge)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "    #layer = LeakyReLU()(layer)\n",
    "\n",
    "    cnn_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureCNNGenerationModel') # inputs=visible\n",
    "\n",
    "    return cnn_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr6ObTXiaALH"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "vC7MQXEsaCeG",
    "outputId": "65e647a9-c5d3-4009-b8a4-2e2d97b52684"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, GRU, Dropout, Bidirectional, GlobalAveragePooling1D, TimeDistributed\n",
    "\n",
    "def lstm_model(embedding_layer, max_sequence_length):\n",
    "    number_lstm_units = 75\n",
    "    rate_drop_lstm = 0\n",
    "    recurrent_dropout = 0\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None, ), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    left_layer = LSTM(number_lstm_units, return_sequences=True)(embedded_sequences)\n",
    "    right_layer = LSTM(number_lstm_units, return_sequences=True, go_backwards=True)(left_layer)\n",
    "    \n",
    "    lstm_layer = Concatenate()([left_layer, right_layer])\n",
    "    \n",
    "    #lstm_layer = TimeDistributed(Dense(50))(lstm_layer)\n",
    "    #layer = Flatten()(lstm_layer)\n",
    "    layer = GlobalAveragePooling1D()(lstm_layer)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "\n",
    "    lstm_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureLstmGenerationModel') # inputs=visible\n",
    "\n",
    "    return lstm_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    for units in [64, 32]:\n",
    "        layer = Dense(units, activation='tanh', kernel_initializer='random_uniform')(info_input)\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.sum(K.maximum(0.0, margin - pos + neg))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "  \n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    #     bug_feature_output = Activation('tanh')(bug_feature_output)\n",
    "    \n",
    "    # Bug representation layer\n",
    "    # bug_feature_output = Dense(300, activation='tanh')(bug_feature_output)\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    \n",
    "    # Cosine\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "    #optimizer = Nadam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=K.epsilon(), schedule_decay=0.01)\n",
    "    optimizer = Adam(lr=1e-3 * decay_lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer=optimizer, loss=custom_margin_loss, metrics=[pos_distance, neg_distance, custom_margin_loss])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_pos (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_pos (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_neg (InputLayer)          (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_neg (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          219000      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          5772000     title_in[0][0]                   \n",
      "                                                                 title_pos[0][0]                  \n",
      "                                                                 title_neg[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          5818692     desc_in[0][0]                    \n",
      "                                                                 desc_pos[0][0]                   \n",
      "                                                                 desc_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 900)          0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureLstmGenerationModel[2][0] \n",
      "                                                                 FeatureCNNGenerationModel[2][0]  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 900)          0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureLstmGenerationModel[3][0] \n",
      "                                                                 FeatureCNNGenerationModel[3][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances (Lambda)        (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 11,809,692\n",
      "Trainable params: 672,492\n",
      "Non-trainable params: 11,137,200\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 1.08, MarginLoss: 1.08, pos_cosine: 0.88, neg_cosine: 0.96\n",
      "Epoch: 2 Loss: 1.06, MarginLoss: 1.06, pos_cosine: 0.91, neg_cosine: 0.96\n",
      "Epoch: 3 Loss: 1.06, MarginLoss: 1.06, pos_cosine: 0.91, neg_cosine: 0.97\n",
      "Epoch: 4 Loss: 1.04, MarginLoss: 1.04, pos_cosine: 0.94, neg_cosine: 0.98\n",
      "Epoch: 5 Loss: 1.03, MarginLoss: 1.03, pos_cosine: 0.95, neg_cosine: 0.98\n",
      "Epoch: 6 Loss: 1.02, MarginLoss: 1.02, pos_cosine: 0.97, neg_cosine: 0.99\n",
      "Epoch: 7 Loss: 1.02, MarginLoss: 1.02, pos_cosine: 0.97, neg_cosine: 0.99\n",
      "Epoch: 8 Loss: 1.02, MarginLoss: 1.02, pos_cosine: 0.98, neg_cosine: 0.99\n",
      "Epoch: 9 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.98, neg_cosine: 0.99\n",
      "Epoch: 10 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.98, neg_cosine: 0.99\n",
      "Epoch: 11 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 12 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 13 Loss: 1.01, MarginLoss: 1.01, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 14 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 15 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 16 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 17 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 18 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 19 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 20 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 21 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 22 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 23 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 24 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 25 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 26 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 27 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 28 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 29 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 30 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 31 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 32 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 33 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 34 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 35 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 36 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 38 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 39 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 40 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 41 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 42 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 43 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 44 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 45 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 46 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 47 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 48 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 49 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 50 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 51 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 52 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 53 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 54 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 55 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 56 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 57 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 58 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 59 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 60 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 61 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 62 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 63 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 64 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 65 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 66 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 67 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 68 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 69 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 70 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 71 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 72 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 73 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 74 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 75 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 76 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 77 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 78 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 79 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 80 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 81 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 82 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 83 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 84 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 85 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 86 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 87 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 88 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 89 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 90 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 91 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 92 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 93 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 94 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 95 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 96 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 97 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 98 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 99 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 100 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 101 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 102 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 103 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 104 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 105 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 106 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 107 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 108 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 109 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 110 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 111 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 112 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 113 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 114 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 115 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 116 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 117 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 118 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 119 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 120 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 121 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 122 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 123 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 124 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 125 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 126 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 127 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 128 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 129 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 130 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 131 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 132 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 133 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 134 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 135 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 136 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 137 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 138 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 139 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 140 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 141 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 142 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 143 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 144 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 145 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 146 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 147 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 148 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 149 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 150 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 151 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 152 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 153 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 154 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 155 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 156 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 157 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 158 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 159 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 160 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 161 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 162 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 163 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 164 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 165 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 166 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 167 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 168 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 169 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 170 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 171 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 172 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 173 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 174 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 175 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 176 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 177 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 178 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 179 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 180 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 181 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 182 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 183 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 184 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 185 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 186 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 187 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 188 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 189 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 190 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 191 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 192 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 193 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 194 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 195 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 196 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 197 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 198 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 199 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 200 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 201 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 202 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 203 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 204 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 205 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 206 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 207 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 208 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 209 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 210 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 211 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 212 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 213 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 214 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 215 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 216 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 217 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 218 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 219 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 220 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 221 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 222 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 223 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 224 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 225 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 226 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 227 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 228 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 229 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 230 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 231 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 232 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 233 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 234 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 235 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 236 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 237 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 238 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 239 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 240 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 241 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 242 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 243 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 244 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 245 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 246 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 247 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 248 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 249 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 250 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 251 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 252 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 253 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 254 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 255 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 256 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 257 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 258 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 259 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 260 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 261 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 262 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 263 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 264 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 265 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 266 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 267 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 268 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 269 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 270 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 271 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 272 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 273 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 274 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 275 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 276 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 277 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 278 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 279 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 280 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 281 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 282 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 283 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 284 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 285 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 286 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 287 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 288 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 289 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 290 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 291 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 292 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 293 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 294 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 295 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 296 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 297 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 298 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 299 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 300 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 301 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 302 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 303 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 304 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 305 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 306 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 307 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 308 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 309 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 310 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 311 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 312 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 313 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 314 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 315 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 316 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 317 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 318 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 319 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 320 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 321 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 322 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 323 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 324 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 325 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 326 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 327 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 328 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 329 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 330 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 331 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 332 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 333 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 334 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 335 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 336 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 337 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 338 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 339 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 340 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 341 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 342 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 343 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 344 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 345 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 346 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 347 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 348 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 349 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 350 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 351 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 352 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 353 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 354 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 355 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 356 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 357 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 358 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 359 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 360 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 361 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 362 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 363 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 364 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 365 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 366 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 367 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 368 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 369 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 370 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 371 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 372 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 373 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 374 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 375 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 376 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 377 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 378 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 379 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 380 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 381 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 382 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 383 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 384 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 385 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 386 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 387 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 388 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 389 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 390 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 391 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 392 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 393 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 394 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 395 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 396 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 397 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 398 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 399 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 400 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 401 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 402 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 403 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 404 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 405 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 406 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 407 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 408 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 409 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 410 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 411 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 412 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 413 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 414 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 415 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 416 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 417 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 418 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 419 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 420 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 421 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 422 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 423 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 424 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 425 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 426 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 427 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 428 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 429 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 430 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 431 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 432 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 433 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 434 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 435 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 436 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 437 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 438 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 439 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 440 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 441 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 442 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 443 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 444 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 445 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 446 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 447 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 448 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 449 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 450 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 451 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 452 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 453 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 454 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 455 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 456 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 457 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 458 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 459 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 460 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 461 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 462 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 463 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 464 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 465 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 466 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 467 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 468 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 469 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 470 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 471 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 472 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 473 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 474 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 475 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 476 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 477 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 478 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 479 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 480 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 481 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 482 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 483 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 484 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 485 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 486 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 487 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 488 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 489 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 490 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 491 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 492 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 493 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 494 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 495 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 496 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 497 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 498 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 499 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 500 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 501 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 502 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 503 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 504 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 505 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 506 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 507 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 508 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 509 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 510 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 511 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 512 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 513 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 514 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 515 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 516 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 517 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 518 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 519 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 520 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 521 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 522 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 523 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 524 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 525 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 526 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 527 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 528 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 529 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 530 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 531 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 532 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 533 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 534 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 535 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 536 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 537 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 538 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 539 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 540 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 541 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 542 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 543 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 544 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 545 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 546 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 547 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 548 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 549 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 550 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 551 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 552 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 553 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 554 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 555 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 556 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 557 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 558 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 559 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 560 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 561 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 562 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 563 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 564 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 565 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 566 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 567 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 568 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 569 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 570 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 571 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 572 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 573 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 574 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 575 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 576 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 577 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 578 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 579 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 580 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 581 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 582 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 583 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 584 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 585 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 586 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 587 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 588 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 589 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 590 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 591 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 592 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 593 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 594 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 595 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 596 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 597 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 598 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 599 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 600 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 601 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 602 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 603 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 604 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 605 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 606 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 607 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 608 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 609 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 610 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 611 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 612 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 613 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 614 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 615 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 616 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 617 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 618 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 619 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 620 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 621 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 622 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 623 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 624 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 625 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 626 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 627 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 628 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 629 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 630 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 631 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 632 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 633 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 634 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 635 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 636 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 637 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 638 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 639 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 640 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 641 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 642 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 643 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 644 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 645 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 646 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 647 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 648 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 649 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 650 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 651 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 652 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 653 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 654 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 655 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 656 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 657 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 658 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 659 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 660 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 661 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 662 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 663 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 664 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 665 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 666 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 667 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 668 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 669 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 670 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 671 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 672 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 673 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 674 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 675 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 676 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 677 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 678 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 679 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 680 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 681 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 682 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 683 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 684 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 685 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 686 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 687 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 688 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 689 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 690 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 691 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 692 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 693 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 694 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 695 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 696 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 697 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 698 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 699 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 700 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 701 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 702 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 703 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 704 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 705 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 706 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 707 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 708 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 709 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 710 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 711 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 712 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 713 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 714 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 715 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 716 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 717 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 718 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 719 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 720 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 721 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 722 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 723 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 724 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 725 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 726 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 727 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 728 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 729 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 730 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 731 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 732 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 733 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 734 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 735 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 736 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 737 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 738 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 739 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 740 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 741 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 742 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 743 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 744 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 745 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 746 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 747 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 748 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 749 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 750 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 751 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 752 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 753 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 754 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 755 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 756 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 757 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 758 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 759 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 760 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 761 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 762 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 763 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 764 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 765 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 766 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 767 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 768 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 769 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 770 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 771 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 772 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 773 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 774 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 775 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 776 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 777 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 778 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 779 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 780 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 781 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 782 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 783 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 784 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 785 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 786 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 787 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 788 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 789 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 790 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 791 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 792 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 793 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 794 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 795 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 796 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 797 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 798 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 799 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 800 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 801 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 802 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 803 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 804 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 805 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 806 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 807 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 808 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 809 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 810 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 811 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 812 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 813 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 814 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 815 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 816 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 817 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 818 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 819 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 820 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 821 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 822 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 823 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 824 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 825 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 826 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 827 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 828 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 829 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 830 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 831 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 832 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 833 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 834 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 835 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 836 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 837 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 838 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 839 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 840 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 841 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 842 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 843 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 844 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 845 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 846 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 847 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 848 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 849 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 850 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 851 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 852 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 853 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 854 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 855 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 856 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 857 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 858 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 859 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 860 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 861 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 862 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 863 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 864 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 865 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 866 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 867 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 868 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 869 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 870 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 871 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 872 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 873 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 874 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 875 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 876 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 877 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 878 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 879 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 880 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 881 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 882 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 883 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 884 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 885 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 886 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 887 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 888 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 889 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 890 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 891 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 892 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 893 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 894 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 895 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 896 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 897 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 898 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 899 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 900 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 901 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 902 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 903 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 904 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 905 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 906 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 907 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 908 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 909 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 910 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 911 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 912 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 913 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 914 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 915 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 916 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 917 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 918 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 919 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 920 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 921 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 922 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 923 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 924 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 925 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 926 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 927 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 928 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 929 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 930 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 931 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 932 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 933 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 934 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 935 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 936 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 937 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 938 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 939 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 940 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 941 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 942 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 943 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 944 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 945 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 946 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 947 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 948 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 949 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 950 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 951 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 952 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 953 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 954 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 955 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 956 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 957 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 958 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 959 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 960 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 961 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 962 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 963 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 964 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 965 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 966 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 967 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 968 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 969 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 970 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 971 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 972 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 973 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 974 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 975 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 976 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 977 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 978 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 979 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 980 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 981 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 982 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 983 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 984 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 985 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 986 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 987 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 988 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 989 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 990 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 991 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 992 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 993 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 994 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 995 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 996 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 997 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 998 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 999 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 1000 Loss: 1.00, MarginLoss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00, recall@25: 0.51\n",
      "Saved model 'modelos/model_baseline_1000_feature_1000epochs_64batch(openoffice).h5' to disk\n",
      "Best_epoch=0, Best_loss=1.00, Recall@25=0.51\n",
      "CPU times: user 9h 50min 9s, sys: 2h 45min 13s, total: 12h 35min 23s\n",
      "Wall time: 7h 39min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False)\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(vocab), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False)\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    mlp_model\n",
    "'''\n",
    "desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "title_feature_model = lstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, \\\n",
    "            train_sim = experiment.batch_iterator(encoded_anchor, baseline.train_data, baseline.dup_sets_train, bug_train_ids, \n",
    "                                       batch_size, 1, issues_by_buckets)\n",
    "    train_batch = [train_input_sample['title'], train_input_sample['description'], train_input_sample['info'],\n",
    "                   train_input_pos['title'], train_input_pos['description'], train_input_pos['info'], \n",
    "                   train_input_neg['title'], train_input_neg['description'], train_input_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, MarginLoss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],  h[3],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[3]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['108544:111059,109674,108379,109366|102470:0.963911809027195,14454:0.9630606733262539,109674:0.9616216197609901,111059:0.9608864150941372,111297:0.959563922137022,115100:0.9588290862739086,46957:0.9583318904042244,92117:0.9570300281047821,115569:0.9570199176669121,92348:0.9562196135520935,115421:0.9558651223778725,94421:0.9555420242249966,92690:0.9548383057117462,105671:0.9546678513288498,102495:0.9544434510171413,86960:0.954442922025919,95277:0.9543333686888218,104574:0.9542505517601967,104576:0.9542505517601967,93177:0.9542159736156464,116229:0.9540876485407352,93169:0.9540772624313831,98212:0.9539180845022202,108379:0.9538363441824913,89620:0.9537629596889019,105166:0.9537356644868851,107267:0.953667726367712,92613:0.9535845369100571,94909:0.9535478688776493',\n",
       " '109674:108544,111059,108379,109366|92117:0.9754188433289528,115100:0.9750226605683565,92348:0.9749806709587574,14454:0.9747119471430779,102470:0.9746984858065844,115569:0.9740808866918087,92690:0.9740739706903696,94421:0.973881309852004,115421:0.9733727239072323,86960:0.9730843771249056,104574:0.9728760719299316,104576:0.9728760719299316,98212:0.9724122881889343,46957:0.9719488844275475,94909:0.9718413297086954,111297:0.9715365469455719,105166:0.9714114870876074,95277:0.9713722188025713,113509:0.97136783413589,105671:0.9712340235710144,89620:0.9712133165448904,111059:0.9708079565316439,102788:0.9699939098209143,89456:0.9695735406130552,97026:0.968423917889595,114310:0.9682612530887127,102003:0.9680571220815182,105272:0.9676995575428009,104267:0.9675456546247005',\n",
       " '111059:108544,109674,108379,109366|111297:0.9936249633319676,110274:0.9748630002140999,102470:0.9740285631269217,14454:0.9717430155724287,115100:0.9710515402257442,109674:0.9708079565316439,92117:0.969925282523036,115569:0.9694740995764732,92348:0.9692474156618118,104574:0.968889718875289,104576:0.968889718875289,46957:0.9687108471989632,115421:0.9683946408331394,92690:0.9679286517202854,89620:0.9676571302115917,105166:0.9670737981796265,94421:0.9670710228383541,95277:0.9670346453785896,105671:0.9663806818425655,97026:0.9663086496293545,89456:0.965453501790762,86960:0.965393178164959,102788:0.9651294946670532,101398:0.9651278294622898,92613:0.9650701507925987,102003:0.9650032967329025,94909:0.9648266360163689,82495:0.9648211784660816,102495:0.9646102637052536',\n",
       " '108379:108544,111059,109674,109366|108492:0.9862669389694929,102470:0.9655665382742882,14454:0.9649014808237553,115100:0.9616685137152672,109674:0.9612968824803829,115569:0.9600787907838821,92117:0.9600067473948002,111059:0.9596794880926609,92348:0.959288164973259,46957:0.9592457711696625,115421:0.9590422511100769,111297:0.9589649029076099,92690:0.9580813944339752,94421:0.958037719130516,105671:0.9575495831668377,105166:0.9574697837233543,113509:0.957171805202961,102495:0.957158762961626,102003:0.956597201526165,93055:0.9564295746386051,105757:0.9561275094747543,104574:0.9561184570193291,104576:0.9561184570193291,95277:0.9559969417750835,104267:0.9558326043188572,94909:0.9558268822729588,93177:0.9555838629603386,102788:0.9555500037968159,98212:0.9555165953934193',\n",
       " '109366:108544,111059,109674,108379|110044:0.9961420651525259,109592:0.9644720889627934,104266:0.9627579040825367,102497:0.9625180549919605,103056:0.9624713659286499,109363:0.9622518420219421,91310:0.9615497961640358,110692:0.9596833698451519,106574:0.9586354270577431,109909:0.9583143815398216,108311:0.9580605663359165,102082:0.956770833581686,98821:0.9566824100911617,92537:0.956630252301693,109081:0.956453625112772,101622:0.9562010690569878,105482:0.9560420252382755,105086:0.9559569023549557,100666:0.954963780939579,114671:0.9548609517514706,114770:0.9547384157776833,109431:0.9547338262200356,112617:0.954552199691534,106191:0.9543763808906078,99191:0.9541887864470482,104956:0.9541786946356297,107044:0.9538975432515144,115579:0.9538353309035301,115491:0.9535614438354969',\n",
       " '110594:107073,108355,108453,109162,111761,111800|109162:0.9857621854171157,108439:0.9733106903731823,108084:0.9730800911784172,107073:0.9730643630027771,108240:0.9719114787876606,106479:0.9715801831334829,95494:0.9709603320807219,96633:0.968882979825139,106207:0.9683041758835316,105251:0.9679081812500954,96468:0.9668674319982529,95926:0.9667044691741467,95191:0.9664637893438339,104930:0.9659786596894264,95750:0.9657735414803028,109014:0.9656822420656681,110118:0.9654044732451439,107802:0.9651603549718857,108333:0.9649278521537781,105739:0.9643055312335491,111078:0.9642829485237598,98310:0.9635554067790508,95242:0.9630696922540665,111235:0.963052786886692,120944:0.9627159461379051,105273:0.9612340666353703,106561:0.9612224586308002,93178:0.9606757089495659,100253:0.9604396298527718',\n",
       " '111800:107073,110594,108355,108453,109162,111761|81539:0.9668851271271706,111833:0.965477928519249,91324:0.9647998288273811,57538:0.9644107930362225,56891:0.9643379598855972,76670:0.9642145857214928,108513:0.9639849700033665,94719:0.9639774151146412,97681:0.9639207050204277,98278:0.9639154858887196,98966:0.9638076946139336,94707:0.963442824780941,102865:0.9632738828659058,106939:0.9629650115966797,78260:0.9626076854765415,98770:0.9625260904431343,114322:0.9624492302536964,113312:0.9624101668596268,98967:0.9621739313006401,73946:0.9620822705328465,96913:0.9619272723793983,103210:0.9619172886013985,96787:0.9618918336927891,94675:0.9617138467729092,98948:0.9616879485547543,100490:0.961669035255909,97289:0.9616517946124077,94030:0.9616239964962006,99070:0.9616237580776215',\n",
       " '111761:107073,110594,108355,108453,109162,111800|111758:0.9819373153150082,110992:0.9817959256470203,110712:0.9815600719302893,110005:0.9745464827865362,109550:0.9715987648814917,111165:0.9702599924057722,110795:0.9684587717056274,109407:0.9667226560413837,110123:0.9665885642170906,110468:0.9659429863095284,110594:0.9658875577151775,110365:0.9658396728336811,109729:0.9657819420099258,109911:0.9657502807676792,109681:0.9648356474936008,113107:0.9647961854934692,109485:0.9632653631269932,103827:0.9630726352334023,114811:0.9626720733940601,101545:0.962277926504612,107209:0.9612517729401588,98554:0.9610437676310539,90612:0.9598344787955284,107906:0.9597730599343777,105969:0.9596955254673958,109393:0.9593168869614601,101504:0.9588597640395164,95853:0.9587890021502972,103447:0.9579408764839172',\n",
       " '109162:107073,110594,108355,108453,111761,111800|110594:0.9857621854171157,108240:0.9723909944295883,107073:0.9710681084543467,108439:0.9698154553771019,106479:0.9689186960458755,105251:0.9684125334024429,108084:0.9677251949906349,96633:0.9673745147883892,95494:0.9665781445801258,106207:0.9654536843299866,95191:0.9654211141169071,95926:0.9650838896632195,107802:0.9649744965136051,110118:0.9647386930882931,105739:0.963933952152729,108333:0.9636810980737209,96468:0.9629190862178802,104930:0.9618165791034698,95750:0.9617453888058662,109014:0.9617005810141563,111078:0.9609047770500183,111235:0.9608529657125473,98310:0.9608331136405468,100253:0.9604886993765831,120944:0.9593030735850334,95242:0.9591465145349503,105273:0.9582630470395088,108601:0.9581994116306305,106561:0.9577547609806061',\n",
       " '108355:107073,110594,108453,109162,111761,111800|110059:0.9680148549377918,102921:0.9563448429107666,105243:0.9560317806899548,114718:0.9559646956622601,94242:0.9555498361587524,107249:0.9554908759891987,106083:0.9552054926753044,94900:0.9551822133362293,109544:0.9548563994467258,96538:0.9546612836420536,95319:0.9546352066099644,106591:0.9546222612261772,112385:0.9545525386929512,116943:0.9545177668333054,106523:0.9542857632040977,102353:0.954236838966608,105047:0.9540201984345913,106068:0.953920628875494,101552:0.9539151564240456,100671:0.9534643888473511,115898:0.9533920437097549,106581:0.9533449858427048,95152:0.9533399343490601,116681:0.9532772079110146,96918:0.9530546218156815,98659:0.952941183000803,105368:0.9525484628975391,105747:0.9524866528809071,90800:0.9523652270436287',\n",
       " '108453:107073,110594,108355,109162,111761,111800|101462:0.9634283110499382,103471:0.9630595184862614,95494:0.9627146646380424,103827:0.9626790918409824,114811:0.9615235216915607,100158:0.9614784568548203,95269:0.961468730121851,103771:0.9612576849758625,93569:0.9610275626182556,101051:0.9603194557130337,95055:0.9603053703904152,96871:0.9602852873504162,104278:0.9601948522031307,96633:0.9601124189794064,103282:0.9598537012934685,109162:0.9597603902220726,100327:0.9596443921327591,107209:0.9594718627631664,103447:0.9593505896627903,98554:0.9591003134846687,106479:0.9590792320668697,105970:0.9590716622769833,101545:0.959065955132246,108206:0.9589917920529842,107167:0.9589636363089085,107749:0.9588572196662426,101504:0.9588138461112976,105266:0.9587150625884533,96913:0.9587076157331467',\n",
       " '114705:114676|116457:0.9750686455518007,98659:0.9633209556341171,105368:0.9632913582026958,96918:0.962512269616127,99254:0.9622882828116417,100671:0.9617687799036503,113313:0.9617631137371063,106523:0.9615448266267776,112218:0.961191151291132,105747:0.9604815542697906,105727:0.9603411816060543,102921:0.9596647508442402,111193:0.9595482051372528,109640:0.9591734483838081,97135:0.9591019377112389,91166:0.9588121473789215,116681:0.958721037954092,112385:0.9584640190005302,114718:0.9581230282783508,102518:0.9581055417656898,94242:0.9579497203230858,95152:0.957901906222105,104156:0.9578224010765553,113047:0.9578064754605293,95319:0.9577798508107662,105243:0.9577735811471939,105822:0.9577581770718098,106581:0.9577348344027996,108423:0.957611121237278',\n",
       " '114676:114705|99186:0.9650449678301811,91458:0.9650085903704166,102648:0.9606424421072006,106269:0.9590835347771645,106268:0.9590667188167572,101867:0.9590226672589779,96817:0.9587830193340778,91245:0.9581983238458633,107893:0.9577260203659534,110900:0.957710150629282,110879:0.957487840205431,108061:0.956848181784153,110866:0.9566554836928844,115350:0.9566256254911423,104359:0.9565347917377949,104360:0.9565347917377949,111908:0.9563059322535992,103513:0.9560685604810715,115237:0.9559345878660679,101522:0.9556265398859978,111881:0.9555666036903858,121385:0.9552003182470798,112930:0.954091913998127,112931:0.954091913998127,121279:0.9529291726648808,120563:0.9468774236738682,108191:0.9428984746336937,115695:0.9403626024723053,114045:0.9396317265927792',\n",
       " '110593:110618|110397:0.9969294990878552,111172:0.9924465003423393,111286:0.9902831614017487,111651:0.9861292196437716,110343:0.9860187601298094,110329:0.9860171340405941,109486:0.9858547020703554,110366:0.9856187477707863,110392:0.9856020594015718,110374:0.985322268679738,110026:0.985165017656982,110375:0.9849933236837387,110485:0.9849774613976479,109568:0.9848142052069306,110346:0.9844421939924359,114133:0.9843522347509861,109880:0.9838399719446898,112708:0.9827116429805756,114440:0.9826818499714136,111673:0.9820612538605928,109513:0.9817412197589874,115496:0.9816975109279156,109751:0.9815074019134045,111417:0.9814582895487547,112276:0.9814497325569391,110351:0.9813870284706354,111389:0.9813647232949734,111277:0.9812235087156296,110657:0.9808695390820503',\n",
       " '110618:110593|110922:0.9831128846853971,112234:0.9795147851109505,110709:0.9775605741888285,110306:0.976720966398716,108553:0.9766298104077578,90892:0.9692973531782627,95207:0.9692002851516008,89006:0.9685564301908016,90511:0.9684214703738689,112099:0.9683696776628494,73288:0.968033280223608,94544:0.9679547548294067,96115:0.9679530113935471,29797:0.9679001718759537,98768:0.9675633423030376,95667:0.9675447382032871,95031:0.9675092995166779,97263:0.9674331024289131,99270:0.9673677906394005,87788:0.9672387503087521,12248:0.9670364446938038,97523:0.9669622406363487,99983:0.9669220112264156,108141:0.9668167531490326,96142:0.9667210765182972,102649:0.9664573110640049,108471:0.9664528854191303,5686:0.9664470516145229,4183:0.9663385339081287',\n",
       " '102409:102053|90949:0.9685997180640697,95237:0.9637653082609177,97350:0.9629149474203587,102495:0.9609067440032959,102003:0.959964994341135,104267:0.9593270532786846,96880:0.9583450481295586,102557:0.9582805968821049,93443:0.9574342928826809,14454:0.9568695574998856,102471:0.9567049853503704,102470:0.9564213752746582,104460:0.9561533257365227,109674:0.9556824788451195,93296:0.9546825401484966,115100:0.9545353874564171,104080:0.954173568636179,115569:0.9534863419830799,111059:0.9532378688454628,111297:0.9529953338205814,115421:0.9528267495334148,103790:0.9527517557144165,102359:0.952418603003025,46957:0.952111043035984,92117:0.9518814943730831,103711:0.9514729492366314,105671:0.9514627791941166,92348:0.9514426067471504,103951:0.9509829208254814',\n",
       " '102053:102409|116288:0.957758404314518,107101:0.9571043662726879,89910:0.9509143307805061,108200:0.9497798904776573,90096:0.9495852179825306,103572:0.9494561031460762,109884:0.9494265355169773,109889:0.9494265355169773,94030:0.9493836425244808,71112:0.9493022225797176,103210:0.9492165595293045,112371:0.949103482067585,94719:0.9490052834153175,103575:0.9488676115870476,94415:0.948651235550642,114339:0.9485972635447979,55499:0.9485757760703564,90864:0.9485470317304134,89276:0.9483548328280449,106939:0.948323056101799,96787:0.948257427662611,17631:0.9481962583959103,105969:0.948107473552227,107906:0.9481019005179405,114811:0.9480798505246639,107749:0.9480526931583881,88476:0.9480506330728531,113312:0.9480009078979492,108333:0.947979748249054',\n",
       " '110604:110612|110612:0.9800592958927155,109067:0.9508517347276211,96258:0.9502090774476528,95878:0.9497900679707527,94719:0.9497562870383263,95913:0.9497265256941319,98278:0.9496480636298656,98966:0.9495953693985939,96597:0.9495750106871128,97681:0.9495728984475136,97593:0.949519719928503,94918:0.9494993686676025,94707:0.9493350721895695,94554:0.9492494240403175,102865:0.9492460638284683,95007:0.9490675888955593,96913:0.9489091634750366,76670:0.9488026984035969,114322:0.9487796649336815,100158:0.948749978095293,94775:0.9487386606633663,105387:0.9487206377089024,105654:0.9486391730606556,105382:0.9486276246607304,113312:0.9485647529363632,96787:0.9485557116568089,100673:0.9484984651207924,99070:0.9484726525843143,11004:0.9484005570411682',\n",
       " '110612:110604|110604:0.9800592958927155,109067:0.9500153213739395,96597:0.9489905908703804,96258:0.9485853463411331,96628:0.9484015852212906,98948:0.9480603970587254,97757:0.9477713219821453,95853:0.9476086348295212,102865:0.9473807141184807,97736:0.947378370910883,94554:0.9473137445747852,94707:0.9472586922347546,105594:0.947220966219902,105508:0.9471865855157375,94775:0.9471316784620285,94719:0.9470906965434551,96929:0.9468990601599216,107209:0.9467881172895432,110669:0.9467750787734985,95007:0.9467385075986385,94935:0.9467325694859028,96871:0.9467296451330185,114154:0.9467216916382313,105266:0.9467109106481075,98966:0.9465680457651615,95878:0.946410808712244,105382:0.946332536637783,103031:0.9462898708879948,103575:0.9462847784161568',\n",
       " '116738:116938,117027|115793:0.9973134901374578,113106:0.9920136071741581,113225:0.9889566041529179,115228:0.9785549696534872,115201:0.9773330986499786,112680:0.9761392939835787,89397:0.9746027700603008,93192:0.9718078412115574,113966:0.9685545451939106,114397:0.9677470028400421,108966:0.9671135619282722,113395:0.9666588976979256,117201:0.9658096358180046,98764:0.9657172150909901,107738:0.9655248485505581,96594:0.9653430320322514,87935:0.9651058465242386,89276:0.964730579406023,93230:0.9646506868302822,93231:0.9646506868302822,90864:0.9645484946668148,114431:0.9645358100533485,88476:0.96451061591506,93696:0.9637834504246712,109630:0.9636172652244568,102274:0.9633589163422585,113881:0.9629336260259151,92166:0.9629237614572048,91224:0.9629140421748161']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "#     Between 0-10 epochs recall@25 = 0.28\n",
    "#     Between 0-20 epochs recall@25 = 0.32\n",
    "#     Between 0-70 epochs recall@25 = ?\n",
    "#     Between 0-100 epochs recall@25 = ?\n",
    "# '''\n",
    "# recall, exported_rank = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 2086\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline_1000_feature_1000epochs_64batch(openoffice)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoded_anchor\n",
    "# model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          219000      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          5772000     title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          5818692     desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "==================================================================================================\n",
      "Total params: 11,809,692\n",
      "Trainable params: 672,492\n",
      "Non-trainable params: 11,137,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, bug_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/openoffice/exported_rank_baseline_1000.txt'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in _:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.37,\n",
       " '2 - recall_at_10': 0.44,\n",
       " '3 - recall_at_15': 0.47,\n",
       " '4 - recall_at_20': 0.5,\n",
       " '5 - recall_at_25': 0.51}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some ideas to visualizate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
