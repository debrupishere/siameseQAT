{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Bug triage with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "5dea0229-9480-462d-9d8d-87099372daf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thiago\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19Oo5yKCrXYG"
   },
   "source": [
    "## Dataset bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "CxFKGhm9repF",
    "outputId": "cd6337f2-4ee3-4211-b12e-a412614ed524"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ymznNYrVaz_5",
    "outputId": "fb12dbde-5110-453a-a236-dc8d99885629"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DIR = 'drive/My Drive/Colab Notebooks/dataset/'\n",
    "\n",
    "x_train, y_train = [], []\n",
    "\n",
    "with open(DIR + 'train_mozilla.txt', 'r') as f:\n",
    "    for row in f:\n",
    "      cols = re.split('\\|', row)\n",
    "      title_a = np.array(re.split(',', cols[0])).astype(int)\n",
    "      title_b = np.array(re.split(',', cols[1])).astype(int)\n",
    "      desc_a = np.array(re.split(',', cols[2])).astype(int)\n",
    "      desc_b = np.array(re.split(',', cols[3])).astype(int)\n",
    "      x_train.append([title_a, title_b, desc_a, desc_b])\n",
    "      y_train.append(int(cols[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "f4DujdnW6bsO",
    "outputId": "b3fdb51f-a584-42e1-cd42-0985d5405103"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DIR = 'drive/My Drive/Colab Notebooks/dataset/'\n",
    "\n",
    "x_test, y_test = [], []\n",
    "\n",
    "with open(DIR + 'test_mozilla.txt', 'r') as f:\n",
    "    for row in f:\n",
    "      cols = re.split('\\|', row)\n",
    "      title_a = np.array(re.split(',', cols[0])).astype(int)\n",
    "      title_b = np.array(re.split(',', cols[1])).astype(int)\n",
    "      desc_a = np.array(re.split(',', cols[2])).astype(int)\n",
    "      desc_b = np.array(re.split(',', cols[3])).astype(int)\n",
    "      x_test.append([title_a, title_b, desc_a, desc_b])\n",
    "      y_test.append(int(cols[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEcakqEJ_cIX"
   },
   "outputs": [],
   "source": [
    "DIR = 'drive/My Drive/Colab Notebooks/dataset/'\n",
    "\n",
    "df_x_train = pd.read_csv(DIR + 'df_train.csv')\n",
    "df_x_test = pd.read_csv(DIR + 'df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "xQWhkZ0N1h3U",
    "outputId": "2d347f1e-2cee-419d-e169-b23e5548cb9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_a</th>\n",
       "      <th>title_b</th>\n",
       "      <th>description_a</th>\n",
       "      <th>description_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>winstripe theme incorrectly positions single tab</td>\n",
       "      <td>first tab content moving opening closing secon...</td>\n",
       "      <td>user agent mozilla 5 0 windows u windows nt 5 ...</td>\n",
       "      <td>user agent mozilla 5 0 windows u windows nt 5 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ctrl invoke prefered mailer</td>\n",
       "      <td>mailto link improperly launches outlook expres...</td>\n",
       "      <td>user agent mozilla 5 0 windows u windows nt 5 ...</td>\n",
       "      <td>user agent mozilla 5 0 windows u windows nt 5 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clicking icon opens new tab switches</td>\n",
       "      <td>implement revised new tab experience</td>\n",
       "      <td>clicking icon tab group opens new tab immediat...</td>\n",
       "      <td>https wiki mozilla org firefox projects tabcan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>windows installer creates directory startmenu ...</td>\n",
       "      <td>start menu folder created despite selecting do...</td>\n",
       "      <td>user agent mozilla 5 0 windows u windows nt 5 ...</td>\n",
       "      <td>user agent mozilla 5 0 x11 u linux i686 en us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>firefox doesnt load images size doesnt match d...</td>\n",
       "      <td>images appearing webpages</td>\n",
       "      <td>user agent mozilla 5 0 x11 u linux i686 fr rv ...</td>\n",
       "      <td>user agent mozilla 5 0 x11 u linux i686 en us ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_a  \\\n",
       "0   winstripe theme incorrectly positions single tab   \n",
       "1                        ctrl invoke prefered mailer   \n",
       "2               clicking icon opens new tab switches   \n",
       "3  windows installer creates directory startmenu ...   \n",
       "4  firefox doesnt load images size doesnt match d...   \n",
       "\n",
       "                                             title_b  \\\n",
       "0  first tab content moving opening closing secon...   \n",
       "1  mailto link improperly launches outlook expres...   \n",
       "2               implement revised new tab experience   \n",
       "3  start menu folder created despite selecting do...   \n",
       "4                          images appearing webpages   \n",
       "\n",
       "                                       description_a  \\\n",
       "0  user agent mozilla 5 0 windows u windows nt 5 ...   \n",
       "1  user agent mozilla 5 0 windows u windows nt 5 ...   \n",
       "2  clicking icon tab group opens new tab immediat...   \n",
       "3  user agent mozilla 5 0 windows u windows nt 5 ...   \n",
       "4  user agent mozilla 5 0 x11 u linux i686 fr rv ...   \n",
       "\n",
       "                                       description_b  \n",
       "0  user agent mozilla 5 0 windows u windows nt 5 ...  \n",
       "1  user agent mozilla 5 0 windows u windows nt 5 ...  \n",
       "2  https wiki mozilla org firefox projects tabcan...  \n",
       "3  user agent mozilla 5 0 x11 u linux i686 en us ...  \n",
       "4  user agent mozilla 5 0 x11 u linux i686 en us ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_train.head()\n",
    "#x_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFfSVkOWx8VL"
   },
   "source": [
    "### Dividir train e test (título e descrição)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvAjKlrpAvUf"
   },
   "outputs": [],
   "source": [
    "x_train_title_a = np.array([ row[0] for row in x_train])\n",
    "x_train_title_b = np.array([ row[1] for row in x_train])\n",
    "x_test_title_a = np.array([ row[0] for row in x_test])\n",
    "x_test_title_b = np.array([ row[1] for row in x_test])\n",
    "\n",
    "x_train_desc_a = np.array([ row[2] for row in x_train])\n",
    "x_train_desc_b = np.array([ row[3] for row in x_train])\n",
    "x_test_desc_a = np.array([ row[2] for row in x_test])\n",
    "x_test_desc_b = np.array([ row[3] for row in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WW3WOG9Pq2A0",
    "outputId": "4c1899ff-94f9-4a11-be4c-1be318c28f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 18s, sys: 614 ms, total: 2min 18s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "sentence_dict = {}\n",
    "\n",
    "def creating_dict(vec_a, vec_b, txt_a, txt_b):\n",
    "  for v1, v2, s1, s2 in zip(vec_a, vec_b, txt_a, txt_b):\n",
    "    #print(v1, v2)\n",
    "    name_1 = ','.join(v1.astype(str))\n",
    "    name_2 = ','.join(v2.astype(str))\n",
    "    sentence_dict[name_1] = s1\n",
    "    sentence_dict[name_2] = s2\n",
    "\n",
    "################# TITLE #############################\n",
    "creating_dict(x_train_title_a, x_train_title_b, df_x_train['title_a'].values, df_x_train['title_b'].values)\n",
    "creating_dict(x_test_title_a, x_test_title_b, df_x_test['title_a'].values, df_x_test['title_b'].values)\n",
    "\n",
    "################ DESCRIPTION #############################\n",
    "creating_dict(x_train_desc_a, x_train_desc_b, df_x_train['description_a'].values, df_x_train['description_b'].values)\n",
    "creating_dict(x_test_desc_a, x_test_desc_b, df_x_test['description_a'].values, df_x_test['description_b'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8RdOXdw8q6rN",
    "outputId": "06cac87a-eca6-49ff-8599-62d8c6ebcd10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374004"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PWUzI_nGjb4"
   },
   "source": [
    "### Reogarnizar grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "-3GPFRppx9A0",
    "outputId": "0a9383d7-8b85-4d6d-d13f-b11785aa0e9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "train groups: [49981, 248421]\n",
      "test groups: [12644, 61957]\n",
      "Description\n",
      "train groups: [49981, 248421]\n",
      "test groups: [12644, 61957]\n"
     ]
    }
   ],
   "source": [
    "# reorganize by groups\n",
    "train_groups = {}\n",
    "test_groups = {}\n",
    "\n",
    "train_groups['title_a'] = [x_train_title_a[np.where(y_train==i)[0]] for i in np.unique(y_train)] \n",
    "train_groups['title_b'] = [x_train_title_b[np.where(y_train==i)[0]] for i in np.unique(y_train)] \n",
    "train_groups['desc_a'] = [x_train_desc_a[np.where(y_train==i)[0]] for i in np.unique(y_train)] \n",
    "train_groups['desc_b'] = [x_train_desc_b[np.where(y_train==i)[0]] for i in np.unique(y_train)] \n",
    "\n",
    "test_groups['title_a'] = [x_test_title_a[np.where(y_test==i)[0]] for i in np.unique(y_test)]\n",
    "test_groups['title_b'] = [x_test_title_b[np.where(y_test==i)[0]] for i in np.unique(y_test)]\n",
    "test_groups['desc_a'] = [x_test_desc_a[np.where(y_test==i)[0]] for i in np.unique(y_test)]\n",
    "test_groups['desc_b'] = [x_test_desc_b[np.where(y_test==i)[0]] for i in np.unique(y_test)]\n",
    "\n",
    "print(\"Title\")\n",
    "print('train groups:', [x.shape[0] for x in train_groups['title_a']])\n",
    "print('test groups:', [x.shape[0] for x in test_groups['title_b']])\n",
    "print(\"Description\")\n",
    "print('train groups:', [x.shape[0] for x in train_groups['desc_a']])\n",
    "print('test groups:', [x.shape[0] for x in test_groups['desc_b']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zZYwRpxeyBsS"
   },
   "source": [
    "### Validando o treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XJQsThRXyDQ_",
    "outputId": "eae9cc61-3774-4d09-9085-c2893102f3f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49981, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_groups['title_a'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xOyTXxsnHp8z"
   },
   "outputs": [],
   "source": [
    "def display_bug(idx, x, y):\n",
    "  # idx = np.random.choice(range(len(x_train)))\n",
    "  print(\"Bugs are '{}''\".format('duplicated' if y[idx] == 1 else 'no duplicated' ))\n",
    "  TITLE_A = 0\n",
    "  TITLE_B = 1\n",
    "  DESC_A = 2\n",
    "  DESC_B = 3\n",
    "  key_t_a = ','.join(x[idx][TITLE_A].astype(str))\n",
    "  key_t_b = ','.join(x[idx][TITLE_B].astype(str))\n",
    "  key_d_a = ','.join(x[idx][DESC_A].astype(str))\n",
    "  key_d_b = ','.join(x[idx][DESC_B].astype(str))\n",
    "  print(\"Title A:\", sentence_dict[key_t_a])\n",
    "  print(\"Title B:\", sentence_dict[key_t_b])\n",
    "  print(\"Desciption A:\", sentence_dict[key_d_a])\n",
    "  print(\"Description B:\", sentence_dict[key_d_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "YDKD9p_hyE-b",
    "outputId": "8306ea58-0894-4e3d-d13c-6220e9ad59fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bugs are 'no duplicated''\n",
      "Title A: new firefox update causes browsing files crash firefox\n",
      "Title B: en us jar different among platforms\n",
      "Desciption A: user agent mozilla 4 0 compatible msie 7 0 windows nt 5 1 net clr 1 1 4322 net clr 2 0 50727 net clr 3 0 04506 30 net clr 3 0 04506 648 build identifier 2 0 0 14 want attach document e mail upload site using bowse function thus browse dialoge box opens whole firefox windowx freeze therefore force killing yesterday didnt problem firefox automatically updated new version regards reproducible always steps reproduce 1 press browse button 2 3\n",
      "Description B: user agent mozilla 5 0 x11 u linux i686 en us rv 1 5 gecko 20031007 firebird 0 7 build identifier mozilla 5 0 x11 u linux i686 en us rv 1 5 gecko 20031007 firebird 0 7 windows specific strings en us jar file bundled windows version firebird 0 7 least locale en us communicator platform pref platformprefoverlay dtd maybe others dont know mentioning default browser settings linux version missing means localization created using en us jar linux binaries error produced complaining missing strings going tools options general strings really en win jar reproducible always steps reproduce 1 start translating mozilla using jars bundled linux version 2 open firebird windows machine translated files loaded 3 go tools options general actual results tools options general window doesnt appear instead gives error xml parsing error undefined entity location chrome browser content pref pref navigator xul line numer 146 column 21 caption label defaultbrowsergroup label expected results general tab open normal workaround reloaded windows en us jar files mozillatranslator done translation based sync files might bugs lurking\n"
     ]
    }
   ],
   "source": [
    "# idx = np.random.choice(range(len(x_train)))\n",
    "idx = 12 # 1-9 duplicates, 12 no duplicate\n",
    "display_bug(idx, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teLp7WtIyHhN"
   },
   "source": [
    "### Validando o teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "umI44hZeyIEs",
    "outputId": "688efab0-14d2-4ef0-a68d-9645eaee9287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bugs are 'duplicated''\n",
      "Title A: restore session multiple tabs requiring passwords results multiple master pw dialogs\n",
      "Title B: master password dialog multiple times upon different tabs\n",
      "Desciption A: user agent mozilla 5 0 x11 u linux i686 en us rv 1 9 2 3 gecko 20100401 firefox 3 6 3 build identifier mozilla 5 0 x11 u linux i686 en us rv 1 9 2 3 gecko 20100401 firefox 3 6 3 one master pw dialog displayed restoring session one tab saved password form reproducible always steps reproduce create session n 1 tabs saved password form close browser reopen workaround fill n max n dialog close rest actual results n master password dialogs stacked sometimes order requires finding filling closing order expected results one master password dialog displayed restoring session multiple tabs saved password forms\n",
      "Description B: user agent mozilla 5 0 windows u windows nt 6 0 de rv 1 9 2 4 gecko 20100611 firefox 3 6 4 net clr 3 5 30729 build identifier mozilla 5 0 windows u windows nt 6 0 de rv 1 9 2 4 gecko 20100611 firefox 3 6 4 net clr 3 5 30729 master password dialog presents per tab already reported thread marked solved make another one reproducible always steps reproduce 1 start firefox multiple tabs login user password saved 2 3 actual results master password entered every tab expected results master password entered one time\n"
     ]
    }
   ],
   "source": [
    "# idx = np.randomvalidation_steps.choice(range(len(x_train)))\n",
    "idx = 1 # 1 duplicates, 0 no duplicate\n",
    "display_bug(idx, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 40\n",
    "MAX_SEQUENCE_LENGTH_D = 200\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0WZNngemNM8"
   },
   "source": [
    "## Geração de batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4evwDTTKe10b"
   },
   "source": [
    "#### Balanced 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34bmpH6n-bOu"
   },
   "outputs": [],
   "source": [
    "def shuffle_in_unison_scary(a, b, c):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(c)\n",
    "    \n",
    "def gen_random_batch(in_groups, batch_size = 128):\n",
    "    titles_a, titles_b, descs_a, descs_b, out_score = [], [], [], [], []\n",
    "    all_groups = list(range(2)) # duplicated and non-duplicated\n",
    "    keys = list(in_groups)\n",
    "    for group in all_groups:\n",
    "        \n",
    "        group_idx = [group for i in range(batch_size)]\n",
    "        \n",
    "        item_selected = [np.random.choice(range(in_groups[keys[0]][c_idx][0].shape[0])) for c_idx in group_idx]\n",
    "        \n",
    "        title_a = [in_groups['title_a'][c_idx][row] for c_idx, row in zip(group_idx, item_selected)]\n",
    "        title_b = [in_groups['title_b'][c_idx][row] for c_idx, row in zip(group_idx, item_selected)]\n",
    "        desc_a = [in_groups['desc_a'][c_idx][row] for c_idx, row in zip(group_idx, item_selected)]\n",
    "        desc_b = [in_groups['desc_b'][c_idx][row] for c_idx, row in zip(group_idx, item_selected)]\n",
    "        out_score += [group] * batch_size\n",
    "        \n",
    "        titles_a += title_a\n",
    "        titles_b += title_b\n",
    "        descs_a += desc_a\n",
    "        descs_b += desc_b\n",
    "        \n",
    "    # shuffle_in_unison_scary(sentence1, sentence2, out_score)\n",
    "        \n",
    "    return np.stack(titles_a,0), np.stack(titles_b,0), np.stack(descs_a,0), np.stack(descs_b,0), np.stack(out_score,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gB69immD44n6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# make a generator out of the data\n",
    "def siam_gen(in_groups, batch_size = 128):\n",
    "    while True:\n",
    "        t_a, t_b, d_a, d_b, sim = gen_random_batch(in_groups, batch_size//2)\n",
    "        yield { 'title_a' : t_a, 'title_b': t_b, 'desc_a' : d_a, 'desc_b' : d_b }, sim\n",
    "        \n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "valid_t_a, valid_t_b, valid_d_a, valid_d_b, valid_sim = gen_random_batch(test_groups, batch_size)\n",
    "train_gen = siam_gen(train_groups, batch_size=512)\n",
    "test_gen = ([valid_t_a, valid_t_b, valid_d_a, valid_d_b], valid_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-"
   },
   "outputs": [],
   "source": [
    "def get_neg_bug(invalid_bugs, bug_ids):\n",
    "  neg_bug = random.choice(bug_ids)\n",
    "  while neg_bug in invalid_bugs:\n",
    "    neg_bug = random.choice(bug_ids)\n",
    "  return neg_bug\n",
    "\n",
    "def read_batch_triplets(batch_triplets, data):\n",
    "  batch_input_bugs = []\n",
    "  batch_pos_bugs = []\n",
    "  batch_neg_bugs = []\n",
    "  for triplet in batch_triplets:\n",
    "    batch_input_bugs.append(triplet[0])\n",
    "    batch_pos_bugs.append(triplet[1])\n",
    "    batch_neg_bugs.append(triplet[2])\n",
    "  return read_batch_bugs(batch_input_bugs, data), \\\n",
    "         read_batch_bugs(batch_pos_bugs, data), \\\n",
    "         read_batch_bugs(batch_neg_bugs, data)\n",
    "\n",
    "def read_batch_bugs(batch_bugs, data, test=False):\n",
    "  desc_word = []\n",
    "  short_desc_word = []\n",
    "  info = []\n",
    "  for bug_id in batch_bugs:\n",
    "    bug = pickle.load(open(os.path.join(data, 'bugs', '{}.pkl'.format(bug_id)), 'rb'))\n",
    "    desc_word.append(bug['description_word'])\n",
    "    short_desc_word.append(bug['title_word'])\n",
    "    \n",
    "  desc_word = Variable(torch.from_numpy(data_padding(desc_word, 500)), volatile=test).cuda()\n",
    "  short_desc_word = Variable(torch.from_numpy(data_padding(short_desc_word, 100)), volatile=test).cuda()\n",
    "  batch_bugs = dict()\n",
    "  batch_bugs['desc'] = (desc_word)\n",
    "  batch_bugs['title'] = (short_desc_word)\n",
    "\n",
    "  return batch_bugs\n",
    "\n",
    "# data - path\n",
    "# batch_size - 128\n",
    "# n_neg - 1\n",
    "def batch_iterator(train_data, data, batch_size, n_neg):\n",
    "  random.shuffle(train_data)\n",
    "  bug_ids = read_bug_ids(data)\n",
    "  num_batches = int(len(train_data) / batch_size)\n",
    "  if len(data) % batch_size > 0:\n",
    "    num_batches += 1\n",
    "  # loop = tqdm(range(num_batches))\n",
    "  # loop.set_description('Training')\n",
    "  for i in range(num_batches):\n",
    "    batch_triplets = []\n",
    "    for j in range(batch_size):\n",
    "      offset = batch_size * i + j\n",
    "      if offset >= len(train_data):\n",
    "        break\n",
    "      for i in range(n_neg):\n",
    "        neg_bug = get_neg_bug(dup_sets[train_data[offset][0]], bug_ids)\n",
    "        batch_triplets.append([train_data[offset][0], train_data[offset][1], neg_bug])\n",
    "    yield loop, read_batch_triplets(batch_triplets, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uOOHpF2j6oY8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics\n",
    "\n",
    "def curve_roc_auc(model, x, y_valid):\n",
    "  y_hat = model.predict(x)\n",
    "  pct_auc = roc_auc_score(y_valid, y_hat) * 100\n",
    "  #print('ROC/AUC: {:0.2f}'.format(pct_auc))\n",
    "\n",
    "  fpr, tpr, _ = sklearn.metrics.roc_curve(y_valid, y_hat)\n",
    "  roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "  plt.figure()\n",
    "  lw = 2\n",
    "  plt.plot(fpr, tpr, color='darkorange',\n",
    "           lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "  plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.ylim([0.0, 1.05])\n",
    "  plt.xlabel('Taxa de Falsos Positivos')\n",
    "  plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "  plt.title('Receiver Operating Characteristic (ROC)')\n",
    "  plt.legend(loc=\"lower right\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6pnMQT0-Soml"
   },
   "outputs": [],
   "source": [
    "def display_batch(groups, nb):\n",
    "  t_a, t_b, d_a, d_b, v_sim = gen_random_batch(groups, nb)\n",
    "\n",
    "  for ta, tb, da, db, sim in zip(t_a, t_b, d_a, d_b, v_sim):\n",
    "    #print(ba.astype(str))\n",
    "    key_t_a = ','.join(ta.astype(str))\n",
    "    key_t_b = ','.join(tb.astype(str))\n",
    "    key_d_a = ','.join(da.astype(str))\n",
    "    key_d_b = ','.join(db.astype(str))\n",
    "    print(\"Title =\", sentence_dict[key_t_a])\n",
    "    print(\"Title =\", sentence_dict[key_t_b])\n",
    "    print(\"Description =\", sentence_dict[key_d_a])\n",
    "    print(\"Description =\", sentence_dict[key_d_b])\n",
    "    print(\"similar =\", str(sim))\n",
    "    print(\"########################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojKT88YudQxO"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1057
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "c690e93d-3a39-48c1-c482-9ca97eddac9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title = unable open preferences undeer options\n",
      "Title = downloaded updated file old version shown\n",
      "Description = user agent mozilla 4 0 compatible msie 6 0 windows 98 win 9x 4 90 tucows build identifier firefox 1 5 trying access preferences tools nothing appears screen except bottom shows ok cancel help reproducible always steps reproduce 1 firefox 2 tools 3 options 4 preferences actual results opening tools options ok go preferences nothing shows screen except bottom shows ok cancel help expected results nothing opened preferences\n",
      "Description = user agent mozilla 5 0 x11 u linux i686 pl pl rv 1 9 2 3 gecko 20100423 ubuntu 10 04 lucid firefox 3 6 3 build identifier mozilla 5 0 x11 u linux i686 pl pl rv 1 9 2 3 gecko 20100423 ubuntu 10 04 lucid firefox 3 6 3 download file updated old version disk name download manager changes name file try open new file using download manager old version shown happend pdf files reproducible always steps reproduce 1 donwload pdf file 2 change content file change name 3 download 4 open download manager newer version actual results old version file shown expected results new file opened\n",
      "similar = 0\n",
      "########################\n",
      "Title = cancelling bookmarklets popup window breaks url field\n",
      "Title = password shown plain text saved plain history\n",
      "Description = user agent mozilla 5 0 x11 u linux i686 en us rv 1 8 1 1 gecko 20061208 firefox 2 0 0 1 build identifier mozilla 5 0 x11 u linux i686 en us rv 1 8 1 1 gecko 20061208 firefox 2 0 0 1 bookmarklet used like one bugs url field pop window bookmark clicked popup cancelled void value returned breaks url entry field cant type tabs url fields continue work tab focus bookmarklet cancelled reproducible always steps reproduce 1 create bookmark javascript url 2 click bookmarklet window pop 3 cancel popup simplified url ok cancel makes difference 4 try typing new web address url field find cant get text cursor go field actual results dont seem able focus text field expected results url field continue behave bookmarklet clicked\n",
      "Description = user agent mozilla 5 0 windows u windows nt 5 1 en us rv 1 9 0 2 gecko 2008091620 firefox 3 0 2 build identifier firefox 3 0 0 please see http www fz juelich de jsc mail firefox info reproducible always steps reproduce 1 go https imapsrv fz juelich de 2 3 actual results pwd shown plain text pwd saved plain history certificate accepted expected results password encrypted pwd saved history certificate accepted could reproduce 3 0 1 3 0 2 portable\n",
      "similar = 0\n",
      "########################\n",
      "Title = mac firefox long delay connect time waking sleep\n",
      "Title = adobe reader cannot close return firefox browser page hang acrobat reader 6 0 0\n",
      "Description = user agent mozilla 5 0 macintosh u intel mac os x 10 5 6 en us applewebkit 525 18 1 khtml like gecko version 3 1 2 safari 525 20 1 build identifier mozilla 5 0 macintosh u intel mac os x 10 5 en us rv 1 9 1b2 gecko 20081201 firefox 3 1b2 putting computer sleep waking firefox takes abnormally long resume internet connection internet applications able access internet fine time shown time blank page loading www google com status bar application lock pinwheel simply connect system info firefox 3 1b2 os x 10 5 6 2 4 intel core 2 duo reproducible always steps reproduce 1 put computer sleep firefox running 2 wake 3 open new firefox window tab try browse actual results firefox delays abnormally long loading page www google com waking sleep page displays white page loading www google com status bar internet connection active able ping www google com safari able immediately start browsing close firefox reopen connection google establishes immediately wait minute firefox finally decides load page slowly expected results os establishes network connection firefox proceed load page within 0 10 currently firefox waits around 45 60 seconds extension installed web developer came following plugins default plugin 2 0 iphotophotocast 7 0 java embedding plugin 0 9 65 mrj plugin version 1 0 jep 0 0 6 5 quicktime plug 7 5 7 shockwave flash 9 0 151\n",
      "Description = user agent mozilla 5 0 windows u windows nt 5 1 en us rv 1 7 gecko 20040803 firefox 0 9 3 build identifier mozilla 5 0 windows u windows nt 5 1 en us rv 1 7 gecko 20040803 firefox 0 9 3 every time tried use back firefox exit adobe reader 6 firefox would lock program responding task manager xp pro problem occur web site documents ie6 reproducible always steps reproduce 1 went pricewaterhouse site 2 clicked info pdf format 3 reading document could get back firefox browser www pwcglobal com extweb pwcpublications nsf docid c2a82df2f68d262f802569a1004f6835 actual results screen went information blank leaving adobe header side rails place locked forefox header went blank expected results close adobe 6 show originating website firefox remember module believe error caused adobe software open link separate new firefox browser everything functions normally close firefox adobe reader 6 normally time spent reporting situation help software ability displace microsoft thank release firefox thunderbird even though issues thinderbird relate organisation fully exploring software perhaps lack experience causing issues like learning open adobe reader 6 new window\n",
      "similar = 0\n",
      "########################\n",
      "Title = firefox freezes trying add attachment e mail gmail\n",
      "Title = text middle column behind images right column\n",
      "Description = user agent mozilla 5 0 windows u windows nt 5 1 en us rv 1 9 0 8 gecko 2009032609 firefox 3 0 8 build identifier mozilla 5 0 windows u windows nt 5 1 en us rv 1 9 0 8 gecko 2009032609 firefox 3 0 8 try add attachment gmail using firefox 3 click add attachment browse button look attachment firefox freezes completely cant click anywhere force quit firefox reproducible always steps reproduce 1 visit gmail 2 compose e mail gmail 3 click add attachment 4 click browse find attachment file actual results firefox completely freezes becomes unresponsive expected results new window open allowing browse computers files find appropriate attachment\n",
      "Description = user agent mozilla 5 0 windows u windows nt 5 1 en us rv 1 4b gecko 20030504 mozilla firebird 0 6 build identifier mozilla 5 0 windows u windows nt 5 1 en us rv 1 4b gecko 20030504 mozilla firebird 0 6 middle column far right behind images right column pages site like http derstandard web everything ok reproducible always steps reproduce 1 visit site 2 3 actual results page rendered wrong expected results colums ok\n",
      "similar = 0\n",
      "########################\n",
      "Title = user know whether link cached prefetched\n",
      "Title = play midi file web site ie play midi\n",
      "Description = user agent mozilla 5 0 x11 u linux i686 en us rv 1 7 6 gecko 20050323 firefox 1 0 2 fedora 1 0 2 1 3 1 build identifier mozilla 5 0 x11 u linux i686 en us rv 1 7 6 gecko 20050323 firefox 1 0 2 fedora 1 0 2 1 3 1 currently seems user cannot easily find whether document referenced link browser cache example user visits page link page gets prefetched might useful indicate link prefetched changing color link way user would know page referred link cached words color change would allow distinguishing cached uncached links user would able adapt browsing behavior based information reproducible always steps reproduce\n",
      "Description = user agent mozilla 5 0 windows u windows nt 5 1 en us rv 1 7 12 gecko 20050915 firefox 1 0 7 build identifier mozilla 5 0 windows u windows nt 5 1 en us rv 1 7 12 gecko 20050915 firefox 1 0 7 play file ie play even china ie played file url reproducible always actual results self explanatory rdoes play midi files\n",
      "similar = 0\n",
      "########################\n",
      "Title = ask proxy id blank box type something search\n",
      "Title = proxy authentication required typing search string\n",
      "Description = user agent mozilla 5 0 x11 u linux i686 en us rv 1 9b1 gecko 2007110903 firefox 2 0 0 6 megaupload 1 0 build identifier mozilla 5 0 x11 u linux i686 en us rv 1 9b1 gecko 2007110903 firefox 2 0 0 6 megaupload 1 0 use proxy login required saved password whenever type something google search new window appear asking username password form filled empty think caused search suggestion username password appears press enter search reproducible always steps reproduce 1 use proxy requires login 2 make sure firefox saved id already 3 restart firefox 4 type something google search 5 new window appear asking username password empty form actual results username password boxes empty expected results username password boxes filled automatically\n",
      "Description = user agent mozilla 5 0 windows u windows nt 5 0 en us rv 1 8 1 1 gecko 20061204 firefox 2 0 0 1 build identifier mozilla 5 0 windows u windows nt 5 0 en us rv 1 8 1 1 gecko 20061204 firefox 2 0 0 1 steps 1 start new instance firefox 2 enter search string problem proxy authentication dialog comes user could click search button search string entered user name since user like watching keyboard reproducible always steps reproduce steps 1 start new instance firefox 2 enter search string problem proxy authentication dialog comes user could click search button search string entered user name since user like watching keyboard actual results problem proxy authentication dialog comes user could click search button search string entered user name since user like watching keyboard expected results proxy authentication come user written search query\n",
      "similar = 1\n",
      "########################\n",
      "Title = address bar drop box closes click button show previous entered addresses\n",
      "Title = initial click location bar drops rolls history\n",
      "Description = user agent mozilla 5 0 windows u windows nt 5 1 en us rv 1 7 10 gecko 20050716 firefox 1 0 6 build identifier mozilla 5 0 windows u windows nt 5 1 en us rv 1 7 10 gecko 20050716 firefox 1 0 6 drop box closes first run exe example open new window works fine exit browser click button itll close reproducible always steps reproduce 1 exit instances firefox 2 open firefox 3 click v button make drop box appear actual results drop box closes crash suppose forcing click first time ive never got close first time expected results window remained open bug occured themes using doesnt matter homepage although google extensions currently use mouse gestures 1 0 1 live http headers html validator adblock finally google pagerank\n",
      "Description = using firefox 20041006 trunk first time open firefox click location bar dropdown onmousedown opens dropdown list onmouseup list rolls back essentially eats first click\n",
      "similar = 1\n",
      "########################\n",
      "Title = bookmarks disappearing firefox auto update 1 5 0 11 version\n",
      "Title = bookmarks prior installing latest version mozilla firefox gone\n",
      "Description = user agent mozilla 5 0 windows u windows nt 5 1 en us rv 1 8 0 11 gecko 20070312 firefox 1 5 0 11 build identifier mozilla 5 0 windows u windows nt 5 1 en us rv 1 8 0 11 gecko 20070312 firefox 1 5 0 11 firefox version non 2 0 version got automatically updated shocked find bookmarks disappeared find please consider issue serious suggest solution available would appreciate prompt feedback regards vinod present version mozilla 5 0 windows u windows nt 5 1 en us rv 1 8 0 11 gecko 20070312 firefox 1 5 0 11 reproducible always steps reproduce 1 asked autoupdate 2 updation restart browser bookmarks went missing 3 able add new bookmarks old list mysteriously hurtingly disappeared actual results bookmarks expected results old bookmarks\n",
      "Description = user agent mozilla 5 0 windows u win98 en us rv 1 8 1 5 gecko 20070713 firefox 2 0 0 5 build identifier mozilla 5 0 windows u win98 en us rv 1 8 1 5 gecko 20070713 firefox 2 0 0 5 upon attempting check stored bookmark found bookmarks gone except two marked installing latest update mozilla 7 22 07 attempted run goback undo problem computer reboots update enforces installation reproducible always steps reproduce 1 click bookmarks 2 observe everything except bookmarks toolbar folder two recent bookmarks gone 3 actual results bookmarks except two added update gone expected results bookmarks dating back several years available reference dont lot savy regarding type information computer windows 98 4 10 1998 amd k7 processor 639 mb ram\n",
      "similar = 1\n",
      "########################\n",
      "Title = tabs open instead new windows set preferences\n",
      "Title = firefox didnt open new window respective java command\n",
      "Description = user agent mozilla 5 0 x11 u linux i686 en us rv 1 8 1 1 gecko 20061208 firefox 2 0 0 1 build identifier mozilla 5 0 x11 u linux i686 en us rv 1 8 1 1 gecko 20061208 firefox 2 0 0 1 sometimes firefox opens new tab instead new window selected preferences tabs look preferences open new window still set new tab click new window preference opens new windows instead tabs also wmv files still get prompt program plugin use even though click use program file type next time option wasnt problem windows windows sucks use linux small price pay small issues like reproducible sometimes steps reproduce 1 2 3 doesnt happen frequently cant make happen seems random\n",
      "Description = user agent mozilla 4 0 compatible msie 6 0 windows nt 5 1 sv1 build identifier http www mozilla com en us firefox 2 0 windows german instead new window view info page firefox shows page existing parent window reproducible always steps reproduce 1 put http www ibs de ms 2 go bottom 3 click link java 4 popup click first button teatimer java 1 5 5 teatimer click button 6 repeat steps within internetexplorer find expected result 7 want repeat opera also find result firefox ie actual results instead new window like browsers react firefox open info page within existing small popup window expected results java opens new browser window view info page within new window\n",
      "similar = 1\n",
      "########################\n",
      "Title = cant close flash object tab using ctrl w\n",
      "Title = failure load new tab window displying pdf page main window\n",
      "Description = user agent mozilla 5 0 windows u windows nt 5 1 de rv 1 9 1 gecko 20090624 firefox 3 5 build identifier mozilla 5 0 windows u windows nt 5 1 de rv 1 9 1 gecko 20090624 firefox 3 5 open flash object new tab directly browser cant close using ctrl w still close tabs using ctrl w reproducible always steps reproduce 1 open application x shockwave flash object new tab 2 try close using ctrl w actual results tab doesnt close expected results close tab im using newest flash player 10 0 22 87\n",
      "Description = user agent mozilla 5 0 windows u windows nt 5 1 en gb rv 1 8b5 gecko 20051006 firefox 1 4 1 build identifier mozilla 5 0 windows u windows nt 5 1 en gb rv 1 8b5 gecko 20051006 firefox 1 4 1 hotkeys ctrl ctrl n work tabs open displaying pdf page main window via adobe plugin open new tabs another way eg middle click bookmark hotkeys work even focus pdf tab using relevant extensions reproducible always steps reproduce 1 get adobe plugin 2 follow link pdf page make sure displays browser window separately 3 make sure tabs open tab bar present visible actual results described summary expected results open new tab window using relevant extensions extensions currently used ieview forecastfox adblock gmail notifier\n",
      "similar = 1\n",
      "########################\n"
     ]
    }
   ],
   "source": [
    "display_batch(train_groups, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2S7PiEM7WxGN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def word_index_count(df):\n",
    "  rows = []\n",
    "\n",
    "  for d in [df['title_a'], df['title_b'], df['description_a'], df['description_b']]:\n",
    "    added = [{'text' : r} for r in d.values]\n",
    "    rows += added\n",
    "  \n",
    "  df = pd.DataFrame(data=rows, columns=['text'])['text']\n",
    "  \n",
    "  # Fill missing description or title\n",
    "  df.fillna('', inplace=True)\n",
    "  \n",
    "  tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "  tokenizer.fit_on_texts(df)\n",
    "  word_index = tokenizer.word_index\n",
    "  print('Found %s unique tokens.' % len(word_index))\n",
    "  \n",
    "  return word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "DN-4jZ_o154I",
    "outputId": "b746097c-49db-4bd0-ea57-0ae7cbce045e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 298402 entries, 0 to 298401\n",
      "Data columns (total 4 columns):\n",
      "title_a          298373 non-null object\n",
      "title_b          298378 non-null object\n",
      "description_a    297934 non-null object\n",
      "description_b    297963 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "c25adc1c-daac-43ae-ce44-b3ba4b3e11e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1917494 word vectors in Glove 42B 300d.\n",
      "Found 211132 unique tokens.\n",
      "CPU times: user 4min 7s, sys: 5.87 s, total: 4min 13s\n",
      "Wall time: 10min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "GLOVE_DIR = \"drive/My Drive/Colab Notebooks/dataset/\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.42B.300d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "word_index = word_index_count(df_x_train)\n",
    "\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLxWmHaU8y7O"
   },
   "source": [
    "### Plot ROC/AUC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srKKbyM2ffZm"
   },
   "source": [
    "### Plot validation accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULjGk-eCfT8B"
   },
   "outputs": [],
   "source": [
    "def validation_accuracy_loss(history):\n",
    "  acc=history.history['acc']\n",
    "  val_acc=history.history['val_acc']\n",
    "  loss=history.history['loss']\n",
    "  val_loss=history.history['val_loss']\n",
    "\n",
    "  plt.plot(acc, label='acc')\n",
    "  plt.plot(val_acc, label='val_acc')\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  plt.plot(loss, label='acc')\n",
    "  plt.plot(val_loss, label='val_acc')\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zQaDKGoHB_s"
   },
   "outputs": [],
   "source": [
    "def show_model_output(valid_a, valid_b, valid_sim, model, nb_examples = 3):\n",
    "    #pv_a, pv_b, pv_sim = gen_random_batch(test_groups, nb_examples)\n",
    "    pred_sim = model.predict([valid_a, valid_b])\n",
    "#     pred_sim = [1,1,1,1,1,1]\n",
    "    for b_a, b_b, sim, pred in zip(valid_a, valid_b, valid_sim, pred_sim):\n",
    "        key_a = ','.join(b_a.astype(str))\n",
    "        key_b = ','.join(b_b.astype(str))\n",
    "        print(sentence_dict[key_a])\n",
    "        print(sentence_dict[key_b])\n",
    "        print(\"similar=\" + str(sim))\n",
    "        print(\"prediction=\" + str(pred[0]))\n",
    "        print(\"########################\")\n",
    "    return valid_a, valid_b, valid_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI074wU4Y13y"
   },
   "source": [
    "### CNN with filter 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "h6YJU9GtFTyq",
    "outputId": "2e271a01-8a72-4eb9-aeb1-a04a9b6fc8ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Feature_BugInput (InputLayer)   (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 300)     63339900    Feature_BugInput[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 198, 32)      28832       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 196, 32)      48032       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 66, 32)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 65, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 131, 32)      0           max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 129, 64)      6208        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64)           0           global_max_pooling1d_1[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 63,422,972\n",
      "Trainable params: 83,072\n",
      "Non-trainable params: 63,339,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import GlobalMaxPooling1D \n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "def cnn_model(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "\n",
    "  embedding_layer = Embedding(num_words,\n",
    "                              embedding_dim,\n",
    "                              weights=[embeddings],\n",
    "                              input_length=max_sequence_length,\n",
    "                              trainable=trainable)\n",
    "\n",
    "  sequence_input = Input(shape=(max_sequence_length,), name='Feature_BugInput')\n",
    "  embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "  # Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "  convs = []\n",
    "  filter_sizes = [3,5]\n",
    "\n",
    "  for filter_size in filter_sizes:\n",
    "      l_conv = Conv1D(filters=32, kernel_size=filter_size, activation='relu')(embedded_sequences)\n",
    "      l_pool = MaxPooling1D(pool_size=3)(l_conv)\n",
    "      convs.append(l_pool)\n",
    "\n",
    "  # l_merge = Merge(mode='concat', concat_axis=1)(convs)\n",
    "\n",
    "  l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "  # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "  conv = Conv1D(filters=64, kernel_size=3, activation='relu')(l_merge)\n",
    "  pool = GlobalMaxPooling1D()(conv) # pool_size=3\n",
    "  # Original Yoon Kim model\n",
    "  #x = Flatten()(pool)\n",
    "  #x = Dropout(0.5)(x)\n",
    "  layer = Activation('relu')(pool)\n",
    "\n",
    "  cnn_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureCNNGenerationModel') # inputs=visible\n",
    "  cnn_feature_model.summary()\n",
    "  \n",
    "  return cnn_feature_model\n",
    "\n",
    "\n",
    "cnn_feature_model = cnn_model(embeddings=embedding_matrix, \n",
    "                              num_words=len(word_index) + 1, \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr6ObTXiaALH"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "vC7MQXEsaCeG",
    "outputId": "9fb2ce6d-1b53-4488-b86d-f522782dc03d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Feature_BugInput (InputLayer (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 40, 300)           63339900  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                85248     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 63,425,148\n",
      "Trainable params: 85,248\n",
      "Non-trainable params: 63,339,900\n",
      "_________________________________________________________________\n",
      "CPU times: user 1.18 s, sys: 56 ms, total: 1.23 s\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
    "\n",
    "def lstm_model(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "  number_lstm_units = 32\n",
    "  rate_drop_lstm = 0.75\n",
    "  recurrent_dropout = 0.25\n",
    "\n",
    "  embedding_layer = Embedding(num_words,\n",
    "                          embedding_dim,\n",
    "                          weights=[embeddings],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=trainable)\n",
    "\n",
    "  sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "  embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "   # Creating LSTM Encoder\n",
    "  lstm_layer = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
    "\n",
    "  x = lstm_layer(embedded_sequences)\n",
    "\n",
    "  layer = Activation('relu')(x)\n",
    "\n",
    "  lstm_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureLstmGenerationModel') # inputs=visible\n",
    "  lstm_feature_model.summary()\n",
    "  \n",
    "  return lstm_feature_model\n",
    "\n",
    "lstm_feature_model = lstm_model(embeddings=embedding_matrix, \n",
    "                              num_words=len(word_index) + 1, \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dGx3qyWhmLMF"
   },
   "outputs": [],
   "source": [
    "class CustomLayer(keras.layers.Layer):\n",
    "  def call(self, inputs):\n",
    "    bug_a = inputs[0]\n",
    "    bug_b = inputs[1]\n",
    "    loss = self.distance(bug_a, bug_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "2eac4848-e121-425b-9e9a-55e7a89af835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "desc_a (InputLayer)             (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_a (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_b (InputLayer)             (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_b (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 64)           63422972    desc_a[0][0]                     \n",
      "                                                                 desc_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 64)           63425148    title_a[0][0]                    \n",
      "                                                                 title_b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_a (Concatenate)  (None, 128)          0           FeatureCNNGenerationModel[3][0]  \n",
      "                                                                 FeatureLstmGenerationModel[3][0] \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_b (Concatenate)  (None, 128)          0           FeatureCNNGenerationModel[4][0]  \n",
      "                                                                 FeatureLstmGenerationModel[4][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128)          0           merge_features_a[0][0]           \n",
      "                                                                 merge_features_b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 126,848,249\n",
      "Trainable params: 168,449\n",
      "Non-trainable params: 126,679,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import concatenate, Add\n",
    "\n",
    "def siamese_model(max_sequence_length_t, max_sequence_length_d):\n",
    "  bug_t_a_in = Input(shape = (max_sequence_length_t, ), name = 'title_a')\n",
    "  bug_t_b_in = Input(shape = (max_sequence_length_t, ), name = 'title_b')\n",
    "  bug_d_a_in = Input(shape = (max_sequence_length_d, ), name = 'desc_a')\n",
    "  bug_d_b_in = Input(shape = (max_sequence_length_d, ), name = 'desc_b')\n",
    "\n",
    "  bug_d_a_feat_cnn = cnn_feature_model(bug_d_a_in)\n",
    "  bug_d_b_feat_cnn = cnn_feature_model(bug_d_b_in)\n",
    "\n",
    "  bug_t_a_feat_lstm = lstm_feature_model(bug_t_a_in)\n",
    "  bug_t_b_feat_lstm = lstm_feature_model(bug_t_b_in)\n",
    "\n",
    "  combined_features_a = concatenate([bug_t_a_feat_lstm, bug_d_a_feat_cnn], name = 'merge_features_a')\n",
    "  combined_features_b = concatenate([bug_t_b_feat_lstm, bug_d_b_feat_cnn], name = 'merge_features_b')\n",
    "\n",
    "  #combined = concatenate([combined_features_a, combined_features_b])\n",
    "  combined = Add()([combined_features_a, combined_features_b])\n",
    "  # combined_features = Dense(100, activation = 'linear')(combined)\n",
    "  # combined_features = BatchNormalization()(combined_features)\n",
    "  # combined_features = Activation('relu')(combined_features)\n",
    "  # combined_features = Dense(4, activation = 'linear')(combined_features)\n",
    "  # combined_features = BatchNormalization()(combined_features)\n",
    "  # combined_features = Activation('relu')(combined_features)\n",
    "  combined_features = Dense(1, activation = 'sigmoid')(combined)\n",
    "  similarity_model = Model(inputs = [bug_t_a_in, bug_t_b_in, bug_d_a_in, bug_d_b_in], outputs = [combined_features], name = 'Similarity_Model')\n",
    "  # setup the optimization process\n",
    "  similarity_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy']) # 'binary_crossentropy'\n",
    "  similarity_model.summary()\n",
    "  \n",
    "  return similarity_model\n",
    "\n",
    "similarity_model = siamese_model(MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yOK2zcnxd5PL"
   },
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "q8AOthGid3lS",
    "outputId": "d8b7f953-64ef-4f25-e5bc-d418fb4ff82d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "256/256 [==============================] - 144s 561ms/step - loss: 0.1264 - acc: 0.9711 - val_loss: 0.7697 - val_acc: 0.6016\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 137s 536ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.8615 - val_acc: 0.6133\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 134s 522ms/step - loss: 7.8137e-04 - acc: 1.0000 - val_loss: 0.9226 - val_acc: 0.6035\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 116s 452ms/step - loss: 3.6637e-04 - acc: 1.0000 - val_loss: 0.9710 - val_acc: 0.6055\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 116s 452ms/step - loss: 2.0794e-04 - acc: 1.0000 - val_loss: 1.0063 - val_acc: 0.6055\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 115s 451ms/step - loss: 1.3171e-04 - acc: 1.0000 - val_loss: 1.0376 - val_acc: 0.5977\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 116s 451ms/step - loss: 8.9976e-05 - acc: 1.0000 - val_loss: 1.0655 - val_acc: 0.5938\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 116s 451ms/step - loss: 6.4199e-05 - acc: 1.0000 - val_loss: 1.0930 - val_acc: 0.5859\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 116s 451ms/step - loss: 4.7425e-05 - acc: 1.0000 - val_loss: 1.1148 - val_acc: 0.5938\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 116s 451ms/step - loss: 3.6128e-05 - acc: 1.0000 - val_loss: 1.1366 - val_acc: 0.5938\n",
      "CPU times: user 24min 31s, sys: 3min 18s, total: 27min 50s\n",
      "Wall time: 20min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# early = EarlyStopping(monitor='loss', patience = 5, min_delta=0, verbose=0)\n",
    "\n",
    "h = similarity_model.fit_generator(train_gen, \n",
    "                               steps_per_epoch = 256,\n",
    "                               validation_data=test_gen,\n",
    "                                             epochs = 10,\n",
    "                                             verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1j41YFByes7o"
   },
   "outputs": [],
   "source": [
    "pred_t_a, pred_t_b, pred_t_sim = gen_random_batch(test_groups, 10)\n",
    "validation_accuracy_loss(h)\n",
    "curve_roc_auc(similarity_model, x=[pred_t_a, pred_t_b], y_valid=pred_t_sim)\n",
    "_ = show_model_output(pred_t_a, pred_t_b, pred_t_sim, similarity_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0_0-sH2QCNn"
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfuIqJ9xQEr1"
   },
   "outputs": [],
   "source": [
    "# Configuration to experiments CNN dilated\n",
    "embeddings = embedding_matrix\n",
    "num_words = len(word_index)+1\n",
    "embedding_dim = EMBEDDING_DIM\n",
    "max_sequence_length = MAX_SEQUENCE_LENGTH\n",
    "trainable = False\n",
    "drop_rate = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWjjB2qzQGIT"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                        embedding_dim,\n",
    "                        weights=[embeddings],\n",
    "                        input_length=max_sequence_length,\n",
    "                        trainable=trainable)\n",
    "\n",
    "sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "embedded = embedding_layer(sequence_input)\n",
    "\n",
    "\n",
    "x = Dense(1, activation='linear')(embedded)\n",
    "#x = Reshape((EMBEDDING_DIM, 1))(embedded)\n",
    "#x = Dense(EMBEDDING_DIM)(x)\n",
    "# x = Dropout(drop_rate)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# layer = Activation('relu')(x)\n",
    "#x = Dense(2)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "layer = Flatten()(x)\n",
    "#layer = Activation('relu')(x)\n",
    "#yhat = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureGenerationModel') # inputs=visible\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbGKiwi_QpGK"
   },
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "bug_a_in = Input(shape = (max_sequence_length, ), name = 'title1')\n",
    "bug_b_in = Input(shape = (max_sequence_length, ), name = 'title2')\n",
    "bug_a_feat = feature_model(bug_a_in)\n",
    "bug_b_feat = feature_model(bug_b_in)\n",
    "combined_features = concatenate([bug_a_feat, bug_b_feat], name = 'merge_features')\n",
    "combined_features = Dense(max_sequence_length, activation = 'linear')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Dropout(drop_rate)(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(max_sequence_length//2, activation = 'linear')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Dropout(drop_rate)(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(1, activation = 'sigmoid')(combined_features)\n",
    "similarity_model = Model(inputs = [bug_a_in, bug_b_in], outputs = [combined_features], name = 'Similarity_Model')\n",
    "# setup the optimization process\n",
    "#adam = keras.optimizers.Adam(lr=0.05, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)\n",
    "similarity_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVGIkuDcQxhk"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# early = EarlyStopping(monitor='loss', patience = 5, min_delta=0, verbose=0)\n",
    "\n",
    "h = similarity_model.fit_generator(train_gen, \n",
    "                               steps_per_epoch = 512,\n",
    "                               validation_data=test_gen,\n",
    "                                             epochs = 10,\n",
    "                                             verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7uxhCdSVTow"
   },
   "outputs": [],
   "source": [
    "pred_t_a, pred_t_b, pred_t_sim = gen_random_batch(test_groups, 10)\n",
    "validation_accuracy_loss(h)\n",
    "curve_roc_auc(similarity_model, x=[pred_t_a, pred_t_b], y_valid=pred_t_sim)\n",
    "_ = show_model_output(pred_t_a, pred_t_b, pred_t_sim, similarity_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHEk025Knr05"
   },
   "source": [
    "## CNN dilatada\n",
    "\n",
    "Arquitetura de https://github.com/kristpapadopoulos/seriesnet/blob/master/seriesnet-Krist-Papadopoulos-v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GprVV9XDgvxU"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mgWgfso9sO_"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# estratégia de treino com parada antecipada consiste em parar o treino\n",
    "# quando nenhuma melhoria no erro de validação (val_loss) é observada após\n",
    "# \"patience\" épocas\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10, verbose=1, mode='auto')\n",
    "callback_list = [earlystop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9bE88y-ChdWe"
   },
   "source": [
    "### Dilataçã*o* 2 a 32 (7 camadas com kernel de 2 e 3 cada)\n",
    "\n",
    "Seriesnet Krist Papadopoulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phcwwMqpnP5M"
   },
   "outputs": [],
   "source": [
    "def DC_CNN_Block(nb_filter, filter_length, dilation, l2_layer_reg):\n",
    "    def block(block_input):        \n",
    "        residual =    block_input\n",
    "        \n",
    "        layer_out =   Conv1D(filters=nb_filter, kernel_size=filter_length, \n",
    "                      dilation_rate=dilation, \n",
    "                      activation='linear', padding='causal', use_bias=False,\n",
    "                      kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.05, \n",
    "                      seed=42), kernel_regularizer=l2(l2_layer_reg))(block_input)                    \n",
    "        selu_out =    Activation('selu')(layer_out)\n",
    "        \n",
    "        skip_out =    Conv1D(1,1, activation='linear', use_bias=False, \n",
    "                      kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.05, \n",
    "                      seed=42), kernel_regularizer=l2(l2_layer_reg))(selu_out)\n",
    "        \n",
    "        c1x1_out =    Conv1D(1,1, activation='linear', use_bias=False, \n",
    "                      kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.05, \n",
    "                      seed=42), kernel_regularizer=l2(l2_layer_reg))(selu_out)\n",
    "                      \n",
    "        block_out =   Add()([residual, c1x1_out])\n",
    "        \n",
    "        return block_out, skip_out\n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1YBUMzU8I6-V"
   },
   "source": [
    "### Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFphujVHg2Pa"
   },
   "outputs": [],
   "source": [
    "# Configuration to experiments CNN dilated\n",
    "embeddings = embedding_matrix\n",
    "num_words = len(word_index)+1\n",
    "embedding_dim = EMBEDDING_DIM\n",
    "max_sequence_length = MAX_SEQUENCE_LENGTH\n",
    "trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJdXOQOsnx77"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                        embedding_dim,\n",
    "                        weights=[embeddings],\n",
    "                        input_length=max_sequence_length,\n",
    "                        trainable=trainable)\n",
    "\n",
    "sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "units = 32\n",
    "\n",
    "l1a, l1b = DC_CNN_Block(units,2,1,0.01)(embedded_sequences)    \n",
    "l2a, l2b = DC_CNN_Block(units,2,2,0.01)(l1a) \n",
    "l3a, l3b = DC_CNN_Block(units,2,4,0.01)(l2a)\n",
    "l4a, l4b = DC_CNN_Block(units,2,8,0.01)(l3a)\n",
    "l5a, l5b = DC_CNN_Block(units,2,16,0.01)(l4a)\n",
    "l6a, l6b = DC_CNN_Block(units,2,32,0.01)(l5a)\n",
    "l7a, l7b = DC_CNN_Block(units,2,64,0.01)(l6a)\n",
    "\n",
    "l8 =   Add()([l1b, l2b, l3b, l4b, l5b, l6b, l7b])\n",
    "\n",
    "l9 =   Activation('relu')(l8)\n",
    "\n",
    "x =  Conv1D(1,1, activation='linear', use_bias=False, \n",
    "       kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.05, seed=42),\n",
    "       kernel_regularizer=l2(0.001))(l9)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(MAX_SEQUENCE_LENGTH)(x)\n",
    "#x = Dropout(0.45)(x)\n",
    "x = BatchNormalization()(x)\n",
    "layer = Activation('relu')(x)\n",
    "#x = Dense(2)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#layer = Activation('relu')(x)\n",
    "#yhat = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureGenerationModel') # inputs=visible\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phY6r7uoutXk"
   },
   "source": [
    "### Modelo siamês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zziMAlu3usiU"
   },
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "bug_a_in = Input(shape = (max_sequence_length, ), name = 'title1')\n",
    "bug_b_in = Input(shape = (max_sequence_length, ), name = 'title2')\n",
    "bug_a_feat = feature_model(bug_a_in)\n",
    "bug_b_feat = feature_model(bug_b_in)\n",
    "combined_features = concatenate([bug_a_feat, bug_b_feat], name = 'merge_features')\n",
    "combined_features = Dense(MAX_SEQUENCE_LENGTH, activation = 'linear')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(MAX_SEQUENCE_LENGTH//2, activation = 'linear')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Activation('relu')(combined_features)\n",
    "combined_features = Dense(1, activation = 'sigmoid')(combined_features)\n",
    "similarity_model = Model(inputs = [bug_a_in, bug_b_in], outputs = [combined_features], name = 'Similarity_Model')\n",
    "# setup the optimization process\n",
    "#adam = keras.optimizers.Adam(lr=0.05, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)\n",
    "similarity_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xDIhIB19VwnV"
   },
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "au-kwI8AjFYM"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# early = EarlyStopping(monitor='loss', patience = 5, min_delta=0, verbose=0)\n",
    "\n",
    "h = similarity_model.fit_generator(train_gen, \n",
    "                               steps_per_epoch = 512,\n",
    "                               validation_data=test_gen,\n",
    "                                             epochs = 10,\n",
    "                                             verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4zDexKwuu4w"
   },
   "outputs": [],
   "source": [
    "pred_t_a, pred_t_b, pred_t_sim = gen_random_batch(test_groups, 10)\n",
    "validation_accuracy_loss(h)\n",
    "curve_roc_auc(similarity_model, x=[pred_t_a, pred_t_b], y_valid=pred_t_sim)\n",
    "_ = show_model_output(pred_t_a, pred_t_b, pred_t_sim, similarity_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jiAvnm6t1YLJ"
   },
   "source": [
    "## ARCII-for-Matching-Natural-Language-Sentences\n",
    "\n",
    "https://github.com/ddddwy/ARCII-for-Matching-Natural-Language-Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEnqxQn11hEv"
   },
   "outputs": [],
   "source": [
    "embed_size=EMBEDDING_DIM\n",
    "text1_maxlen=MAX_SEQUENCE_LENGTH\n",
    "text2_maxlen=MAX_SEQUENCE_LENGTH\n",
    "filters_1d=text2_maxlen\n",
    "num_words = len(word_index)+1\n",
    "kernel_size_1d=3\n",
    "num_conv2d_layers=2\n",
    "filters_2d=[MAX_SEQUENCE_LENGTH,MAX_SEQUENCE_LENGTH//2]\n",
    "kernel_size_2d=[[3,3], [3,3]]\n",
    "mpool_size_2d=[[2,2], [2,2]]\n",
    "dropout_rate=.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_55ODmiD3Cmj"
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import concatenate\n",
    "from keras import backend as K\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "query=Input(shape=(text1_maxlen,), name = 'title1')\n",
    "doc=Input(shape=(text2_maxlen,), name = 'title2')\n",
    "\n",
    "embedding = Embedding(num_words, embed_size, weights=[embedding_matrix], trainable=True)\n",
    "q_embed = embedding(query)\n",
    "d_embed = embedding(doc)\n",
    "\n",
    "layer1_input=concatenate([q_embed, d_embed])\n",
    "\n",
    "layer1_conv=Conv1D(filters=filters_1d, kernel_size=kernel_size_1d, padding='same')(layer1_input)\n",
    "layer1_activation=Activation('relu')(layer1_conv)\n",
    "layer1_reshaped=Reshape((text1_maxlen, text2_maxlen, -1))(layer1_activation)\n",
    "z=MaxPooling2D(pool_size=(2,2))(layer1_reshaped)\n",
    "residual = Flatten()(z)\n",
    "\n",
    "for i in range(num_conv2d_layers):\n",
    "    z=Conv2D(filters=filters_2d[i], kernel_size=kernel_size_2d[i], padding='same')(z)\n",
    "    z=Activation('relu')(z)\n",
    "    z=MaxPooling2D(pool_size=(mpool_size_2d[i][0], mpool_size_2d[i][1]))(z)\n",
    "\n",
    "# pool1_flat=Flatten()(z)\n",
    "# residual = Reshape((1, K.int_shape(residual)[1]))(residual)\n",
    "# pool1_flat = Reshape((K.int_shape(pool1_flat)[1], 1))(pool1_flat)\n",
    "# residual=Add()([residual, pool1_flat]) # residual\n",
    "# residual=Flatten()(residual)\n",
    "# shape_after_flatten = K.int_shape(residual)\n",
    "\n",
    "pool1_flat=Flatten()(z)\n",
    "\n",
    "pool1_flat_drop=Dropout(rate=dropout_rate)(pool1_flat)\n",
    "pool1_norm=BatchNormalization()(pool1_flat_drop)\n",
    "mlp1=Dense(MAX_SEQUENCE_LENGTH)(pool1_norm)\n",
    "mlp1=Activation('relu')(mlp1)\n",
    "out=Dense(1, activation='sigmoid')(mlp1)\n",
    "\n",
    "model=Model(inputs=[query, doc], outputs=out)\n",
    "#adam = keras.optimizers.Adam(lr=0.1, beta_1=0.7, beta_2=0.7, epsilon=None, decay=0.1, amsgrad=False)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xHMIGyIUner"
   },
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gC5aYcJAKWgR"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "h = model.fit_generator(train_gen, \n",
    "                               steps_per_epoch = 1000,\n",
    "                               validation_data=test_gen,\n",
    "                                             epochs = 10,\n",
    "                                             verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cj0CP1n7KZrR"
   },
   "outputs": [],
   "source": [
    "pred_t_a, pred_t_b, pred_t_sim = gen_random_batch(test_groups, 10)\n",
    "validation_accuracy_loss(h)\n",
    "curve_roc_auc(model, x=[pred_t_a, pred_t_b], y_valid=pred_t_sim)\n",
    "_ = show_model_output(pred_t_a, pred_t_b, pred_t_sim, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLQ_IlRORHXk"
   },
   "source": [
    "## Bi-LSTM siamese\n",
    "\n",
    "https://github.com/amansrivastava17/lstm-siamese-text-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlmUZHn5OeXP"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "number_lstm_units = 2\n",
    "rate_drop_lstm = 0\n",
    "recurrent_dropout = 0\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                        embedding_dim,\n",
    "                        weights=[embeddings],\n",
    "                        input_length=max_sequence_length,\n",
    "                        trainable=trainable)\n",
    "\n",
    "sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    " # Creating LSTM Encoder\n",
    "lstm_layer = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
    "\n",
    "x = lstm_layer(embedded_sequences)\n",
    "\n",
    "layer = Activation('tanh')(x)\n",
    "\n",
    "feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureGenerationModel') # inputs=visible\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJbuHnHDQJGy"
   },
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "number_dense_units = 32\n",
    "rate_drop_dense = 0.2\n",
    "\n",
    "bug_a_in = Input(shape = (max_sequence_length, ), name = 'title1')\n",
    "bug_b_in = Input(shape = (max_sequence_length, ), name = 'title2')\n",
    "bug_a_feat = feature_model(bug_a_in)\n",
    "bug_b_feat = feature_model(bug_b_in)\n",
    "combined_features = concatenate([bug_a_feat, bug_b_feat], name = 'merge_features')\n",
    "merged = BatchNormalization()(combined_features)\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "merged = Dense(number_dense_units, activation='relu')(merged)\n",
    "merged = Dense(1, activation = 'sigmoid')(merged)\n",
    "similarity_model = Model(inputs = [bug_a_in, bug_b_in], outputs = [merged], name = 'Similarity_Model')\n",
    "# setup the optimization process\n",
    "similarity_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kY_hQdwWRcV"
   },
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ij5aswg0Qe-g"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# early = EarlyStopping(monitor='loss', patience = 5, min_delta=0, verbose=0)\n",
    "\n",
    "h = similarity_model.fit_generator(train_gen, \n",
    "                               steps_per_epoch = 512,\n",
    "                               validation_data=test_gen,\n",
    "                                             epochs = 10,\n",
    "                                             verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Er40dlhIRaWO"
   },
   "outputs": [],
   "source": [
    "pred_t_a, pred_t_b, pred_t_sim = gen_random_batch(test_groups, 10)\n",
    "validation_accuracy_loss(h)\n",
    "curve_roc_auc(similarity_model, x=[pred_t_a, pred_t_b], y_valid=pred_t_sim)\n",
    "_ = show_model_output(pred_t_a, pred_t_b, pred_t_sim, similarity_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1OoRgAphiIY"
   },
   "source": [
    "## Filtros de 3, 4, 5\n",
    "\n",
    "https://richliao.github.io/supervised/classification/2016/11/26/textclassifier-convolutional/\n",
    "\n",
    "Yoon Kim model (https://arxiv.org/abs/1408.5882)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAFUPGcBhUsO"
   },
   "outputs": [],
   "source": [
    "embeddings = embedding_matrix\n",
    "num_words = len(word_index) + 1\n",
    "embedding_dim = EMBEDDING_DIM\n",
    "max_sequence_length = MAX_SEQUENCE_LENGTH\n",
    "trainable = False\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            weights=[embeddings],\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=trainable)\n",
    "\n",
    "sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "convs = []\n",
    "filter_sizes = [3,4,5]\n",
    "\n",
    "for filter_size in filter_sizes:\n",
    "    l_conv = Conv1D(filters=128, kernel_size=filter_size, activation='relu')(embedded_sequences)\n",
    "    l_pool = MaxPooling1D(pool_size=3)(l_conv)\n",
    "    convs.append(l_pool)\n",
    "\n",
    "# l_merge = Merge(mode='concat', concat_axis=1)(convs)\n",
    "\n",
    "l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "# add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "conv = Conv1D(filters=128, kernel_size=3, activation='relu')(embedded_sequences)\n",
    "pool = MaxPooling1D(pool_size=3)(conv)\n",
    "\n",
    "# Original Yoon Kim model\n",
    "x = Dropout(0.5)(pool)\n",
    "   \n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2, activation='relu')(x)\n",
    "# Finally, we feed the output into a Sigmoid layer.\n",
    "# The reason why sigmoid is used is because we are trying to achieve a binary classification(1,0) \n",
    "# for each of the 6 labels, and the sigmoid function will squash the output between the bounds of 0 and 1.\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0h0hOMEbOrBh"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMF3MVzITpsD"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "early = EarlyStopping(monitor='loss', patience = 5, min_delta=0, verbose=0)\n",
    "\n",
    "h = model.fit(X, y, epochs=15, verbose=1, validation_split=0.30, batch_size=256, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zTCmphdN8ux"
   },
   "outputs": [],
   "source": [
    "plt.plot(h.history['loss'], label='train')\n",
    "plt.plot(h.history['val_loss'], label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0kmmf_mC0KgT"
   },
   "source": [
    "## Dilatação com 32, 64 e 128 neurônios com 3 camadas de dilatação 1, 2, 3 e kernel 3\n",
    "\n",
    "https://www.kaggle.com/kmader/text-classification-with-atrous-convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TYI2T9s0PKL"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Configuration to CNN dilated\n",
    "embeddings = embedding_matrix\n",
    "num_words = len(word_index)+1\n",
    "embedding_dim = EMBEDDING_DIM\n",
    "max_sequence_length = MAX_SEQUENCE_LENGTH\n",
    "trainable = True\n",
    "\n",
    "max_dilation_rate = 3\n",
    "        \n",
    "embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=trainable)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "x = Dropout(0.25)(embedded_sequences)\n",
    "x = Conv1D(2 * 128, \n",
    "               kernel_size = 3)(x)\n",
    "prefilt_x = Conv1D(128, \n",
    "               kernel_size = 3)(x)\n",
    "out_conv = []\n",
    "# dilation rate lets us use ngrams and skip grams to process \n",
    "for dilation_rate in range(max_dilation_rate):\n",
    "    x = prefilt_x\n",
    "    for i in range(3):\n",
    "        x = Conv1D(32*2**(i), \n",
    "                   kernel_size = 3, \n",
    "                   dilation_rate = dilation_rate+1)(x)    \n",
    "    out_conv += [Dropout(0.8)(GlobalMaxPool1D()(x))] # \n",
    "# x = concatenate(out_conv, axis = -1)  \n",
    "x = Concatenate(axis=-1)(out_conv)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(2, activation=\"sigmoid\")(x)\n",
    "\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k9LhrGJS8T1b"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NI-9KX718HrG"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "early = EarlyStopping(monitor='loss', patience = 5, min_delta=0, verbose=0)\n",
    "\n",
    "h = model.fit(X, y, epochs=15, verbose=1, validation_split=0.30, batch_size=256, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYV6aiTN8Mgs"
   },
   "outputs": [],
   "source": [
    "plt.plot(h.history['loss'], label='train')\n",
    "plt.plot(h.history['val_loss'], label='val')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "McKLrJNQeSQt",
    "f0_0-sH2QCNn",
    "XHEk025Knr05",
    "jiAvnm6t1YLJ",
    "eLQ_IlRORHXk",
    "-1OoRgAphiIY",
    "0kmmf_mC0KgT"
   ],
   "name": "Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
