{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Propose BERT siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import keras\n",
    "# from tensorflow.python import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the use of GPUs\n",
    "# https://datascience.stackexchange.com/questions/23895/multi-gpu-in-keras\n",
    "# https://keras.io/getting-started/faq/#how-can-i-run-a-keras-model-on-multiple-gpus\n",
    "# https://stackoverflow.com/questions/56316451/how-to-use-specific-gpus-in-keras-for-multi-gpu-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 20\n",
    "MAX_SEQUENCE_LENGTH_D = 20 # 80\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'openoffice'\n",
    "METHOD = 'propose_bert_{}'.format(epochs)\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Path embeddings\n",
    "EMBED_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_feature@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_feature_@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c988001e3d0346b28896da862011cab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=57667), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ea09be06e24db98ec7a3d44247e731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14567), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72234"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "# !unzip -o uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "model_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_vocabulary\n",
    "\n",
    "token_dict = load_vocabulary(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 30522'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(token_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc76cbbe7fd44b5ba9bd47e16a6bf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=72234), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ff9c806b224540b06fedafeb818713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 5.17 s, sys: 701 ms, total: 5.87 s\n",
      "Wall time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83cea43240404d26a084e11d241ec6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58572), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n",
      "CPU times: user 19.9 s, sys: 10.3 ms, total: 19.9 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a random bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': '4\\n',\n",
       " 'bug_status': '1\\n',\n",
       " 'component': '37\\n',\n",
       " 'creation_ts': '2005-05-26 15:16:00 +0000',\n",
       " 'delta_ts': '2013-08-07 15:00:58 +0000',\n",
       " 'description': '[CLS] hi ian , under tools / macro / run macro , the extended tip is still in english . kind regards - sophie [SEP]',\n",
       " 'description_bert': '[CLS] hi ian , under tools / macro / run macro , the extended tip is still in english . kind regards - sophie [SEP]',\n",
       " 'description_word': array([  101,  7632,  4775,  1010,  2104,  5906,  1013, 26632,  1013,\n",
       "         2448, 26632,  1010,  1996,  3668,  5955,  2003,  2145,  1999,\n",
       "         2394,  1012]),\n",
       " 'description_word_bert': [101,\n",
       "  7632,\n",
       "  4775,\n",
       "  1010,\n",
       "  2104,\n",
       "  5906,\n",
       "  1013,\n",
       "  26632,\n",
       "  1013,\n",
       "  2448,\n",
       "  26632,\n",
       "  1010,\n",
       "  1996,\n",
       "  3668,\n",
       "  5955,\n",
       "  2003,\n",
       "  2145,\n",
       "  1999,\n",
       "  2394,\n",
       "  1012,\n",
       "  2785,\n",
       "  12362,\n",
       "  1011,\n",
       "  8234,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'dup_id': '[]',\n",
       " 'issue_id': 49917,\n",
       " 'priority': '3\\n',\n",
       " 'product': '40\\n',\n",
       " 'resolution': 'FIXED',\n",
       " 'textual_word': array([  101, 10424,  1010,  2139,  5449,  4394,  2005,  3668, 10247,\n",
       "         1997,  2448, 26632,   102,     0,     0,     0,     0,     0,\n",
       "            0,     0,   101,  7632,  4775,  1010,  2104,  5906,  1013,\n",
       "        26632,  1013,  2448, 26632,  1010,  1996,  3668,  5955,  2003,\n",
       "         2145,  1999,  2394,  1012]),\n",
       " 'title': '[CLS] fr , de translation missing for extended tips of run macro [SEP]',\n",
       " 'title_bert': '[CLS] fr , de translation missing for extended tips of run macro [SEP]',\n",
       " 'title_word': array([  101, 10424,  1010,  2139,  5449,  4394,  2005,  3668, 10247,\n",
       "         1997,  2448, 26632,   102,     0,     0,     0,     0,     0,\n",
       "            0,     0]),\n",
       " 'title_word_bert': [101,\n",
       "  10424,\n",
       "  1010,\n",
       "  2139,\n",
       "  5449,\n",
       "  4394,\n",
       "  2005,\n",
       "  3668,\n",
       "  10247,\n",
       "  1997,\n",
       "  2448,\n",
       "  26632,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'version': '375\\n'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 11043)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indexed all train'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_idx = bug_train_ids[0]\n",
    "vector = baseline.bug_set[bug_idx]['textual_word']\n",
    "annoy_train = AnnoyIndex(vector.shape[0])\n",
    "for bug_id in bug_train_ids:\n",
    "    annoy_train.add_item(bug_id, baseline.bug_set[bug_id]['textual_word'])\n",
    "annoy_train.build(10) # 10 trees\n",
    "\"Indexed all train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.9 ms, sys: 158 µs, total: 35.1 ms\n",
      "Wall time: 34.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, \\\n",
    "                            valid_master_sample, valid_master_neg, valid_sim = experiment.batch_iterator_bert(None, baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train,\n",
    "                                                                                          bug_train_ids,\n",
    "                                                                                          batch_size_test, 1, \n",
    "                                                                                              issues_by_buckets, INCLUDE_MASTER=True)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title']['token'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description']['token'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 20), (128, 20), (128, 729), (128,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title']['token'].shape, valid_input_sample['description']['token'].shape, \\\n",
    "    valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5, batch_iterator, issues_by_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Propose\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomUniform, RandomNormal, Ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "https://github.com/CyberZHG/keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import compile_model, get_model\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "def bert_model(MAX_SEQUENCE_LENGTH, name):\n",
    "    layer_num = 8\n",
    "#     model = load_trained_model_from_checkpoint(\n",
    "#             config_path,\n",
    "#             model_path,\n",
    "#             training=True,\n",
    "#             trainable=True,\n",
    "#             seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#     )\n",
    "    model = load_trained_model_from_checkpoint(\n",
    "        config_path,\n",
    "        model_path,\n",
    "        training=False,\n",
    "        use_adapter=True,\n",
    "        seq_len=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=['Encoder-{}-MultiHeadSelfAttention-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-MultiHeadSelfAttention-Norm'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Norm'.format(i + 1) for i in range(layer_num)],\n",
    "    )\n",
    "#     model = get_model(\n",
    "#         token_num=len(token_dict),\n",
    "#         head_num=10,\n",
    "#         transformer_num=layer_num,\n",
    "#         embed_dim=100,\n",
    "#         feed_forward_dim=100,\n",
    "#         seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#         pos_num=MAX_SEQUENCE_LENGTH,\n",
    "#         dropout_rate=0.05,\n",
    "#     )\n",
    "    compile_model(model)\n",
    "    inputs = model.inputs[:2]\n",
    "    outputs = model.get_layer('Encoder-{}-FeedForward-Norm'.format(layer_num)).output\n",
    "    #outputs = model.get_layer('Extract').output\n",
    "    outputs = GlobalAveragePooling1D()(outputs)\n",
    "#     outputs = Dense(300, activation='tanh')(outputs)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='FeatureBERTGenerationModel{}'.format(name))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    #layer = GRU(100, activation='tanh')(layer)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "'''\n",
    "    Some loss ideas\n",
    "    hinge loss Kullback-Leibler\n",
    "    https://stackoverflow.com/questions/53581298/custom-combined-hinge-kb-divergence-loss-function-in-siamese-net-fails-to-genera\n",
    "'''\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    distance = K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "    # Normalize https://stats.stackexchange.com/questions/53068/euclidean-distance-score-and-similarity\n",
    "    distance = K.constant(1) / (K.constant(1) + distance)\n",
    "    return K.mean(distance, keepdims=False)\n",
    "    #return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "# https://jdhao.github.io/2017/03/13/some_loss_and_explanations/\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.mean(K.maximum(0.0, pos - neg + margin))\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.mean(K.maximum(0.0, margin - pos + neg), keepdims=False)\n",
    "\n",
    "# https://www.kaggle.com/c/quora-question-pairs/discussion/33631\n",
    "# https://www.researchgate.net/figure/Illustration-of-triplet-loss-contrastive-loss-for-negative-samples-and-binomial_fig2_322060548\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    margin = 1\n",
    "    return K.mean(pos * K.square(neg) +\n",
    "                  (1 - pos) * K.square(K.maximum(margin - neg, 0)))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, Average, Maximum, Subtract, Average, AveragePooling1D, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "    \n",
    "    # Title\n",
    "    bug_t_token = Input(shape = (sequence_length_t, ), name = 'title_token_{}'.format(name))\n",
    "    bug_t_segment = Input(shape = (sequence_length_t, ), name = 'title_segment_{}'.format(name))\n",
    "    # Description\n",
    "    bug_d_token = Input(shape = (sequence_length_d, ), name = 'desc_token_{}'.format(name))\n",
    "    bug_d_segment = Input(shape = (sequence_length_d, ), name = 'desc_segment_{}'.format(name))\n",
    "    # Categorical\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model([bug_t_token, bug_t_segment])\n",
    "    bug_d_feat = desc_feature_model([bug_d_token, bug_d_segment])\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t_token, bug_t_segment, bug_d_token, bug_d_segment, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Average\n",
    "from keras_radam import RAdam\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, \n",
    "                             master_anchor, master_negative, master_positive, \n",
    "                         NUMBER_OF_INSTANCES, BATCH_SIZE, EPOCHS, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input, \n",
    "                                 master_anchor.input, master_positive.input, master_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    master_anchor = master_anchor.output\n",
    "    master_negative = master_negative.output\n",
    "    master_positive = master_positive.output\n",
    "    \n",
    "    # Distance bugs\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "    \n",
    "    # Distance masters anchor\n",
    "    master_anchor_positive_d = Lambda(cosine_distance, name='pos_master_cosine_distance', output_shape=[1])([encoded_anchor, master_positive])\n",
    "    master_anchor_negative_d = Lambda(cosine_distance, name='neg_master_cosine_distance', output_shape=[1])([encoded_anchor, master_negative])\n",
    "    \n",
    "    # Distance master positive\n",
    "    master_pos_positive_d = Lambda(cosine_distance, name='pos_master_pos_cosine_distance', output_shape=[1])([encoded_positive, master_positive])\n",
    "    master_pos_negative_d = Lambda(cosine_distance, name='neg_master_pos_cosine_distance', output_shape=[1])([encoded_positive, master_negative])\n",
    "    \n",
    "    # Distance master negative\n",
    "    master_neg_positive_d = Lambda(cosine_distance, name='pos_master_neg_cosine_distance', output_shape=[1])([encoded_negative, master_negative])\n",
    "    master_neg_negative_d = Lambda(cosine_distance, name='neg_master_neg_cosine_distance', output_shape=[1])([encoded_negative, master_positive])\n",
    "    \n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output_bug = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances-bug',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    output_master = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances-master-anchor',\n",
    "        output_shape=(2, 1)\n",
    "    )([master_anchor_positive_d, master_anchor_negative_d])\n",
    "    \n",
    "    output_master_pos = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances-master-pos',\n",
    "        output_shape=(2, 1)\n",
    "    )([master_pos_positive_d, master_pos_negative_d])\n",
    "    \n",
    "    output_master_neg = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances-master-neg',\n",
    "        output_shape=(2, 1)\n",
    "    )([master_neg_positive_d, master_neg_negative_d])\n",
    "    \n",
    "    output = Average()([output_bug, output_master, output_master_pos, output_master_neg])\n",
    "    \n",
    "    #output_avg_master = Average()([output_master, output_master_pos, output_master_neg])\n",
    "    #output = Average()([output_bug, output_avg_master])\n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = [output], name = 'Similarity_Model')\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer='adam', loss=custom_margin_loss, \n",
    "                                 metrics=[pos_distance, neg_distance])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size  64\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_pos (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_pos (InputLayer)  (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_pos (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_pos (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_neg (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_neg (InputLayer)  (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_neg (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_neg (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_master_pos (InputLayer)    (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_master_pos (InputLa (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_master_pos (Input (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_master_pos (InputLay (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_master_pos (InputL (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_master_neg (InputLayer)    (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_master_neg (InputLa (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_master_neg (Input (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_master_neg (InputLay (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_master_neg (InputL (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          219000      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "                                                                 info_master_pos[0][0]            \n",
      "                                                                 info_master_neg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 768)          80346736    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "                                                                 title_token_pos[0][0]            \n",
      "                                                                 title_segment_pos[0][0]          \n",
      "                                                                 title_token_neg[0][0]            \n",
      "                                                                 title_segment_neg[0][0]          \n",
      "                                                                 title_token_master_pos[0][0]     \n",
      "                                                                 title_segment_master_pos[0][0]   \n",
      "                                                                 title_token_master_neg[0][0]     \n",
      "                                                                 title_segment_master_neg[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 768)          80346736    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "                                                                 desc_token_pos[0][0]             \n",
      "                                                                 desc_segment_pos[0][0]           \n",
      "                                                                 desc_token_neg[0][0]             \n",
      "                                                                 desc_segment_neg[0][0]           \n",
      "                                                                 desc_token_master_pos[0][0]      \n",
      "                                                                 desc_segment_master_pos[0][0]    \n",
      "                                                                 desc_token_master_neg[0][0]      \n",
      "                                                                 desc_segment_master_neg[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1836)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 1836)         0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[2\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 1836)         0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[3\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_master_pos (Conc (None, 1836)         0           FeatureMlpGenerationModel[5][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[5\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_master_neg (Conc (None, 1836)         0           FeatureMlpGenerationModel[6][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[6\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "pos_master_cosine_distance (Lam (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_master_pos[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "neg_master_cosine_distance (Lam (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_master_neg[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_master_pos_cosine_distance  (None, 1)            0           merge_features_pos[0][0]         \n",
      "                                                                 merge_features_master_pos[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "neg_master_pos_cosine_distance  (None, 1)            0           merge_features_pos[0][0]         \n",
      "                                                                 merge_features_master_neg[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_master_neg_cosine_distance  (None, 1)            0           merge_features_neg[0][0]         \n",
      "                                                                 merge_features_master_neg[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "neg_master_neg_cosine_distance  (None, 1)            0           merge_features_neg[0][0]         \n",
      "                                                                 merge_features_master_pos[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances-bug (Lambda)    (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances-master-anchor ( (None, 2, 1)         0           pos_master_cosine_distance[0][0] \n",
      "                                                                 neg_master_cosine_distance[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances-master-pos (Lam (None, 2, 1)         0           pos_master_pos_cosine_distance[0]\n",
      "                                                                 neg_master_pos_cosine_distance[0]\n",
      "__________________________________________________________________________________________________\n",
      "stack-distances-master-neg (Lam (None, 2, 1)         0           pos_master_neg_cosine_distance[0]\n",
      "                                                                 neg_master_neg_cosine_distance[0]\n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 2, 1)         0           stack-distances-bug[0][0]        \n",
      "                                                                 stack-distances-master-anchor[0][\n",
      "                                                                 stack-distances-master-pos[0][0] \n",
      "                                                                 stack-distances-master-neg[0][0] \n",
      "==================================================================================================\n",
      "Total params: 160,912,472\n",
      "Trainable params: 440,296\n",
      "Non-trainable params: 160,472,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 1.00, pos_cosine: 0.90, neg_cosine: 0.89\n",
      "Epoch: 2 Loss: 1.00, pos_cosine: 0.89, neg_cosine: 0.89\n",
      "Epoch: 3 Loss: 1.00, pos_cosine: 0.89, neg_cosine: 0.89\n",
      "Epoch: 4 Loss: 1.00, pos_cosine: 0.89, neg_cosine: 0.89\n",
      "Epoch: 5 Loss: 1.00, pos_cosine: 0.89, neg_cosine: 0.89\n",
      "Epoch: 6 Loss: 1.00, pos_cosine: 0.88, neg_cosine: 0.89\n",
      "Epoch: 7 Loss: 1.00, pos_cosine: 0.88, neg_cosine: 0.88\n",
      "Epoch: 8 Loss: 1.00, pos_cosine: 0.88, neg_cosine: 0.88\n",
      "Epoch: 9 Loss: 1.00, pos_cosine: 0.88, neg_cosine: 0.88\n",
      "Epoch: 10 Loss: 1.00, pos_cosine: 0.88, neg_cosine: 0.88\n",
      "Epoch: 11 Loss: 1.00, pos_cosine: 0.88, neg_cosine: 0.88\n",
      "Epoch: 12 Loss: 1.00, pos_cosine: 0.88, neg_cosine: 0.87\n",
      "Epoch: 13 Loss: 1.00, pos_cosine: 0.88, neg_cosine: 0.87\n",
      "Epoch: 14 Loss: 1.00, pos_cosine: 0.88, neg_cosine: 0.88\n",
      "Epoch: 15 Loss: 1.00, pos_cosine: 0.88, neg_cosine: 0.87\n",
      "Epoch: 16 Loss: 1.00, pos_cosine: 0.87, neg_cosine: 0.87\n",
      "Epoch: 17 Loss: 0.99, pos_cosine: 0.87, neg_cosine: 0.86\n",
      "Epoch: 18 Loss: 1.00, pos_cosine: 0.87, neg_cosine: 0.87\n",
      "Epoch: 19 Loss: 0.99, pos_cosine: 0.87, neg_cosine: 0.86\n",
      "Epoch: 20 Loss: 0.99, pos_cosine: 0.86, neg_cosine: 0.85\n",
      "Epoch: 21 Loss: 1.00, pos_cosine: 0.85, neg_cosine: 0.85\n",
      "Epoch: 22 Loss: 1.00, pos_cosine: 0.84, neg_cosine: 0.84\n",
      "Epoch: 23 Loss: 0.99, pos_cosine: 0.84, neg_cosine: 0.83\n",
      "Epoch: 24 Loss: 0.99, pos_cosine: 0.84, neg_cosine: 0.82\n",
      "Epoch: 25 Loss: 0.99, pos_cosine: 0.83, neg_cosine: 0.83\n",
      "Epoch: 26 Loss: 0.99, pos_cosine: 0.82, neg_cosine: 0.81\n",
      "Epoch: 27 Loss: 1.00, pos_cosine: 0.81, neg_cosine: 0.80\n",
      "Epoch: 28 Loss: 0.99, pos_cosine: 0.80, neg_cosine: 0.80\n",
      "Epoch: 29 Loss: 0.99, pos_cosine: 0.79, neg_cosine: 0.78\n",
      "Epoch: 30 Loss: 0.99, pos_cosine: 0.78, neg_cosine: 0.77\n",
      "Epoch: 31 Loss: 0.98, pos_cosine: 0.79, neg_cosine: 0.77\n",
      "Epoch: 32 Loss: 0.99, pos_cosine: 0.77, neg_cosine: 0.76\n",
      "Epoch: 33 Loss: 0.99, pos_cosine: 0.76, neg_cosine: 0.75\n",
      "Epoch: 34 Loss: 0.98, pos_cosine: 0.76, neg_cosine: 0.74\n",
      "Epoch: 35 Loss: 0.98, pos_cosine: 0.75, neg_cosine: 0.73\n",
      "Epoch: 36 Loss: 0.97, pos_cosine: 0.75, neg_cosine: 0.73\n",
      "Epoch: 37 Loss: 0.99, pos_cosine: 0.73, neg_cosine: 0.72\n",
      "Epoch: 38 Loss: 0.99, pos_cosine: 0.72, neg_cosine: 0.71\n",
      "Epoch: 39 Loss: 0.98, pos_cosine: 0.72, neg_cosine: 0.70\n",
      "Epoch: 40 Loss: 0.98, pos_cosine: 0.71, neg_cosine: 0.69\n",
      "Epoch: 41 Loss: 0.99, pos_cosine: 0.71, neg_cosine: 0.69\n",
      "Epoch: 42 Loss: 0.98, pos_cosine: 0.71, neg_cosine: 0.68\n",
      "Epoch: 43 Loss: 0.97, pos_cosine: 0.71, neg_cosine: 0.68\n",
      "Epoch: 44 Loss: 0.98, pos_cosine: 0.70, neg_cosine: 0.67\n",
      "Epoch: 45 Loss: 0.99, pos_cosine: 0.70, neg_cosine: 0.69\n",
      "Epoch: 46 Loss: 0.97, pos_cosine: 0.69, neg_cosine: 0.66\n",
      "Epoch: 47 Loss: 1.00, pos_cosine: 0.67, neg_cosine: 0.67\n",
      "Epoch: 48 Loss: 0.97, pos_cosine: 0.70, neg_cosine: 0.66\n",
      "Epoch: 49 Loss: 0.96, pos_cosine: 0.69, neg_cosine: 0.65\n",
      "Epoch: 50 Loss: 0.98, pos_cosine: 0.67, neg_cosine: 0.65\n",
      "Epoch: 51 Loss: 0.98, pos_cosine: 0.67, neg_cosine: 0.65\n",
      "Epoch: 52 Loss: 0.98, pos_cosine: 0.67, neg_cosine: 0.65\n",
      "Epoch: 53 Loss: 0.97, pos_cosine: 0.69, neg_cosine: 0.66\n",
      "Epoch: 54 Loss: 0.98, pos_cosine: 0.66, neg_cosine: 0.65\n",
      "Epoch: 55 Loss: 0.97, pos_cosine: 0.67, neg_cosine: 0.64\n",
      "Epoch: 56 Loss: 0.98, pos_cosine: 0.67, neg_cosine: 0.65\n",
      "Epoch: 57 Loss: 0.97, pos_cosine: 0.67, neg_cosine: 0.64\n",
      "Epoch: 58 Loss: 0.96, pos_cosine: 0.69, neg_cosine: 0.65\n",
      "Epoch: 59 Loss: 0.98, pos_cosine: 0.66, neg_cosine: 0.64\n",
      "Epoch: 60 Loss: 0.97, pos_cosine: 0.66, neg_cosine: 0.63\n",
      "Epoch: 61 Loss: 0.98, pos_cosine: 0.65, neg_cosine: 0.63\n",
      "Epoch: 62 Loss: 0.96, pos_cosine: 0.67, neg_cosine: 0.64\n",
      "Epoch: 63 Loss: 0.96, pos_cosine: 0.68, neg_cosine: 0.63\n",
      "Epoch: 64 Loss: 0.97, pos_cosine: 0.68, neg_cosine: 0.65\n",
      "Epoch: 65 Loss: 0.97, pos_cosine: 0.66, neg_cosine: 0.63\n",
      "Epoch: 66 Loss: 0.97, pos_cosine: 0.66, neg_cosine: 0.63\n",
      "Epoch: 67 Loss: 0.95, pos_cosine: 0.67, neg_cosine: 0.62\n",
      "Epoch: 68 Loss: 0.97, pos_cosine: 0.65, neg_cosine: 0.62\n",
      "Epoch: 69 Loss: 0.97, pos_cosine: 0.66, neg_cosine: 0.63\n",
      "Epoch: 70 Loss: 0.95, pos_cosine: 0.68, neg_cosine: 0.63\n",
      "Epoch: 71 Loss: 0.96, pos_cosine: 0.67, neg_cosine: 0.63\n",
      "Epoch: 72 Loss: 0.96, pos_cosine: 0.67, neg_cosine: 0.63\n",
      "Epoch: 73 Loss: 0.98, pos_cosine: 0.65, neg_cosine: 0.64\n",
      "Epoch: 74 Loss: 0.96, pos_cosine: 0.68, neg_cosine: 0.64\n",
      "Epoch: 75 Loss: 0.96, pos_cosine: 0.68, neg_cosine: 0.64\n",
      "Epoch: 76 Loss: 0.97, pos_cosine: 0.66, neg_cosine: 0.63\n",
      "Epoch: 77 Loss: 0.96, pos_cosine: 0.67, neg_cosine: 0.63\n",
      "Epoch: 78 Loss: 0.97, pos_cosine: 0.66, neg_cosine: 0.63\n",
      "Epoch: 79 Loss: 0.96, pos_cosine: 0.66, neg_cosine: 0.63\n",
      "Epoch: 80 Loss: 0.96, pos_cosine: 0.67, neg_cosine: 0.63\n",
      "Epoch: 81 Loss: 0.95, pos_cosine: 0.66, neg_cosine: 0.61\n",
      "Epoch: 82 Loss: 0.96, pos_cosine: 0.66, neg_cosine: 0.61\n",
      "Epoch: 83 Loss: 0.97, pos_cosine: 0.66, neg_cosine: 0.63\n",
      "Epoch: 84 Loss: 0.96, pos_cosine: 0.67, neg_cosine: 0.63\n",
      "Epoch: 85 Loss: 0.96, pos_cosine: 0.66, neg_cosine: 0.62\n",
      "Epoch: 86 Loss: 0.96, pos_cosine: 0.66, neg_cosine: 0.62\n",
      "Epoch: 87 Loss: 0.95, pos_cosine: 0.68, neg_cosine: 0.63\n",
      "Epoch: 88 Loss: 0.96, pos_cosine: 0.68, neg_cosine: 0.64\n",
      "Epoch: 89 Loss: 0.97, pos_cosine: 0.66, neg_cosine: 0.63\n",
      "Epoch: 90 Loss: 0.96, pos_cosine: 0.67, neg_cosine: 0.63\n",
      "Epoch: 91 Loss: 0.96, pos_cosine: 0.68, neg_cosine: 0.64\n",
      "Epoch: 92 Loss: 0.97, pos_cosine: 0.67, neg_cosine: 0.64\n",
      "Epoch: 93 Loss: 0.95, pos_cosine: 0.69, neg_cosine: 0.65\n",
      "Epoch: 94 Loss: 0.93, pos_cosine: 0.69, neg_cosine: 0.63\n",
      "Epoch: 95 Loss: 0.96, pos_cosine: 0.68, neg_cosine: 0.63\n",
      "Epoch: 96 Loss: 0.97, pos_cosine: 0.66, neg_cosine: 0.63\n",
      "Epoch: 97 Loss: 0.96, pos_cosine: 0.68, neg_cosine: 0.64\n",
      "Epoch: 98 Loss: 0.95, pos_cosine: 0.68, neg_cosine: 0.62\n",
      "Epoch: 99 Loss: 0.95, pos_cosine: 0.67, neg_cosine: 0.62\n",
      "Epoch: 100 Loss: 0.96, pos_cosine: 0.67, neg_cosine: 0.63, recall@25: 0.75\n",
      "Saved model 'modelos/model_propose_bert_100_feature_100epochs_64batch(openoffice).h5' to disk\n",
      "Best_epoch=94, Best_loss=0.93s, Recall@25=0.75\n",
      "CPU times: user 1h 32min 14s, sys: 38min 11s, total: 2h 10min 26s\n",
      "Wall time: 2h 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "print(\"Batch size \", batch_size)\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_dilated_model\n",
    "    arcii_model\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    bilstm_model\n",
    "'''\n",
    "# title_feature_model = bilstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "title_feature_model = bert_model(MAX_SEQUENCE_LENGTH_T, 'Title')\n",
    "desc_feature_model = bert_model(MAX_SEQUENCE_LENGTH_D, 'Description')\n",
    "#desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "# Master model\n",
    "master_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'master_in')\n",
    "master_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'master_pos')\n",
    "master_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'master_neg')\n",
    "\n",
    "NUMBER_OF_INSTANCES = len(baseline.dup_sets_train)\n",
    "BATCH_SIZE = batch_size\n",
    "EPOCHS = epochs\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, \n",
    "                                            master_anchor, master_negative, master_positive,\n",
    "                                            NUMBER_OF_INSTANCES, BATCH_SIZE, EPOCHS, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, train_master_input, train_master_neg, \\\n",
    "            train_sim = experiment.batch_iterator_bert(encoded_anchor, baseline.train_data, baseline.dup_sets_train, bug_train_ids, \n",
    "                                       batch_size, 1, issues_by_buckets, INCLUDE_MASTER=True)\n",
    "    \n",
    "    train_batch = [train_input_sample['title']['token'], train_input_sample['title']['segment'], train_input_sample['description']['token'], train_input_sample['description']['segment'], train_input_sample['info'],\n",
    "                   train_input_pos['title']['token'], train_input_pos['title']['segment'], train_input_pos['description']['token'], train_input_pos['description']['segment'], train_input_pos['info'], \n",
    "                   train_input_neg['title']['token'], train_input_neg['title']['segment'], train_input_neg['description']['token'], train_input_neg['description']['segment'], train_input_neg['info'],\n",
    "                  train_input_sample['title']['token'], train_input_sample['title']['segment'], train_input_sample['description']['token'], train_input_sample['description']['segment'], train_input_sample['info'],\n",
    "                  train_master_input['title']['token'], train_master_input['title']['segment'], train_master_input['description']['token'], train_master_input['description']['segment'], train_master_input['info'],\n",
    "                   train_master_neg['title']['token'], train_master_neg['title']['segment'], train_master_neg['description']['token'], train_master_neg['description']['segment'], train_master_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, \n",
    "                                                               bug_train_ids, method='bert')\n",
    "        print(\"Epoch: {} Loss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}s, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 20), (128, 20), (128, 729), (128,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((128, 20), (128, 20), (128, 729), (128,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 20), (128, 20), (128, 1682), (128,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((128, 20), (128, 20), (128, 1682), (128,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['108544:111059,109674,108379,109366|94907:0.13950681686401367,104162:0.13591670989990234,120275:0.1022799015045166,93731:0.09717166423797607,108379:0.07252287864685059,119525:0.06920051574707031,97139:0.06845641136169434,97167:0.052492499351501465,54535:0.051451921463012695,108896:0.05104327201843262,115569:0.038519978523254395,92016:0.026851773262023926,89718:0.0260542631149292,95130:0.025155186653137207,104587:0.017557621002197266,93192:0.01702880859375,103951:0.015637636184692383,93289:0.014157652854919434,93404:0.011136412620544434,93405:0.011136412620544434,109833:0.010228276252746582,94421:0.009391069412231445,109366:0.009049296379089355,115857:0.007692456245422363,95617:0.006536364555358887,115182:0.0047490596771240234,93580:0.001718759536743164,116470:0.0006524324417114258,109674:0.0',\n",
       " '109674:108544,111059,108379,109366|111059:0.22224199771881104,109366:0.2049877643585205,98033:0.17814850807189941,98715:0.10245418548583984,97577:0.09228098392486572,95380:0.07618892192840576,95381:0.06625938415527344,93583:0.06464087963104248,101159:0.05597662925720215,108544:0.05191314220428467,102003:0.04576289653778076,97212:0.0388416051864624,102600:0.03393828868865967,95688:0.028134465217590332,102553:0.026986122131347656,97860:0.023672103881835938,90896:0.021348118782043457,95382:0.017383575439453125,109249:0.007424592971801758,77664:0.00686490535736084,97978:0.005446314811706543,110928:0.002544999122619629,108404:0.0020226240158081055,106728:0.001967310905456543,92173:0.001784205436706543,112693:0.001222372055053711,90970:0.0008008480072021484,97584:0.0007926225662231445,105993:0.0',\n",
       " '111059:108544,109674,108379,109366|109366:0.21451663970947266,109674:0.21248149871826172,98033:0.1315016746520996,95380:0.11497163772583008,95381:0.11108720302581787,97577:0.0721961259841919,98715:0.06507980823516846,99541:0.064292311668396,97212:0.061800360679626465,108290:0.05256164073944092,103284:0.049477458000183105,105661:0.04253184795379639,107999:0.03800690174102783,108544:0.027680277824401855,91990:0.02262592315673828,102274:0.019617795944213867,112690:0.018203020095825195,92973:0.017788171768188477,96594:0.017769813537597656,93583:0.017687439918518066,103171:0.01648569107055664,93192:0.01576101779937744,102003:0.0070542097091674805,112853:0.006468534469604492,105250:0.006353139877319336,92697:0.004908442497253418,102600:0.003370046615600586,110397:0.0024352073669433594,102447:0.0',\n",
       " '108379:108544,111059,109674,109366|105671:0.18631243705749512,107764:0.16466712951660156,117276:0.10918188095092773,108544:0.10329008102416992,46957:0.07261979579925537,107738:0.06574010848999023,98861:0.06166481971740723,105993:0.05756831169128418,121551:0.05646252632141113,93288:0.05599713325500488,93296:0.045614004135131836,107794:0.04208636283874512,118021:0.03966331481933594,96732:0.039637088775634766,114245:0.03934907913208008,108333:0.0322190523147583,91251:0.027003884315490723,106877:0.023305416107177734,105371:0.022396445274353027,105961:0.01615309715270996,103171:0.010366559028625488,113395:0.009692668914794922,113113:0.00793313980102539,103459:0.0067636966705322266,105272:0.006569385528564453,112520:0.006410956382751465,107999:0.005899548530578613,112038:0.0051833391189575195,96739:0.0',\n",
       " '109366:108544,111059,109674,108379|111059:0.19354629516601562,109674:0.17425692081451416,90612:0.08897757530212402,107293:0.07649791240692139,105176:0.05254852771759033,102447:0.04326009750366211,89255:0.04293620586395264,96079:0.03986763954162598,105661:0.03354966640472412,107999:0.03316092491149902,122200:0.031461238861083984,113395:0.030682802200317383,97212:0.030249953269958496,108544:0.030231595039367676,92645:0.02862858772277832,92973:0.02534770965576172,99094:0.024485349655151367,93583:0.022864341735839844,99182:0.02064061164855957,100962:0.01982283592224121,101607:0.017866969108581543,53220:0.014840483665466309,97323:0.013147711753845215,108404:0.01201009750366211,98033:0.009868502616882324,112853:0.007103562355041504,24535:0.0041533708572387695,99307:0.003273606300354004,106581:0.0',\n",
       " '110594:107073,108355,108453,109162,111761,111800|111761:0.20513403415679932,89188:0.17548787593841553,96944:0.14366793632507324,101504:0.09881532192230225,99507:0.09796333312988281,99842:0.09675991535186768,108355:0.09405946731567383,102251:0.0853196382522583,86960:0.062210917472839355,106051:0.062119245529174805,47990:0.061342477798461914,101462:0.05242347717285156,102941:0.046199917793273926,102744:0.031125903129577637,110052:0.027759671211242676,105377:0.026239752769470215,97809:0.02622675895690918,103968:0.025665998458862305,91614:0.024872660636901855,120075:0.02462947368621826,112255:0.024191856384277344,116112:0.01871049404144287,91063:0.012525439262390137,92135:0.01012420654296875,81355:0.006960630416870117,122652:0.006685853004455566,105307:0.004521012306213379,111054:0.0006825923919677734,111583:0.0',\n",
       " '111800:107073,110594,108355,108453,109162,111761|121756:0.2700602412223816,91826:0.25866204500198364,92771:0.2312781810760498,107843:0.14789485931396484,92000:0.14705121517181396,111626:0.1332550048828125,100801:0.12814724445343018,92333:0.12329959869384766,99603:0.09373247623443604,115168:0.09013998508453369,110442:0.06864571571350098,92532:0.06414425373077393,109662:0.060073137283325195,110341:0.05798459053039551,111347:0.05789816379547119,121632:0.0555340051651001,109162:0.05525624752044678,107073:0.049806952476501465,102522:0.037973880767822266,110374:0.03236997127532959,95007:0.03127884864807129,104697:0.025568127632141113,108440:0.01767408847808838,92547:0.01483762264251709,116250:0.014758586883544922,100980:0.01054692268371582,104112:0.01054239273071289,98276:0.007638692855834961,110555:0.0',\n",
       " '111761:107073,110594,108355,108453,109162,111800|110594:0.16772615909576416,89188:0.10424494743347168,102251:0.09375452995300293,102941:0.0895383358001709,47990:0.07849705219268799,101504:0.05419003963470459,101462:0.05113577842712402,99507:0.04893457889556885,91063:0.04846084117889404,96944:0.04829251766204834,102000:0.04641580581665039,120075:0.04334414005279541,109162:0.0387190580368042,108355:0.03338909149169922,112255:0.03149127960205078,106051:0.027971982955932617,107073:0.02533876895904541,102744:0.018770813941955566,99842:0.015870094299316406,105307:0.01337134838104248,97221:0.012090921401977539,111347:0.009120821952819824,103968:0.008012771606445312,110052:0.006782889366149902,114810:0.005990743637084961,105377:0.00477910041809082,114431:0.0035005807876586914,112099:0.0007464885711669922,103827:0.0',\n",
       " '109162:107073,110594,108355,108453,111761,111800|111761:0.08726882934570312,107073:0.08184945583343506,113351:0.07400691509246826,108035:0.07272934913635254,103827:0.07174992561340332,123438:0.06325256824493408,102744:0.056994080543518066,108453:0.05408203601837158,102114:0.04984128475189209,111521:0.047234296798706055,108355:0.043174147605895996,106855:0.04160654544830322,111626:0.035827040672302246,91310:0.03301537036895752,98563:0.0326230525970459,106051:0.027071356773376465,111347:0.02482450008392334,122776:0.021856188774108887,111800:0.018456339836120605,95968:0.018396377563476562,93172:0.017409086227416992,92771:0.016245603561401367,102941:0.011883735656738281,91826:0.011301875114440918,97568:0.008722186088562012,98964:0.007509112358093262,99603:0.004430532455444336,108529:0.0022726058959960938,120037:0.0',\n",
       " '108355:107073,110594,108453,109162,111761,111800|101462:0.19313108921051025,110594:0.11968719959259033,111761:0.09642469882965088,98206:0.06052958965301514,89920:0.05955195426940918,109162:0.05765998363494873,107073:0.05073046684265137,103827:0.04895460605621338,95341:0.0453113317489624,107242:0.0437852144241333,93678:0.04357123374938965,102941:0.04272270202636719,110052:0.04137217998504639,99483:0.038251280784606934,104333:0.03274810314178467,104163:0.032151222229003906,102251:0.029772162437438965,96944:0.028414607048034668,92135:0.026580333709716797,95191:0.023220539093017578,109879:0.013526558876037598,100478:0.013393878936767578,111521:0.010642409324645996,120075:0.008442997932434082,105419:0.007797122001647949,90273:0.007003188133239746,123438:0.006273627281188965,91063:0.002913951873779297,106051:0.0',\n",
       " '108453:107073,110594,108355,109162,111761,111800|103827:0.21669763326644897,106855:0.07486176490783691,95968:0.06448078155517578,109909:0.05669689178466797,102675:0.05392420291900635,115300:0.04804718494415283,102114:0.04470467567443848,96581:0.04097568988800049,88677:0.034331440925598145,98563:0.032875657081604004,74923:0.029965519905090332,80626:0.028377175331115723,116965:0.026778340339660645,92564:0.02490413188934326,91896:0.017812013626098633,14454:0.015545845031738281,30153:0.015080094337463379,97332:0.01322031021118164,110712:0.01166379451751709,100549:0.011018514633178711,94430:0.006144285202026367,102434:0.0046236515045166016,105307:0.004475593566894531,98206:0.004300832748413086,122004:0.0037560462951660156,111235:0.0026292800903320312,100326:0.0016109943389892578,119756:0.0002453327178955078,91907:0.0',\n",
       " '114705:114676|97969:0.18901491165161133,101937:0.17763733863830566,108012:0.1571751832962036,95171:0.13998210430145264,90796:0.0905381441116333,101160:0.04839122295379639,107749:0.041858553886413574,100744:0.035868167877197266,116993:0.03140127658843994,102298:0.029417753219604492,63537:0.027597904205322266,102409:0.021878480911254883,95088:0.02157127857208252,121250:0.01526176929473877,107721:0.014072179794311523,101837:0.013030171394348145,103513:0.011358976364135742,119353:0.009183049201965332,92564:0.008701562881469727,114786:0.008438587188720703,30870:0.008371353149414062,101799:0.007940173149108887,87549:0.003648996353149414,100324:0.0027445554733276367,92115:0.0026949644088745117,98861:0.0013275146484375,105511:0.001296401023864746,113912:0.0003445148468017578,94189:0.0',\n",
       " '114676:114705|112523:0.1450400948524475,111908:0.13646727800369263,112843:0.10699999332427979,112844:0.10699999332427979,113669:0.10697066783905029,108401:0.0926891565322876,110900:0.08196663856506348,115350:0.06958472728729248,115349:0.06741797924041748,99186:0.06635355949401855,111648:0.054482102394104004,89516:0.03799843788146973,97715:0.034131646156311035,98674:0.03174161911010742,109431:0.03163158893585205,94947:0.03028285503387451,101522:0.02264225482940674,96132:0.02101147174835205,102648:0.013896346092224121,81539:0.011164188385009766,97907:0.007733941078186035,113145:0.007150888442993164,112606:0.006737470626831055,122331:0.00551450252532959,105368:0.0051081180572509766,121199:0.0017957687377929688,114725:0.0008586645126342773,107058:0.0004143714904785156,112265:0.0',\n",
       " '110593:110618|110618:0.3167181611061096,94900:0.12114381790161133,98903:0.10314738750457764,105970:0.06803655624389648,112232:0.06182277202606201,104162:0.047441959381103516,115825:0.045440673828125,100465:0.044371724128723145,108985:0.0370868444442749,122920:0.031046271324157715,91404:0.028762340545654297,99560:0.02693498134613037,111354:0.02632462978363037,120540:0.02325892448425293,106861:0.017326831817626953,82280:0.01693880558013916,108544:0.01317906379699707,110346:0.01276540756225586,117096:0.012446165084838867,101159:0.00990760326385498,99990:0.008796453475952148,100161:0.008521080017089844,100023:0.0064885616302490234,101731:0.004070758819580078,110207:0.003736257553100586,99082:0.0022696256637573242,111362:0.001826643943786621,108454:0.0015032291412353516,100271:0.0',\n",
       " '110618:110593|110593:0.3232141137123108,94900:0.11509263515472412,115825:0.11273777484893799,93756:0.08004164695739746,99082:0.07661211490631104,122920:0.06260812282562256,104574:0.057646870613098145,104576:0.057646870613098145,108408:0.054137587547302246,100465:0.027188897132873535,104270:0.025702476501464844,100161:0.025147080421447754,99560:0.023836970329284668,98903:0.023388147354125977,96732:0.01952517032623291,107778:0.016167521476745605,106861:0.015382647514343262,102342:0.01253807544708252,116770:0.012502193450927734,119292:0.011690974235534668,108544:0.009960293769836426,105970:0.009918570518493652,91404:0.007140994071960449,82280:0.0066487789154052734,101731:0.005673766136169434,107192:0.004922747611999512,101159:0.002454519271850586,122867:0.0003241300582885742,123005:0.0',\n",
       " '102409:102053|107039:0.09173429012298584,105931:0.08491683006286621,119542:0.0730825662612915,90796:0.06950545310974121,90096:0.05661511421203613,91972:0.053797364234924316,97969:0.04143035411834717,108012:0.040020108222961426,107749:0.03988909721374512,105719:0.03919041156768799,116293:0.030346989631652832,91575:0.029596924781799316,98664:0.029318928718566895,95088:0.02861034870147705,101225:0.026975631713867188,121232:0.02680075168609619,119049:0.02637767791748047,119048:0.022362828254699707,95237:0.020734548568725586,96970:0.01715099811553955,102223:0.016826868057250977,112621:0.012138962745666504,97437:0.009956836700439453,111455:0.008555293083190918,92940:0.006785154342651367,117454:0.002231121063232422,111650:0.0012611150741577148,90471:0.0006085634231567383,99254:0.0',\n",
       " '102053:102409|108190:0.10950577259063721,115564:0.09029531478881836,90417:0.08968138694763184,103115:0.08961343765258789,97095:0.08176922798156738,109630:0.07879400253295898,117201:0.07273781299591064,109853:0.06734919548034668,101563:0.056996703147888184,121558:0.050902724266052246,113633:0.045628905296325684,89480:0.04232823848724365,90864:0.022638678550720215,111603:0.020534873008728027,93889:0.020325541496276855,118032:0.016873836517333984,111557:0.013747096061706543,112877:0.013446569442749023,110609:0.013367176055908203,106067:0.012407422065734863,116196:0.011381268501281738,117356:0.00961005687713623,98549:0.006835818290710449,91413:0.006105661392211914,96912:0.0053817033767700195,79559:0.004302382469177246,97862:0.0020941495895385742,96471:0.00013315677642822266,93419:0.0',\n",
       " '110604:110612|115767:0.13949668407440186,109298:0.09389173984527588,102786:0.08585762977600098,112804:0.07980406284332275,93439:0.0759350061416626,103575:0.07234787940979004,105482:0.06177377700805664,112103:0.048380255699157715,115376:0.03242826461791992,106337:0.03196918964385986,117356:0.029255986213684082,110601:0.02831244468688965,115793:0.026759743690490723,95414:0.022431254386901855,108745:0.02193605899810791,99376:0.020050406455993652,103481:0.019903898239135742,95413:0.016964197158813477,93076:0.016016125679016113,122550:0.015988945960998535,99469:0.01396334171295166,100031:0.011191248893737793,115419:0.009944677352905273,112713:0.0033532381057739258,113669:0.002239704132080078,117487:0.000624537467956543,113106:5.8531761169433594e-05,90267:0.0,90268:0.0',\n",
       " '110612:110604|98545:0.0884324312210083,108190:0.063132643699646,97860:0.05990707874298096,77515:0.05677926540374756,96894:0.03200328350067139,91337:0.02841925621032715,98005:0.02620565891265869,92822:0.021099209785461426,95089:0.01994788646697998,105566:0.019757628440856934,93827:0.016142606735229492,93828:0.016142606735229492,111990:0.015266776084899902,115599:0.014954090118408203,99874:0.012264609336853027,105295:0.011890053749084473,120369:0.009518742561340332,113468:0.0075331926345825195,112377:0.007316708564758301,116007:0.006570100784301758,90424:0.0054128170013427734,68942:0.0037910938262939453,103714:0.0036895275115966797,114811:0.0029298067092895508,97178:0.0011260509490966797,91605:0.001096487045288086,111078:0.00019919872283935547,100749:0.0,100750:0.0',\n",
       " '116738:116938,117027|106542:0.13911128044128418,101531:0.08352553844451904,122894:0.07711613178253174,118021:0.07145059108734131,93311:0.059229373931884766,92290:0.055806517601013184,104155:0.05291104316711426,118451:0.050780296325683594,118169:0.04975605010986328,90796:0.044173479080200195,90431:0.04183042049407959,90881:0.04110980033874512,71327:0.0410233736038208,99257:0.02367079257965088,106589:0.0228121280670166,121199:0.017020463943481445,91972:0.014788627624511719,68248:0.014103055000305176,102595:0.012328147888183594,115898:0.01203775405883789,101160:0.009091734886169434,109972:0.008351802825927734,92977:0.008182883262634277,122864:0.007909774780273438,93306:0.00789797306060791,95162:0.0073544979095458984,95130:0.0005522966384887695,106268:1.1563301086425781e-05,99728:0.0']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall, exported_rank, debug = experiment.evaluate_validation_test(experiment, retrieval, verbose, \n",
    "#                                                         encoded_anchor, issues_by_buckets, evaluate_validation_test)\n",
    "# test_vectorized, queries_test_vectorized, annoy, X_test, distance_test, indices_test = debug\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 2086\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'propose_bert_100_feature_100epochs_64batch(openoffice)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoded_anchor\n",
    "# model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 729)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          219000      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 768)          80346736    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 768)          80346736    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1836)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "==================================================================================================\n",
      "Total params: 160,912,472\n",
      "Trainable params: 440,296\n",
      "Non-trainable params: 160,472,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, \n",
    "                                                                   bug_train_ids, method='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/openoffice/exported_rank_propose_bert_100.txt'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.6,\n",
       " '2 - recall_at_10': 0.67,\n",
       " '3 - recall_at_15': 0.7,\n",
       " '4 - recall_at_20': 0.74,\n",
       " '5 - recall_at_25': 0.75}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
