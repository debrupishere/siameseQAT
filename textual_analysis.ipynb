{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 100 # 40\n",
    "MAX_SEQUENCE_LENGTH_D = 500 # 200\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN = 'netbeans'\n",
    "DIR = 'data/processed/{}/{}'.format(DOMAIN, 'bert')\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# uncased_L-12_H-768_A-12\n",
    "# multi_cased_L-12_H-768_A-12\n",
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "model_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_vocabulary\n",
    "\n",
    "token_dict = load_vocabulary(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pair = pd.read_csv(os.path.join(DIR_PAIRS, '{}_pairs.csv'.format(DOMAIN)))\n",
    "baseline = Baseline(DOMAIN, DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, token_dict['[CLS]'], token_dict['[SEP]'])\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "experiment.load_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216715"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e30deed535a497dab8d753eb6ddc064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=216715), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2623e3a963ac4facb4d1f88631e95bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.load_bugs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title_corpus = [baseline.bug_set[i]['title'][:MAX_SEQUENCE_LENGTH_T][5:-5] for i in tqdm(baseline.bug_ids)]\n",
    "description_corpus = [baseline.bug_set[i]['description'][:MAX_SEQUENCE_LENGTH_D][5:-5] for i in tqdm(baseline.bug_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_length = [len(baseline.bug_set[i]['title'][5:-5].split(' ')) for i in tqdm(baseline.bug_ids)]\n",
    "description_length = [len(baseline.bug_set[i]['description'][5:-5].split(' ')) for i in tqdm(baseline.bug_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17, 8))\n",
    "# Title\n",
    "df_title = pd.DataFrame(title_length, columns=['short_desc'])\n",
    "print(df_title.describe())\n",
    "ax = df_title.plot.hist(ax=axes[0])\n",
    "ax.set_title('Frequência de tokens para títulos (short_desc)')\n",
    "ax.set_ylabel('frequência')\n",
    "ax.set_xlabel('número de tokens')\n",
    "# Description\n",
    "df_desc = pd.DataFrame(description_length, columns=['description'])\n",
    "print(df_desc.describe())\n",
    "df_desc = df_desc[df_desc['description'] <= 600]\n",
    "ax = df_desc.plot.hist(color='g', ax=axes[1])\n",
    "ax.set_title('Frequência de tokens para descrição (description)')\n",
    "ax.set_ylabel('frequência')\n",
    "ax.set_xlabel('número de tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(corpus, callback):\n",
    "    corpus_filtered_words = [row.split(' ') for row in corpus]\n",
    "    corpus_in_words = []\n",
    "    for row in corpus_filtered_words:\n",
    "        corpus_in_words += [word for word in row if callback(len(word))]\n",
    "    return corpus_in_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=100,width = 1520, height = 535).generate(\" \".join(title_corpus))\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=100,width = 1520, height = 535).generate(\" \".join(description_corpus))\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word cloud 2 words in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_2_words = [row.split(' ') for row in title_corpus]\n",
    "title_corpus_2_words = []\n",
    "for row in corpus_2_words:\n",
    "    title_corpus_2_words += [word for word in row if len(word) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=100,width = 1520, height = 535).generate(' '.join(title_corpus_2_words))\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud 2 words in description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_2_words = [row.split(' ') for row in description_corpus]\n",
    "desc_corpus_2_words = []\n",
    "for row in corpus_2_words:\n",
    "    desc_corpus_2_words += [word for word in row if len(word) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=100,width = 1520, height = 535).generate(' '.join(desc_corpus_2_words))\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud 1 word in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_1_word = [row.split(' ') for row in title_corpus]\n",
    "title_corpus_1_word = []\n",
    "for row in corpus_1_word:\n",
    "    title_corpus_1_word += [word for word in row if len(word) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = {}\n",
    "for word in title_corpus_1_word:\n",
    "    if word not in freq_words:\n",
    "        freq_words[word] = 0\n",
    "        \n",
    "    freq_words[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MEDIUM_SIZE = 16\n",
    "SMALL_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)\n",
    "\n",
    "df = pd.DataFrame(freq_words, columns=list(freq_words), index=range(len(freq_words))).transpose()[[0]]\n",
    "df.columns = ['freq']\n",
    "ax = df.sort_values('freq', ascending=True).plot.barh(figsize=(12, 8))\n",
    "ax.set_title('Frequency of tokens in title')\n",
    "ax.set_ylabel('tokens')\n",
    "ax.set_xlabel('frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud 1 word in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_1_word = [row.split(' ') for row in description_corpus]\n",
    "desc_corpus_1_word = []\n",
    "for row in corpus_1_word:\n",
    "    desc_corpus_1_word += [word for word in row if len(word) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = {}\n",
    "for word in desc_corpus_1_word:\n",
    "    if word not in freq_words:\n",
    "        freq_words[word] = 0\n",
    "        \n",
    "    freq_words[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIUM_SIZE = 16\n",
    "SMALL_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)\n",
    "\n",
    "df = pd.DataFrame(freq_words, columns=list(freq_words), index=range(len(freq_words))).transpose()[[0]]\n",
    "df.columns = ['freq']\n",
    "ax = df.sort_values('freq', ascending=True).plot.barh(figsize=(12, 8))\n",
    "ax.set_title('Frequency of tokens in description')\n",
    "ax.set_ylabel('tokens')\n",
    "ax.set_xlabel('frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of words in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_word = [row.split(' ') for row in title_corpus]\n",
    "size_tokens = []\n",
    "for row in dist_word:\n",
    "    size_tokens += [len(word) for word in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "freq_tokens = Counter(size_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(freq_tokens, index=range(len(freq_tokens))).transpose()[[0]]\n",
    "df.columns = ['token_size']\n",
    "ax = df.sort_values('token_size', ascending=True).plot.bar(figsize=(18, 8))\n",
    "ax.set_title('Size of tokens in title')\n",
    "ax.set_xlabel('token_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_words_title(token_size):\n",
    "    return token_size == 6\n",
    "\n",
    "corpus_filtered = filter_words(title_corpus, filter_by_words_title)\n",
    "len(corpus_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=100,width = 1520, height = 535).generate(' '.join(corpus_filtered))\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_words_title(token_size):\n",
    "    return token_size > 8\n",
    "\n",
    "corpus_filtered = filter_words(title_corpus, filter_by_words_title)\n",
    "len(corpus_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=100,width = 1520, height = 535).generate(' '.join(corpus_filtered))\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of words in description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_word = [row.split(' ') for row in description_corpus]\n",
    "size_tokens = []\n",
    "for row in dist_word:\n",
    "    size_tokens += [len(word) for word in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "freq_tokens = Counter(size_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(freq_tokens, index=range(len(freq_tokens))).transpose()[[0]]\n",
    "df.columns = ['token_size']\n",
    "ax = df.sort_values('token_size', ascending=True).plot.bar(figsize=(18, 8))\n",
    "ax.set_title('Size of tokens in description')\n",
    "ax.set_xlabel('token_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_words_desc(token_size):\n",
    "    return token_size == 3\n",
    "\n",
    "corpus_filtered = filter_words(description_corpus, filter_by_words_desc)\n",
    "len(corpus_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=100,width = 1520, height = 535).generate(' '.join(corpus_filtered))\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_words_desc(token_size):\n",
    "    return token_size > 8\n",
    "\n",
    "corpus_filtered = filter_words(description_corpus, filter_by_words_desc)\n",
    "len(corpus_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=100,width = 1520, height = 535).generate(' '.join(corpus_filtered))\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a random bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_selected = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "\n",
    "bug = baseline.bug_set[bug_selected]\n",
    "\n",
    "bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total missing values after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs_empty_desc = [idx for idx in list(baseline.bug_set) if baseline.bug_set[idx]['description'] == '']\n",
    "bugs_empty_title = [idx for idx in list(baseline.bug_set) if baseline.bug_set[idx]['title'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bugs_empty_title), len(bugs_empty_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET)\n",
    "df[df['bug_id'].isin(bugs_empty_desc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bugs_empty_desc) / len(baseline.bug_set) * 100.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
