{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Propose BERT siamese with triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import keras\n",
    "# from tensorflow.python import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow.keras.backend as K_tf\n",
    "\n",
    "# sess = K_tf.get_session()\n",
    "# uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
    "# init_op = tf.variables_initializer(\n",
    "#     [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
    "# )\n",
    "# sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 20\n",
    "MAX_SEQUENCE_LENGTH_D = 20 # 80\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 100\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'eclipse'\n",
    "METHOD = 'propose_bert_triplet_{}'.format(epochs)\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Path embeddings\n",
    "EMBED_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_feature@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_feature_@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f87ac70038b494190c77897840cdac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322339), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b886964a8605473a93cea611f91e9674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39545), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "361006"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "# !unzip -o uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "model_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_vocabulary\n",
    "\n",
    "token_dict = load_vocabulary(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 30522'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(token_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c051b158b774c5198070ff3fcf99aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=361006), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b58d5ce21504495b659cf26339d2e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 27.6 s, sys: 3.53 s, total: 31.1 s\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b762fe67a549c79d199221abb2fa8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=321536), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n",
      "CPU times: user 2min 36s, sys: 28.9 ms, total: 2min 36s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a random bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': '2\\n',\n",
       " 'bug_status': '2\\n',\n",
       " 'component': '482\\n',\n",
       " 'creation_ts': '2008-08-07 22:43:00 -0400',\n",
       " 'delta_ts': '2009-09-08 01:19:51 -0400',\n",
       " 'description': '[CLS] description : script ##fu ##nction ##ser ##vic ##e . ex ##sd should be included in binary build properties , when sb defined extension of org . eclipse . bi ##rt . core . script ##fu ##nction ##ser ##vic ##e , it will help him to see how sc ##hema defined and he can use the tool ##tip to create function , category and etc . build number : 2 . 3 . 1 . v ##200 ##80 ##80 ##8 - 06 ##30 steps to reproduce : 1 , start all - in - one bi ##rt 2 , new a plug ##in project 3 , new a extension and the extension point is org . eclipse . bi ##rt . core . script ##fu ##nction ##ser ##vic ##e 4 , show extension sc ##hema expected result : be able to show the extension sc ##hema actual result : can not show the extension sc ##hema [SEP]',\n",
       " 'description_bert': '[CLS] description : script ##fu ##nction ##ser ##vic ##e . ex ##sd should be included in binary build properties , when sb defined extension of org . eclipse . bi ##rt . core . script ##fu ##nction ##ser ##vic ##e , it will help him to see how sc ##hema defined and he can use the tool ##tip to create function , category and etc . build number : 2 . 3 . 1 . v ##200 ##80 ##80 ##8 - 06 ##30 steps to reproduce : 1 , start all - in - one bi ##rt 2 , new a plug ##in project 3 , new a extension and the extension point is org . eclipse . bi ##rt . core . script ##fu ##nction ##ser ##vic ##e 4 , show extension sc ##hema expected result : be able to show the extension sc ##hema actual result : can not show the extension sc ##hema [SEP]',\n",
       " 'description_word': array([  101,  6412,  1024,  5896, 11263, 27989,  8043,  7903,  2063,\n",
       "         1012,  4654, 16150,  2323,  2022,  2443,  1999, 12441,  3857,\n",
       "         5144,  1010]),\n",
       " 'description_word_bert': [101,\n",
       "  6412,\n",
       "  1024,\n",
       "  5896,\n",
       "  11263,\n",
       "  27989,\n",
       "  8043,\n",
       "  7903,\n",
       "  2063,\n",
       "  1012,\n",
       "  4654,\n",
       "  16150,\n",
       "  2323,\n",
       "  2022,\n",
       "  2443,\n",
       "  1999,\n",
       "  12441,\n",
       "  3857,\n",
       "  5144,\n",
       "  1010,\n",
       "  2043,\n",
       "  24829,\n",
       "  4225,\n",
       "  5331,\n",
       "  1997,\n",
       "  8917,\n",
       "  1012,\n",
       "  13232,\n",
       "  1012,\n",
       "  12170,\n",
       "  5339,\n",
       "  1012,\n",
       "  4563,\n",
       "  1012,\n",
       "  5896,\n",
       "  11263,\n",
       "  27989,\n",
       "  8043,\n",
       "  7903,\n",
       "  2063,\n",
       "  1010,\n",
       "  2009,\n",
       "  2097,\n",
       "  2393,\n",
       "  2032,\n",
       "  2000,\n",
       "  2156,\n",
       "  2129,\n",
       "  8040,\n",
       "  28433,\n",
       "  4225,\n",
       "  1998,\n",
       "  2002,\n",
       "  2064,\n",
       "  2224,\n",
       "  1996,\n",
       "  6994,\n",
       "  25101,\n",
       "  2000,\n",
       "  3443,\n",
       "  3853,\n",
       "  1010,\n",
       "  4696,\n",
       "  1998,\n",
       "  4385,\n",
       "  1012,\n",
       "  3857,\n",
       "  2193,\n",
       "  1024,\n",
       "  1016,\n",
       "  1012,\n",
       "  1017,\n",
       "  1012,\n",
       "  1015,\n",
       "  1012,\n",
       "  1058,\n",
       "  28332,\n",
       "  17914,\n",
       "  17914,\n",
       "  2620,\n",
       "  1011,\n",
       "  5757,\n",
       "  14142,\n",
       "  4084,\n",
       "  2000,\n",
       "  21376,\n",
       "  1024,\n",
       "  1015,\n",
       "  1010,\n",
       "  2707,\n",
       "  2035,\n",
       "  1011,\n",
       "  1999,\n",
       "  1011,\n",
       "  2028,\n",
       "  12170,\n",
       "  5339,\n",
       "  1016,\n",
       "  1010,\n",
       "  2047,\n",
       "  1037,\n",
       "  13354,\n",
       "  2378,\n",
       "  2622,\n",
       "  1017,\n",
       "  1010,\n",
       "  2047,\n",
       "  1037,\n",
       "  5331,\n",
       "  1998,\n",
       "  1996,\n",
       "  5331,\n",
       "  2391,\n",
       "  2003,\n",
       "  8917,\n",
       "  1012,\n",
       "  13232,\n",
       "  1012,\n",
       "  12170,\n",
       "  5339,\n",
       "  1012,\n",
       "  4563,\n",
       "  1012,\n",
       "  5896,\n",
       "  11263,\n",
       "  27989,\n",
       "  8043,\n",
       "  7903,\n",
       "  2063,\n",
       "  1018,\n",
       "  1010,\n",
       "  2265,\n",
       "  5331,\n",
       "  8040,\n",
       "  28433,\n",
       "  3517,\n",
       "  2765,\n",
       "  1024,\n",
       "  2022,\n",
       "  2583,\n",
       "  2000,\n",
       "  2265,\n",
       "  1996,\n",
       "  5331,\n",
       "  8040,\n",
       "  28433,\n",
       "  5025,\n",
       "  2765,\n",
       "  1024,\n",
       "  102],\n",
       " 'dup_id': '[]',\n",
       " 'issue_id': 243531,\n",
       " 'priority': '4\\n',\n",
       " 'product': '143\\n',\n",
       " 'resolution': 'FIXED',\n",
       " 'textual_word': array([  101,  5896, 11263, 27989,  8043,  7903,  2063,  1012,  4654,\n",
       "        16150,  2323,  2022,  2443,  1999, 12441,  3857,  5144,   102,\n",
       "            0,     0,   101,  6412,  1024,  5896, 11263, 27989,  8043,\n",
       "         7903,  2063,  1012,  4654, 16150,  2323,  2022,  2443,  1999,\n",
       "        12441,  3857,  5144,  1010]),\n",
       " 'title': '[CLS] script ##fu ##nction ##ser ##vic ##e . ex ##sd should be included in binary build properties [SEP]',\n",
       " 'title_bert': '[CLS] script ##fu ##nction ##ser ##vic ##e . ex ##sd should be included in binary build properties [SEP]',\n",
       " 'title_word': array([  101,  5896, 11263, 27989,  8043,  7903,  2063,  1012,  4654,\n",
       "        16150,  2323,  2022,  2443,  1999, 12441,  3857,  5144,   102,\n",
       "            0,     0]),\n",
       " 'title_word_bert': [101,\n",
       "  5896,\n",
       "  11263,\n",
       "  27989,\n",
       "  8043,\n",
       "  7903,\n",
       "  2063,\n",
       "  1012,\n",
       "  4654,\n",
       "  16150,\n",
       "  2323,\n",
       "  2022,\n",
       "  2443,\n",
       "  1999,\n",
       "  12441,\n",
       "  3857,\n",
       "  5144,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'version': '179\\n'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 34882)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indexed all train'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_idx = bug_train_ids[0]\n",
    "vector = baseline.bug_set[bug_idx]['textual_word']\n",
    "annoy_train = AnnoyIndex(vector.shape[0])\n",
    "for bug_id in bug_train_ids:\n",
    "    annoy_train.add_item(bug_id, baseline.bug_set[bug_id]['textual_word'])\n",
    "annoy_train.build(10) # 10 trees\n",
    "\"Indexed all train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49 ms, sys: 0 ns, total: 49 ms\n",
      "Wall time: 48.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, valid_sim = experiment.batch_iterator_bert(None, \n",
    "                                                                                                                  baseline.train_data, \n",
    "                                                                                                                  baseline.dup_sets_train,\n",
    "                                                                                                                  bug_train_ids,\n",
    "                                                                                                                  batch_size_test, 1, \n",
    "                                                                                                                  issues_by_buckets)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title']['token'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description']['token'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 20), (128, 20), (128, 1682), (128,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title']['token'].shape, valid_input_sample['description']['token'].shape, \\\n",
    "    valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5, batch_iterator, issues_by_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Propose\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomUniform, RandomNormal, Ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "https://github.com/CyberZHG/keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import compile_model, get_model\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "def bert_model(MAX_SEQUENCE_LENGTH, name):\n",
    "    layer_num = 8\n",
    "#     model = load_trained_model_from_checkpoint(\n",
    "#             config_path,\n",
    "#             model_path,\n",
    "#             training=True,\n",
    "#             trainable=True,\n",
    "#             seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#     )\n",
    "    model = load_trained_model_from_checkpoint(\n",
    "        config_path,\n",
    "        model_path,\n",
    "        training=False,\n",
    "        use_adapter=True,\n",
    "        seq_len=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=['Encoder-{}-MultiHeadSelfAttention-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-MultiHeadSelfAttention-Norm'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Norm'.format(i + 1) for i in range(layer_num)],\n",
    "    )\n",
    "#     model = get_model(\n",
    "#         token_num=len(token_dict),\n",
    "#         head_num=10,\n",
    "#         transformer_num=layer_num,\n",
    "#         embed_dim=100,\n",
    "#         feed_forward_dim=100,\n",
    "#         seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#         pos_num=MAX_SEQUENCE_LENGTH,\n",
    "#         dropout_rate=0.05,\n",
    "#     )\n",
    "    compile_model(model)\n",
    "    inputs = model.inputs[:2]\n",
    "    outputs = model.get_layer('Encoder-{}-FeedForward-Norm'.format(layer_num)).output\n",
    "    #outputs = model.get_layer('Extract').output\n",
    "    outputs = GlobalAveragePooling1D()(outputs)\n",
    "#     outputs = Dense(300, activation='tanh')(outputs)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='FeatureBERTGenerationModel{}'.format(name))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    #layer = GRU(100, activation='tanh')(layer)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "'''\n",
    "    Some loss ideas\n",
    "    hinge loss Kullback-Leibler\n",
    "    https://stackoverflow.com/questions/53581298/custom-combined-hinge-kb-divergence-loss-function-in-siamese-net-fails-to-genera\n",
    "'''\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    distance = K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "    # Normalize https://stats.stackexchange.com/questions/53068/euclidean-distance-score-and-similarity\n",
    "    distance = K.constant(1) / (K.constant(1) + distance)\n",
    "    return K.mean(distance, keepdims=False)\n",
    "    #return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "# https://jdhao.github.io/2017/03/13/some_loss_and_explanations/\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.mean(K.maximum(0.0, pos - neg + margin))\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.mean(K.maximum(0.0, margin - pos + neg), keepdims=False)\n",
    "\n",
    "# https://www.kaggle.com/c/quora-question-pairs/discussion/33631\n",
    "# https://www.researchgate.net/figure/Illustration-of-triplet-loss-contrastive-loss-for-negative-samples-and-binomial_fig2_322060548\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    margin = 1\n",
    "    return K.mean(pos * K.square(neg) +\n",
    "                  (1 - pos) * K.square(K.maximum(margin - neg, 0)))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, Average, Maximum, Subtract, Average, AveragePooling1D, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "    \n",
    "    # Title\n",
    "    bug_t_token = Input(shape = (sequence_length_t, ), name = 'title_token_{}'.format(name))\n",
    "    bug_t_segment = Input(shape = (sequence_length_t, ), name = 'title_segment_{}'.format(name))\n",
    "    # Description\n",
    "    bug_d_token = Input(shape = (sequence_length_d, ), name = 'desc_token_{}'.format(name))\n",
    "    bug_d_segment = Input(shape = (sequence_length_d, ), name = 'desc_segment_{}'.format(name))\n",
    "    # Categorical\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model([bug_t_token, bug_t_segment])\n",
    "    bug_d_feat = desc_feature_model([bug_d_token, bug_d_segment])\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t_token, bug_t_segment, bug_d_token, bug_d_segment, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Average\n",
    "from keras_radam import RAdam\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, \n",
    "                         NUMBER_OF_INSTANCES, BATCH_SIZE, EPOCHS, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    \n",
    "    # Distance bugs\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances-bug',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    #output_avg_master = Average()([output_master, output_master_pos, output_master_neg])\n",
    "    #output = Average()([output_bug, output_avg_master])\n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = [output], name = 'Similarity_Model')\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer='adam', loss=custom_margin_loss, \n",
    "                                 metrics=[pos_distance, neg_distance])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size  64\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_pos (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_pos (InputLayer)  (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_pos (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_pos (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_neg (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_neg (InputLayer)  (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_neg (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_neg (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 768)          80346736    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "                                                                 title_token_pos[0][0]            \n",
      "                                                                 title_segment_pos[0][0]          \n",
      "                                                                 title_token_neg[0][0]            \n",
      "                                                                 title_segment_neg[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 768)          80346736    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "                                                                 desc_token_pos[0][0]             \n",
      "                                                                 desc_segment_pos[0][0]           \n",
      "                                                                 desc_token_neg[0][0]             \n",
      "                                                                 desc_segment_neg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1836)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 1836)         0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[2\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 1836)         0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[3\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances-bug (Lambda)    (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 161,198,372\n",
      "Trainable params: 726,196\n",
      "Non-trainable params: 160,472,176\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1 Loss: 1.02, pos_cosine: 0.89, neg_cosine: 0.92\n",
      "Epoch: 2 Loss: 1.02, pos_cosine: 0.90, neg_cosine: 0.93\n",
      "Epoch: 3 Loss: 1.02, pos_cosine: 0.90, neg_cosine: 0.93\n",
      "Epoch: 4 Loss: 1.02, pos_cosine: 0.91, neg_cosine: 0.93\n",
      "Epoch: 5 Loss: 1.02, pos_cosine: 0.92, neg_cosine: 0.93\n",
      "Epoch: 6 Loss: 1.02, pos_cosine: 0.92, neg_cosine: 0.94\n",
      "Epoch: 7 Loss: 1.01, pos_cosine: 0.92, neg_cosine: 0.94\n",
      "Epoch: 8 Loss: 1.01, pos_cosine: 0.93, neg_cosine: 0.94\n",
      "Epoch: 9 Loss: 1.02, pos_cosine: 0.93, neg_cosine: 0.95\n",
      "Epoch: 10 Loss: 1.01, pos_cosine: 0.94, neg_cosine: 0.95\n",
      "Epoch: 11 Loss: 1.01, pos_cosine: 0.94, neg_cosine: 0.96\n",
      "Epoch: 12 Loss: 1.01, pos_cosine: 0.95, neg_cosine: 0.96\n",
      "Epoch: 13 Loss: 1.01, pos_cosine: 0.95, neg_cosine: 0.96\n",
      "Epoch: 14 Loss: 1.01, pos_cosine: 0.95, neg_cosine: 0.96\n",
      "Epoch: 15 Loss: 1.01, pos_cosine: 0.96, neg_cosine: 0.97\n",
      "Epoch: 16 Loss: 1.01, pos_cosine: 0.96, neg_cosine: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 Loss: 1.01, pos_cosine: 0.96, neg_cosine: 0.97\n",
      "Epoch: 18 Loss: 1.00, pos_cosine: 0.97, neg_cosine: 0.97\n",
      "Epoch: 19 Loss: 1.00, pos_cosine: 0.97, neg_cosine: 0.98\n",
      "Epoch: 20 Loss: 1.00, pos_cosine: 0.97, neg_cosine: 0.98\n",
      "Epoch: 21 Loss: 1.00, pos_cosine: 0.97, neg_cosine: 0.98\n",
      "Epoch: 22 Loss: 1.00, pos_cosine: 0.98, neg_cosine: 0.98\n",
      "Epoch: 23 Loss: 1.00, pos_cosine: 0.98, neg_cosine: 0.98\n",
      "Epoch: 24 Loss: 1.00, pos_cosine: 0.98, neg_cosine: 0.98\n",
      "Epoch: 25 Loss: 1.01, pos_cosine: 0.98, neg_cosine: 0.99\n",
      "Epoch: 26 Loss: 1.01, pos_cosine: 0.98, neg_cosine: 0.98\n",
      "Epoch: 27 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 28 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 29 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 30 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 31 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 32 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 33 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 34 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 35 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 36 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 37 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 38 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 0.99\n",
      "Epoch: 39 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 40 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 41 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 42 Loss: 1.00, pos_cosine: 0.99, neg_cosine: 1.00\n",
      "Epoch: 43 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 44 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 45 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 46 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 47 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 48 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 49 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 50 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 51 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 52 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 53 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 54 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 55 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 56 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 57 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 58 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 59 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 60 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 61 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 62 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 63 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 64 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 65 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 66 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 67 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 68 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 69 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 70 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 71 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 72 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 73 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 74 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 75 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 76 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 77 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 78 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 79 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 80 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 81 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 82 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 83 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 84 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 85 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 86 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 87 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 88 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 89 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 90 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 91 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 92 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 93 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 94 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 95 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 96 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 97 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 98 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 99 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00\n",
      "Epoch: 100 Loss: 1.00, pos_cosine: 1.00, neg_cosine: 1.00, recall@25: 0.56\n",
      "Saved model 'modelos/model_propose_bert_triplet_100_feature_100epochs_64batch(eclipse).h5' to disk\n",
      "Best_epoch=83, Best_loss=1.00s, Recall@25=0.56\n",
      "CPU times: user 1h 13min 39s, sys: 1h 23min 23s, total: 2h 37min 2s\n",
      "Wall time: 2h 32min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "print(\"Batch size \", batch_size)\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_dilated_model\n",
    "    arcii_model\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    bilstm_model\n",
    "'''\n",
    "# title_feature_model = bilstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "title_feature_model = bert_model(MAX_SEQUENCE_LENGTH_T, 'Title')\n",
    "desc_feature_model = bert_model(MAX_SEQUENCE_LENGTH_D, 'Description')\n",
    "#desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "\n",
    "\n",
    "NUMBER_OF_INSTANCES = len(baseline.dup_sets_train)\n",
    "BATCH_SIZE = batch_size\n",
    "EPOCHS = epochs\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, \n",
    "                                            NUMBER_OF_INSTANCES, BATCH_SIZE, EPOCHS, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, train_sim = experiment.batch_iterator_bert(encoded_anchor, baseline.train_data, baseline.dup_sets_train, bug_train_ids, \n",
    "                                       batch_size, 1, issues_by_buckets)\n",
    "    \n",
    "    train_batch = [train_input_sample['title']['token'], train_input_sample['title']['segment'], train_input_sample['description']['token'], train_input_sample['description']['segment'], train_input_sample['info'],\n",
    "                   train_input_pos['title']['token'], train_input_pos['title']['segment'], train_input_pos['description']['token'], train_input_pos['description']['segment'], train_input_pos['info'], \n",
    "                   train_input_neg['title']['token'], train_input_neg['title']['segment'], train_input_neg['description']['token'], train_input_neg['description']['segment'], train_input_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, \n",
    "                                                               bug_train_ids, method='bert')\n",
    "        print(\"Epoch: {} Loss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}s, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['327681:324658|349698:0.9275888130068779,382193:0.9271839782595634,419879:0.927103690803051,379307:0.9268945828080177,387326:0.926813542842865,411055:0.926767148077488,373616:0.9267318025231361,339559:0.9264327138662338,317354:0.9262215942144394,408804:0.9261510372161865,378686:0.9259432405233383,382774:0.9258996769785881,369323:0.9258065074682236,421713:0.9255981668829918,371739:0.9255660474300385,339660:0.9255509823560715,422559:0.9255027025938034,380734:0.925346814095974,358328:0.9251073971390724,404262:0.9250729531049728,382604:0.9250468388199806,358326:0.9249281510710716,345394:0.9247261583805084,419880:0.9245997443795204,322782:0.9245677962899208,385273:0.9245665147900581,335784:0.9244606047868729,359021:0.9243979677557945,347079:0.9243347197771072',\n",
       " '324658:327681|364263:0.9289511740207672,359267:0.927791140973568,384962:0.9271568581461906,385202:0.9255689904093742,335448:0.9251424744725227,363792:0.924806997179985,387080:0.9246819466352463,359504:0.9245071560144424,408326:0.924295462667942,337099:0.9239651933312416,396678:0.9238078221678734,357203:0.9236892685294151,365275:0.9236009791493416,357573:0.9235509634017944,322210:0.9235392808914185,349788:0.9233258217573166,394482:0.9232323169708252,336962:0.9232238009572029,406684:0.9230938106775284,334309:0.9229971095919609,334310:0.9229971095919609,377720:0.922934465110302,320688:0.9229268878698349,340434:0.9228266924619675,322943:0.9228090718388557,337422:0.9227879792451859,356218:0.9227762296795845,365817:0.9227486327290535,327681:0.9226925447583199',\n",
       " '417795:417796,403749|417796:0.9903295701369643,403749:0.9456713423132896,368390:0.9407266043126583,422902:0.9402659721672535,406277:0.9393708407878876,348435:0.9392412789165974,398995:0.9390665106475353,350521:0.9383148178458214,389246:0.9372487515211105,409086:0.9357206374406815,390196:0.9344342350959778,334455:0.9336414262652397,341209:0.9333722963929176,104395:0.9333462119102478,377243:0.933037519454956,378139:0.9326084479689598,350323:0.9325669556856155,411794:0.9322323873639107,393359:0.931979201734066,87239:0.9313922896981239,348867:0.931220255792141,364815:0.9312084540724754,350396:0.9310078471899033,421292:0.9305037930607796,398965:0.9299378991127014,94755:0.9297422021627426,367866:0.9292119145393372,384922:0.9291309490799904,65876:0.9288177490234375',\n",
       " '417796:417795,403749|417795:0.9903295701369643,403749:0.9451180659234524,368390:0.9401346892118454,422902:0.9392488598823547,406277:0.9388453885912895,398995:0.9380792081356049,348435:0.9378345236182213,350521:0.9377591721713543,389246:0.9366954490542412,409086:0.9357376769185066,390196:0.9342498108744621,334455:0.932980015873909,104395:0.9326442629098892,377243:0.932079054415226,341209:0.9320364743471146,411794:0.9320260137319565,350323:0.9315613433718681,378139:0.9315484687685966,393359:0.9312018305063248,87239:0.930636078119278,350396:0.9305484294891357,364815:0.9305095076560974,421292:0.9302046075463295,348867:0.9301840513944626,398965:0.9289714992046356,384922:0.928717352449894,94755:0.9285622537136078,65876:0.9283419102430344,367866:0.9279997423291206',\n",
       " '403749:417795,417796|398995:0.9472647607326508,417795:0.9456713423132896,417796:0.9451180659234524,406277:0.9432309940457344,349798:0.9386326186358929,348435:0.9379989095032215,350521:0.936677023768425,394692:0.9363033324480057,409520:0.9362346902489662,104395:0.9354803562164307,409086:0.9352281540632248,407864:0.9349883869290352,398965:0.9347129762172699,348459:0.9344530627131462,348708:0.9343292117118835,383540:0.9336095154285431,384922:0.9330940097570419,409246:0.9327462762594223,364815:0.9322118312120438,418000:0.9321926161646843,399794:0.932152770459652,404690:0.9320023953914642,414631:0.9319356456398964,280819:0.9318196922540665,411794:0.9312656298279762,350323:0.9309328123927116,350375:0.930923119187355,378298:0.9308421686291695,390196:0.9307619333267212',\n",
       " '417796:417795,403749|417795:0.9903295701369643,403749:0.9451180659234524,368390:0.9401346892118454,422902:0.9392488598823547,406277:0.9388453885912895,398995:0.9380792081356049,348435:0.9378345236182213,350521:0.9377591721713543,389246:0.9366954490542412,409086:0.9357376769185066,390196:0.9342498108744621,334455:0.932980015873909,104395:0.9326442629098892,377243:0.932079054415226,341209:0.9320364743471146,411794:0.9320260137319565,350323:0.9315613433718681,378139:0.9315484687685966,393359:0.9312018305063248,87239:0.930636078119278,350396:0.9305484294891357,364815:0.9305095076560974,421292:0.9302046075463295,348867:0.9301840513944626,398965:0.9289714992046356,384922:0.928717352449894,94755:0.9285622537136078,65876:0.9283419102430344,367866:0.9279997423291206',\n",
       " '403749:417795,417796|398995:0.9472647607326508,417795:0.9456713423132896,417796:0.9451180659234524,406277:0.9432309940457344,349798:0.9386326186358929,348435:0.9379989095032215,350521:0.936677023768425,394692:0.9363033324480057,409520:0.9362346902489662,104395:0.9354803562164307,409086:0.9352281540632248,407864:0.9349883869290352,398965:0.9347129762172699,348459:0.9344530627131462,348708:0.9343292117118835,383540:0.9336095154285431,384922:0.9330940097570419,409246:0.9327462762594223,364815:0.9322118312120438,418000:0.9321926161646843,399794:0.932152770459652,404690:0.9320023953914642,414631:0.9319356456398964,280819:0.9318196922540665,411794:0.9312656298279762,350323:0.9309328123927116,350375:0.930923119187355,378298:0.9308421686291695,390196:0.9307619333267212',\n",
       " '319495:319752,319435,319915,319471,319895,318297,319514,319515,319517,319551|403339:0.9404655210673809,336302:0.9388240799307823,319515:0.9373511746525764,405707:0.9350355342030525,390153:0.9337769150733948,361120:0.9335822463035583,340402:0.9328344464302063,411745:0.9326862767338753,355950:0.9316471219062805,399608:0.9314430207014084,411482:0.9312574565410614,392061:0.9311609193682671,409513:0.9310816898941994,411120:0.9309578314423561,396128:0.930813767015934,370804:0.9306126534938812,378916:0.9306125640869141,393232:0.9304908737540245,225780:0.9304303005337715,354691:0.9300322383642197,402592:0.9300255998969078,376562:0.929981105029583,395752:0.9297673776745796,373174:0.9295343309640884,323459:0.9295032843947411,421946:0.9294739291071892,406736:0.9291989132761955,323601:0.9291699156165123,303904:0.929135374724865',\n",
       " '319752:319495,319435,319915,319471,319895,318297,319514,319515,319517,319551|406748:0.9405653700232506,318297:0.9339362531900406,338228:0.9330018386244774,419786:0.9329609274864197,405707:0.9321042075753212,376232:0.9317147582769394,340402:0.9308932051062584,396128:0.9307621568441391,404182:0.9302944764494896,403532:0.9301380142569542,403428:0.9300580099225044,391659:0.9297930896282196,388999:0.9297491237521172,355950:0.9294742867350578,225780:0.9294103384017944,390395:0.9293691366910934,358240:0.929220899939537,318623:0.9291038811206818,406926:0.9289504736661911,389108:0.9289439022541046,320590:0.9288421347737312,319131:0.9286179766058922,382974:0.9284253716468811,323601:0.9283683151006699,421946:0.9282932728528976,399608:0.9281475469470024,378421:0.928131602704525,319435:0.9279263019561768,408099:0.9278644397854805',\n",
       " '319435:319495,319752,319915,319471,319895,318297,319514,319515,319517,319551|419786:0.9306124895811081,403339:0.930536262691021,322312:0.929140143096447,406736:0.9285171031951904,389108:0.9281937852501869,319752:0.9279263019561768,389738:0.9275051802396774,347887:0.9273915365338326,340402:0.9273798242211342,336302:0.9273593053221703,390395:0.927072212100029,396548:0.9267454892396927,356306:0.9262286275625229,411034:0.9262115061283112,370804:0.9257624372839928,420310:0.9257470294833183,395577:0.9257089495658875,392674:0.9256375283002853,315906:0.9256187975406647,389594:0.9255601167678833,321218:0.9252731949090958,395915:0.9252073764801025,325028:0.9249963909387589,317902:0.9249350875616074,358240:0.9249292761087418,407749:0.9247150123119354,319495:0.9245694205164909,389805:0.9245137721300125,319438:0.9243592098355293',\n",
       " '319915:319495,319752,319435,319471,319895,318297,319514,319515,319517,319551|389738:0.9174214452505112,319752:0.9137376248836517,329650:0.9121311977505684,395752:0.9106471091508865,323459:0.9090483859181404,364395:0.9090351536870003,336302:0.9088641554117203,421474:0.9087222963571548,304678:0.9083114415407181,419786:0.9082280620932579,392674:0.9081349447369576,389861:0.9080847352743149,403532:0.9077920764684677,329721:0.9075506776571274,294321:0.9074498564004898,317763:0.9074480012059212,376232:0.907373920083046,391659:0.9073080196976662,319435:0.9069307744503021,373174:0.9068549275398254,390896:0.9063538759946823,325313:0.9062836170196533,394516:0.9062549322843552,411257:0.9058143422007561,382974:0.9057660698890686,262194:0.9051616117358208,386931:0.9051567167043686,368457:0.9051521569490433,409977:0.9049146398901939',\n",
       " '319471:319495,319752,319435,319915,319895,318297,319514,319515,319517,319551|332843:0.9397767707705498,333365:0.9377880580723286,342819:0.9353158101439476,420131:0.9353017434477806,340629:0.9351847395300865,381172:0.9351630583405495,351498:0.9348383992910385,341789:0.9338319599628448,317762:0.9335768148303032,320633:0.9334801509976387,322371:0.9334712401032448,368108:0.9334449470043182,419506:0.9332854449748993,379871:0.9332695156335831,343947:0.9332561567425728,319517:0.9331363067030907,353535:0.9328860118985176,346012:0.9327402040362358,375409:0.9324513450264931,333360:0.9323629215359688,335751:0.9321356490254402,416610:0.9320899546146393,340181:0.9320354014635086,423070:0.9318069219589233,354108:0.9314408972859383,414191:0.9313829839229584,331631:0.9313586875796318,422502:0.9311338737607002,368003:0.9311042428016663',\n",
       " '319895:319495,319752,319435,319915,319471,318297,319514,319515,319517,319551|401550:0.9386761002242565,319345:0.9306957796216011,361129:0.9306428730487823,392880:0.9305776730179787,322056:0.9293824210762978,328765:0.9288216903805733,376141:0.9281147569417953,322158:0.9270268380641937,417523:0.926689900457859,321483:0.92656259983778,347391:0.9263326898217201,312784:0.9256430864334106,396678:0.9254273995757103,363185:0.9254082813858986,339661:0.9252994135022163,323511:0.9250612556934357,411072:0.9245980083942413,328587:0.9245288968086243,321210:0.9244189038872719,317896:0.9243623241782188,355922:0.9243115782737732,320688:0.9241257533431053,325666:0.9239600002765656,316213:0.9239041805267334,352049:0.9237466603517532,319543:0.9233869165182114,328530:0.9232036173343658,303168:0.9231860637664795,409153:0.9230938851833344',\n",
       " '318297:319495,319752,319435,319915,319471,319895,319514,319515,319517,319551|319752:0.9339362531900406,364908:0.9333338662981987,344665:0.9332355037331581,360610:0.9326288923621178,374870:0.932577908039093,382486:0.9323615878820419,353905:0.9323095232248306,327414:0.9320135191082954,383539:0.9318080469965935,320931:0.9316976293921471,379401:0.9316354617476463,360623:0.931447334587574,342518:0.9312078803777695,348567:0.9309216067194939,345982:0.9308299273252487,339774:0.9307839572429657,402661:0.9305095225572586,410623:0.9303978309035301,319131:0.9298871830105782,323601:0.9296880587935448,343056:0.9296624287962914,315906:0.9294777885079384,395915:0.9291343688964844,420558:0.9289639592170715,341547:0.9289149343967438,344849:0.9289094433188438,415235:0.9286843687295914,361718:0.9286573752760887,413091:0.9286132007837296',\n",
       " '319514:319495,319752,319435,319915,319471,319895,318297,319515,319517,319551|402343:0.9372088313102722,324473:0.9371389672160149,319123:0.935833029448986,317929:0.9345939978957176,378155:0.9332747608423233,342114:0.933178722858429,325294:0.9327694103121758,320546:0.9323125705122948,351083:0.9316292405128479,344696:0.9305563643574715,328795:0.9303330779075623,314129:0.9302721694111824,390175:0.9300249889492989,328926:0.9299456477165222,373216:0.9297951832413673,332039:0.9297452792525291,366388:0.9297251328825951,358923:0.9296987727284431,407433:0.9295433238148689,381447:0.9291711375117302,329375:0.9291430935263634,350645:0.9290773943066597,390756:0.9285001903772354,347183:0.9284017086029053,320005:0.9281330555677414,396552:0.9280773997306824,365722:0.9279481023550034,352235:0.9279389381408691,356114:0.9277592524886131',\n",
       " '319515:319495,319752,319435,319915,319471,319895,318297,319514,319517,319551|374411:0.9403239339590073,411120:0.9402938596904278,319495:0.9373511746525764,271953:0.936846412718296,368184:0.9361451417207718,347606:0.9358711764216423,378421:0.9351977333426476,324470:0.9350480288267136,409356:0.9348827302455902,353470:0.9343903213739395,349387:0.9337344542145729,323255:0.9337157309055328,352801:0.9330216646194458,396548:0.9326439648866653,374870:0.9326320886611938,378916:0.9324046596884727,350030:0.932386040687561,372824:0.9323337450623512,340402:0.9322323501110077,382829:0.9322156682610512,328765:0.9320779666304588,413106:0.9320606589317322,316621:0.9319123551249504,323913:0.9318860024213791,357211:0.9317590370774269,357761:0.9316507875919342,335374:0.931622639298439,363194:0.9312011376023293,344665:0.9311004728078842',\n",
       " '319517:319495,319752,319435,319915,319471,319895,318297,319514,319515,319551|319471:0.9331363067030907,326517:0.9321170151233673,333365:0.9311933219432831,342819:0.9302517175674438,415368:0.9291798174381256,350669:0.9289387539029121,331632:0.9283300116658211,332311:0.9277335181832314,320802:0.9277301803231239,348339:0.9270975813269615,340629:0.9264637678861618,367118:0.9264503493905067,423070:0.9264347478747368,331631:0.9263947233557701,352026:0.9263283237814903,339276:0.9262926429510117,343947:0.9262238815426826,322371:0.9259377270936966,404003:0.9259027019143105,332843:0.9258190244436264,317762:0.9257825016975403,318020:0.9257636815309525,424320:0.9257069528102875,354108:0.9256996214389801,390558:0.9254138767719269,416917:0.9253978952765465,346700:0.9253668487071991,361181:0.9252767860889435,330765:0.9252496510744095',\n",
       " '319551:319495,319752,319435,319915,319471,319895,318297,319514,319515,319517|350701:0.9371093139052391,346906:0.9352615177631378,374590:0.9338977932929993,358138:0.9335394948720932,330530:0.9328257367014885,370058:0.9324006959795952,381476:0.9323161095380783,350698:0.9322353079915047,351778:0.9320709556341171,320027:0.9310141503810883,387178:0.9309743940830231,352174:0.9307849854230881,371901:0.9307361841201782,386255:0.9307211264967918,351018:0.9306232109665871,376022:0.9303807467222214,318809:0.9302630126476288,389581:0.9301311448216438,387003:0.9300558939576149,341428:0.9299771264195442,347602:0.9298952147364616,343009:0.9295272752642632,331301:0.9295032545924187,422471:0.9294959530234337,343754:0.9292884096503258,401910:0.929287277162075,403554:0.9292827323079109,350444:0.9290845394134521,389454:0.9290551468729973',\n",
       " '401416:401362,401363,401461,401023|374895:0.9396389313042164,401461:0.9355524554848671,333392:0.9355026558041573,330097:0.9352667704224586,379376:0.9346164613962173,380606:0.9345837756991386,401419:0.9336710795760155,343563:0.9336535856127739,376166:0.9332546815276146,393735:0.9331648275256157,351413:0.9329418763518333,373904:0.9328613355755806,338783:0.9328378066420555,379473:0.932483971118927,355927:0.9324188604950905,410675:0.9323780760169029,330702:0.9322434067726135,401023:0.9322419539093971,415024:0.9322215616703033,335206:0.9320093840360641,322867:0.9319682866334915,319998:0.9319588541984558,381661:0.9319238886237144,378497:0.9313546642661095,373896:0.9311605244874954,372384:0.9310813471674919,319853:0.9309880882501602,366022:0.9306048080325127,313873:0.9305550456047058',\n",
       " '401362:401416,401363,401461,401023|382112:0.9232310354709625,392674:0.9190374240279198,419841:0.918824590742588,409356:0.9187754020094872,357117:0.9187476709485054,396548:0.9180921465158463,341628:0.9175993129611015,402661:0.9174282252788544,367948:0.9173103421926498,390896:0.917037807404995,389738:0.9167620837688446,360783:0.9165063053369522,382829:0.9164832681417465,403339:0.9162419438362122,406676:0.9160602539777756,415235:0.9160085842013359,408680:0.9159967973828316,421946:0.9159795194864273,392494:0.9158820807933807,380714:0.9156124144792557,395921:0.9155303314328194,406669:0.9154404848814011,421474:0.9154147431254387,405350:0.9153538048267365,350988:0.9152775481343269,339673:0.9152334481477737,399971:0.9152048230171204,394516:0.9151546359062195,412515:0.9150295183062553']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall, exported_rank, debug = experiment.evaluate_validation_test(experiment, retrieval, verbose, \n",
    "#                                                         encoded_anchor, issues_by_buckets, evaluate_validation_test)\n",
    "# test_vectorized, queries_test_vectorized, annoy, X_test, distance_test, indices_test = debug\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 4641\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'propose_bert_triplet_100_feature_100epochs_64batch(eclipse)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoded_anchor\n",
    "# model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 768)          80346736    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 768)          80346736    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1836)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "==================================================================================================\n",
      "Total params: 161,198,372\n",
      "Trainable params: 726,196\n",
      "Non-trainable params: 160,472,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, \n",
    "                                                                   bug_train_ids, method='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/eclipse/exported_rank_propose_bert_triplet_100.txt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.42,\n",
       " '2 - recall_at_10': 0.48,\n",
       " '3 - recall_at_15': 0.52,\n",
       " '4 - recall_at_20': 0.55,\n",
       " '5 - recall_at_25': 0.56}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
