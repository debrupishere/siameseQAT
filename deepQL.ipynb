{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# Propose centroid replacing the masters with BERT siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import keras\n",
    "# from tensorflow.python import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the use of GPUs\n",
    "# https://datascience.stackexchange.com/questions/23895/multi-gpu-in-keras\n",
    "# https://keras.io/getting-started/faq/#how-can-i-run-a-keras-model-on-multiple-gpus\n",
    "# https://stackoverflow.com/questions/56316451/how-to-use-specific-gpus-in-keras-for-multi-gpu-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnSCLmiomFE1"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c57gQiuAnJAe",
    "outputId": "9eaf2d3f-619a-492d-f40b-6ba2c48426fa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 20\n",
    "MAX_SEQUENCE_LENGTH_D = 20 # 80\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = 1000\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = 'eclipse'\n",
    "METHOD = 'propose_centroid_bert_{}'.format(epochs)\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}'.format(DOMAIN)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Path embeddings\n",
    "EMBED_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_feature@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_feature_@number_of_epochs@epochs_64batch({})'.format(METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D)\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buckets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5812bee091e148b3a47452380b2dbbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=322339), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dd75c0c9f7413bbcd55b56196502ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39545), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "361006"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "# !unzip -o uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "model_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_vocabulary\n",
    "\n",
    "token_dict = load_vocabulary(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 30522'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(token_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d7e19ff79e41e592c39adc28b221a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=361006), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ca65c183564e44b1f0802889dd30a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 27.6 s, sys: 3.01 s, total: 30.6 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs()\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12211729342241e78f07548b574f5f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=321536), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n",
      "CPU times: user 2min 37s, sys: 13.7 ms, total: 2min 37s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a random bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': '2\\n',\n",
       " 'bug_status': '0\\n',\n",
       " 'component': '30\\n',\n",
       " 'creation_ts': '2008-02-20 13:14:00 -0500',\n",
       " 'delta_ts': '2008-05-20 19:41:45 -0400',\n",
       " 'description': '[CLS] i \\' ve moved up to higgins sts milestone 1 . 0 using nightly build n ##200 ##80 ##21 ##3 . after rebuilding against and installing under web ##sphere 6 . 1 , i \\' m getting a java . lang . null ##point ##ere ##x ##ception at servers ##er ##vic ##eb ##ind ##ing . java : 55 when i submit a w ##s - trust validation request . i think that you \\' ve told me that you can remove those trace statements from the gets ##er ##vic ##e ( ) method . if you can fix this for higgins milestone 1 . 0 , that would allow me to move up . org . eclipse . higgins . sts . binding . axis ##1 ##x . service \\\\ sr ##c \\\\ org \\\\ eclipse \\\\ higgins \\\\ sts \\\\ binding \\\\ axis ##1 ##x \\\\ servers ##er ##vic ##eb ##ind ##ing . java : public org . eclipse . higgins . configuration . api . icon ##fi ##gur ##able ##com ##pone ##nt gets ##er ##vic ##e ( ) throws exception { java . ut ##il . map map ##gl ##ob ##als ##etti ##ng ##s = this . get ##gl ##ob ##als ##etti ##ng ##s ( ) ; string st ##rse ##r ##vic ##ena ##me = this . gets ##er ##vic ##ena ##me ( ) ; object objects ##er ##vic ##e = map ##gl ##ob ##als ##etti ##ng ##s . get ( st ##rse ##r ##vic ##ena ##me ) ; remove - - - - - - > log . trace ( \" service : \" + st ##rse ##r ##vic ##ena ##me + \" from : \" + objects ##er ##vic ##e . get ##class ( ) . get ##pro ##tec ##tion ##dom ##ain ( ) . get ##codes ##our ##ce ( ) . get ##lo ##cation ( ) . get ##fi ##le ( ) ) ; remove - - - - - - > log . trace ( \" icon ##fi ##gur ##able ##com ##pone ##nt from : \" + org . eclipse . higgins . configuration . api . icon ##fi ##gur ##able ##com ##pone ##nt . class . get ##pro ##tec ##tion ##dom ##ain ( ) . get ##codes ##our ##ce ( ) . get ##lo ##cation ( ) . get ##fi ##le ( ) ) ; return ( org . eclipse . higgins . configuration . api . icon ##fi ##gur ##able ##com ##pone ##nt ) ( map ##gl ##ob ##als ##etti ##ng ##s . get ( this . gets ##er ##vic ##ena ##me ( ) ) ) ; } [SEP]',\n",
       " 'description_bert': '[CLS] i \\' ve moved up to higgins sts milestone 1 . 0 using nightly build n ##200 ##80 ##21 ##3 . after rebuilding against and installing under web ##sphere 6 . 1 , i \\' m getting a java . lang . null ##point ##ere ##x ##ception at servers ##er ##vic ##eb ##ind ##ing . java : 55 when i submit a w ##s - trust validation request . i think that you \\' ve told me that you can remove those trace statements from the gets ##er ##vic ##e ( ) method . if you can fix this for higgins milestone 1 . 0 , that would allow me to move up . org . eclipse . higgins . sts . binding . axis ##1 ##x . service \\\\ sr ##c \\\\ org \\\\ eclipse \\\\ higgins \\\\ sts \\\\ binding \\\\ axis ##1 ##x \\\\ servers ##er ##vic ##eb ##ind ##ing . java : public org . eclipse . higgins . configuration . api . icon ##fi ##gur ##able ##com ##pone ##nt gets ##er ##vic ##e ( ) throws exception { java . ut ##il . map map ##gl ##ob ##als ##etti ##ng ##s = this . get ##gl ##ob ##als ##etti ##ng ##s ( ) ; string st ##rse ##r ##vic ##ena ##me = this . gets ##er ##vic ##ena ##me ( ) ; object objects ##er ##vic ##e = map ##gl ##ob ##als ##etti ##ng ##s . get ( st ##rse ##r ##vic ##ena ##me ) ; remove - - - - - - > log . trace ( \" service : \" + st ##rse ##r ##vic ##ena ##me + \" from : \" + objects ##er ##vic ##e . get ##class ( ) . get ##pro ##tec ##tion ##dom ##ain ( ) . get ##codes ##our ##ce ( ) . get ##lo ##cation ( ) . get ##fi ##le ( ) ) ; remove - - - - - - > log . trace ( \" icon ##fi ##gur ##able ##com ##pone ##nt from : \" + org . eclipse . higgins . configuration . api . icon ##fi ##gur ##able ##com ##pone ##nt . class . get ##pro ##tec ##tion ##dom ##ain ( ) . get ##codes ##our ##ce ( ) . get ##lo ##cation ( ) . get ##fi ##le ( ) ) ; return ( org . eclipse . higgins . configuration . api . icon ##fi ##gur ##able ##com ##pone ##nt ) ( map ##gl ##ob ##als ##etti ##ng ##s . get ( this . gets ##er ##vic ##ena ##me ( ) ) ) ; } [SEP]',\n",
       " 'description_word': array([  101,  1045,  1005,  2310,  2333,  2039,  2000, 13466,  8541,\n",
       "        19199,  1015,  1012,  1014,  2478, 22390,  3857,  1050, 28332,\n",
       "        17914, 17465]),\n",
       " 'description_word_bert': [101,\n",
       "  1045,\n",
       "  1005,\n",
       "  2310,\n",
       "  2333,\n",
       "  2039,\n",
       "  2000,\n",
       "  13466,\n",
       "  8541,\n",
       "  19199,\n",
       "  1015,\n",
       "  1012,\n",
       "  1014,\n",
       "  2478,\n",
       "  22390,\n",
       "  3857,\n",
       "  1050,\n",
       "  28332,\n",
       "  17914,\n",
       "  17465,\n",
       "  2509,\n",
       "  1012,\n",
       "  2044,\n",
       "  14584,\n",
       "  2114,\n",
       "  1998,\n",
       "  23658,\n",
       "  2104,\n",
       "  4773,\n",
       "  23874,\n",
       "  1020,\n",
       "  1012,\n",
       "  1015,\n",
       "  1010,\n",
       "  1045,\n",
       "  1005,\n",
       "  1049,\n",
       "  2893,\n",
       "  1037,\n",
       "  9262,\n",
       "  1012,\n",
       "  11374,\n",
       "  1012,\n",
       "  19701,\n",
       "  8400,\n",
       "  7869,\n",
       "  2595,\n",
       "  24422,\n",
       "  2012,\n",
       "  14903,\n",
       "  2121,\n",
       "  7903,\n",
       "  15878,\n",
       "  22254,\n",
       "  2075,\n",
       "  1012,\n",
       "  9262,\n",
       "  1024,\n",
       "  4583,\n",
       "  2043,\n",
       "  1045,\n",
       "  12040,\n",
       "  1037,\n",
       "  1059,\n",
       "  2015,\n",
       "  1011,\n",
       "  3404,\n",
       "  27354,\n",
       "  5227,\n",
       "  1012,\n",
       "  1045,\n",
       "  2228,\n",
       "  2008,\n",
       "  2017,\n",
       "  1005,\n",
       "  2310,\n",
       "  2409,\n",
       "  2033,\n",
       "  2008,\n",
       "  2017,\n",
       "  2064,\n",
       "  6366,\n",
       "  2216,\n",
       "  7637,\n",
       "  8635,\n",
       "  2013,\n",
       "  1996,\n",
       "  4152,\n",
       "  2121,\n",
       "  7903,\n",
       "  2063,\n",
       "  1006,\n",
       "  1007,\n",
       "  4118,\n",
       "  1012,\n",
       "  2065,\n",
       "  2017,\n",
       "  2064,\n",
       "  8081,\n",
       "  2023,\n",
       "  2005,\n",
       "  13466,\n",
       "  19199,\n",
       "  1015,\n",
       "  1012,\n",
       "  1014,\n",
       "  1010,\n",
       "  2008,\n",
       "  2052,\n",
       "  3499,\n",
       "  2033,\n",
       "  2000,\n",
       "  2693,\n",
       "  2039,\n",
       "  1012,\n",
       "  8917,\n",
       "  1012,\n",
       "  13232,\n",
       "  1012,\n",
       "  13466,\n",
       "  1012,\n",
       "  8541,\n",
       "  1012,\n",
       "  8031,\n",
       "  1012,\n",
       "  8123,\n",
       "  2487,\n",
       "  2595,\n",
       "  1012,\n",
       "  2326,\n",
       "  1032,\n",
       "  5034,\n",
       "  2278,\n",
       "  1032,\n",
       "  8917,\n",
       "  1032,\n",
       "  13232,\n",
       "  1032,\n",
       "  13466,\n",
       "  1032,\n",
       "  8541,\n",
       "  1032,\n",
       "  8031,\n",
       "  1032,\n",
       "  8123,\n",
       "  2487,\n",
       "  2595,\n",
       "  1032,\n",
       "  14903,\n",
       "  102],\n",
       " 'dup_id': '[]',\n",
       " 'issue_id': 219638,\n",
       " 'priority': '4\\n',\n",
       " 'product': '51\\n',\n",
       " 'resolution': 'FIXED',\n",
       " 'textual_word': array([  101, 19701,  8400,  2121,  6453,  1999, 14903,  2121,  7903,\n",
       "        15878, 22254,  2075,  1012,  4152,  2121,  7903,  2063,  1006,\n",
       "         1007,  2104,   101,  1045,  1005,  2310,  2333,  2039,  2000,\n",
       "        13466,  8541, 19199,  1015,  1012,  1014,  2478, 22390,  3857,\n",
       "         1050, 28332, 17914, 17465]),\n",
       " 'title': '[CLS] null ##point ##er exception in servers ##er ##vic ##eb ##ind ##ing . gets ##er ##vic ##e ( ) under web ##sphere [SEP]',\n",
       " 'title_bert': '[CLS] null ##point ##er exception in servers ##er ##vic ##eb ##ind ##ing . gets ##er ##vic ##e ( ) under web ##sphere [SEP]',\n",
       " 'title_word': array([  101, 19701,  8400,  2121,  6453,  1999, 14903,  2121,  7903,\n",
       "        15878, 22254,  2075,  1012,  4152,  2121,  7903,  2063,  1006,\n",
       "         1007,  2104]),\n",
       " 'title_word_bert': [101,\n",
       "  19701,\n",
       "  8400,\n",
       "  2121,\n",
       "  6453,\n",
       "  1999,\n",
       "  14903,\n",
       "  2121,\n",
       "  7903,\n",
       "  15878,\n",
       "  22254,\n",
       "  2075,\n",
       "  1012,\n",
       "  4152,\n",
       "  2121,\n",
       "  7903,\n",
       "  2063,\n",
       "  1006,\n",
       "  1007,\n",
       "  2104,\n",
       "  4773,\n",
       "  23874,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'version': '334\\n'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 34882)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indexed all train'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_idx = bug_train_ids[0]\n",
    "vector = baseline.bug_set[bug_idx]['textual_word']\n",
    "annoy_train = AnnoyIndex(vector.shape[0])\n",
    "for bug_id in bug_train_ids:\n",
    "    annoy_train.add_item(bug_id, baseline.bug_set[bug_id]['textual_word'])\n",
    "annoy_train.build(10) # 10 trees\n",
    "\"Indexed all train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.6 ms, sys: 11 µs, total: 52.6 ms\n",
      "Wall time: 52.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_input_pos, valid_input_neg, \\\n",
    "                            valid_master_sample, valid_master_neg, valid_sim = experiment.batch_iterator_bert(None, baseline.train_data, \n",
    "                                                                                          baseline.dup_sets_train,\n",
    "                                                                                          bug_train_ids,\n",
    "                                                                                          batch_size_test, 1, \n",
    "                                                                                              issues_by_buckets, INCLUDE_MASTER=True)\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title']['token'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description']['token'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 20), (128, 20), (128, 1682), (128,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title']['token'].shape, valid_input_sample['description']['token'].shape, \\\n",
    "    valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5, batch_iterator, issues_by_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Propose\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomUniform, RandomNormal, Ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "https://github.com/CyberZHG/keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import compile_model, get_model\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "def bert_model(MAX_SEQUENCE_LENGTH, name):\n",
    "    layer_num = 8\n",
    "#     model = load_trained_model_from_checkpoint(\n",
    "#             config_path,\n",
    "#             model_path,\n",
    "#             training=True,\n",
    "#             trainable=True,\n",
    "#             seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#     )\n",
    "    model = load_trained_model_from_checkpoint(\n",
    "        config_path,\n",
    "        model_path,\n",
    "        training=False,\n",
    "        use_adapter=True,\n",
    "        seq_len=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=['Encoder-{}-MultiHeadSelfAttention-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-MultiHeadSelfAttention-Norm'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Norm'.format(i + 1) for i in range(layer_num)],\n",
    "    )\n",
    "#     model = get_model(\n",
    "#         token_num=len(token_dict),\n",
    "#         head_num=10,\n",
    "#         transformer_num=layer_num,\n",
    "#         embed_dim=100,\n",
    "#         feed_forward_dim=100,\n",
    "#         seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#         pos_num=MAX_SEQUENCE_LENGTH,\n",
    "#         dropout_rate=0.05,\n",
    "#     )\n",
    "    compile_model(model)\n",
    "    inputs = model.inputs[:2]\n",
    "    outputs = model.get_layer('Encoder-{}-FeedForward-Norm'.format(layer_num)).output\n",
    "    #outputs = model.get_layer('Extract').output\n",
    "    outputs = GlobalAveragePooling1D()(outputs)\n",
    "#     outputs = Dense(300, activation='tanh')(outputs)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='FeatureBERTGenerationModel{}'.format(name))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    #layer = GRU(100, activation='tanh')(layer)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "'''\n",
    "    Some loss ideas\n",
    "    hinge loss Kullback-Leibler\n",
    "    https://stackoverflow.com/questions/53581298/custom-combined-hinge-kb-divergence-loss-function-in-siamese-net-fails-to-genera\n",
    "'''\n",
    "\n",
    "def normalize(x, axis):\n",
    "    norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=False))\n",
    "    return x, K.maximum(norm, K.epsilon())\n",
    "    \n",
    "# https://github.com/keras-team/keras/issues/3031\n",
    "# https://github.com/keras-team/keras/issues/8335\n",
    "def cosine_distance(inputs):\n",
    "    x, y = inputs\n",
    "    x, x_norm = normalize(x, axis=-1)\n",
    "    y, y_norm = normalize(y, axis=-1)\n",
    "    distance = K.sum( x * y, axis=-1) / (x_norm * y_norm)\n",
    "    distance = (distance + K.constant(1)) / K.constant(2)\n",
    "    # Distance goes from 0 to 2 in theory, but from 0 to 1 if x and y are both\n",
    "    # positive (which is the case after ReLU activation).\n",
    "    return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    distance = K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "    # Normalize https://stats.stackexchange.com/questions/53068/euclidean-distance-score-and-similarity\n",
    "    distance = K.constant(1) / (K.constant(1) + distance)\n",
    "    return K.mean(distance, keepdims=False)\n",
    "    #return K.mean(distance, axis=-1, keepdims=False)\n",
    "\n",
    "# https://jdhao.github.io/2017/03/13/some_loss_and_explanations/\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.mean(K.maximum(0.0, pos - neg + margin))\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred):\n",
    "    margin = K.constant(1.0)\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    return K.mean(K.maximum(0.0, margin - pos + neg), keepdims=False)\n",
    "\n",
    "# https://www.kaggle.com/c/quora-question-pairs/discussion/33631\n",
    "# https://www.researchgate.net/figure/Illustration-of-triplet-loss-contrastive-loss-for-negative-samples-and-binomial_fig2_322060548\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    pos = y_pred[0]\n",
    "    neg = y_pred[1]\n",
    "    margin = 1\n",
    "    return K.mean(pos * K.square(neg) +\n",
    "                  (1 - pos) * K.square(K.maximum(margin - neg, 0)))\n",
    "\n",
    "def pos_distance(y_true, y_pred):\n",
    "    return y_pred[0]\n",
    "\n",
    "def neg_distance(y_true, y_pred):\n",
    "    return y_pred[1]\n",
    "\n",
    "def stack_tensors(vects):\n",
    "    return K.stack(vects, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, Add, Lambda, Average, Maximum, Subtract, Average, AveragePooling1D, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "    \n",
    "    # Title\n",
    "    bug_t_token = Input(shape = (sequence_length_t, ), name = 'title_token_{}'.format(name))\n",
    "    bug_t_segment = Input(shape = (sequence_length_t, ), name = 'title_segment_{}'.format(name))\n",
    "    # Description\n",
    "    bug_d_token = Input(shape = (sequence_length_d, ), name = 'desc_token_{}'.format(name))\n",
    "    bug_d_segment = Input(shape = (sequence_length_d, ), name = 'desc_segment_{}'.format(name))\n",
    "    # Categorical\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model([bug_t_token, bug_t_segment])\n",
    "    bug_d_feat = desc_feature_model([bug_d_token, bug_d_segment])\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t_token, bug_t_segment, bug_d_token, bug_d_segment, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Average\n",
    "from keras_radam import RAdam\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "def max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, \n",
    "                             master_anchor, master_negative, master_positive, \n",
    "                         NUMBER_OF_INSTANCES, BATCH_SIZE, EPOCHS, decay_lr=1):\n",
    "    \n",
    "    inputs = np.concatenate([encoded_anchor.input, encoded_positive.input, encoded_negative.input, \n",
    "                                 master_anchor.input, master_positive.input, master_negative.input], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    encoded_positive = encoded_positive.output\n",
    "    encoded_negative = encoded_negative.output\n",
    "    master_anchor = master_anchor.output\n",
    "    master_negative = master_negative.output\n",
    "    master_positive = master_positive.output\n",
    "    \n",
    "    # Distance bugs\n",
    "    positive_d = Lambda(cosine_distance, name='pos_cosine_distance', output_shape=[1])([encoded_anchor, encoded_positive])\n",
    "    negative_d = Lambda(cosine_distance, name='neg_cosine_distance', output_shape=[1])([encoded_anchor, encoded_negative])\n",
    "    \n",
    "    # Distance masters anchor\n",
    "    master_anchor_positive_d = Lambda(cosine_distance, name='pos_master_cosine_distance', output_shape=[1])([encoded_anchor, master_positive])\n",
    "    master_anchor_negative_d = Lambda(cosine_distance, name='neg_master_cosine_distance', output_shape=[1])([encoded_anchor, master_negative])\n",
    "    \n",
    "    # Distance master positive\n",
    "    master_pos_positive_d = Lambda(cosine_distance, name='pos_master_pos_cosine_distance', output_shape=[1])([encoded_positive, master_positive])\n",
    "    master_pos_negative_d = Lambda(cosine_distance, name='neg_master_pos_cosine_distance', output_shape=[1])([encoded_positive, master_negative])\n",
    "    \n",
    "    # Distance master negative\n",
    "    master_neg_positive_d = Lambda(cosine_distance, name='pos_master_neg_cosine_distance', output_shape=[1])([encoded_negative, master_negative])\n",
    "    master_neg_negative_d = Lambda(cosine_distance, name='neg_master_neg_cosine_distance', output_shape=[1])([encoded_negative, master_positive])\n",
    "    \n",
    "\n",
    "    # Loss function only works with a single output\n",
    "    output_bug = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances-bug',\n",
    "        output_shape=(2, 1)\n",
    "    )([positive_d, negative_d])\n",
    "    \n",
    "    output_master = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances-master-anchor',\n",
    "        output_shape=(2, 1)\n",
    "    )([master_anchor_positive_d, master_anchor_negative_d])\n",
    "    \n",
    "    output_master_pos = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances-master-pos',\n",
    "        output_shape=(2, 1)\n",
    "    )([master_pos_positive_d, master_pos_negative_d])\n",
    "    \n",
    "    output_master_neg = Lambda(\n",
    "        lambda vects: stack_tensors(vects),\n",
    "        name='stack-distances-master-neg',\n",
    "        output_shape=(2, 1)\n",
    "    )([master_neg_positive_d, master_neg_negative_d])\n",
    "    \n",
    "    output = Average()([output_bug, output_master, output_master_pos, output_master_neg])\n",
    "    \n",
    "    #output_avg_master = Average()([output_master, output_master_pos, output_master_neg])\n",
    "    #output = Average()([output_bug, output_avg_master])\n",
    "    #loss = MarginLoss()(output)\n",
    "\n",
    "    similarity_model = Model(inputs = inputs, outputs = [output], name = 'Similarity_Model')\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer='adam', loss=custom_margin_loss, \n",
    "                                 metrics=[pos_distance, neg_distance])\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size  64\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_pos (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_pos (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_pos (InputLayer)  (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_pos (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_pos (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_neg (InputLayer)           (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_neg (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_neg (InputLayer)  (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_neg (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_neg (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_master_pos (InputLayer)    (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_master_pos (InputLa (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_master_pos (Input (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_master_pos (InputLay (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_master_pos (InputL (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "info_master_neg (InputLayer)    (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_master_neg (InputLa (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_master_neg (Input (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_master_neg (InputLay (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_master_neg (InputL (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "                                                                 info_pos[0][0]                   \n",
      "                                                                 info_neg[0][0]                   \n",
      "                                                                 info_master_pos[0][0]            \n",
      "                                                                 info_master_neg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 768)          80346736    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "                                                                 title_token_pos[0][0]            \n",
      "                                                                 title_segment_pos[0][0]          \n",
      "                                                                 title_token_neg[0][0]            \n",
      "                                                                 title_segment_neg[0][0]          \n",
      "                                                                 title_token_master_pos[0][0]     \n",
      "                                                                 title_segment_master_pos[0][0]   \n",
      "                                                                 title_token_master_neg[0][0]     \n",
      "                                                                 title_segment_master_neg[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 768)          80346736    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "                                                                 desc_token_pos[0][0]             \n",
      "                                                                 desc_segment_pos[0][0]           \n",
      "                                                                 desc_token_neg[0][0]             \n",
      "                                                                 desc_segment_neg[0][0]           \n",
      "                                                                 desc_token_master_pos[0][0]      \n",
      "                                                                 desc_segment_master_pos[0][0]    \n",
      "                                                                 desc_token_master_neg[0][0]      \n",
      "                                                                 desc_segment_master_neg[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1836)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_pos (Concatenate (None, 1836)         0           FeatureMlpGenerationModel[2][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[2\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_neg (Concatenate (None, 1836)         0           FeatureMlpGenerationModel[3][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[3\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_master_pos (Conc (None, 1836)         0           FeatureMlpGenerationModel[5][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[5\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "merge_features_master_neg (Conc (None, 1836)         0           FeatureMlpGenerationModel[6][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[6\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "__________________________________________________________________________________________________\n",
      "pos_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_pos[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "neg_cosine_distance (Lambda)    (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_neg[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "pos_master_cosine_distance (Lam (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_master_pos[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "neg_master_cosine_distance (Lam (None, 1)            0           merge_features_in[0][0]          \n",
      "                                                                 merge_features_master_neg[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_master_pos_cosine_distance  (None, 1)            0           merge_features_pos[0][0]         \n",
      "                                                                 merge_features_master_pos[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "neg_master_pos_cosine_distance  (None, 1)            0           merge_features_pos[0][0]         \n",
      "                                                                 merge_features_master_neg[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "pos_master_neg_cosine_distance  (None, 1)            0           merge_features_neg[0][0]         \n",
      "                                                                 merge_features_master_neg[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "neg_master_neg_cosine_distance  (None, 1)            0           merge_features_neg[0][0]         \n",
      "                                                                 merge_features_master_pos[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances-bug (Lambda)    (None, 2, 1)         0           pos_cosine_distance[0][0]        \n",
      "                                                                 neg_cosine_distance[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances-master-anchor ( (None, 2, 1)         0           pos_master_cosine_distance[0][0] \n",
      "                                                                 neg_master_cosine_distance[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stack-distances-master-pos (Lam (None, 2, 1)         0           pos_master_pos_cosine_distance[0]\n",
      "                                                                 neg_master_pos_cosine_distance[0]\n",
      "__________________________________________________________________________________________________\n",
      "stack-distances-master-neg (Lam (None, 2, 1)         0           pos_master_neg_cosine_distance[0]\n",
      "                                                                 neg_master_neg_cosine_distance[0]\n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 2, 1)         0           stack-distances-bug[0][0]        \n",
      "                                                                 stack-distances-master-anchor[0][\n",
      "                                                                 stack-distances-master-pos[0][0] \n",
      "                                                                 stack-distances-master-neg[0][0] \n",
      "==================================================================================================\n",
      "Total params: 161,198,372\n",
      "Trainable params: 726,196\n",
      "Non-trainable params: 160,472,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.99, pos_cosine: 0.91, neg_cosine: 0.90\n",
      "Epoch: 2 Loss: 0.99, pos_cosine: 0.91, neg_cosine: 0.90\n",
      "Epoch: 3 Loss: 0.98, pos_cosine: 0.91, neg_cosine: 0.89\n",
      "Epoch: 4 Loss: 0.98, pos_cosine: 0.90, neg_cosine: 0.88\n",
      "Epoch: 5 Loss: 0.97, pos_cosine: 0.90, neg_cosine: 0.87\n",
      "Epoch: 6 Loss: 0.98, pos_cosine: 0.88, neg_cosine: 0.86\n",
      "Epoch: 7 Loss: 0.98, pos_cosine: 0.88, neg_cosine: 0.85\n",
      "Epoch: 8 Loss: 0.98, pos_cosine: 0.87, neg_cosine: 0.85\n",
      "Epoch: 9 Loss: 0.98, pos_cosine: 0.86, neg_cosine: 0.83\n",
      "Epoch: 10 Loss: 0.97, pos_cosine: 0.85, neg_cosine: 0.82\n",
      "Epoch: 11 Loss: 0.97, pos_cosine: 0.84, neg_cosine: 0.81\n",
      "Epoch: 12 Loss: 0.96, pos_cosine: 0.84, neg_cosine: 0.80\n",
      "Epoch: 13 Loss: 0.96, pos_cosine: 0.83, neg_cosine: 0.78\n",
      "Epoch: 14 Loss: 0.96, pos_cosine: 0.81, neg_cosine: 0.78\n",
      "Epoch: 15 Loss: 0.97, pos_cosine: 0.80, neg_cosine: 0.77\n",
      "Epoch: 16 Loss: 0.96, pos_cosine: 0.78, neg_cosine: 0.75\n",
      "Epoch: 17 Loss: 0.95, pos_cosine: 0.79, neg_cosine: 0.74\n",
      "Epoch: 18 Loss: 0.96, pos_cosine: 0.77, neg_cosine: 0.73\n",
      "Epoch: 19 Loss: 0.95, pos_cosine: 0.76, neg_cosine: 0.71\n",
      "Epoch: 20 Loss: 0.95, pos_cosine: 0.75, neg_cosine: 0.70\n",
      "Epoch: 21 Loss: 0.93, pos_cosine: 0.76, neg_cosine: 0.69\n",
      "Epoch: 22 Loss: 0.95, pos_cosine: 0.74, neg_cosine: 0.69\n",
      "Epoch: 23 Loss: 0.93, pos_cosine: 0.74, neg_cosine: 0.68\n",
      "Epoch: 24 Loss: 0.94, pos_cosine: 0.73, neg_cosine: 0.68\n",
      "Epoch: 25 Loss: 0.93, pos_cosine: 0.74, neg_cosine: 0.67\n",
      "Epoch: 26 Loss: 0.95, pos_cosine: 0.71, neg_cosine: 0.66\n",
      "Epoch: 27 Loss: 0.94, pos_cosine: 0.71, neg_cosine: 0.65\n",
      "Epoch: 28 Loss: 0.92, pos_cosine: 0.72, neg_cosine: 0.64\n",
      "Epoch: 29 Loss: 0.95, pos_cosine: 0.70, neg_cosine: 0.65\n",
      "Epoch: 30 Loss: 0.93, pos_cosine: 0.72, neg_cosine: 0.64\n",
      "Epoch: 31 Loss: 0.94, pos_cosine: 0.68, neg_cosine: 0.63\n",
      "Epoch: 32 Loss: 0.95, pos_cosine: 0.70, neg_cosine: 0.65\n",
      "Epoch: 33 Loss: 0.93, pos_cosine: 0.69, neg_cosine: 0.62\n",
      "Epoch: 34 Loss: 0.94, pos_cosine: 0.68, neg_cosine: 0.61\n",
      "Epoch: 35 Loss: 0.93, pos_cosine: 0.70, neg_cosine: 0.63\n",
      "Epoch: 36 Loss: 0.93, pos_cosine: 0.68, neg_cosine: 0.62\n",
      "Epoch: 37 Loss: 0.93, pos_cosine: 0.67, neg_cosine: 0.61\n",
      "Epoch: 38 Loss: 0.93, pos_cosine: 0.67, neg_cosine: 0.60\n",
      "Epoch: 39 Loss: 0.92, pos_cosine: 0.69, neg_cosine: 0.62\n",
      "Epoch: 40 Loss: 0.91, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 41 Loss: 0.92, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 42 Loss: 0.91, pos_cosine: 0.70, neg_cosine: 0.61\n",
      "Epoch: 43 Loss: 0.92, pos_cosine: 0.68, neg_cosine: 0.60\n",
      "Epoch: 44 Loss: 0.92, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 45 Loss: 0.93, pos_cosine: 0.67, neg_cosine: 0.60\n",
      "Epoch: 46 Loss: 0.93, pos_cosine: 0.68, neg_cosine: 0.60\n",
      "Epoch: 47 Loss: 0.92, pos_cosine: 0.66, neg_cosine: 0.58\n",
      "Epoch: 48 Loss: 0.91, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 49 Loss: 0.93, pos_cosine: 0.66, neg_cosine: 0.59\n",
      "Epoch: 50 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.61\n",
      "Epoch: 51 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 52 Loss: 0.92, pos_cosine: 0.68, neg_cosine: 0.60\n",
      "Epoch: 53 Loss: 0.92, pos_cosine: 0.68, neg_cosine: 0.60\n",
      "Epoch: 54 Loss: 0.92, pos_cosine: 0.67, neg_cosine: 0.59\n",
      "Epoch: 55 Loss: 0.91, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 56 Loss: 0.91, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 57 Loss: 0.90, pos_cosine: 0.68, neg_cosine: 0.58\n",
      "Epoch: 58 Loss: 0.90, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 59 Loss: 0.90, pos_cosine: 0.68, neg_cosine: 0.58\n",
      "Epoch: 60 Loss: 0.93, pos_cosine: 0.70, neg_cosine: 0.63\n",
      "Epoch: 61 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 62 Loss: 0.90, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 63 Loss: 0.89, pos_cosine: 0.68, neg_cosine: 0.57\n",
      "Epoch: 64 Loss: 0.92, pos_cosine: 0.67, neg_cosine: 0.59\n",
      "Epoch: 65 Loss: 0.91, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 66 Loss: 0.91, pos_cosine: 0.67, neg_cosine: 0.58\n",
      "Epoch: 67 Loss: 0.94, pos_cosine: 0.67, neg_cosine: 0.61\n",
      "Epoch: 68 Loss: 0.91, pos_cosine: 0.67, neg_cosine: 0.59\n",
      "Epoch: 69 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 70 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 71 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 72 Loss: 0.91, pos_cosine: 0.67, neg_cosine: 0.58\n",
      "Epoch: 73 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 74 Loss: 0.90, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 75 Loss: 0.91, pos_cosine: 0.67, neg_cosine: 0.57\n",
      "Epoch: 76 Loss: 0.91, pos_cosine: 0.67, neg_cosine: 0.59\n",
      "Epoch: 77 Loss: 0.92, pos_cosine: 0.66, neg_cosine: 0.57\n",
      "Epoch: 78 Loss: 0.91, pos_cosine: 0.67, neg_cosine: 0.58\n",
      "Epoch: 79 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 80 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 81 Loss: 0.92, pos_cosine: 0.67, neg_cosine: 0.59\n",
      "Epoch: 82 Loss: 0.92, pos_cosine: 0.70, neg_cosine: 0.62\n",
      "Epoch: 83 Loss: 0.89, pos_cosine: 0.69, neg_cosine: 0.58\n",
      "Epoch: 84 Loss: 0.92, pos_cosine: 0.68, neg_cosine: 0.60\n",
      "Epoch: 85 Loss: 0.90, pos_cosine: 0.68, neg_cosine: 0.58\n",
      "Epoch: 86 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 87 Loss: 0.92, pos_cosine: 0.67, neg_cosine: 0.58\n",
      "Epoch: 88 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 89 Loss: 0.89, pos_cosine: 0.69, neg_cosine: 0.58\n",
      "Epoch: 90 Loss: 0.90, pos_cosine: 0.67, neg_cosine: 0.58\n",
      "Epoch: 91 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 92 Loss: 0.91, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 93 Loss: 0.90, pos_cosine: 0.68, neg_cosine: 0.58\n",
      "Epoch: 94 Loss: 0.89, pos_cosine: 0.69, neg_cosine: 0.58\n",
      "Epoch: 95 Loss: 0.91, pos_cosine: 0.67, neg_cosine: 0.58\n",
      "Epoch: 96 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 97 Loss: 0.89, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 98 Loss: 0.88, pos_cosine: 0.70, neg_cosine: 0.58\n",
      "Epoch: 99 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.58\n",
      "Epoch: 100 Loss: 0.89, pos_cosine: 0.69, neg_cosine: 0.58\n",
      "Epoch: 101 Loss: 0.91, pos_cosine: 0.68, neg_cosine: 0.58\n",
      "Epoch: 102 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 103 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 104 Loss: 0.88, pos_cosine: 0.70, neg_cosine: 0.58\n",
      "Epoch: 105 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 106 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 107 Loss: 0.89, pos_cosine: 0.69, neg_cosine: 0.58\n",
      "Epoch: 108 Loss: 0.92, pos_cosine: 0.69, neg_cosine: 0.61\n",
      "Epoch: 109 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 110 Loss: 0.89, pos_cosine: 0.69, neg_cosine: 0.58\n",
      "Epoch: 111 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 112 Loss: 0.90, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 113 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 114 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 115 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 116 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 117 Loss: 0.91, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 118 Loss: 0.92, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 119 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 120 Loss: 0.88, pos_cosine: 0.70, neg_cosine: 0.58\n",
      "Epoch: 121 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 122 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 123 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 124 Loss: 0.90, pos_cosine: 0.68, neg_cosine: 0.59\n",
      "Epoch: 125 Loss: 0.87, pos_cosine: 0.71, neg_cosine: 0.58\n",
      "Epoch: 126 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 127 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 128 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 129 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 130 Loss: 0.86, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 131 Loss: 0.89, pos_cosine: 0.69, neg_cosine: 0.58\n",
      "Epoch: 132 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 133 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.58\n",
      "Epoch: 134 Loss: 0.92, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 135 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 136 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 137 Loss: 0.91, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 138 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 139 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 140 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 141 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 142 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 143 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 144 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 146 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 147 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 148 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 149 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 150 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 151 Loss: 0.88, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 152 Loss: 0.89, pos_cosine: 0.69, neg_cosine: 0.58\n",
      "Epoch: 153 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 154 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 155 Loss: 0.90, pos_cosine: 0.69, neg_cosine: 0.59\n",
      "Epoch: 156 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 157 Loss: 0.87, pos_cosine: 0.71, neg_cosine: 0.58\n",
      "Epoch: 158 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 159 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 160 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 161 Loss: 0.87, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 162 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.58\n",
      "Epoch: 163 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 164 Loss: 0.88, pos_cosine: 0.70, neg_cosine: 0.58\n",
      "Epoch: 165 Loss: 0.91, pos_cosine: 0.69, neg_cosine: 0.60\n",
      "Epoch: 166 Loss: 0.91, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 167 Loss: 0.87, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 168 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 169 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 170 Loss: 0.87, pos_cosine: 0.71, neg_cosine: 0.58\n",
      "Epoch: 171 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 172 Loss: 0.90, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 173 Loss: 0.87, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 174 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 175 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 176 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 177 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 178 Loss: 0.88, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 179 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 180 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 181 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 182 Loss: 0.87, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 183 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 184 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 185 Loss: 0.86, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 186 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 187 Loss: 0.86, pos_cosine: 0.72, neg_cosine: 0.58\n",
      "Epoch: 188 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 189 Loss: 0.87, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 190 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 191 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 192 Loss: 0.87, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 193 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 194 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 195 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 196 Loss: 0.90, pos_cosine: 0.72, neg_cosine: 0.62\n",
      "Epoch: 197 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 198 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 199 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 200 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 201 Loss: 0.87, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 202 Loss: 0.89, pos_cosine: 0.69, neg_cosine: 0.58\n",
      "Epoch: 203 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 204 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 205 Loss: 0.90, pos_cosine: 0.71, neg_cosine: 0.61\n",
      "Epoch: 206 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 207 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 208 Loss: 0.87, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 209 Loss: 0.90, pos_cosine: 0.71, neg_cosine: 0.61\n",
      "Epoch: 210 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 211 Loss: 0.87, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 212 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 213 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 214 Loss: 0.90, pos_cosine: 0.71, neg_cosine: 0.62\n",
      "Epoch: 215 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 216 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 217 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.61\n",
      "Epoch: 218 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 219 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 220 Loss: 0.86, pos_cosine: 0.73, neg_cosine: 0.59\n",
      "Epoch: 221 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 222 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 223 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 224 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 225 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 226 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 227 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 228 Loss: 0.90, pos_cosine: 0.71, neg_cosine: 0.61\n",
      "Epoch: 229 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 230 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 231 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 232 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 233 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 234 Loss: 0.90, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 235 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 236 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 237 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 238 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 239 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 240 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 241 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 242 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 243 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 244 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 245 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 246 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 247 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 248 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 249 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 250 Loss: 0.90, pos_cosine: 0.71, neg_cosine: 0.61\n",
      "Epoch: 251 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 252 Loss: 0.89, pos_cosine: 0.70, neg_cosine: 0.59\n",
      "Epoch: 253 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 254 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 255 Loss: 0.87, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 256 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 257 Loss: 0.85, pos_cosine: 0.75, neg_cosine: 0.60\n",
      "Epoch: 258 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 259 Loss: 0.86, pos_cosine: 0.73, neg_cosine: 0.59\n",
      "Epoch: 260 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 261 Loss: 0.87, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 262 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 263 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 264 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 265 Loss: 0.90, pos_cosine: 0.71, neg_cosine: 0.61\n",
      "Epoch: 266 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 267 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 268 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 269 Loss: 0.86, pos_cosine: 0.72, neg_cosine: 0.58\n",
      "Epoch: 270 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 271 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.59\n",
      "Epoch: 272 Loss: 0.87, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 273 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 274 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 275 Loss: 0.87, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 276 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 277 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 278 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 279 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 280 Loss: 0.88, pos_cosine: 0.71, neg_cosine: 0.59\n",
      "Epoch: 281 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 282 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 283 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 284 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 285 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 286 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 287 Loss: 0.87, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 288 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 289 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 290 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 291 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 292 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.59\n",
      "Epoch: 293 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 294 Loss: 0.85, pos_cosine: 0.74, neg_cosine: 0.59\n",
      "Epoch: 295 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.59\n",
      "Epoch: 296 Loss: 0.89, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 297 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 298 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 299 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 300 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 301 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 302 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 303 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 304 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 305 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 306 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 307 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 308 Loss: 0.90, pos_cosine: 0.72, neg_cosine: 0.63\n",
      "Epoch: 309 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 310 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 311 Loss: 0.89, pos_cosine: 0.73, neg_cosine: 0.62\n",
      "Epoch: 312 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 313 Loss: 0.89, pos_cosine: 0.73, neg_cosine: 0.62\n",
      "Epoch: 314 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 315 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 316 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 317 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 318 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 319 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 320 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.60\n",
      "Epoch: 321 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 322 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 323 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 324 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 325 Loss: 0.89, pos_cosine: 0.73, neg_cosine: 0.62\n",
      "Epoch: 326 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 327 Loss: 0.85, pos_cosine: 0.74, neg_cosine: 0.59\n",
      "Epoch: 328 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 329 Loss: 0.85, pos_cosine: 0.74, neg_cosine: 0.59\n",
      "Epoch: 330 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 331 Loss: 0.89, pos_cosine: 0.73, neg_cosine: 0.62\n",
      "Epoch: 332 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 333 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 334 Loss: 0.89, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 335 Loss: 0.90, pos_cosine: 0.72, neg_cosine: 0.63\n",
      "Epoch: 336 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 337 Loss: 0.86, pos_cosine: 0.73, neg_cosine: 0.59\n",
      "Epoch: 338 Loss: 0.85, pos_cosine: 0.74, neg_cosine: 0.59\n",
      "Epoch: 339 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 340 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 341 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 342 Loss: 0.89, pos_cosine: 0.73, neg_cosine: 0.62\n",
      "Epoch: 343 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 344 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 345 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 346 Loss: 0.84, pos_cosine: 0.76, neg_cosine: 0.60\n",
      "Epoch: 347 Loss: 0.90, pos_cosine: 0.71, neg_cosine: 0.61\n",
      "Epoch: 348 Loss: 0.86, pos_cosine: 0.73, neg_cosine: 0.59\n",
      "Epoch: 349 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 350 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 351 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.60\n",
      "Epoch: 352 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 353 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 354 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 355 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 356 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 357 Loss: 0.89, pos_cosine: 0.71, neg_cosine: 0.60\n",
      "Epoch: 358 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 359 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 360 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 361 Loss: 0.85, pos_cosine: 0.74, neg_cosine: 0.59\n",
      "Epoch: 362 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 363 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 364 Loss: 0.90, pos_cosine: 0.70, neg_cosine: 0.60\n",
      "Epoch: 365 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 366 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 367 Loss: 0.85, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 368 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.59\n",
      "Epoch: 369 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 370 Loss: 0.90, pos_cosine: 0.73, neg_cosine: 0.63\n",
      "Epoch: 371 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 372 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 373 Loss: 0.89, pos_cosine: 0.73, neg_cosine: 0.63\n",
      "Epoch: 374 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 375 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 376 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 377 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 378 Loss: 0.89, pos_cosine: 0.74, neg_cosine: 0.63\n",
      "Epoch: 379 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 380 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.60\n",
      "Epoch: 381 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 382 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 383 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 384 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 385 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 386 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 387 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 388 Loss: 0.85, pos_cosine: 0.75, neg_cosine: 0.59\n",
      "Epoch: 389 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 390 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.62\n",
      "Epoch: 391 Loss: 0.85, pos_cosine: 0.75, neg_cosine: 0.60\n",
      "Epoch: 392 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 393 Loss: 0.88, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 394 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 395 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 396 Loss: 0.85, pos_cosine: 0.74, neg_cosine: 0.59\n",
      "Epoch: 397 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 398 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.64\n",
      "Epoch: 399 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 400 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 401 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 402 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 403 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 404 Loss: 0.85, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 405 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 406 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 407 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 408 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 409 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 410 Loss: 0.86, pos_cosine: 0.73, neg_cosine: 0.59\n",
      "Epoch: 411 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 412 Loss: 0.86, pos_cosine: 0.73, neg_cosine: 0.60\n",
      "Epoch: 413 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 414 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 415 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 416 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 417 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 418 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 419 Loss: 0.87, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 420 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 421 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 422 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 423 Loss: 0.88, pos_cosine: 0.73, neg_cosine: 0.61\n",
      "Epoch: 424 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.61\n",
      "Epoch: 425 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 426 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 427 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 428 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 429 Loss: 0.89, pos_cosine: 0.74, neg_cosine: 0.63\n",
      "Epoch: 430 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 431 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 432 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 433 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 434 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 435 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 436 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 437 Loss: 0.89, pos_cosine: 0.73, neg_cosine: 0.62\n",
      "Epoch: 438 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 439 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 440 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 441 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 442 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 443 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 444 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 445 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 446 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 447 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 448 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 449 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 450 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 451 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 452 Loss: 0.89, pos_cosine: 0.75, neg_cosine: 0.64\n",
      "Epoch: 453 Loss: 0.88, pos_cosine: 0.76, neg_cosine: 0.64\n",
      "Epoch: 454 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 455 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 456 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 457 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 458 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 459 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 460 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 461 Loss: 0.89, pos_cosine: 0.74, neg_cosine: 0.63\n",
      "Epoch: 462 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 463 Loss: 0.90, pos_cosine: 0.72, neg_cosine: 0.62\n",
      "Epoch: 464 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 465 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 466 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 467 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 468 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 469 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 470 Loss: 0.89, pos_cosine: 0.75, neg_cosine: 0.64\n",
      "Epoch: 471 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.60\n",
      "Epoch: 472 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 473 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 474 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 475 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 476 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 477 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 478 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 479 Loss: 0.89, pos_cosine: 0.75, neg_cosine: 0.64\n",
      "Epoch: 480 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 481 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 482 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 483 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 484 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 485 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 486 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 487 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 488 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.62\n",
      "Epoch: 489 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 490 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 491 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 492 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 493 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 494 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 495 Loss: 0.89, pos_cosine: 0.72, neg_cosine: 0.61\n",
      "Epoch: 496 Loss: 0.88, pos_cosine: 0.76, neg_cosine: 0.64\n",
      "Epoch: 497 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 498 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 499 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 500 Loss: 0.84, pos_cosine: 0.77, neg_cosine: 0.61\n",
      "Epoch: 501 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 502 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 503 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 504 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 505 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 506 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 507 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 508 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 509 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 510 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 511 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 512 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 513 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 514 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 515 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 516 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 517 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 518 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 519 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 520 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 521 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 522 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 523 Loss: 0.88, pos_cosine: 0.76, neg_cosine: 0.64\n",
      "Epoch: 524 Loss: 0.86, pos_cosine: 0.74, neg_cosine: 0.60\n",
      "Epoch: 525 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 526 Loss: 0.88, pos_cosine: 0.74, neg_cosine: 0.62\n",
      "Epoch: 527 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.61\n",
      "Epoch: 528 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 529 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 530 Loss: 0.84, pos_cosine: 0.77, neg_cosine: 0.61\n",
      "Epoch: 531 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 532 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 533 Loss: 0.87, pos_cosine: 0.74, neg_cosine: 0.61\n",
      "Epoch: 534 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 535 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 536 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 537 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 538 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.60\n",
      "Epoch: 539 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 540 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 541 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 542 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 543 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 544 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 545 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 546 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 547 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 548 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 549 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 550 Loss: 0.83, pos_cosine: 0.78, neg_cosine: 0.61\n",
      "Epoch: 551 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 552 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 553 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 554 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 555 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 556 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 557 Loss: 0.83, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 558 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 559 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 560 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 561 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 562 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 563 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 564 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 565 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 566 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 567 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.61\n",
      "Epoch: 568 Loss: 0.86, pos_cosine: 0.75, neg_cosine: 0.61\n",
      "Epoch: 569 Loss: 0.84, pos_cosine: 0.77, neg_cosine: 0.61\n",
      "Epoch: 570 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 571 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 572 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 573 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 574 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 575 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 576 Loss: 0.84, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 577 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 578 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 579 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 580 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 581 Loss: 0.84, pos_cosine: 0.77, neg_cosine: 0.61\n",
      "Epoch: 582 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 583 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.61\n",
      "Epoch: 584 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 585 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.65\n",
      "Epoch: 586 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 587 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 588 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 589 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 590 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 591 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 592 Loss: 0.85, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 593 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 594 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 595 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 596 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 597 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 598 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 599 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 600 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 601 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 602 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 603 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 604 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 605 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 606 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 607 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 608 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 609 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 610 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 611 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 612 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 613 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 614 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 615 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 616 Loss: 0.88, pos_cosine: 0.77, neg_cosine: 0.65\n",
      "Epoch: 617 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 618 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 619 Loss: 0.88, pos_cosine: 0.77, neg_cosine: 0.65\n",
      "Epoch: 620 Loss: 0.84, pos_cosine: 0.77, neg_cosine: 0.61\n",
      "Epoch: 621 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 622 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 623 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 624 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 625 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 626 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 627 Loss: 0.83, pos_cosine: 0.79, neg_cosine: 0.62\n",
      "Epoch: 628 Loss: 0.88, pos_cosine: 0.77, neg_cosine: 0.65\n",
      "Epoch: 629 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 630 Loss: 0.88, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 631 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 632 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 633 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 634 Loss: 0.88, pos_cosine: 0.77, neg_cosine: 0.65\n",
      "Epoch: 635 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 636 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 637 Loss: 0.88, pos_cosine: 0.76, neg_cosine: 0.64\n",
      "Epoch: 638 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 639 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 640 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 641 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 642 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 643 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 644 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 645 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 646 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 647 Loss: 0.83, pos_cosine: 0.79, neg_cosine: 0.62\n",
      "Epoch: 648 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 649 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 650 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 651 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 652 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 653 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 654 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 655 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 656 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 657 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 658 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 659 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 660 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 661 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 662 Loss: 0.88, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 663 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 664 Loss: 0.84, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 665 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 666 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 667 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 668 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 669 Loss: 0.88, pos_cosine: 0.76, neg_cosine: 0.65\n",
      "Epoch: 670 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 671 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 672 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 673 Loss: 0.89, pos_cosine: 0.76, neg_cosine: 0.66\n",
      "Epoch: 674 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 675 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 676 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 677 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 678 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 679 Loss: 0.82, pos_cosine: 0.81, neg_cosine: 0.63\n",
      "Epoch: 680 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 681 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 682 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 683 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 684 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 685 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 686 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 687 Loss: 0.88, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 688 Loss: 0.89, pos_cosine: 0.76, neg_cosine: 0.64\n",
      "Epoch: 689 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 690 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 691 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 692 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 693 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 694 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 695 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 696 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 697 Loss: 0.87, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 698 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 699 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 700 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 701 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 702 Loss: 0.89, pos_cosine: 0.75, neg_cosine: 0.64\n",
      "Epoch: 703 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 704 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 705 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 706 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 707 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.66\n",
      "Epoch: 708 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 709 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 710 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 711 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 712 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 713 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 714 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 715 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 716 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 717 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 718 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 719 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 720 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.66\n",
      "Epoch: 721 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 722 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 723 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 724 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 725 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 726 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 727 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 728 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 729 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 730 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 731 Loss: 0.83, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 732 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 733 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 734 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 735 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 736 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 737 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.64\n",
      "Epoch: 738 Loss: 0.87, pos_cosine: 0.76, neg_cosine: 0.63\n",
      "Epoch: 739 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 740 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 741 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 742 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 743 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 744 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 745 Loss: 0.82, pos_cosine: 0.81, neg_cosine: 0.63\n",
      "Epoch: 746 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 747 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 748 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 749 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 750 Loss: 0.83, pos_cosine: 0.78, neg_cosine: 0.61\n",
      "Epoch: 751 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 752 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 753 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 754 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 755 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 756 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 757 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 758 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 759 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 760 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 761 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 762 Loss: 0.85, pos_cosine: 0.81, neg_cosine: 0.65\n",
      "Epoch: 763 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 764 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 765 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 766 Loss: 0.88, pos_cosine: 0.75, neg_cosine: 0.63\n",
      "Epoch: 767 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 768 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 769 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 770 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 771 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 772 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 773 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 774 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 775 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 776 Loss: 0.87, pos_cosine: 0.75, neg_cosine: 0.62\n",
      "Epoch: 777 Loss: 0.86, pos_cosine: 0.76, neg_cosine: 0.62\n",
      "Epoch: 778 Loss: 0.89, pos_cosine: 0.76, neg_cosine: 0.65\n",
      "Epoch: 779 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 780 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 781 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 782 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 783 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 784 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 785 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 786 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 787 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 788 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 789 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 790 Loss: 0.83, pos_cosine: 0.79, neg_cosine: 0.62\n",
      "Epoch: 791 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 792 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.66\n",
      "Epoch: 793 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 794 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 795 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 796 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 797 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 798 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 799 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 800 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 801 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 802 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 803 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 804 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 805 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 806 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 807 Loss: 0.87, pos_cosine: 0.79, neg_cosine: 0.66\n",
      "Epoch: 808 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 809 Loss: 0.88, pos_cosine: 0.76, neg_cosine: 0.64\n",
      "Epoch: 810 Loss: 0.89, pos_cosine: 0.76, neg_cosine: 0.65\n",
      "Epoch: 811 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 812 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 813 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 814 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 815 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 816 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 817 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 818 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 819 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 820 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 821 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 822 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 823 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 824 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 825 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 826 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 827 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 828 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 829 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 830 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 831 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 832 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 833 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 834 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 835 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 836 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.66\n",
      "Epoch: 837 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 838 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 839 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 840 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.66\n",
      "Epoch: 841 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 842 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 843 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 844 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 845 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 846 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 847 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 848 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 849 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 850 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 851 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 852 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 853 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 854 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 855 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 856 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 857 Loss: 0.85, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 858 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 859 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 860 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 861 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 862 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 863 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.66\n",
      "Epoch: 864 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 865 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 866 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 867 Loss: 0.84, pos_cosine: 0.81, neg_cosine: 0.65\n",
      "Epoch: 868 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 869 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 870 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 871 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 872 Loss: 0.86, pos_cosine: 0.81, neg_cosine: 0.67\n",
      "Epoch: 873 Loss: 0.85, pos_cosine: 0.81, neg_cosine: 0.66\n",
      "Epoch: 874 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 875 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 876 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 877 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 878 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 879 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 880 Loss: 0.88, pos_cosine: 0.76, neg_cosine: 0.64\n",
      "Epoch: 881 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 882 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 883 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 884 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 885 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 886 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 887 Loss: 0.83, pos_cosine: 0.79, neg_cosine: 0.62\n",
      "Epoch: 888 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 889 Loss: 0.84, pos_cosine: 0.81, neg_cosine: 0.65\n",
      "Epoch: 890 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 891 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 892 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 893 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 894 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 895 Loss: 0.87, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 896 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 897 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 898 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 899 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 900 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 901 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 902 Loss: 0.83, pos_cosine: 0.81, neg_cosine: 0.64\n",
      "Epoch: 903 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 904 Loss: 0.83, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 905 Loss: 0.82, pos_cosine: 0.82, neg_cosine: 0.64\n",
      "Epoch: 906 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.63\n",
      "Epoch: 907 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 908 Loss: 0.87, pos_cosine: 0.79, neg_cosine: 0.66\n",
      "Epoch: 909 Loss: 0.83, pos_cosine: 0.78, neg_cosine: 0.61\n",
      "Epoch: 910 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 911 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 912 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 913 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 914 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 915 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 916 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 917 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.61\n",
      "Epoch: 918 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 919 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 920 Loss: 0.88, pos_cosine: 0.78, neg_cosine: 0.66\n",
      "Epoch: 921 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 922 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 923 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 924 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 925 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 926 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 927 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 928 Loss: 0.88, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 929 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 930 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 931 Loss: 0.87, pos_cosine: 0.79, neg_cosine: 0.67\n",
      "Epoch: 932 Loss: 0.83, pos_cosine: 0.81, neg_cosine: 0.64\n",
      "Epoch: 933 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 934 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 935 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 936 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 937 Loss: 0.83, pos_cosine: 0.81, neg_cosine: 0.64\n",
      "Epoch: 938 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 939 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 940 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 941 Loss: 0.86, pos_cosine: 0.77, neg_cosine: 0.62\n",
      "Epoch: 942 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 943 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 944 Loss: 0.83, pos_cosine: 0.81, neg_cosine: 0.64\n",
      "Epoch: 945 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 946 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 947 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 948 Loss: 0.87, pos_cosine: 0.79, neg_cosine: 0.66\n",
      "Epoch: 949 Loss: 0.88, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 950 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 951 Loss: 0.83, pos_cosine: 0.78, neg_cosine: 0.61\n",
      "Epoch: 952 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 953 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 954 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 955 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 956 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 957 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 958 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 959 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 960 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 961 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 962 Loss: 0.88, pos_cosine: 0.76, neg_cosine: 0.64\n",
      "Epoch: 963 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 964 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 965 Loss: 0.87, pos_cosine: 0.77, neg_cosine: 0.64\n",
      "Epoch: 966 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 967 Loss: 0.87, pos_cosine: 0.79, neg_cosine: 0.66\n",
      "Epoch: 968 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 969 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 970 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 971 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 972 Loss: 0.84, pos_cosine: 0.79, neg_cosine: 0.63\n",
      "Epoch: 973 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 974 Loss: 0.83, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 975 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.66\n",
      "Epoch: 976 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 977 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 978 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 979 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.66\n",
      "Epoch: 980 Loss: 0.86, pos_cosine: 0.80, neg_cosine: 0.66\n",
      "Epoch: 981 Loss: 0.84, pos_cosine: 0.81, neg_cosine: 0.65\n",
      "Epoch: 982 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 983 Loss: 0.85, pos_cosine: 0.79, neg_cosine: 0.64\n",
      "Epoch: 984 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 985 Loss: 0.83, pos_cosine: 0.81, neg_cosine: 0.65\n",
      "Epoch: 986 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 987 Loss: 0.87, pos_cosine: 0.79, neg_cosine: 0.66\n",
      "Epoch: 988 Loss: 0.88, pos_cosine: 0.78, neg_cosine: 0.65\n",
      "Epoch: 989 Loss: 0.85, pos_cosine: 0.78, neg_cosine: 0.63\n",
      "Epoch: 990 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 991 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.64\n",
      "Epoch: 992 Loss: 0.84, pos_cosine: 0.78, neg_cosine: 0.62\n",
      "Epoch: 993 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.66\n",
      "Epoch: 994 Loss: 0.86, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 995 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.63\n",
      "Epoch: 996 Loss: 0.84, pos_cosine: 0.80, neg_cosine: 0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 997 Loss: 0.85, pos_cosine: 0.80, neg_cosine: 0.65\n",
      "Epoch: 998 Loss: 0.87, pos_cosine: 0.78, neg_cosine: 0.64\n",
      "Epoch: 999 Loss: 0.86, pos_cosine: 0.79, neg_cosine: 0.65\n",
      "Epoch: 1000 Loss: 0.87, pos_cosine: 0.79, neg_cosine: 0.66, recall@25: 0.63\n",
      "Saved model 'modelos/model_propose_centroid_bert_1000_feature_1000epochs_64batch(eclipse).h5' to disk\n",
      "Best_epoch=905, Best_loss=0.82s, Recall@25=0.63\n",
      "CPU times: user 17h 35min 27s, sys: 1d 6h 40min 45s, total: 2d 16min 12s\n",
      "Wall time: 1d 17h 5min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "print(\"Batch size \", batch_size)\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_dilated_model\n",
    "    arcii_model\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    bilstm_model\n",
    "'''\n",
    "# title_feature_model = bilstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "title_feature_model = bert_model(MAX_SEQUENCE_LENGTH_T, 'Title')\n",
    "desc_feature_model = bert_model(MAX_SEQUENCE_LENGTH_D, 'Description')\n",
    "#desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "encoded_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'pos')\n",
    "encoded_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'neg')\n",
    "# Master model\n",
    "master_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'master_in')\n",
    "master_positive = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'master_pos')\n",
    "master_negative = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'master_neg')\n",
    "\n",
    "NUMBER_OF_INSTANCES = len(baseline.dup_sets_train)\n",
    "BATCH_SIZE = batch_size\n",
    "EPOCHS = epochs\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, \n",
    "                                            master_anchor, master_negative, master_positive,\n",
    "                                            NUMBER_OF_INSTANCES, BATCH_SIZE, EPOCHS, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "for epoch in range(epochs):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_input_pos, train_input_neg, train_master_input, train_master_neg, \\\n",
    "            train_sim = experiment.batch_iterator_bert(encoded_anchor, baseline.train_data, baseline.dup_sets_train, \\\n",
    "                                                       bug_train_ids, \n",
    "                                       batch_size, 1, issues_by_buckets, USE_CENTROID=True)\n",
    "    \n",
    "    train_batch = [train_input_sample['title']['token'], train_input_sample['title']['segment'], train_input_sample['description']['token'], train_input_sample['description']['segment'], train_input_sample['info'],\n",
    "                   train_input_pos['title']['token'], train_input_pos['title']['segment'], train_input_pos['description']['token'], train_input_pos['description']['segment'], train_input_pos['info'], \n",
    "                   train_input_neg['title']['token'], train_input_neg['title']['segment'], train_input_neg['description']['token'], train_input_neg['description']['segment'], train_input_neg['info'],\n",
    "                  train_input_sample['title']['token'], train_input_sample['title']['segment'], train_input_sample['description']['token'], train_input_sample['description']['segment'], train_input_sample['info'],\n",
    "                  train_master_input['title']['token'], train_master_input['title']['segment'], train_master_input['description']['token'], train_master_input['description']['segment'], train_master_input['info'],\n",
    "                   train_master_neg['title']['token'], train_master_neg['title']['segment'], train_master_neg['description']['token'], train_master_neg['description']['segment'], train_master_neg['info']]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    \n",
    "    if (epoch+1 == epochs): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, _, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, \n",
    "                                                               bug_train_ids, method='bert')\n",
    "        print(\"Epoch: {} Loss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}, recall@25: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],\n",
    "                                                                                                         h[1], h[2], recall))\n",
    "    else:\n",
    "        print(\"Epoch: {} Loss: {:.2f}, pos_cosine: {:.2f}, neg_cosine: {:.2f}\".format(epoch+1,\n",
    "                                                                                                         h[0],\n",
    "                                                                                                         h[1],\n",
    "                                                                                                         h[2]))\n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}s, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['327681:324658|328902:0.20219290256500244,385231:0.14864778518676758,385123:0.11840546131134033,368864:0.10125398635864258,403605:0.08657681941986084,352380:0.08451366424560547,345394:0.08418786525726318,384096:0.08212721347808838,375221:0.07378482818603516,354967:0.06539309024810791,401574:0.054329633712768555,389770:0.04940605163574219,324658:0.04428708553314209,359853:0.044245362281799316,424120:0.042270779609680176,386059:0.04154181480407715,349802:0.03825533390045166,317354:0.03647923469543457,391255:0.030619263648986816,383253:0.022669553756713867,384086:0.022188186645507812,404112:0.01717376708984375,386001:0.016611576080322266,382247:0.010206460952758789,355512:0.0082017183303833,351350:0.006562232971191406,394384:0.0024319887161254883,346913:0.0016518831253051758,375393:0.0',\n",
       " '324658:327681|363792:0.08784544467926025,411467:0.0643991231918335,406684:0.0418318510055542,358568:0.04155397415161133,393124:0.0317002534866333,354901:0.026573657989501953,353218:0.022261857986450195,399571:0.021602272987365723,416267:0.01273965835571289,369291:0.011150836944580078,412623:0.009876608848571777,323006:0.009587287902832031,391117:0.009363055229187012,367722:0.00919795036315918,402040:0.009184002876281738,361773:0.008729696273803711,364685:0.008654117584228516,325625:0.006710529327392578,399570:0.005423307418823242,394890:0.005217790603637695,411453:0.005035877227783203,396017:0.004566550254821777,345394:0.004499673843383789,423414:0.003313302993774414,403754:0.0029778480529785156,376433:0.0023766756057739258,382184:0.0014164447784423828,329254:0.0012700557708740234,405691:0.0',\n",
       " '417795:417796,403749|417796:0.9366982877254486,348435:0.22827988862991333,403749:0.20828431844711304,104395:0.1975584626197815,350323:0.19163620471954346,398995:0.16202598810195923,389246:0.1485249400138855,406277:0.10995697975158691,331195:0.09763526916503906,390196:0.07811671495437622,393359:0.07632172107696533,387940:0.07056432962417603,352547:0.06706470251083374,348867:0.057688772678375244,336390:0.05698394775390625,378139:0.05573183298110962,409520:0.054874300956726074,367866:0.05353611707687378,94755:0.051835715770721436,341209:0.05011206865310669,319991:0.03105705976486206,386279:0.02484041452407837,410076:0.02414083480834961,271551:0.021405577659606934,348708:0.014428794384002686,352402:0.012863755226135254,216898:0.011343598365783691,389018:0.0108109712600708,237638:0.006239771842956543',\n",
       " '417796:417795,403749|417795:0.9366982877254486,348435:0.2371504306793213,403749:0.21125251054763794,350323:0.19559603929519653,104395:0.19483298063278198,398995:0.1597650647163391,389246:0.14895153045654297,406277:0.11602550745010376,331195:0.09471124410629272,390196:0.08073252439498901,393359:0.07399249076843262,352547:0.07309180498123169,387940:0.07110464572906494,348867:0.060276806354522705,409520:0.059041619300842285,336390:0.05720633268356323,378139:0.057195067405700684,367866:0.056410014629364014,94755:0.05278623104095459,341209:0.051740825176239014,319991:0.030753791332244873,386279:0.028485894203186035,410076:0.02738851308822632,271551:0.022091567516326904,352402:0.018869221210479736,348708:0.018740832805633545,216898:0.012401282787322998,389018:0.010979831218719482,340095:0.010837852954864502',\n",
       " '403749:417795,417796|417796:0.38037675619125366,417795:0.37740856409072876,348435:0.22101843357086182,406277:0.1730138063430786,390915:0.17004549503326416,398995:0.16035103797912598,350323:0.15777301788330078,104395:0.1418057680130005,347159:0.12085592746734619,424146:0.06190800666809082,333429:0.0547027587890625,389775:0.0421297550201416,342792:0.02896106243133545,340095:0.025387287139892578,237638:0.02260899543762207,346650:0.017227768898010254,338717:0.01720571517944336,350396:0.016420602798461914,405705:0.01549530029296875,342590:0.015426278114318848,394687:0.00983893871307373,330048:0.00956737995147705,374069:0.009404897689819336,337285:0.008473038673400879,341076:0.00826120376586914,358103:0.0036917924880981445,393154:0.0033326148986816406,327913:0.0018235445022583008,319056:0.0',\n",
       " '417796:417795,403749|417795:0.9366982877254486,348435:0.2371504306793213,403749:0.21125251054763794,350323:0.19559603929519653,104395:0.19483298063278198,398995:0.1597650647163391,389246:0.14895153045654297,406277:0.11602550745010376,331195:0.09471124410629272,390196:0.08073252439498901,393359:0.07399249076843262,352547:0.07309180498123169,387940:0.07110464572906494,348867:0.060276806354522705,409520:0.059041619300842285,336390:0.05720633268356323,378139:0.057195067405700684,367866:0.056410014629364014,94755:0.05278623104095459,341209:0.051740825176239014,319991:0.030753791332244873,386279:0.028485894203186035,410076:0.02738851308822632,271551:0.022091567516326904,352402:0.018869221210479736,348708:0.018740832805633545,216898:0.012401282787322998,389018:0.010979831218719482,340095:0.010837852954864502',\n",
       " '403749:417795,417796|417796:0.38037675619125366,417795:0.37740856409072876,348435:0.22101843357086182,406277:0.1730138063430786,390915:0.17004549503326416,398995:0.16035103797912598,350323:0.15777301788330078,104395:0.1418057680130005,347159:0.12085592746734619,424146:0.06190800666809082,333429:0.0547027587890625,389775:0.0421297550201416,342792:0.02896106243133545,340095:0.025387287139892578,237638:0.02260899543762207,346650:0.017227768898010254,338717:0.01720571517944336,350396:0.016420602798461914,405705:0.01549530029296875,342590:0.015426278114318848,394687:0.00983893871307373,330048:0.00956737995147705,374069:0.009404897689819336,337285:0.008473038673400879,341076:0.00826120376586914,358103:0.0036917924880981445,393154:0.0033326148986816406,327913:0.0018235445022583008,319056:0.0',\n",
       " '319495:319752,319435,319915,319471,319895,318297,319514,319515,319517,319551|319515:0.29779279232025146,390153:0.10063695907592773,298750:0.09297025203704834,403339:0.07004010677337646,321640:0.06977689266204834,391078:0.06596088409423828,348931:0.06364798545837402,324470:0.06260955333709717,325927:0.05605900287628174,312187:0.05324256420135498,382829:0.05138540267944336,319752:0.04075264930725098,333531:0.039873600006103516,421474:0.03887617588043213,406736:0.03605961799621582,225780:0.02881753444671631,262194:0.02200639247894287,411120:0.017666339874267578,255817:0.013274550437927246,293689:0.01229846477508545,309465:0.012053608894348145,386608:0.00698399543762207,271953:0.006759047508239746,419786:0.005968332290649414,271291:0.0028672218322753906,328765:0.0023479461669921875,355182:0.001656174659729004,400436:0.001313924789428711,319895:0.0',\n",
       " '319752:319495,319435,319915,319471,319895,318297,319514,319515,319517,319551|350958:0.25877588987350464,288261:0.24061375856399536,318297:0.16893506050109863,338228:0.16674035787582397,382829:0.14864033460617065,402912:0.13176918029785156,406748:0.12850522994995117,322714:0.1263047456741333,400436:0.12284791469573975,319915:0.10683298110961914,369475:0.08440136909484863,225780:0.0792531967163086,319515:0.06479954719543457,347887:0.06348884105682373,376232:0.05730152130126953,390153:0.05155611038208008,319435:0.05153501033782959,389805:0.04547882080078125,319495:0.043021440505981445,415235:0.030576109886169434,304857:0.030289053916931152,378359:0.021704554557800293,330373:0.016233205795288086,329650:0.012249112129211426,403411:0.006646871566772461,294321:0.0029027462005615234,420310:0.0011314153671264648,329281:0.0008344650268554688,406736:0.0',\n",
       " '319435:319495,319752,319915,319471,319895,318297,319514,319515,319517,319551|389738:0.1556444764137268,392674:0.14640599489212036,403339:0.14375030994415283,359660:0.1208922266960144,303904:0.11462819576263428,364824:0.10486364364624023,341628:0.09697121381759644,395915:0.09356081485748291,283024:0.09309548139572144,393918:0.08853030204772949,319119:0.08769887685775757,360776:0.08759838342666626,315906:0.08612263202667236,411745:0.08410578966140747,349539:0.08264070749282837,424679:0.08057945966720581,317862:0.07984578609466553,323913:0.06945645809173584,321218:0.06738650798797607,391328:0.06484782695770264,323107:0.06425702571868896,323416:0.06243783235549927,357445:0.05905139446258545,320931:0.057504892349243164,424671:0.05726438760757446,349554:0.054975926876068115,317763:0.052381277084350586,389861:0.04965120553970337,334109:0.047070443630218506',\n",
       " '319915:319495,319752,319435,319471,319895,318297,319514,319515,319517,319551|288261:0.19739139080047607,262194:0.11540555953979492,350958:0.10692036151885986,319752:0.10553610324859619,330373:0.09890162944793701,278146:0.08069062232971191,389738:0.07994866371154785,294321:0.07622110843658447,322880:0.07318663597106934,376232:0.05789673328399658,389805:0.05317652225494385,403411:0.05023479461669922,390153:0.046720147132873535,405691:0.04068303108215332,419786:0.035976529121398926,384046:0.03165292739868164,399570:0.025133609771728516,359634:0.02190220355987549,324470:0.02154994010925293,334493:0.017181038856506348,410647:0.015041232109069824,394516:0.012751460075378418,340374:0.011168718338012695,240048:0.010223150253295898,414325:0.008812546730041504,421474:0.005922913551330566,319201:0.0013259649276733398,403532:0.000453948974609375,396166:0.0',\n",
       " '319471:319495,319752,319435,319915,319895,318297,319514,319515,319517,319551|319517:0.20460981130599976,411427:0.19473987817764282,326517:0.14963889122009277,420131:0.13703292608261108,323927:0.10479843616485596,317762:0.09862971305847168,322371:0.09439706802368164,352065:0.07046818733215332,321548:0.06531941890716553,319515:0.06306195259094238,404003:0.059548020362854004,322545:0.05008053779602051,379871:0.04314887523651123,341789:0.040184974670410156,343947:0.03776371479034424,325399:0.032277703285217285,394987:0.02980661392211914,381172:0.029667019844055176,345289:0.021887779235839844,400861:0.01797342300415039,332311:0.014391422271728516,320633:0.008188009262084961,393745:0.0071686506271362305,380048:0.007104992866516113,329288:0.006881833076477051,402008:0.006324172019958496,321926:0.003937840461730957,373891:0.0021692514419555664,384739:0.0',\n",
       " '319895:319495,319752,319435,319915,319471,318297,319514,319515,319517,319551|400084:0.24110233783721924,361129:0.22442376613616943,404100:0.21248102188110352,365256:0.20952272415161133,321640:0.19344383478164673,321483:0.18323785066604614,396548:0.17308342456817627,393864:0.16734635829925537,401550:0.16576433181762695,341608:0.1656295657157898,346782:0.15319710969924927,319543:0.1514410376548767,350616:0.14328795671463013,344727:0.14174067974090576,326628:0.13665491342544556,323238:0.13556796312332153,387446:0.12995487451553345,348931:0.12411755323410034,335656:0.1216881275177002,342132:0.1025841236114502,400436:0.09294450283050537,375210:0.07836854457855225,391573:0.06326210498809814,339276:0.04832029342651367,340405:0.04743063449859619,374324:0.036865234375,376141:0.02448272705078125,341901:0.02239370346069336,321926:0.0',\n",
       " '318297:319495,319752,319435,319915,319471,319895,319514,319515,319517,319551|402912:0.8974792957305908,322714:0.7030412554740906,369475:0.28512513637542725,304857:0.13351404666900635,170200:0.08268201351165771,419841:0.08152639865875244,353661:0.07550609111785889,353803:0.07374536991119385,319808:0.06218111515045166,319438:0.06201064586639404,387377:0.04645848274230957,353521:0.0419158935546875,382096:0.04025626182556152,338968:0.03975796699523926,371558:0.039192795753479004,320931:0.03351247310638428,398738:0.032190918922424316,324502:0.027779459953308105,391078:0.02570974826812744,379031:0.014131903648376465,362020:0.013437509536743164,310675:0.012367010116577148,371874:0.012064695358276367,389085:0.01157677173614502,330729:0.008967995643615723,356423:0.006834983825683594,384086:0.0045119524002075195,411647:0.0017671585083007812,389096:0.0',\n",
       " '319514:319495,319752,319435,319915,319471,319895,318297,319515,319517,319551|378868:0.24175792932510376,323511:0.22237741947174072,325294:0.15701627731323242,319345:0.09526073932647705,319419:0.08676862716674805,339788:0.08230745792388916,343843:0.07096099853515625,319123:0.0699460506439209,332039:0.05757737159729004,369880:0.0548933744430542,324473:0.045922160148620605,344833:0.041979074478149414,408901:0.0325542688369751,344915:0.030959129333496094,322158:0.030785322189331055,312784:0.03014659881591797,350225:0.019861578941345215,388299:0.01739645004272461,409838:0.01717352867126465,336837:0.01519763469696045,361679:0.010552167892456055,336077:0.008628606796264648,329375:0.008341312408447266,420270:0.006538867950439453,389961:0.0065267086029052734,328765:0.006309151649475098,348805:0.003902435302734375,321239:0.0033321380615234375,411072:0.0',\n",
       " '319515:319495,319752,319435,319915,319471,319895,318297,319514,319517,319551|319495:0.2738678455352783,382829:0.22621428966522217,391078:0.21472954750061035,400436:0.11269903182983398,346782:0.063362717628479,390153:0.061113595962524414,324470:0.0543057918548584,411120:0.05254936218261719,369475:0.04650747776031494,339673:0.04539620876312256,271953:0.03915250301361084,361120:0.038828134536743164,319752:0.03860580921173096,349603:0.03579246997833252,406736:0.032913804054260254,352656:0.025234103202819824,347887:0.023508667945861816,321640:0.02035653591156006,340402:0.01907503604888916,391573:0.017042160034179688,393864:0.015540838241577148,377119:0.013834118843078613,402912:0.012169837951660156,321044:0.01082158088684082,396548:0.007689833641052246,370490:0.007453560829162598,262194:0.003459334373474121,318297:0.002741217613220215,335374:0.0',\n",
       " '319517:319495,319752,319435,319915,319471,319895,318297,319514,319515,319551|382829:0.24315452575683594,319471:0.23310309648513794,322714:0.21400892734527588,417748:0.1807117462158203,323927:0.13667011260986328,326517:0.13322174549102783,319515:0.12453329563140869,400436:0.12343728542327881,333531:0.12269604206085205,346782:0.09529423713684082,319752:0.06873273849487305,411427:0.06267404556274414,326628:0.05933654308319092,329288:0.059046030044555664,351765:0.05899834632873535,377813:0.04538166522979736,394987:0.04094970226287842,369475:0.04069685935974121,321548:0.03864932060241699,322371:0.03175234794616699,400861:0.020125269889831543,361181:0.01785409450531006,317762:0.017592787742614746,347104:0.01481318473815918,402008:0.009736418724060059,333365:0.0025665760040283203,390153:0.0016677379608154297,411647:0.00023496150970458984,389248:0.0',\n",
       " '319551:319495,319752,319435,319915,319471,319895,318297,319514,319515,319517|350701:0.1298205852508545,354304:0.09017729759216309,327646:0.07962250709533691,363044:0.06443548202514648,331301:0.061914682388305664,351765:0.05226004123687744,373451:0.04902935028076172,399726:0.04639005661010742,422451:0.04332602024078369,415368:0.0323716402053833,408955:0.0318758487701416,414244:0.03023374080657959,322882:0.02484595775604248,346906:0.018390536308288574,403116:0.017186760902404785,392635:0.01706862449645996,335751:0.016396164894104004,321979:0.015371322631835938,400874:0.013897895812988281,414038:0.011788249015808105,370058:0.009636282920837402,347602:0.008993983268737793,417287:0.007750511169433594,392629:0.0029872655868530273,329588:0.0025222301483154297,399794:0.001961231231689453,350444:0.0015894174575805664,318809:0.000110626220703125,320496:0.0',\n",
       " '401416:401362,401363,401461,401023|415080:0.10212749242782593,385334:0.09452515840530396,376166:0.09289777278900146,415188:0.07815790176391602,401419:0.06902825832366943,330702:0.05328404903411865,382574:0.04860424995422363,351611:0.046077728271484375,332534:0.0407637357711792,365033:0.030581951141357422,382901:0.030534029006958008,350031:0.030219316482543945,339027:0.030111312866210938,336702:0.029120922088623047,350336:0.02841472625732422,333392:0.027487516403198242,347882:0.025029301643371582,333434:0.0243532657623291,404333:0.02226245403289795,370643:0.021074295043945312,347749:0.01431119441986084,381307:0.014024496078491211,373896:0.008948087692260742,358456:0.008880972862243652,352353:0.006827712059020996,351687:0.006676435470581055,423067:0.006517529487609863,362874:0.0041512250900268555,323229:0.0',\n",
       " '401362:401416,401363,401461,401023|420259:0.3010241389274597,382112:0.16456222534179688,354318:0.1391007900238037,419841:0.10811245441436768,419838:0.10587036609649658,332728:0.0979989767074585,342561:0.09679603576660156,322675:0.09577631950378418,360663:0.09411287307739258,416617:0.08444511890411377,378274:0.06508839130401611,386562:0.057806968688964844,199110:0.04962038993835449,313597:0.04722154140472412,400762:0.0471421480178833,376670:0.02923727035522461,335844:0.026311755180358887,334031:0.02088344097137451,329593:0.020641684532165527,364142:0.017724156379699707,362219:0.016707539558410645,326029:0.014839529991149902,391025:0.010309696197509766,355989:0.006761670112609863,353780:0.005899548530578613,321044:0.004535317420959473,372954:0.002490520477294922,343947:0.001891016960144043,319915:0.0']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall, exported_rank, debug = experiment.evaluate_validation_test(experiment, retrieval, verbose, \n",
    "#                                                         encoded_anchor, issues_by_buckets, evaluate_validation_test)\n",
    "# test_vectorized, queries_test_vectorized, annoy, X_test, distance_test, indices_test = debug\n",
    "# \"recall@25 last epoch:\", recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 4641\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'propose_centroid_bert_1000_feature_1000epochs_64batch(eclipse)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoded_anchor\n",
    "# model = experiment.get_model_vectorizer(path=SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 768)          80346736    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 768)          80346736    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1836)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "==================================================================================================\n",
      "Total params: 161,198,372\n",
      "Trainable params: 726,196\n",
      "Non-trainable params: 160,472,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 0, model, issues_by_buckets, \n",
    "                                                                   bug_train_ids, method='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/eclipse/exported_rank_propose_centroid_bert_1000.txt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 - recall_at_5': 0.49,\n",
       " '2 - recall_at_10': 0.55,\n",
       " '3 - recall_at_15': 0.59,\n",
       " '4 - recall_at_20': 0.61,\n",
       " '5 - recall_at_25': 0.63}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
