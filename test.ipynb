{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "import os\n",
    "import keras\n",
    "from jobs.data_pipeline import DataPipeline\n",
    "from utils.keras_utils import KerasUtils\n",
    "from deep_learning.training.train_config import TrainConfig\n",
    "from deep_learning.training.train_retrieval import TrainRetrieval\n",
    "from deep_learning.training.train_classification import TrainClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 936.87it/s]\n",
      "15it [00:00, 15001.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 7/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data\n",
      "Reading bug ids\n"
     ]
    }
   ],
   "source": [
    "# Retrieval\n",
    "EPOCHS_TRAINED = 1\n",
    "MODEL_NAME = 'SiameseTA'\n",
    "DIR = \"data/processed/eclipse_test/fake\"\n",
    "DOMAIN = 'eclipse_test'\n",
    "PREPROCESSING = 'bert'\n",
    "retrieval = TrainRetrieval(MODEL_NAME, DIR, DOMAIN, PREPROCESSING, \n",
    "            MAX_SEQUENCE_LENGTH_T=1, MAX_SEQUENCE_LENGTH_D=1,\n",
    "            BERT_LAYERS=1, EPOCHS=EPOCHS_TRAINED, BATCH_SIZE=1, BATCH_SIZE_TEST=1).build()\n",
    "\n",
    "retrieval_preload = retrieval.get_model()\n",
    "\n",
    "# Classification\n",
    "MODEL_NAME = 'SiameseTA'\n",
    "DOMAIN = 'eclipse_test'\n",
    "PREPROCESSING = 'bert'\n",
    "PRETRAINED_MODEL = os.path.join(TrainConfig.OUTPUT_MODELS, TrainConfig.MODEL_NAME.format(PREPROCESSING, MODEL_NAME, EPOCHS_TRAINED, DOMAIN))\n",
    "train = TrainClassification(retrieval_preload, MODEL_NAME, PRETRAINED_MODEL, \n",
    "            DIR, DOMAIN, PREPROCESSING, EPOCHS=2, \n",
    "            BATCH_SIZE=1, BATCH_SIZE_TEST=1)\n",
    "train.pre_load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "categorical (InputLayer)        (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "categorical_encoder (MLPModel)  (None, 300)          3000        categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "description_encoder (BERTModel) (None, 300)          30786362    desc_token[0][0]                 \n",
      "                                                                 desc_segment[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder (BERTModel)       (None, 300)          30786362    title_token[0][0]                \n",
      "                                                                 title_segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenated_bug_embed (Concate (None, 900)          0           categorical_encoder[0][0]        \n",
      "                                                                 description_encoder[0][0]        \n",
      "                                                                 title_encoder[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 901)          0           input_label[0][0]                \n",
      "                                                                 concatenated_bug_embed[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 61,575,724\n",
      "Trainable params: 467,472\n",
      "Non-trainable params: 61,108,252\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.model.get_layer('categorical').output_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_learning.model.classifier_base import ClassifierBase\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, concatenate\n",
    "from keras.models import Model\n",
    "from deep_learning.model.classifier_model import ClassifierModel\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input\n",
    "from utils.util import Util\n",
    "\n",
    "class ClassifierModel:\n",
    "\n",
    "    def __init__(self, input_list, model_list):\n",
    "        \n",
    "        # Inputs\n",
    "        for key, obj in input_list.items():\n",
    "            obj['input'] = Input(shape = (obj['input_size'], ), name = key)\n",
    "\n",
    "        # Outputs\n",
    "        for obj in model_list.values():\n",
    "            model_input = [input_list[i]['input'] for i in obj['input']]\n",
    "            obj['feat'] = obj['model'](model_input)\n",
    "\n",
    "        # Concatenate model features\n",
    "        self.inputs = [tensor['input'] for tensor in Util.sort_dict_by_key(input_list).values()]\n",
    "        self.model = [model['feat'] for model in Util.sort_dict_by_key(model_list).values()]\n",
    "\n",
    "\n",
    "class ClassifierBase:\n",
    "\n",
    "    NUMBER_OF_UNITS = 2\n",
    "\n",
    "    def __init__(self, model, title_size=0, desc_size=0, \n",
    "                    categorical_size=0, topic_size=0):\n",
    "        model_name = 'bug_classifier'\n",
    "        \n",
    "        encoder = model.get_layer('concatenated_bug_embed')\n",
    "        bugs_inputs = []\n",
    "        bugs_embed = []\n",
    "        for i in range(2):\n",
    "            input_list = {}\n",
    "            model_list = {}\n",
    "\n",
    "            if title_size > 0:\n",
    "                title_feat = model.get_layer('title_encoder')\n",
    "                input_list['title_token_{}'.format(i)]   = { 'input_size' : title_size }\n",
    "                input_list['title_segment_{}'.format(i)] = { 'input_size' : title_size }\n",
    "                model_list['title_feat'] = {\n",
    "                    'input' : ['title_token_{}'.format(i), 'title_segment_{}'.format(i)],\n",
    "                    'model' : title_feat,\n",
    "                    'name'  : 'title_encoder'\n",
    "                }\n",
    "            if desc_size > 0:\n",
    "                desc_feat = model.get_layer('description_encoder')\n",
    "                input_list['desc_token_{}'.format(i)]   = { 'input_size' : desc_size }\n",
    "                input_list['desc_segment_{}'.format(i)] = { 'input_size' : desc_size }\n",
    "                model_list['desc_feat'] =  {\n",
    "                    'input' : ['desc_token_{}'.format(i), 'desc_segment_{}'.format(i)],\n",
    "                    'model' : desc_feat,\n",
    "                    'name'  : 'description_encoder'\n",
    "                }\n",
    "            if topic_size > 0:\n",
    "                topic_feat = model.get_layer('topic_encoder')\n",
    "                input_list['topic_{}'.format(i)]  = { 'input_size' : topic_size }\n",
    "                model_list['topic'] =  {\n",
    "                    'input' : ['topic_{}'.format(i)],\n",
    "                    'model' : topic_feat,\n",
    "                    'name'  : 'topic_encoder',\n",
    "                }\n",
    "            if categorical_size > 0:\n",
    "                categorical_feat = model.get_layer('categorical_encoder')\n",
    "                input_list['categorical_{}'.format(i)]  = { 'input_size' : categorical_size }\n",
    "                model_list['categorical'] =  {\n",
    "                    'input' : ['categorical_{}'.format(i)],\n",
    "                    'model' : categorical_feat,\n",
    "                    \"name\"  : \"categorical_encoder\"\n",
    "                }\n",
    "            \n",
    "            print(input_list)\n",
    "            bug_feat = ClassifierModel(input_list, model_list)\n",
    "            bugs_inputs.append(bug_feat.inputs)\n",
    "            print(bug_feat.model)\n",
    "            bug_embed = encoder(bug_feat.model)\n",
    "            bugs_embed.append(bug_embed)\n",
    "        \n",
    "        x = concatenate(bugs_embed, name='bugs') # \n",
    "\n",
    "        for _ in range(self.NUMBER_OF_UNITS):\n",
    "            x = Dense(64)(x)\n",
    "            x = Dropout(0.25)(x)\n",
    "            x = Activation('tanh')(x)\n",
    "\n",
    "        inputs = np.concatenate(bugs_inputs).tolist()\n",
    "        output = Dense(2, activation = 'softmax', name = 'softmax')(x)\n",
    "        \n",
    "        model = Model(inputs=inputs, outputs=[output], name=model_name)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "class SiameseQATClassifier:\n",
    "    \n",
    "    def __init__(self, model, title_size=0, desc_size=0, \n",
    "                    categorical_size=0, topic_size=0):\n",
    "        \n",
    "        model = ClassifierBase(model, title_size=title_size, desc_size=desc_size, \n",
    "                    categorical_size=categorical_size, topic_size=topic_size).get_model()\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return ['accuracy']\n",
    "\n",
    "    def get_loss(self):\n",
    "        return 'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title_segment_0': {'input_size': 1}, 'title_token_0': {'input_size': 1}, 'desc_token_0': {'input_size': 1}, 'categorical_0': {'input_size': 9}, 'desc_segment_0': {'input_size': 1}}\n",
      "[<tf.Tensor 'categorical_encoder_3/categorical_encoder/dense_3/Tanh:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'description_encoder_3/description_encoder/dense_2/Tanh:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'title_encoder_3/title_encoder/dense_1/Tanh:0' shape=(?, 300) dtype=float32>]\n",
      "{'categorical_1': {'input_size': 9}, 'desc_token_1': {'input_size': 1}, 'title_token_1': {'input_size': 1}, 'desc_segment_1': {'input_size': 1}, 'title_segment_1': {'input_size': 1}}\n",
      "[<tf.Tensor 'categorical_encoder_4/categorical_encoder/dense_3/Tanh:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'description_encoder_4/description_encoder/dense_2/Tanh:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'title_encoder_4/title_encoder/dense_1/Tanh:0' shape=(?, 300) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# from deep_learning.model.siameseQAT_classifier import SiameseQATClassifier\n",
    "\n",
    "model = SiameseQATClassifier(train.model, \n",
    "                            title_size=train.TITLE_SIZE, \n",
    "                            desc_size=train.DESC_SIZE, \n",
    "                            categorical_size=train.CATEGORICAL_SIZE, \n",
    "                            topic_size=train.TOPIC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_learning.model.compile_model import compile_model\n",
    "cls = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "categorical_0 (InputLayer)      (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_0 (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_0 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_0 (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_0 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "categorical_1 (InputLayer)      (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_1 (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_1 (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_1 (InputLayer)      (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_1 (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "categorical_encoder (MLPModel)  (None, 300)          3000        categorical_0[0][0]              \n",
      "                                                                 categorical_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "description_encoder (BERTModel) (None, 300)          30786362    desc_token_0[0][0]               \n",
      "                                                                 desc_segment_0[0][0]             \n",
      "                                                                 desc_token_1[0][0]               \n",
      "                                                                 desc_segment_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "title_encoder (BERTModel)       (None, 300)          30786362    title_token_0[0][0]              \n",
      "                                                                 title_segment_0[0][0]            \n",
      "                                                                 title_token_1[0][0]              \n",
      "                                                                 title_segment_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenated_bug_embed (Concate (None, 900)          0           categorical_encoder[3][0]        \n",
      "                                                                 description_encoder[3][0]        \n",
      "                                                                 title_encoder[3][0]              \n",
      "                                                                 categorical_encoder[4][0]        \n",
      "                                                                 description_encoder[4][0]        \n",
      "                                                                 title_encoder[4][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bugs (Concatenate)              (None, 1800)         0           concatenated_bug_embed[3][0]     \n",
      "                                                                 concatenated_bug_embed[4][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           115264      bugs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64)           0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           4160        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64)           0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 2)            130         activation_4[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 61,695,278\n",
      "Trainable params: 587,026\n",
      "Non-trainable params: 61,108,252\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cls.summary()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
