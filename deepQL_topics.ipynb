{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# DeepQL with topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the use of GPUs\n",
    "# https://datascience.stackexchange.com/questions/23895/multi-gpu-in-keras\n",
    "# https://keras.io/getting-started/faq/#how-can-i-run-a-keras-model-on-multiple-gpus\n",
    "# https://stackoverflow.com/questions/56316451/how-to-use-specific-gpus-in-keras-for-multi-gpu-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import keras\n",
    "# from __future__ import print_function, division\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras import optimizers\n",
    "\n",
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval\n",
    "\n",
    "import os\n",
    "from keras_bert import load_vocabulary\n",
    "import random\n",
    "\n",
    "from keras.initializers import RandomUniform, RandomNormal, Ones\n",
    "\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_bert import compile_model, get_model\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "\n",
    "## required for semi-hard triplet loss:\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum\n",
    "from keras.optimizers import Adam, Nadam\n",
    "import _pickle as pickle\n",
    "\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "    \n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VUZ6oG1gb91"
   },
   "source": [
    "## Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: epochs=10\n",
      "env: base=openoffice\n"
     ]
    }
   ],
   "source": [
    "%env epochs 10\n",
    "%env base openoffice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 100\n",
    "MAX_SEQUENCE_LENGTH_D = 20 # 500\n",
    "TOPIC_SEQUENCE = 30 # Number of topics considered\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = int(os.environ['epochs'])\n",
    "freeze_train = .1 # 10% with freeze weights\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = os.environ['base']\n",
    "METHOD = 'deepQL_topics_{}'.format(epochs)\n",
    "PREPROCESSING = 'bert'\n",
    "TOKEN = 'bert'\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}/{}'.format(DOMAIN, PREPROCESSING)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Glove embeddings\n",
    "GLOVE_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_preprocessing_{}_feature@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_preprocessing_{}_feature_@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/openoffice/bert'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "deepQL_topics_10 for 10 epochs in openoffice\n",
      "*********\n"
     ]
    }
   ],
   "source": [
    "print(\"*********\")\n",
    "print(\"{} for {} epochs in {}\".format(METHOD, epochs, DOMAIN))\n",
    "print(\"*********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "model_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = load_vocabulary(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 30522'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(token_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DOMAIN, DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D,\n",
    "                   token_dict['[CLS]'], token_dict['[SEP]'])\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': 6,\n",
       " 'bug_status': 3,\n",
       " 'component': 144,\n",
       " 'priority': 5,\n",
       " 'product': 41,\n",
       " 'version': 539}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.info_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98070"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4ad97cb90946478df0e94613e0d311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=98070), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3341cef6ecf84c04b0e2cdecfffaeead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 17.9 s, sys: 1.35 s, total: 19.3 s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs(TOKEN)\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e45b8663424906aa8e67af68b58fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=98070), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvyMGBD4IhB-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.98 s, sys: 51.6 ms, total: 4.03 s\n",
      "Wall time: 4.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6036, 35039],\n",
       " [26311, 15091],\n",
       " [5142, 34523],\n",
       " [8323, 9594],\n",
       " [76676, 88775],\n",
       " [59725, 71546],\n",
       " [121756, 116964],\n",
       " [32936, 30911],\n",
       " [15257, 16297],\n",
       " [99719, 106395]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the corpus train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CORPUS:\n",
    "    corpus = []\n",
    "    export_file = open(os.path.join(DIR, 'corpus_train.txt'), 'w')\n",
    "    for bug_id in tqdm(baseline.bug_set):\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title = bug['title']\n",
    "        desc = bug['description']\n",
    "        export_file.write(\"{}\\n{}\\n\".format(title, desc))\n",
    "    export_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': '2\\n',\n",
       " 'bug_status': '1\\n',\n",
       " 'component': '49\\n',\n",
       " 'creation_ts': '2005-09-30 17:06:00 +0000',\n",
       " 'delta_ts': '2005-10-21 15:54:16 +0000',\n",
       " 'description': '[CLS] if one uses the wrong syntax weekday ( 09 / 27 / 2005 ) ( without the quotes ) , one gets 7 as result . this may be misleading , as one may assume that this result is correct . therefore , i think that a error should be given when the quotes are forgotten . [SEP]',\n",
       " 'description_segment': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'description_token': array([  101,  2065,  2028,  3594,  1996,  3308, 20231, 16904,  1006,\n",
       "         5641,  1013,  2676,  1013,  2384,  1007,  1006,  2302,  1996,\n",
       "        16614,   102]),\n",
       " 'dup_id': '[]',\n",
       " 'issue_id': 55311,\n",
       " 'priority': '3\\n',\n",
       " 'product': '5\\n',\n",
       " 'resolution': 'NOT_AN_ISSUE',\n",
       " 'textual_token': array([  101,  7561,  2043, 16904,  2038,  2053, 16614,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,   102,   101,  2065,  2028,  3594,  1996,  3308, 20231,\n",
       "        16904,  1006,  5641,  1013,  2676,  1013,  2384,  1007,  1006,\n",
       "         2302,  1996, 16614,   102]),\n",
       " 'title': '[CLS] error when weekday has no quotes [SEP]',\n",
       " 'title_segment': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'title_token': array([  101,  7561,  2043, 16904,  2038,  2053, 16614,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,   102]),\n",
       " 'topic': 24,\n",
       " 'topic_index': 23,\n",
       " 'topics': array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.09, 0.  , 0.16, 0.  , 0.12, 0.  , 0.  , 0.  , 0.2 , 0.  ,\n",
       "        0.  , 0.  , 0.38, 0.  , 0.  , 0.  , 0.  , 0.  ]),\n",
       " 'version': '245\\n'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 14508)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data - path\n",
    "# batch_size - 128\n",
    "# n_neg - 1\n",
    "def batch_iterator(self, retrieval, model, data, dup_sets, bug_ids, \n",
    "                   batch_size, n_neg, issues_by_buckets, TRIPLET_HARD=False, FLOATING_PADDING=False):\n",
    "    # global train_data\n",
    "    # global self.dup_sets\n",
    "    # global self.bug_ids\n",
    "    # global self.bug_set\n",
    "\n",
    "    random.shuffle(data)\n",
    "\n",
    "    batch_features = {'title' : [], 'desc' : [], 'info' : [], 'topics' : []}\n",
    "    n_train = len(data)\n",
    "\n",
    "    batch_triplets, batch_bugs_anchor, batch_bugs_pos, batch_bugs_neg, batch_bugs = [], [], [], [], []\n",
    "\n",
    "    all_bugs = list(issues_by_buckets.keys())\n",
    "    buckets = retrieval.buckets\n",
    "\n",
    "    for offset in range(batch_size):\n",
    "        anchor, pos = data[offset][0], data[offset][1]\n",
    "        batch_bugs_anchor.append(anchor)\n",
    "        batch_bugs_pos.append(pos)\n",
    "        batch_bugs.append(anchor)\n",
    "        batch_bugs.append(pos)\n",
    "        #batch_bugs += dup_sets[anchor]\n",
    "\n",
    "    for anchor, pos in zip(batch_bugs_anchor, batch_bugs_pos):\n",
    "        while True:\n",
    "            neg = self.get_neg_bug(anchor, buckets[issues_by_buckets[anchor]], issues_by_buckets, all_bugs)\n",
    "            bug_anchor = self.bug_set[anchor]\n",
    "            bug_pos = self.bug_set[pos]\n",
    "            if neg not in self.bug_set:\n",
    "                continue\n",
    "            batch_bugs.append(neg)\n",
    "            batch_bugs_neg.append(neg)\n",
    "            bug_neg = self.bug_set[neg]\n",
    "            break\n",
    "        \n",
    "        # triplet bug and master\n",
    "        batch_triplets.append([anchor, pos, neg])\n",
    "    \n",
    "    random.shuffle(batch_bugs)\n",
    "    title_ids = np.full((len(batch_bugs), MAX_SEQUENCE_LENGTH_T), 0)\n",
    "    description_ids = np.full((len(batch_bugs), MAX_SEQUENCE_LENGTH_D), 0)\n",
    "    for i, bug_id in enumerate(batch_bugs):\n",
    "        bug = self.bug_set[bug_id]\n",
    "        self.read_batch_bugs(batch_features, bug, index=i, title_ids=title_ids, description_ids=description_ids)\n",
    "\n",
    "    batch_features['title'] = { 'token' : np.array(batch_features['title']), 'segment' : title_ids }\n",
    "    batch_features['desc'] = { 'token' : np.array(batch_features['desc']), 'segment' : description_ids }\n",
    "    batch_features['info'] = np.array(batch_features['info'])\n",
    "    batch_features['topics'] = np.array(batch_features['topics'])\n",
    "    \n",
    "    sim = np.asarray([issues_by_buckets[bug_id] for bug_id in batch_bugs])\n",
    "\n",
    "    input_sample = {}\n",
    "\n",
    "    input_sample = { 'title' : batch_features['title'], \n",
    "                        'description' : batch_features['desc'], \n",
    "                            'info' : batch_features['info'],\n",
    "                            'topics' : batch_features['topics'] }\n",
    "\n",
    "    return batch_triplets, input_sample, sim #sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_sim = batch_iterator(baseline, retrieval, None, \n",
    "                                                                                      baseline.train_data, \n",
    "                                                                                      baseline.dup_sets_train,\n",
    "                                                                                      bug_train_ids,\n",
    "                                                                                      batch_size_test, 1,\n",
    "                                                                                      issues_by_buckets)\n",
    "\n",
    "validation_sample = [valid_input_sample['title']['token'], valid_input_sample['title']['segment'], \n",
    "                   valid_input_sample['description']['token'], valid_input_sample['description']['segment'],\n",
    "                   valid_input_sample['info'], valid_input_sample['topics'], valid_sim]\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title']['token'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description']['token'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384, 20), (384, 20), (384, 20), (384, 20), (384, 738), (384, 30), (384,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title']['token'].shape, \\\n",
    "valid_input_sample['description']['token'].shape, \\\n",
    "valid_input_sample['title']['segment'].shape, \\\n",
    "valid_input_sample['description']['segment'].shape, \\\n",
    "valid_input_sample['info'].shape, valid_input_sample['topics'].shape, \\\n",
    "valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "#baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test ', 8265)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Test \", len(baseline.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Propose\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "https://github.com/CyberZHG/keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_model(MAX_SEQUENCE_LENGTH, name):\n",
    "    layer_num = 8\n",
    "#     model = load_trained_model_from_checkpoint(\n",
    "#             config_path,\n",
    "#             model_path,\n",
    "#             training=True,\n",
    "#             trainable=True,\n",
    "#             seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#     )\n",
    "    model = load_trained_model_from_checkpoint(\n",
    "        config_path,\n",
    "        model_path,\n",
    "        training=True,\n",
    "        use_adapter=True,\n",
    "        seq_len=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=['Encoder-{}-MultiHeadSelfAttention-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Adapter'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-MultiHeadSelfAttention-Norm'.format(i + 1) for i in range(12-layer_num, 13)] +\n",
    "        ['Encoder-{}-FeedForward-Norm'.format(i + 1) for i in range(layer_num)],\n",
    "    )\n",
    "#     model = get_model(\n",
    "#         token_num=len(token_dict),\n",
    "#         head_num=10,\n",
    "#         transformer_num=layer_num,\n",
    "#         embed_dim=100,\n",
    "#         feed_forward_dim=100,\n",
    "#         seq_len=MAX_SEQUENCE_LENGTH,\n",
    "#         pos_num=MAX_SEQUENCE_LENGTH,\n",
    "#         dropout_rate=0.05,\n",
    "#     )\n",
    "    compile_model(model)\n",
    "    inputs = model.inputs[:2]\n",
    "    layers = ['Encoder-{}-MultiHeadSelfAttention-Adapter', 'Encoder-{}-FeedForward-Adapter', \n",
    "     'Encoder-{}-MultiHeadSelfAttention-Norm', 'Encoder-{}-FeedForward-Norm']\n",
    "    outputs = []\n",
    "    for i in range(1, 13):\n",
    "        outputs += [ model.get_layer(layer.format(layer_num)).output for layer in layers ]\n",
    "    outputs = Average()(outputs)\n",
    "    #outputs = model.get_layer('Extract').output\n",
    "    outputs = GlobalAveragePooling1D()(outputs)\n",
    "    outputs = Dense(300, activation='tanh')(outputs)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='FeatureBERTGenerationModel{}'.format(name))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    for units in [64, 32]:\n",
    "        layer = Dense(units, activation='tanh', kernel_initializer='random_uniform')(info_input)\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='FeatureTopic_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureTopicMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "VWBkSIYVaXyP",
    "outputId": "ed2a3d37-b8ec-4960-ef45-2909a87c8fa5"
   },
   "outputs": [],
   "source": [
    "def pairwise_distance(feature, squared=False):\n",
    "    \"\"\"Computes the pairwise distance matrix with numerical stability.\n",
    "\n",
    "    output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
    "\n",
    "    Args:\n",
    "      feature: 2-D Tensor of size [number of data, feature dimension].\n",
    "      squared: Boolean, whether or not to square the pairwise distances.\n",
    "\n",
    "    Returns:\n",
    "      pairwise_distances: 2-D Tensor of size [number of data, number of data].\n",
    "    \"\"\"\n",
    "    pairwise_distances_squared = math_ops.add(\n",
    "        math_ops.reduce_sum(math_ops.square(feature), axis=[1], keepdims=True),\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.square(array_ops.transpose(feature)),\n",
    "            axis=[0],\n",
    "            keepdims=True)) - 2.0 * math_ops.matmul(feature,\n",
    "                                                    array_ops.transpose(feature))\n",
    "\n",
    "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    pairwise_distances_squared = math_ops.maximum(pairwise_distances_squared, 0.0)\n",
    "    # Get the mask where the zero distances are at.\n",
    "    error_mask = math_ops.less_equal(pairwise_distances_squared, 0.0)\n",
    "\n",
    "    # Optionally take the sqrt.\n",
    "    if squared:\n",
    "        pairwise_distances = pairwise_distances_squared\n",
    "    else:\n",
    "        pairwise_distances = math_ops.sqrt(\n",
    "            pairwise_distances_squared + math_ops.to_float(error_mask) * 1e-16)\n",
    "\n",
    "    # Undo conditionally adding 1e-16.\n",
    "    pairwise_distances = math_ops.multiply(\n",
    "        pairwise_distances, math_ops.to_float(math_ops.logical_not(error_mask)))\n",
    "\n",
    "    num_data = array_ops.shape(feature)[0]\n",
    "    # Explicitly set diagonals to zero.\n",
    "    mask_offdiagonals = array_ops.ones_like(pairwise_distances) - array_ops.diag(\n",
    "        array_ops.ones([num_data]))\n",
    "    pairwise_distances = math_ops.multiply(pairwise_distances, mask_offdiagonals)\n",
    "    return pairwise_distances\n",
    "\n",
    "def masked_maximum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise maximum over chosen elements.\n",
    "\n",
    "    Args:\n",
    "      data: 2-D float `Tensor` of size [n, m].\n",
    "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "      dim: The dimension over which to compute the maximum.\n",
    "\n",
    "    Returns:\n",
    "      masked_maximums: N-D `Tensor`.\n",
    "        The maximized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_minimums = math_ops.reduce_min(data, dim, keepdims=True)\n",
    "    masked_maximums = math_ops.reduce_max(\n",
    "        math_ops.multiply(data - axis_minimums, mask), dim,\n",
    "        keepdims=True) + axis_minimums\n",
    "    return masked_maximums\n",
    "\n",
    "def masked_minimum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise minimum over chosen elements.\n",
    "\n",
    "    Args:\n",
    "      data: 2-D float `Tensor` of size [n, m].\n",
    "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "      dim: The dimension over which to compute the minimum.\n",
    "\n",
    "    Returns:\n",
    "      masked_minimums: N-D `Tensor`.\n",
    "        The minimized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_maximums = math_ops.reduce_max(data, dim, keepdims=True)\n",
    "    masked_minimums = math_ops.reduce_min(\n",
    "        math_ops.multiply(data - axis_maximums, mask), dim,\n",
    "        keepdims=True) + axis_maximums\n",
    "    return masked_minimums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(vects):\n",
    "    margin = 1.\n",
    "    labels = vects[:, :1]\n",
    " \n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "\n",
    "    embeddings = tf.cast(vects[:, 1:], dtype='float32')\n",
    "\n",
    "    ### Code from Tensorflow function [tf.contrib.losses.metric_learning.triplet_semihard_loss] starts here:\n",
    "    \n",
    "    # Reshape [batch_size] label tensor to a [batch_size, 1] label tensor.\n",
    "    # lshape=array_ops.shape(labels)\n",
    "    # assert lshape.shape == 1\n",
    "    # labels = array_ops.reshape(labels, [lshape[0], 1])\n",
    "\n",
    "    # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = pairwise_distance(embeddings, squared=True)\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = math_ops.logical_not(adjacency)\n",
    "\n",
    "    # global batch_size  \n",
    "    batch_size = array_ops.size(labels) # was 'array_ops.size(labels)'\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = math_ops.logical_and(\n",
    "        array_ops.tile(adjacency_not, [batch_size, 1]),\n",
    "        math_ops.greater(\n",
    "            pdist_matrix_tile, array_ops.reshape(\n",
    "                array_ops.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = array_ops.reshape(\n",
    "        math_ops.greater(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    mask_final = array_ops.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
    "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = array_ops.reshape(\n",
    "        masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = array_ops.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = array_ops.tile(\n",
    "        masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "    semi_hard_negatives = array_ops.where(\n",
    "        mask_final, negatives_outside, negatives_inside)\n",
    "\n",
    "    loss_mat = math_ops.add(margin, pdist_matrix - semi_hard_negatives)\n",
    "\n",
    "    mask_positives = math_ops.cast(\n",
    "        adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
    "        array_ops.ones([batch_size]))\n",
    "\n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = math_ops.reduce_sum(mask_positives)\n",
    "\n",
    "    semi_hard_triplet_loss_distance = math_ops.truediv(\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.maximum(\n",
    "                math_ops.multiply(loss_mat, mask_positives), 0.0)),\n",
    "        num_positives,\n",
    "        name='triplet_semihard_loss')\n",
    "    \n",
    "    ### Code from Tensorflow function semi-hard triplet loss ENDS here.\n",
    "    return semi_hard_triplet_loss_distance\n",
    "\n",
    "def quintet_loss(inputs):\n",
    "    margin = 1.\n",
    "    labels = inputs[:, :1]\n",
    " \n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "\n",
    "    embeddings = inputs[:, 1:]\n",
    "\n",
    "    # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = pairwise_distance(embeddings, squared=True)\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = math_ops.logical_not(adjacency)\n",
    "\n",
    "    # global batch_size  \n",
    "    batch_size = array_ops.size(labels) # was 'array_ops.size(labels)'\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = math_ops.logical_and(\n",
    "        array_ops.tile(adjacency_not, [batch_size, 1]),\n",
    "        math_ops.greater(\n",
    "            pdist_matrix_tile, array_ops.reshape(\n",
    "                array_ops.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = array_ops.reshape(\n",
    "        math_ops.greater(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    \n",
    "    mask_final = array_ops.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
    "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = array_ops.reshape(\n",
    "        masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = array_ops.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = array_ops.tile(\n",
    "        masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "\n",
    "    semi_hard_negatives = array_ops.where(\n",
    "        mask_final, negatives_outside, negatives_inside)\n",
    "    \n",
    "    semi_hard_negatives_mask = math_ops.equal(pdist_matrix, masked_maximum(pdist_matrix, adjacency_not))\n",
    "    \n",
    "    # Remove false negatives with similarity equal to the true negatives\n",
    "    semi_hard_negatives_mask = tf.reshape(tf.cast(semi_hard_negatives_mask, 'int32'), (-1, 1)) * tf.reshape(tf.cast(adjacency_not, 'int32'), (-1, 1))\n",
    "    semi_hard_negatives_mask = tf.cast(tf.reshape(semi_hard_negatives_mask, (batch_size, batch_size)), 'bool')\n",
    "    \n",
    "    # Recovery the bug label from semi-hard-negatives\n",
    "    label_matrix = tf.repeat(tf.reshape(labels, (1, -1)), repeats=[batch_size], axis=0)\n",
    "    semi_hard_negatives_ids = tf.reshape(label_matrix, (-1, 1)) * tf.cast(tf.reshape(semi_hard_negatives_mask, (-1, 1)), 'int32')\n",
    "    semi_hard_negatives_ids = tf.reshape(semi_hard_negatives_ids, (batch_size, batch_size))\n",
    "\n",
    "    i = tf.constant(0)\n",
    "    most_freq_matrix = tf.Variable([])\n",
    "    def most_frequent(i, most_freq_matrix):\n",
    "        batch = tf.gather(semi_hard_negatives_ids, i)\n",
    "        neg_label_default = [tf.unique(batch)[0][0]]\n",
    "        batch = tf.boolean_mask(batch, tf.greater(batch, 0))\n",
    "        unique, _, count = tf.unique_with_counts(batch)\n",
    "        max_occurrences = tf.reduce_max(count)\n",
    "        max_cond = tf.equal(count, max_occurrences)\n",
    "        max_numbers = tf.squeeze(tf.gather(unique, tf.where(max_cond)))\n",
    "        max_numbers = tf.cond(tf.cast(tf.size(unique) > 1, tf.bool), lambda: unique[0], lambda: max_numbers)\n",
    "        max_numbers = tf.cond(tf.cast(tf.shape(unique) == 0, tf.bool), \n",
    "                              lambda: neg_label_default, \n",
    "                              lambda: max_numbers)\n",
    "        most_freq_matrix = tf.concat([most_freq_matrix, [max_numbers]], axis=0)\n",
    "        return [tf.add(i, 1), most_freq_matrix]\n",
    "    _, negatives_ids = tf.while_loop(lambda i, _: i<batch_size, \n",
    "                                        most_frequent, \n",
    "                                        [i, most_freq_matrix],\n",
    "                                       shape_invariants=[i.get_shape(),\n",
    "                                                   tf.TensorShape([None])])\n",
    "    negatives_ids = tf.cast(negatives_ids, 'int32')\n",
    "    labels_neg = tf.reshape(negatives_ids, (-1, 1))\n",
    "    mask_negatives = math_ops.equal(labels_neg, semi_hard_negatives_ids)\n",
    "    mask_negatives = tf.cast(mask_negatives, 'float32')\n",
    "    labels_neg = tf.cast(labels_neg, 'float32')\n",
    "    \n",
    "    mask_positives = math_ops.cast(\n",
    "        adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
    "        array_ops.ones([batch_size]))\n",
    "    \n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = math_ops.reduce_sum(mask_positives)\n",
    "\n",
    "    # Include the anchor to positives\n",
    "    mask_positives_centroids = math_ops.cast(adjacency, dtype=dtypes.float32)\n",
    "\n",
    "    # centroid pos \n",
    "    embed_pos = tf.matmul(mask_positives, embeddings)\n",
    "    num_of_pos = tf.reduce_sum(mask_positives_centroids, axis=1, keepdims=True)\n",
    "    centroid_embed_pos = tf.math.xdivy(embed_pos, num_of_pos)\n",
    "    labels_pos = tf.cast(labels, dtype=dtypes.float32)\n",
    "\n",
    "    # centroid negs\n",
    "    embed_neg = tf.matmul(mask_negatives, embeddings)\n",
    "    num_of_neg = tf.reduce_sum(mask_negatives, axis=1, keepdims=True)\n",
    "    centroid_embed_neg = tf.math.xdivy(embed_neg, num_of_neg)\n",
    "    \n",
    "    i = tf.constant(0)\n",
    "    batch_centroid_matrix = tf.Variable([])\n",
    "    def iter_centroids(i, batch_centroid_matrix):\n",
    "        # anchor\n",
    "        anchor = [tf.gather(embeddings, i)]\n",
    "        label_pos = [tf.gather(labels_pos, i)]\n",
    "        # centroid pos\n",
    "        centroid_pos = [tf.gather(centroid_embed_pos, i)]\n",
    "        # centroid neg\n",
    "        centroid_neg = [tf.gather(centroid_embed_neg, i)]\n",
    "        label_neg = [tf.gather(labels_neg, i)]\n",
    "        # new batch\n",
    "        new_batch = tf.concat([anchor, centroid_pos, centroid_neg], axis=0)\n",
    "        new_labels = tf.concat([label_pos, label_pos, label_neg], axis=0)\n",
    "        # Batch anchor + centroid_positive + centroid_negative\n",
    "        batch_anchor_centroids = tf.concat([new_labels, new_batch], axis=1)\n",
    "        TL_single_triplet = triplet_loss(batch_anchor_centroids)\n",
    "        batch_centroid_matrix = tf.concat([batch_centroid_matrix, [TL_single_triplet]], axis=0)\n",
    "        \n",
    "        return [tf.add(i, 1), batch_centroid_matrix]\n",
    "    _, batch_centroid_matrix = tf.while_loop(lambda i, a: i<batch_size, \n",
    "                                        iter_centroids, \n",
    "                                        [i, batch_centroid_matrix],\n",
    "                                       shape_invariants=[i.get_shape(),\n",
    "                                                   tf.TensorShape([None])])\n",
    "    \n",
    "    TL_centroid = tf.reduce_mean(batch_centroid_matrix)\n",
    "    TL = triplet_loss(inputs)\n",
    "    TL_pos = tf.constant(0.0)\n",
    "    TL_neg = tf.constant(0.0) #tf.reduce_mean(batch_centroid_matrix_neg)\n",
    "   \n",
    "    return K.stack([TL, TL_pos, TL_neg, TL_centroid], axis=0)\n",
    "\n",
    "def quintet_trainable(inputs):\n",
    "    TL = inputs[0]\n",
    "    TL_pos = inputs[1]\n",
    "    TL_neg = inputs[2]\n",
    "    TL_centroid = inputs[3]\n",
    "    TL_anchor_w = inputs[4]\n",
    "    TL_pos_w = inputs[5]\n",
    "    TL_neg_w = inputs[6]\n",
    "    TL_centroid_w = inputs[7]\n",
    "    \n",
    "    TL_anchor_w = math_ops.maximum(TL_anchor_w, 0.0)\n",
    "    TL_neg_w = math_ops.maximum(TL_neg_w, 0.0)\n",
    "    TL_centroid_w = math_ops.maximum(TL_centroid_w, 0.0)\n",
    "\n",
    "    sum_of_median = tf.reduce_sum([ TL * TL_anchor_w, TL_centroid * TL_centroid_w]) # , TL_neg * TL_neg_w,\n",
    "    sum_of_weigths = tf.reduce_sum([TL_anchor_w, TL_centroid_w])\n",
    "    weigthed_median = tf.truediv(sum_of_median, sum_of_weigths)    \n",
    "    return K.stack([weigthed_median, TL_anchor_w, TL_pos_w, TL_neg_w, TL_centroid_w, TL, TL_pos, TL_neg, TL_centroid], axis=0)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[0])\n",
    "\n",
    "def TL_w_anchor(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[1])\n",
    "def TL_w_pos(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[2])\n",
    "def TL_w_neg(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[3])\n",
    "def TL_w_centroid(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[4])\n",
    "def TL(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[5])\n",
    "def TL_pos(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[6])\n",
    "def TL_neg(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[7])\n",
    "def TL_centroid(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, topic_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, sequence_length_topics, name):\n",
    "  \n",
    "    # Title\n",
    "    bug_t_token = Input(shape = (sequence_length_t, ), name = 'title_token_{}'.format(name))\n",
    "    bug_t_segment = Input(shape = (sequence_length_t, ), name = 'title_segment_{}'.format(name))\n",
    "    # Description\n",
    "    bug_d_token = Input(shape = (sequence_length_d, ), name = 'desc_token_{}'.format(name))\n",
    "    bug_d_segment = Input(shape = (sequence_length_d, ), name = 'desc_segment_{}'.format(name))\n",
    "    # Categorical\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    # Topics\n",
    "    bug_topics = Input(shape = (sequence_length_topics, ), name='topics_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model([bug_t_token, bug_t_segment])\n",
    "    bug_d_feat = desc_feature_model([bug_d_token, bug_d_segment])\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    bug_topics_feat = topic_feature_model(bug_topics)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat, bug_topics_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t_token, bug_t_segment, bug_d_token, bug_d_segment, bug_i, bug_topics], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuintetWeights(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(QuintetWeights, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = tf.reshape(self.add_weight(name='quintet_kernel_weight', \n",
    "                                      shape=(input_shape[0], self.output_dim),\n",
    "                                      initializer=keras.initializers.Ones(),\n",
    "#                                       initializer=keras.initializers.RandomUniform(minval=0.0, maxval=1.0, seed=None),\n",
    "                                      trainable=False), (1, 1))\n",
    "        super(QuintetWeights, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, (1, 1))\n",
    "        return [K.dot(x, self.kernel), self.kernel]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [input_shape, input_shape]\n",
    "    \n",
    "def max_margin_objective(encoded_anchor, decay_lr=1):\n",
    "    \n",
    "    input_labels = Input(shape=(1,), name='input_label')    # input layer for labels\n",
    "    inputs = np.concatenate([encoded_anchor.input, [input_labels]], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    \n",
    "    feature = concatenate([input_labels, encoded_anchor])  # concatenating the labels + embeddings\n",
    "    \n",
    "    TL_loss = Lambda(quintet_loss, name='quintet_loss')(feature)\n",
    "    \n",
    "    tl_l = Lambda(lambda x:tf.reshape(x[0], (1,)), name='TL')(TL_loss)\n",
    "    tl_l_p = Lambda(lambda x:tf.reshape(x[1], (1,)), name='TL_pos')(TL_loss)\n",
    "    tl_l_n = Lambda(lambda x:tf.reshape(x[2], (1,)), name='TL_neg')(TL_loss)\n",
    "    tl_l_c = Lambda(lambda x:tf.reshape(x[3], (1, )), name='TL_centroid')(TL_loss)\n",
    "    \n",
    "    TL_w = QuintetWeights(output_dim=1)(tl_l)\n",
    "    TL_pos_w = QuintetWeights(output_dim=1)(tl_l_p)\n",
    "    TL_neg_w = QuintetWeights(output_dim=1)(tl_l_n)\n",
    "    TL_centroid_w = QuintetWeights(output_dim=1)(tl_l_c)\n",
    "    \n",
    "    TL_weight = Lambda(lambda x:tf.reshape(x[1], (1,)), name='TL_weight')(TL_w)\n",
    "    TL_pos_weight = Lambda(lambda x:tf.reshape(x[1], (1,)), name='TL_pos_weight')(TL_pos_w)\n",
    "    TL_neg_weight = Lambda(lambda x:tf.reshape(x[1], (1,)), name='TL_neg_weight')(TL_neg_w)\n",
    "    TL_centroid_weight = Lambda(lambda x:tf.reshape(x[1], (1,)), name='TL_centroid_weight')(TL_centroid_w)\n",
    "    \n",
    "    output = concatenate([tl_l, tl_l_p, tl_l_n, tl_l_c, TL_weight, TL_pos_weight, TL_neg_weight, TL_centroid_weight])\n",
    "    output = Lambda(quintet_trainable, name='quintet_trainable')(output)\n",
    "    \n",
    "    similarity_model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer='adam', loss=custom_loss, metrics=[TL_w_anchor, TL_w_pos, TL_w_neg, TL_w_centroid,\n",
    "                                                                         TL, TL_pos, TL_neg, TL_centroid]) \n",
    "    # metrics=[pos_distance, neg_distance, custom_margin_loss]\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_loss(result):\n",
    "    with open(os.path.join(DIR,'{}_log.pkl'.format(METHOD)), 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "    print(\"=> result saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "result = { 'train' : [], 'test' : [] }\n",
    "limit_train = int(epochs * freeze_train) # 10% de 1000 , 100 epocas\n",
    "METHOD = 'deepQL_topics_{}'.format(limit_train)\n",
    "SAVE_PATH = '{}_preprocessing_{}_feature@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_preprocessing_{}_feature_@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-31-cd325db98846>:35: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From <ipython-input-32-3bc265d0a7cc>:120: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 738)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "topics_in (InputLayer)          (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          221700      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 300)          80577436    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 300)          80577436    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureTopicMlpGenerationModel  (None, 300)          9300        topics_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1200)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "                                                                 FeatureTopicMlpGenerationModel[1]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1201)         0           input_label[0][0]                \n",
      "                                                                 merge_features_in[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "quintet_loss (Lambda)           (4,)                 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TL (Lambda)                     (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_pos (Lambda)                 (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_neg (Lambda)                 (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_centroid (Lambda)            (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_1 (QuintetWeigh [(1,), (1,)]         1           TL[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_2 (QuintetWeigh [(1,), (1,)]         1           TL_pos[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_3 (QuintetWeigh [(1,), (1,)]         1           TL_neg[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_4 (QuintetWeigh [(1,), (1,)]         1           TL_centroid[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "TL_weight (Lambda)              (1,)                 0           quintet_weights_1[0][0]          \n",
      "                                                                 quintet_weights_1[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_pos_weight (Lambda)          (1,)                 0           quintet_weights_2[0][0]          \n",
      "                                                                 quintet_weights_2[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_neg_weight (Lambda)          (1,)                 0           quintet_weights_3[0][0]          \n",
      "                                                                 quintet_weights_3[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_centroid_weight (Lambda)     (1,)                 0           quintet_weights_4[0][0]          \n",
      "                                                                 quintet_weights_4[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (8,)                 0           TL[0][0]                         \n",
      "                                                                 TL_pos[0][0]                     \n",
      "                                                                 TL_neg[0][0]                     \n",
      "                                                                 TL_centroid[0][0]                \n",
      "                                                                 TL_weight[0][0]                  \n",
      "                                                                 TL_pos_weight[0][0]              \n",
      "                                                                 TL_neg_weight[0][0]              \n",
      "                                                                 TL_centroid_weight[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quintet_trainable (Lambda)      (9,)                 0           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 161,385,876\n",
      "Trainable params: 913,696\n",
      "Non-trainable params: 160,472,180\n",
      "__________________________________________________________________________________________________\n",
      "Total of  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "=> result saved!\n",
      "Epoch: 1 Loss: 3.55, Loss_test: 1.86\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.83, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 6.28, recall@25: 0.39\n",
      "Best_epoch=0, Best_loss=1.00, Recall@25=0.39\n",
      "CPU times: user 1h 11s, sys: 27.2 s, total: 1h 38s\n",
      "Wall time: 21min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    mlp_model\n",
    "'''\n",
    "title_feature_model = bert_model(MAX_SEQUENCE_LENGTH_T, 'Title')\n",
    "desc_feature_model = bert_model(MAX_SEQUENCE_LENGTH_D, 'Description')\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "topic_feature_model = topic_model(TOPIC_SEQUENCE)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, topic_feature_model,\n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, TOPIC_SEQUENCE, 'in')\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "print(\"Total of \", limit_train)\n",
    "for epoch in range(limit_train):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_sim = batch_iterator(baseline, retrieval, encoded_anchor, baseline.train_data, \n",
    "                                                       baseline.dup_sets_train, bug_train_ids, \n",
    "                                                           batch_size, 1, issues_by_buckets, TRIPLET_HARD=False)\n",
    "    train_batch = [train_input_sample['title']['token'], train_input_sample['title']['segment'], \n",
    "                   train_input_sample['description']['token'], train_input_sample['description']['segment'],\n",
    "                   train_input_sample['info'], train_input_sample['topics'], train_sim]\n",
    "    \n",
    "#     if epoch == 10:\n",
    "#         similarity_model = max_margin_objective(encoded_anchor, encoded_positive, encoded_negative, decay_lr=0.1)\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    h_validation = similarity_model.test_on_batch(x=validation_sample, y=valid_sim)\n",
    "    \n",
    "    # save results\n",
    "    result['train'].append(h)\n",
    "    result['test'].append(h_validation)\n",
    "    \n",
    "    if( (epoch+1) % 10 == 0 or (epoch+1 == limit_train) ):\n",
    "        save_loss(result)\n",
    "    \n",
    "    if (epoch+1 == limit_train): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, \n",
    "                                                               bug_train_ids, method='bert-topic')\n",
    "        print((\"Epoch: {} Loss: {:.2f}, Loss_test: {:.2f}\\n\" +\n",
    "               \"TL_w: {:.2f}, TL_pos_w: {:.2f}, TL_neg_w: {:.2f}, TL_centroid_w: {:.2f}\\n\" + \n",
    "                \"TL: {:.2f}, TL_pos: {:.2f}, TL_neg: {:.2f}, TL_centroid: {:.2f}, \" +\n",
    "              \"recall@25: {:.2f}\").format(epoch+1, h[0], h_validation[0], h[1], h[2], h[3], \n",
    "                                          h[4], h[5], h[6], h[7], h[8], recall))\n",
    "    else:\n",
    "        print((\"Epoch: {} Loss: {:.2f}, Loss_test: {:.2f}\\n\" +\n",
    "               \"TL_w: {:.2f}, TL_pos_w: {:.2f}, TL_neg_w: {:.2f}, TL_centroid_w: {:.2f}\\n\" + \n",
    "              \"TL: {:.2f}, TL_pos: {:.2f}, TL_neg: {:.2f}, TL_centroid: {:.2f}\").format(\n",
    "            epoch+1, h[0], h_validation[0], h[1], h[2], h[3], h[4], h[5], h[6], h[7], h[8]))\n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "# experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "# experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/openoffice/bert/exported_rank_deepQL_topics_1.txt'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model 'modelos/model_bert_preprocessing_deepQL_topics_1_feature_1epochs_64batch(openoffice).h5' to disk\n"
     ]
    }
   ],
   "source": [
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(limit_train)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(limit_train)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['train']), len(result['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 738)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "topics_in (InputLayer)          (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          221700      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 300)          80577436    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 300)          80577436    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureTopicMlpGenerationModel  (None, 300)          9300        topics_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1200)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "                                                                 FeatureTopicMlpGenerationModel[1]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1201)         0           input_label[0][0]                \n",
      "                                                                 merge_features_in[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "quintet_loss (Lambda)           (4,)                 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TL (Lambda)                     (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_pos (Lambda)                 (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_neg (Lambda)                 (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_centroid (Lambda)            (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_1 (QuintetWeigh [(1,), (1,)]         1           TL[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_2 (QuintetWeigh [(1,), (1,)]         1           TL_pos[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_3 (QuintetWeigh [(1,), (1,)]         1           TL_neg[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_4 (QuintetWeigh [(1,), (1,)]         1           TL_centroid[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "TL_weight (Lambda)              (1,)                 0           quintet_weights_1[0][0]          \n",
      "                                                                 quintet_weights_1[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_pos_weight (Lambda)          (1,)                 0           quintet_weights_2[0][0]          \n",
      "                                                                 quintet_weights_2[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_neg_weight (Lambda)          (1,)                 0           quintet_weights_3[0][0]          \n",
      "                                                                 quintet_weights_3[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_centroid_weight (Lambda)     (1,)                 0           quintet_weights_4[0][0]          \n",
      "                                                                 quintet_weights_4[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (8,)                 0           TL[0][0]                         \n",
      "                                                                 TL_pos[0][0]                     \n",
      "                                                                 TL_neg[0][0]                     \n",
      "                                                                 TL_centroid[0][0]                \n",
      "                                                                 TL_weight[0][0]                  \n",
      "                                                                 TL_pos_weight[0][0]              \n",
      "                                                                 TL_neg_weight[0][0]              \n",
      "                                                                 TL_centroid_weight[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quintet_trainable (Lambda)      (9,)                 0           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 161,385,876\n",
      "Trainable params: 913,696\n",
      "Non-trainable params: 160,472,180\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = similarity_model.get_layer('concatenate_2')\n",
    "output = Lambda(quintet_trainable, name='quintet_trainable')(model.output)\n",
    "inputs = similarity_model.inputs\n",
    "model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "# setup the optimization process \n",
    "model.compile(optimizer='adam', loss=custom_loss, metrics=[TL_w_anchor, TL_w_pos, TL_w_neg, TL_w_centroid,\n",
    "                                                                     TL, TL_pos, TL_neg, TL_centroid])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "METHOD = 'deepQL_topics_{}'.format(epochs)\n",
    "SAVE_PATH = '{}_preprocessing_{}_feature@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_preprocessing_{}_feature_@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101 Loss: 0.07, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.10, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 102 Loss: 0.07, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 103 Loss: 0.04, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 104 Loss: 0.06, Loss_test: 0.05\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 105 Loss: 0.07, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 106 Loss: 0.05, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 107 Loss: 0.09, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 108 Loss: 0.06, Loss_test: 0.05\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.09, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 109 Loss: 0.07, Loss_test: 0.05\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.08\n",
      "=> result saved!\n",
      "Epoch: 110 Loss: 0.05, Loss_test: 0.05\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.08, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 111 Loss: 0.04, Loss_test: 0.05\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 112 Loss: 0.11, Loss_test: 0.05\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.07, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 113 Loss: 0.12, Loss_test: 0.05\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 114 Loss: 0.05, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.10, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 115 Loss: 0.09, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 116 Loss: 0.01, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 117 Loss: 0.05, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 118 Loss: 0.03, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 119 Loss: 0.07, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.10\n",
      "=> result saved!\n",
      "Epoch: 120 Loss: 0.06, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.10, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 121 Loss: 0.03, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 122 Loss: 0.05, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 123 Loss: 0.05, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 124 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 125 Loss: 0.03, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 126 Loss: 0.08, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 127 Loss: 0.06, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.07, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 128 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 129 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 130 Loss: 0.03, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 131 Loss: 0.06, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 132 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 133 Loss: 0.06, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.07, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 134 Loss: 0.03, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 135 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 136 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 137 Loss: 0.03, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 138 Loss: 0.05, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.07, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 139 Loss: 0.09, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 140 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 141 Loss: 0.04, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 142 Loss: 0.02, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 143 Loss: 0.02, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 144 Loss: 0.03, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 145 Loss: 0.02, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 146 Loss: 0.01, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 147 Loss: 0.03, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 148 Loss: 0.04, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 149 Loss: 0.03, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "=> result saved!\n",
      "Epoch: 150 Loss: 0.02, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 151 Loss: 0.03, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 152 Loss: 0.04, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.07, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 153 Loss: 0.01, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 154 Loss: 0.03, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 155 Loss: 0.07, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.09, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 156 Loss: 0.03, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 157 Loss: 0.02, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 158 Loss: 0.04, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 159 Loss: 0.01, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 160 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 161 Loss: 0.03, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 162 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 163 Loss: 0.01, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 164 Loss: 0.01, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 165 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.08, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 166 Loss: 0.03, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 167 Loss: 0.03, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 168 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 169 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 170 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 171 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 172 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 173 Loss: 0.03, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 174 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 175 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 176 Loss: 0.01, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 177 Loss: 0.05, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 178 Loss: 0.02, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 179 Loss: 0.02, Loss_test: 0.03\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 180 Loss: 0.07, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 181 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 182 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 183 Loss: 0.01, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 184 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 185 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 186 Loss: 0.06, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 187 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 188 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 189 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 190 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 191 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 192 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 193 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 194 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 195 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 196 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 197 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 198 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 199 Loss: 0.06, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.10\n",
      "=> result saved!\n",
      "Epoch: 200 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.07\n",
      "Epoch: 201 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 202 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 203 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 204 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 205 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 206 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 207 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 208 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 209 Loss: 0.06, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.11\n",
      "=> result saved!\n",
      "Epoch: 210 Loss: 0.14, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.25\n",
      "Epoch: 211 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 212 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 213 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 214 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 215 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 216 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 217 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 218 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 219 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "=> result saved!\n",
      "Epoch: 220 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 221 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 222 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 223 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 224 Loss: 0.13, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.23\n",
      "Epoch: 225 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 226 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 227 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 228 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 229 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "=> result saved!\n",
      "Epoch: 230 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 231 Loss: 0.09, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 232 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 233 Loss: 0.03, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 234 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 235 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 236 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 237 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 238 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.07\n",
      "Epoch: 239 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 240 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 241 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 242 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 243 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 244 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 245 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 246 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 247 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 248 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 249 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 250 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 251 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 252 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 253 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 254 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 255 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 256 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 257 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 258 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 259 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 260 Loss: 0.10, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 261 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 262 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 263 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 264 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 265 Loss: 0.07, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 266 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 267 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 268 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 269 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 270 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 271 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 272 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 273 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 274 Loss: 0.04, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 275 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 276 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 277 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 278 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.08, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 279 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "=> result saved!\n",
      "Epoch: 280 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 281 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 282 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 283 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 284 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 285 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 286 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 287 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 288 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 289 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.07\n",
      "=> result saved!\n",
      "Epoch: 290 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 291 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 292 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 293 Loss: 0.10, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 294 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 295 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 296 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 297 Loss: 0.07, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 298 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 299 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "=> result saved!\n",
      "Epoch: 300 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 301 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 302 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 303 Loss: 0.01, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 304 Loss: 0.03, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.07, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 305 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 306 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 307 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 308 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 309 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.07\n",
      "=> result saved!\n",
      "Epoch: 310 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 311 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 312 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 313 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 314 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 315 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 316 Loss: 0.07, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 317 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 318 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.07, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 319 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 320 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 321 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 322 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 323 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.06, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 324 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 325 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 326 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 327 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 328 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 329 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "=> result saved!\n",
      "Epoch: 330 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 331 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 332 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 333 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 334 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 335 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 336 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 337 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 338 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 339 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "=> result saved!\n",
      "Epoch: 340 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 341 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 342 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 343 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 344 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 345 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 346 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 347 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 348 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 349 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 350 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 351 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 352 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 353 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 354 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 355 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 356 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 357 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 358 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 359 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 360 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 361 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 362 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 363 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 364 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 365 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 366 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 367 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 368 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 369 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 370 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 371 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 372 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 373 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 374 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 375 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 376 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 377 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 378 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 379 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 380 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 381 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 382 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.07, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 383 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 384 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 385 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 386 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 387 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 388 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 389 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 390 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 391 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 392 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 393 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 394 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 395 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 396 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 397 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 398 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 399 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 400 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 401 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 402 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 403 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 404 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 405 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 406 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 407 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 408 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 409 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "=> result saved!\n",
      "Epoch: 410 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 411 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 412 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 413 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 414 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 415 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 416 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 417 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 418 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 419 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 420 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 421 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 422 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 423 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 424 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 425 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 426 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 427 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 428 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 429 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 430 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 431 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 432 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 433 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 434 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 435 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 436 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 437 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 438 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 439 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 440 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 441 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 442 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 443 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 444 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 445 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 446 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 447 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 448 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 449 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 450 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 451 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 452 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 453 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 454 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 455 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 456 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 457 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 458 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 459 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "=> result saved!\n",
      "Epoch: 460 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 461 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 462 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 463 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 464 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 465 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 466 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 467 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 468 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 469 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 470 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 471 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 472 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 473 Loss: 0.03, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 474 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 475 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 476 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 477 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 478 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 479 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 480 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 481 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 482 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 483 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 484 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 485 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 486 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 487 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 488 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 489 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 490 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 491 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 492 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 493 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 494 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 495 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 496 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 497 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 498 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 499 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 500 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 501 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 502 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 503 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 504 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 505 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 506 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 507 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 508 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 509 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 510 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 511 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 512 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 513 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 514 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 515 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 516 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 517 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 518 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 519 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 520 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 521 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 522 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 523 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 524 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 525 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 526 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 527 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 528 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 529 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "=> result saved!\n",
      "Epoch: 530 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 531 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 532 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 533 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 534 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 535 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 536 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 537 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 538 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 539 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 540 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 541 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 542 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 543 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 544 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 545 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 546 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 547 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 548 Loss: 0.03, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 549 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 550 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 551 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 552 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 553 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 554 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 555 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 556 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 557 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 558 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 559 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> result saved!\n",
      "Epoch: 560 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 561 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 562 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 563 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 564 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 565 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 566 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 567 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 568 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 569 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 570 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 571 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 572 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 573 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 574 Loss: 0.02, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 575 Loss: 0.01, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 576 Loss: 0.01, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 577 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 578 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 579 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "=> result saved!\n",
      "Epoch: 580 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 581 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 582 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 583 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 584 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 585 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 586 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 587 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 588 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 589 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 590 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 591 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 592 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 593 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 594 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 595 Loss: 0.06, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 596 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 597 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 598 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 599 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 600 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 601 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 602 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 603 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 604 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 605 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 606 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 607 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 608 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 609 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 610 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 611 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 612 Loss: 0.00, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 613 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 614 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 615 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 616 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 617 Loss: 0.01, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 618 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 619 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 620 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 621 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 622 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 623 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 624 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 625 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 626 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 627 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 628 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 629 Loss: 0.03, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "=> result saved!\n",
      "Epoch: 630 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 631 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 632 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 633 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 634 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 635 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 636 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 637 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 638 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 639 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 640 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 641 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 642 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 643 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 644 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 645 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 646 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 647 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 648 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 649 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 650 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 651 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 652 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 653 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 654 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 655 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 656 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 657 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 658 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 659 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 660 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 661 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 662 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 663 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 664 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 665 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 666 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 676 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 677 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 678 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 679 Loss: 0.04, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "=> result saved!\n",
      "Epoch: 680 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 681 Loss: 0.04, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 682 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 683 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 684 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 685 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 686 Loss: 0.04, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 687 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 688 Loss: 0.06, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 689 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "=> result saved!\n",
      "Epoch: 690 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 691 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 692 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 693 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 694 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.05, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 695 Loss: 0.07, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 696 Loss: 0.00, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 697 Loss: 0.01, Loss_test: 0.04\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 698 Loss: 0.02, Loss_test: 0.11\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 699 Loss: 0.05, Loss_test: 0.13\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.08\n",
      "=> result saved!\n",
      "Epoch: 700 Loss: 0.14, Loss_test: 0.07\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.26\n",
      "Epoch: 701 Loss: 0.07, Loss_test: 0.02\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 702 Loss: 0.04, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 703 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 704 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 705 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 706 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 707 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 708 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 709 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "=> result saved!\n",
      "Epoch: 710 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 711 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 712 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 713 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 714 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 715 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.04\n",
      "Epoch: 716 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 717 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 718 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 719 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 720 Loss: 0.04, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.07\n",
      "Epoch: 721 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 722 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 723 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 724 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 725 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 726 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 727 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 728 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 729 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "=> result saved!\n",
      "Epoch: 730 Loss: 0.04, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.07\n",
      "Epoch: 731 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 732 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 733 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.04, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 734 Loss: 0.05, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 735 Loss: 0.03, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.06\n",
      "Epoch: 736 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 737 Loss: 0.11, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 738 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 739 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "=> result saved!\n",
      "Epoch: 740 Loss: 0.05, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 741 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 742 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 743 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 744 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 745 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 746 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 747 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 748 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 749 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "=> result saved!\n",
      "Epoch: 750 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 751 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 752 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 753 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 754 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 755 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 756 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 757 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 758 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 759 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 760 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 761 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 762 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 763 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 764 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 765 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 766 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 767 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 768 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 769 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 770 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 771 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 772 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 773 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 774 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 775 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 776 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 777 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 778 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 779 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 780 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 781 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 782 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 783 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 784 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 785 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 786 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 787 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 788 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 789 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 790 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 791 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 792 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 793 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 794 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 795 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 796 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 797 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 798 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 799 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 800 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 801 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 802 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 803 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 804 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 805 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 806 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 807 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 808 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 809 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 810 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 811 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 812 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 813 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 814 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 815 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 816 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 817 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 818 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 819 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 820 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 821 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 822 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 823 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 824 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 825 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 826 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 827 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 828 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 829 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "=> result saved!\n",
      "Epoch: 830 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "Epoch: 831 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 832 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 833 Loss: 0.03, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.05\n",
      "Epoch: 834 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 835 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 836 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 837 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 838 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 839 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 840 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 841 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 842 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 843 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 844 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 845 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 846 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 847 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 848 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 849 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 850 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 851 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 852 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 853 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 854 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 855 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 856 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 857 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 858 Loss: 0.01, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 859 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 860 Loss: 0.00, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 861 Loss: 0.02, Loss_test: 0.01\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.02\n",
      "Epoch: 862 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 863 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 864 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 865 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 866 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 867 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 868 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 869 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 870 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 871 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 872 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 873 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 874 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 875 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 876 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.02, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 877 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 878 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 879 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 880 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 881 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.03, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 882 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 883 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 884 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 885 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 886 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 887 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 888 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 889 Loss: 0.02, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.03\n",
      "=> result saved!\n",
      "Epoch: 890 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 891 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 892 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 893 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 894 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 895 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 896 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 897 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "Epoch: 898 Loss: 0.01, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.01, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.01\n",
      "Epoch: 899 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n",
      "=> result saved!\n",
      "Epoch: 900 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00\n"
     ]
    }
   ],
   "source": [
    "end_train = epochs - limit_train\n",
    "for epoch in range(limit_train, end_train):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_sim = batch_iterator(baseline, retrieval, model, baseline.train_data, \n",
    "                                                       baseline.dup_sets_train, bug_train_ids, \n",
    "                                                           batch_size, 1, issues_by_buckets, TRIPLET_HARD=False)\n",
    "    train_batch = [train_input_sample['title']['token'], train_input_sample['title']['segment'], \n",
    "                   train_input_sample['description']['token'], train_input_sample['description']['segment'],\n",
    "                   train_input_sample['info'], train_input_sample['topics'], train_sim]\n",
    "    \n",
    "\n",
    "    h = model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    h_validation = model.test_on_batch(x=validation_sample, y=valid_sim)\n",
    "    \n",
    "    # save results\n",
    "    result['train'].append(h)\n",
    "    result['test'].append(h_validation)\n",
    "    \n",
    "    if( (epoch+1) % 10 == 0 or (epoch+1 == end_train )):\n",
    "        save_loss(result)\n",
    "    \n",
    "    print((\"Epoch: {} Loss: {:.2f}, Loss_test: {:.2f}\\n\" +\n",
    "               \"TL_w: {:.2f}, TL_pos_w: {:.2f}, TL_neg_w: {:.2f}, TL_centroid_w: {:.2f}\\n\" + \n",
    "              \"TL: {:.2f}, TL_pos: {:.2f}, TL_neg: {:.2f}, TL_centroid: {:.2f}\").format(\n",
    "            epoch+1, h[0], h_validation[0], h[1], h[2], h[3], h[4], h[5], h[6], h[7], h[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 900)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['train']), len(result['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = model.get_layer('merge_features_in')\n",
    "output = encoded.output\n",
    "inputs = similarity_model.inputs[:-1]\n",
    "encoded_anchor = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert_preprocessing_deepQL_topics_1000_feature1000epochs_64batch(openoffice)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model 'modelos/model_bert_preprocessing_deepQL_topics_1000_feature_1000epochs_64batch(openoffice).h5' to disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model saved'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.save_model(model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "\"Model saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5f312bb04146fa9b019583a5f64cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8265), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f278edb58664901bf5b2ad115978069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11757), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30682b1600cb489d859e43b366f89b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12837), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3bddf50a1b4b97a237f12ff10d47be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba9b180125546999709e10f17ec0d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bbaa1d8c47493bb51398608ba6a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefa1dc67a89443887d1783daa8d0b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11757), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 900 Loss: 0.00, Loss_test: 0.00\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 1.00, TL_centroid_w: 1.00\n",
      "TL: 0.00, TL_pos: 0.00, TL_neg: 0.00, TL_centroid: 0.00, recall@25: 0.68\n"
     ]
    }
   ],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 1, encoded_anchor, issues_by_buckets, \n",
    "                                                               bug_train_ids, method='bert-topic')\n",
    "print((\"Epoch: {} Loss: {:.2f}, Loss_test: {:.2f}\\n\" +\n",
    "       \"TL_w: {:.2f}, TL_pos_w: {:.2f}, TL_neg_w: {:.2f}, TL_centroid_w: {:.2f}\\n\" + \n",
    "        \"TL: {:.2f}, TL_pos: {:.2f}, TL_neg: {:.2f}, TL_centroid: {:.2f}, \" +\n",
    "      \"recall@25: {:.2f}\").format(epoch+1, h[0], h_validation[0], h[1], h[2], h[3], h[4], h[5], h[6], h[7], h[8], recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['98306:88871,50853,33630,90791|88871:0.3381749391555786,37651:0.3255718946456909,36495:0.2977479100227356,65485:0.2783980369567871,43589:0.27646785974502563,26091:0.2726343274116516,78716:0.26942014694213867,85708:0.26669037342071533,42420:0.26246941089630127,70706:0.26232588291168213,36353:0.26200127601623535,33630:0.26095712184906006,77976:0.2605603337287903,75781:0.2603600025177002,57162:0.2599606513977051,34632:0.2586956024169922,69738:0.2558134198188782,38304:0.2526378631591797,115935:0.2518168091773987,74244:0.2503477931022644,96878:0.24923914670944214,99625:0.248976469039917,58811:0.2482091784477234,84783:0.24793630838394165,53272:0.2421589493751526,94253:0.23928380012512207,20733:0.23856991529464722,53674:0.23789316415786743,50853:0.23767340183258057',\n",
       " '32771:32490,33548,32560,33879,32699|33506:0.35983628034591675,17105:0.3367994427680969,5245:0.33299142122268677,7354:0.33006417751312256,6970:0.3271963596343994,86473:0.31630510091781616,5330:0.3125731348991394,82685:0.3057987689971924,21467:0.30394554138183594,5080:0.30376237630844116,19220:0.3034050464630127,69374:0.3031435012817383,39209:0.3024100661277771,113147:0.30185002088546753,8837:0.3015395998954773,5885:0.30034393072128296,5412:0.29763275384902954,13469:0.2971065044403076,5515:0.2969067096710205,17409:0.29672396183013916,19554:0.29326677322387695,4516:0.2914578318595886,18587:0.2900604009628296,26003:0.2860291004180908,12158:0.2830401062965393,14128:0.2827199101448059,71665:0.2823221683502197,20262:0.28168123960494995,9917:0.2813383936882019',\n",
       " '32772:22694,36970,39820,34488,33298,36760,34911|36760:0.28685498237609863,69051:0.2666161060333252,34766:0.2476847767829895,4781:0.24611926078796387,14947:0.2431412935256958,3830:0.22459596395492554,13828:0.2232343554496765,28573:0.22084397077560425,34911:0.21910995244979858,19572:0.2168228030204773,89200:0.21616744995117188,28429:0.21421170234680176,12997:0.21357381343841553,19712:0.2087535262107849,79678:0.20503473281860352,94393:0.2026847004890442,3379:0.20105820894241333,89009:0.199731707572937,20299:0.19901078939437866,4720:0.19677484035491943,12867:0.19531333446502686,28178:0.1945626139640808,12276:0.19280612468719482,14572:0.1890600323677063,39293:0.18647170066833496,17972:0.18576151132583618,47132:0.18461918830871582,41312:0.18449914455413818,22251:0.18410056829452515',\n",
       " '32776:30241,33762,31134,33183|31134:0.3456294536590576,47305:0.31765949726104736,15558:0.29081475734710693,25825:0.28669649362564087,14805:0.28144800662994385,76360:0.2596171498298645,71161:0.25810706615448,25655:0.2571176290512085,3281:0.25229793787002563,18008:0.2508258819580078,30241:0.2480044960975647,50333:0.24586379528045654,85902:0.24575060606002808,18009:0.2450205683708191,74052:0.2427123785018921,5121:0.24204206466674805,88031:0.2414400577545166,5103:0.23907339572906494,19024:0.2379940152168274,41017:0.23536020517349243,26681:0.2347325086593628,33762:0.23394936323165894,52250:0.2337327003479004,29646:0.2337138056755066,74532:0.23335766792297363,19713:0.23281127214431763,101934:0.23269051313400269,49488:0.23087471723556519,51734:0.2278798222541809',\n",
       " '65545:55967|64932:0.4842592477798462,52977:0.374549925327301,77422:0.36443763971328735,80295:0.3513907194137573,64968:0.3176482915878296,33413:0.30833935737609863,78767:0.29444557428359985,16204:0.2839183807373047,78538:0.2779500484466553,70591:0.277621865272522,52326:0.2743670344352722,91393:0.2722582221031189,67853:0.2701418995857239,86812:0.2637329697608948,82101:0.2616094946861267,66713:0.261286199092865,38852:0.26049089431762695,71725:0.25280267000198364,52748:0.2516842484474182,79418:0.251339852809906,72793:0.24966895580291748,31876:0.2475948929786682,34419:0.24680262804031372,21388:0.24399620294570923,21473:0.24297469854354858,80274:0.241723895072937,65107:0.2412319779396057,77664:0.24096614122390747,81248:0.23977524042129517',\n",
       " '65549:26122,62365,3411,74204,94365|76422:0.4257190227508545,76037:0.3936501741409302,53250:0.3896544575691223,100529:0.3895832896232605,28932:0.38581418991088867,91578:0.38455307483673096,13699:0.3828847408294678,43459:0.38153284788131714,8660:0.36714494228363037,3997:0.35150885581970215,90074:0.35034751892089844,21652:0.34744685888290405,44072:0.3472338318824768,20032:0.3466529846191406,21653:0.34628212451934814,71174:0.3458597660064697,50655:0.3437899351119995,4826:0.3429321050643921,52800:0.34232014417648315,10453:0.34165000915527344,9888:0.3415873646736145,13437:0.34120696783065796,6699:0.34085988998413086,34263:0.33853667974472046,26497:0.33753502368927,82400:0.3372967839241028,75670:0.33712589740753174,61177:0.33679860830307007,60556:0.3356919288635254',\n",
       " '98318:98570|99728:0.3474557399749756,81342:0.3162580728530884,56693:0.31434279680252075,69512:0.312483549118042,66262:0.3014034628868103,104753:0.2978004217147827,16404:0.29688501358032227,70443:0.29215866327285767,92251:0.29004424810409546,100166:0.2879886031150818,80935:0.2822090983390808,63230:0.28037214279174805,79354:0.2771068811416626,79352:0.2771068811416626,79353:0.2771068811416626,103326:0.27316856384277344,92432:0.27242451906204224,65690:0.2713587284088135,102419:0.2713090777397156,105918:0.2710399031639099,80272:0.26733410358428955,112302:0.26463961601257324,99954:0.2631716728210449,52861:0.26275378465652466,72872:0.26242536306381226,37442:0.2622230052947998,39257:0.2602698802947998,92427:0.260109543800354,69524:0.25996720790863037',\n",
       " '98319:107242,102941|102941:0.36956876516342163,82109:0.36058318614959717,82363:0.35812288522720337,61314:0.3578859567642212,107242:0.35431432723999023,112435:0.35117077827453613,106903:0.34717828035354614,88591:0.34352684020996094,93147:0.3424442410469055,44648:0.33244895935058594,80225:0.3306301236152649,35677:0.32991576194763184,114810:0.3252858519554138,84675:0.3243229389190674,56969:0.32151734828948975,24164:0.3180736303329468,47085:0.3148272633552551,36741:0.3147137761116028,68510:0.31366240978240967,83180:0.31154704093933105,84384:0.30976712703704834,103241:0.3092572093009949,75933:0.30711501836776733,99814:0.30620652437210083,104163:0.30170029401779175,3823:0.3014065623283386,49803:0.30071359872817993,22994:0.30059629678726196,3997:0.30043548345565796',\n",
       " '18:100,271|100:0.30669814348220825,10123:0.20406955480575562,59399:0.1967768669128418,1271:0.18541407585144043,16279:0.1797981858253479,19242:0.17459404468536377,78883:0.17113608121871948,23740:0.17047864198684692,15371:0.17043334245681763,82242:0.16689342260360718,15325:0.1611419916152954,23362:0.15595537424087524,42219:0.15577632188796997,19241:0.15438199043273926,19239:0.15340465307235718,67288:0.15074670314788818,6619:0.1501936912536621,18973:0.14830267429351807,8731:0.14647269248962402,21196:0.14621037244796753,2355:0.14352941513061523,40581:0.14085352420806885,2306:0.13479292392730713,116662:0.12625813484191895,44528:0.12565213441848755,6397:0.12359851598739624,50276:0.11995995044708252,28559:0.11906981468200684,30076:0.11822855472564697',\n",
       " '32788:31681,32789,31726|32789:1.0,65399:0.3028649091720581,29469:0.28429120779037476,36343:0.27475273609161377,33826:0.25984448194503784,57593:0.252910315990448,92794:0.2521398067474365,35506:0.25034451484680176,101633:0.24004238843917847,39178:0.2350054383277893,61334:0.23284775018692017,76795:0.2325388789176941,114339:0.23214352130889893,39119:0.22947049140930176,35929:0.2259904146194458,32678:0.22514933347702026,48966:0.22340792417526245,73129:0.2226313352584839,31726:0.22122681140899658,33508:0.22081172466278076,35846:0.21806257963180542,91667:0.21770548820495605,62793:0.21699213981628418,91514:0.21650338172912598,87291:0.2161407470703125,43547:0.21605980396270752,34072:0.2127559781074524,67874:0.21237319707870483,40631:0.21211665868759155',\n",
       " '32789:31681,32788,31726|32788:1.0,65399:0.3028649091720581,29469:0.28429120779037476,36343:0.27475273609161377,33826:0.25984448194503784,57593:0.252910315990448,92794:0.2521398067474365,35506:0.25034451484680176,101633:0.24004238843917847,39178:0.2350054383277893,61334:0.23284775018692017,76795:0.2325388789176941,114339:0.23214352130889893,39119:0.22947049140930176,35929:0.2259904146194458,32678:0.22514933347702026,48966:0.22340792417526245,73129:0.2226313352584839,31726:0.22122681140899658,33508:0.22081172466278076,35846:0.21806257963180542,91667:0.21770548820495605,62793:0.21699213981628418,91514:0.21650338172912598,87291:0.2161407470703125,43547:0.21605980396270752,34072:0.2127559781074524,67874:0.21237319707870483,40631:0.21211665868759155',\n",
       " '65561:27520,50753,21280,85187,51168,35298,83046,27630,81041,46738,46739,46740,103094,48951,55995,76895|22719:0.40985023975372314,36479:0.36705994606018066,27630:0.34978383779525757,5399:0.33846843242645264,21773:0.3364991545677185,17090:0.33463841676712036,21924:0.32802075147628784,21217:0.32673007249832153,15752:0.3210829496383667,95936:0.3172106146812439,35298:0.3104441165924072,22281:0.3098449110984802,10162:0.30902087688446045,23263:0.30815577507019043,88482:0.3061172366142273,14769:0.30539631843566895,8301:0.3046761751174927,79995:0.3035632371902466,7088:0.3013089895248413,60285:0.299005925655365,94024:0.29417717456817627,18302:0.28594714403152466,4253:0.28383731842041016,67816:0.2837851047515869,68784:0.2835496664047241,35705:0.283332884311676,33221:0.282375693321228,30107:0.2816844582557678,83586:0.28168100118637085',\n",
       " '27:59,92|59:0.45031559467315674,33041:0.4286065101623535,753:0.4251629114151001,22906:0.4125351309776306,18118:0.412189245223999,3359:0.40996015071868896,51824:0.3956238031387329,91423:0.39299440383911133,5532:0.39127981662750244,51937:0.3874538540840149,10646:0.38223761320114136,51722:0.3781219720840454,51595:0.3775902986526489,7917:0.37628692388534546,55317:0.37557435035705566,92:0.37256956100463867,101570:0.3717171549797058,1273:0.3702383041381836,14439:0.3653450608253479,51446:0.3643333911895752,8836:0.36281734704971313,32766:0.36171722412109375,55505:0.36049336194992065,4087:0.35631221532821655,8689:0.3540065884590149,1105:0.3539445996284485,16986:0.353759765625,113106:0.35375863313674927,17581:0.3524327874183655',\n",
       " '32:42944,6342,3207,18886,32905,54854,54855,67697,4756,23861,18648,58138,40286|52952:0.2968778610229492,101335:0.26473528146743774,91313:0.2647157311439514,80652:0.26015836000442505,72019:0.24555140733718872,92794:0.24172168970108032,98949:0.241357684135437,37488:0.23629409074783325,30399:0.2342996597290039,81986:0.23223376274108887,45044:0.2322184443473816,45045:0.2322184443473816,83544:0.2316111922264099,48886:0.2305077314376831,83272:0.23042941093444824,29980:0.22809702157974243,89316:0.22606629133224487,24223:0.22566449642181396,89200:0.22478026151657104,102059:0.22347795963287354,102627:0.22347015142440796,31362:0.2230890393257141,69051:0.22187650203704834,50588:0.22174954414367676,83556:0.2208765745162964,56506:0.22002559900283813,89153:0.219954252243042,3443:0.2197355031967163,83557:0.21845728158950806',\n",
       " '32813:33041|11574:0.31195539236068726,76457:0.29557985067367554,74820:0.2930176854133606,7416:0.2913573980331421,17095:0.2899779677391052,4631:0.2868337035179138,33041:0.2867385745048523,52653:0.2850460410118103,52018:0.2824000120162964,32618:0.28116363286972046,19160:0.28055059909820557,18841:0.27915722131729126,710:0.2778171896934509,27874:0.27737438678741455,80999:0.2769250273704529,14260:0.27665674686431885,52285:0.27561134099960327,8444:0.2722259759902954,11695:0.26807737350463867,91394:0.26485979557037354,32766:0.2640969157218933,12788:0.263277530670166,22906:0.26241207122802734,16805:0.2622443437576294,16806:0.2622443437576294,13810:0.26165783405303955,82605:0.2595013380050659,16827:0.25782763957977295,17286:0.25757038593292236',\n",
       " '32814:37274,38852,37357|52956:0.3132973313331604,70316:0.28626418113708496,70317:0.28626418113708496,37274:0.27415531873703003,50729:0.2689934968948364,25253:0.24618715047836304,27027:0.2036353349685669,112305:0.19998139142990112,70900:0.19595110416412354,113633:0.19382470846176147,100749:0.19277596473693848,100750:0.19277596473693848,100751:0.19277596473693848,62068:0.19072091579437256,25150:0.18566596508026123,35079:0.18484550714492798,52977:0.18396931886672974,52789:0.17844438552856445,41023:0.17743325233459473,77664:0.1757315993309021,81098:0.17216235399246216,86394:0.16958487033843994,34096:0.16829341650009155,65215:0.16813892126083374,27123:0.16772741079330444,76516:0.1664455533027649,42152:0.16602587699890137,32398:0.163535475730896,54726:0.16210639476776123',\n",
       " '32815:32033,31362,31874,33062,31550|33062:0.3758547902107239,44095:0.3661896586418152,48194:0.36276906728744507,61607:0.3356727361679077,18619:0.33301061391830444,26367:0.32301443815231323,46452:0.3212502598762512,41469:0.3184455633163452,41587:0.3167489171028137,39967:0.30816543102264404,44415:0.30402958393096924,32215:0.3036242723464966,31623:0.30322277545928955,32981:0.29999488592147827,45885:0.2976420521736145,76795:0.29686272144317627,60782:0.29405301809310913,50613:0.29322415590286255,32241:0.28858470916748047,43744:0.28296977281570435,52382:0.2822737693786621,32088:0.28028666973114014,34275:0.2800229787826538,44243:0.27908390760421753,52560:0.2773662209510803,44991:0.27717381715774536,53303:0.276103675365448,42202:0.27577757835388184,31362:0.27319079637527466',\n",
       " '65586:71849,67371,67476,83252,88157,67642,71099,69789,81630|45074:0.3065687417984009,25792:0.30130714178085327,25360:0.28570157289505005,1814:0.2694006562232971,55514:0.2687256336212158,55515:0.2687256336212158,55516:0.2687256336212158,55517:0.2687256336212158,82848:0.26102501153945923,27185:0.25675010681152344,4535:0.25555479526519775,87558:0.25446367263793945,65773:0.25420671701431274,20326:0.25275856256484985,74511:0.25224316120147705,17440:0.25140613317489624,54993:0.24973374605178833,12770:0.24943816661834717,67089:0.2490156888961792,12710:0.24201327562332153,11189:0.23802870512008667,3558:0.2363632321357727,19615:0.23514574766159058,117607:0.2338954210281372,4717:0.23364132642745972,21882:0.2314434051513672,14182:0.22874802350997925,4997:0.2266063690185547,40921:0.2258591651916504',\n",
       " '51:52|52:0.8413579016923904,28408:0.38338708877563477,18973:0.3777531385421753,19330:0.36303162574768066,65954:0.345001757144928,31330:0.33701807260513306,24945:0.3261653184890747,82336:0.318417489528656,13343:0.30390745401382446,82314:0.2981215715408325,943:0.2794487476348877,82242:0.2785941958427429,1423:0.27647149562835693,23362:0.27319562435150146,75007:0.27279210090637207,22867:0.2626684308052063,26449:0.2586976885795593,29737:0.2549065947532654,580:0.25188493728637695,1408:0.25170236825942993,26030:0.24344635009765625,1537:0.23845016956329346,22882:0.23358410596847534,89143:0.22542834281921387,230:0.219815194606781,6477:0.21932590007781982,26884:0.21683990955352783,1561:0.21600210666656494,728:0.2082405686378479',\n",
       " '52:51|51:0.8413579016923904,28408:0.3812992572784424,18973:0.37808752059936523,65954:0.37684857845306396,19330:0.3682059049606323,24945:0.3543057441711426,66782:0.35139918327331543,25375:0.3465210795402527,82229:0.34150809049606323,31330:0.32378917932510376,82336:0.3220359683036804,13343:0.313609778881073,23641:0.2975676655769348,82314:0.29468590021133423,82242:0.2922450304031372,943:0.2864876985549927,1423:0.28450828790664673,22867:0.2827151417732239,75007:0.2804717421531677,23362:0.274017333984375,580:0.2609071135520935,9734:0.26029425859451294,1408:0.26020896434783936,29737:0.2590843439102173,26449:0.25510889291763306,111354:0.250912070274353,65953:0.24909037351608276,1537:0.24792343378067017,26030:0.24064421653747559']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exported_rank[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 8265\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_preprocessing_deepQL_topics_1000_feature_1000epochs_64batch(openoffice)\n"
     ]
    }
   ],
   "source": [
    "print(SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 738)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_token_in (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_segment_in (InputLayer)   (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_token_in (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_segment_in (InputLayer)    (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "topics_in (InputLayer)          (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          221700      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelTitle (None, 300)          80577436    title_token_in[0][0]             \n",
      "                                                                 title_segment_in[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FeatureBERTGenerationModelDescr (None, 300)          80577436    desc_token_in[0][0]              \n",
      "                                                                 desc_segment_in[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureTopicMlpGenerationModel  (None, 300)          9300        topics_in[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 1200)         0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureBERTGenerationModelTitle[1\n",
      "                                                                 FeatureBERTGenerationModelDescrip\n",
      "                                                                 FeatureTopicMlpGenerationModel[1]\n",
      "==================================================================================================\n",
      "Total params: 161,385,872\n",
      "Trainable params: 913,696\n",
      "Non-trainable params: 160,472,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoded_anchor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11757\n"
     ]
    }
   ],
   "source": [
    "print(len(exported_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/openoffice/bert/exported_rank_deepQL_topics_1000.txt\n"
     ]
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "print(EXPORT_RANK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1 - recall_at_5': 0.56, '3 - recall_at_15': 0.65, '4 - recall_at_20': 0.67, '0 - recall_at_1': 0.4, '5 - recall_at_25': 0.68, '2 - recall_at_10': 0.62}\n"
     ]
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
