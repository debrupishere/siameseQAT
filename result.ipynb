{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.evaluation import Evaluation, EvaluationPrecision, EvaluationRecall, EvaluationFscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['eclipse', 'netbeans', 'openoffice'] # 'firefox' \n",
    "PREPROCESSING = 'bert'\n",
    "approaches = ['baseline', 'baseline_dwen', 'DWEN_QL', 'DMS_QL', 'deepQL_weights', 'deepQL_trainable', 'deepTL'] # \n",
    "methods = {}\n",
    "authors = {}\n",
    "markers = {}\n",
    "approaches_names = {\n",
    "    'baseline' : 'DMS',\n",
    "    'DMS_QL' : 'DMS_QL',\n",
    "    'baseline_dwen' : 'DWEN',\n",
    "    'DWEN_QL' : 'DWEN_QL',\n",
    "    'deepQL_weights' : 'DeepQL',\n",
    "    'deepQL_trainable' : 'DeepQL_trainable',\n",
    "    'deepTL' : 'DeepTL'\n",
    "}\n",
    "approaches_symbols = {\n",
    "    'baseline' : '.',\n",
    "    'baseline_dwen' : '^',\n",
    "    'deepQL_weights' : '*',\n",
    "    'DWEN_QL' : '>',\n",
    "    'deepQL_trainable' : '4',\n",
    "    'deepTL' : 'D',\n",
    "    'DMS_QL' : '3'\n",
    "}\n",
    "epochs = ['20', '100', '1000']\n",
    "for i in epochs:\n",
    "    if i not in methods:\n",
    "        methods[i] = []\n",
    "    for name in approaches:\n",
    "        methods[i].append(\"{}_{}\".format(name, i))\n",
    "for i in epochs:\n",
    "    for name in approaches:\n",
    "        key = \"{}_{}\".format(name, i)\n",
    "        authors[key] =  approaches_names[name]\n",
    "for i in epochs:\n",
    "    for name in approaches:\n",
    "        key = \"{}_{}\".format(name, i)\n",
    "        markers[key] =  approaches_symbols[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100': ['baseline_100',\n",
       "  'baseline_dwen_100',\n",
       "  'DWEN_QL_100',\n",
       "  'DMS_QL_100',\n",
       "  'deepQL_weights_100',\n",
       "  'deepQL_trainable_100',\n",
       "  'deepTL_100'],\n",
       " '1000': ['baseline_1000',\n",
       "  'baseline_dwen_1000',\n",
       "  'DWEN_QL_1000',\n",
       "  'DMS_QL_1000',\n",
       "  'deepQL_weights_1000',\n",
       "  'deepQL_trainable_1000',\n",
       "  'deepTL_1000'],\n",
       " '20': ['baseline_20',\n",
       "  'baseline_dwen_20',\n",
       "  'DWEN_QL_20',\n",
       "  'DMS_QL_20',\n",
       "  'deepQL_weights_20',\n",
       "  'deepQL_trainable_20',\n",
       "  'deepTL_20']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DMS_QL_100': 'DMS_QL',\n",
       " 'DMS_QL_1000': 'DMS_QL',\n",
       " 'DMS_QL_20': 'DMS_QL',\n",
       " 'DWEN_QL_100': 'DWEN_QL',\n",
       " 'DWEN_QL_1000': 'DWEN_QL',\n",
       " 'DWEN_QL_20': 'DWEN_QL',\n",
       " 'baseline_100': 'DMS',\n",
       " 'baseline_1000': 'DMS',\n",
       " 'baseline_20': 'DMS',\n",
       " 'baseline_dwen_100': 'DWEN',\n",
       " 'baseline_dwen_1000': 'DWEN',\n",
       " 'baseline_dwen_20': 'DWEN',\n",
       " 'deepQL_trainable_100': 'DeepQL_trainable',\n",
       " 'deepQL_trainable_1000': 'DeepQL_trainable',\n",
       " 'deepQL_trainable_20': 'DeepQL_trainable',\n",
       " 'deepQL_weights_100': 'DeepQL',\n",
       " 'deepQL_weights_1000': 'DeepQL',\n",
       " 'deepQL_weights_20': 'DeepQL',\n",
       " 'deepTL_100': 'DeepTL',\n",
       " 'deepTL_1000': 'DeepTL',\n",
       " 'deepTL_20': 'DeepTL'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DMS_QL_100': '3',\n",
       " 'DMS_QL_1000': '3',\n",
       " 'DMS_QL_20': '3',\n",
       " 'DWEN_QL_100': '>',\n",
       " 'DWEN_QL_1000': '>',\n",
       " 'DWEN_QL_20': '>',\n",
       " 'baseline_100': '.',\n",
       " 'baseline_1000': '.',\n",
       " 'baseline_20': '.',\n",
       " 'baseline_dwen_100': '^',\n",
       " 'baseline_dwen_1000': '^',\n",
       " 'baseline_dwen_20': '^',\n",
       " 'deepQL_trainable_100': '4',\n",
       " 'deepQL_trainable_1000': '4',\n",
       " 'deepQL_trainable_20': '4',\n",
       " 'deepQL_weights_100': '*',\n",
       " 'deepQL_weights_1000': '*',\n",
       " 'deepQL_weights_20': '*',\n",
       " 'deepTL_100': 'D',\n",
       " 'deepTL_1000': 'D',\n",
       " 'deepTL_20': 'D'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_rank(evaluation, method, domain, epoch, aproach, recall, recall_index, epochs, datasets, symbols, path):\n",
    "    #evaluation = Evaluation(0)\n",
    "    try:\n",
    "        if(path != ''):\n",
    "            report = evaluation.evaluate(path)\n",
    "        else:\n",
    "            report = evaluation\n",
    "        recall.append(report['0 - recall_at_1'])\n",
    "        recall.append(report['1 - recall_at_5'])\n",
    "        recall.append(report['2 - recall_at_10'])\n",
    "        recall.append(report['3 - recall_at_15'])\n",
    "        recall.append(report['4 - recall_at_20'])\n",
    "        recall.append(report['5 - recall_at_25'])\n",
    "        aproach += [authors[method]] * 6\n",
    "        symbols += [markers[method]] * 6\n",
    "        datasets += [domain] * 6\n",
    "        epochs += [epoch] * 6\n",
    "        recall_index += [1, 5, 10, 15, 20, 25]\n",
    "        print(path)\n",
    "        return report\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Does not exist result for: {}\".format(path))\n",
    "        return\n",
    "def create_dataframe(rank):\n",
    "    recall = [] # recall binary\n",
    "    recall_classic = [] # recall with groundtruth\n",
    "    precision = []\n",
    "    fscore = []\n",
    "    fscore_classic = []\n",
    "    aproach, recall_index, datasets, epochs, symbols = [], [], [], [], []\n",
    "    df = pd.DataFrame(columns=['recall', 'precision', 'f_score', 'top@k', 'method', 'domain', 'epoch', 'symbol'])\n",
    "\n",
    "    for epoch in ['100', '1000']:\n",
    "        for domain in domains:\n",
    "            # Domain to use\n",
    "            DOMAIN = domain\n",
    "            # Dataset paths\n",
    "            DIR = 'data/processed/{}/{}'.format(DOMAIN, PREPROCESSING)\n",
    "            for method in methods[epoch]:\n",
    "                path = os.path.join(DIR, '{}_{}.txt'.format(rank, method))\n",
    "                report_recall = evaluate_rank(Evaluation(0), method, domain, epoch, aproach, recall, recall_index, epochs, datasets, symbols, path)\n",
    "                report_precision = evaluate_rank(EvaluationPrecision(0), method, domain, epoch, [], precision, [], [], [], [], path)\n",
    "#                 report_recall_classic = evaluate_rank(EvaluationRecall(0), epoch, domain, recall_classic, [], path)\n",
    "                if(report_precision != None and report_recall != None):\n",
    "                    report_fscore = evaluate_rank(EvaluationFscore().evaluate(report_precision, report_recall), method, domain, epoch, [], fscore, [], [], [], [], '')\n",
    "    \n",
    "    df['recall'] = recall\n",
    "    df['precision'] = precision\n",
    "    df['f_score'] = fscore\n",
    "    df['top@k'] = recall_index\n",
    "    df['method'] = aproach\n",
    "    df['domain'] = datasets\n",
    "    df['epoch'] = epochs\n",
    "    df['symbol'] = symbols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/eclipse/bert/exported_rank_baseline_100.txt\n",
      "data/processed/eclipse/bert/exported_rank_baseline_100.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_baseline_dwen_100.txt\n",
      "data/processed/eclipse/bert/exported_rank_baseline_dwen_100.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_DWEN_QL_100.txt\n",
      "data/processed/eclipse/bert/exported_rank_DWEN_QL_100.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_DMS_QL_100.txt\n",
      "data/processed/eclipse/bert/exported_rank_DMS_QL_100.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_deepQL_weights_100.txt\n",
      "data/processed/eclipse/bert/exported_rank_deepQL_weights_100.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_deepQL_trainable_100.txt\n",
      "data/processed/eclipse/bert/exported_rank_deepQL_trainable_100.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_deepTL_100.txt\n",
      "data/processed/eclipse/bert/exported_rank_deepTL_100.txt\n",
      "\n",
      "data/processed/netbeans/bert/exported_rank_baseline_100.txt\n",
      "data/processed/netbeans/bert/exported_rank_baseline_100.txt\n",
      "\n",
      "data/processed/netbeans/bert/exported_rank_baseline_dwen_100.txt\n",
      "data/processed/netbeans/bert/exported_rank_baseline_dwen_100.txt\n",
      "\n",
      "[Errno 2] No such file or directory: 'data/processed/netbeans/bert/exported_rank_DWEN_QL_100.txt'\n",
      "Does not exist result for: data/processed/netbeans/bert/exported_rank_DWEN_QL_100.txt\n",
      "[Errno 2] No such file or directory: 'data/processed/netbeans/bert/exported_rank_DWEN_QL_100.txt'\n",
      "Does not exist result for: data/processed/netbeans/bert/exported_rank_DWEN_QL_100.txt\n",
      "data/processed/netbeans/bert/exported_rank_DMS_QL_100.txt\n",
      "data/processed/netbeans/bert/exported_rank_DMS_QL_100.txt\n",
      "\n",
      "data/processed/netbeans/bert/exported_rank_deepQL_weights_100.txt\n",
      "data/processed/netbeans/bert/exported_rank_deepQL_weights_100.txt\n",
      "\n",
      "data/processed/netbeans/bert/exported_rank_deepQL_trainable_100.txt\n",
      "data/processed/netbeans/bert/exported_rank_deepQL_trainable_100.txt\n",
      "\n",
      "data/processed/netbeans/bert/exported_rank_deepTL_100.txt\n",
      "data/processed/netbeans/bert/exported_rank_deepTL_100.txt\n",
      "\n",
      "data/processed/openoffice/bert/exported_rank_baseline_100.txt\n",
      "data/processed/openoffice/bert/exported_rank_baseline_100.txt\n",
      "\n",
      "data/processed/openoffice/bert/exported_rank_baseline_dwen_100.txt\n",
      "data/processed/openoffice/bert/exported_rank_baseline_dwen_100.txt\n",
      "\n",
      "[Errno 2] No such file or directory: 'data/processed/openoffice/bert/exported_rank_DWEN_QL_100.txt'\n",
      "Does not exist result for: data/processed/openoffice/bert/exported_rank_DWEN_QL_100.txt\n",
      "[Errno 2] No such file or directory: 'data/processed/openoffice/bert/exported_rank_DWEN_QL_100.txt'\n",
      "Does not exist result for: data/processed/openoffice/bert/exported_rank_DWEN_QL_100.txt\n",
      "data/processed/openoffice/bert/exported_rank_DMS_QL_100.txt\n",
      "data/processed/openoffice/bert/exported_rank_DMS_QL_100.txt\n",
      "\n",
      "data/processed/openoffice/bert/exported_rank_deepQL_weights_100.txt\n",
      "data/processed/openoffice/bert/exported_rank_deepQL_weights_100.txt\n",
      "\n",
      "data/processed/openoffice/bert/exported_rank_deepQL_trainable_100.txt\n",
      "data/processed/openoffice/bert/exported_rank_deepQL_trainable_100.txt\n",
      "\n",
      "data/processed/openoffice/bert/exported_rank_deepTL_100.txt\n",
      "data/processed/openoffice/bert/exported_rank_deepTL_100.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_baseline_1000.txt\n",
      "data/processed/eclipse/bert/exported_rank_baseline_1000.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_baseline_dwen_1000.txt\n",
      "data/processed/eclipse/bert/exported_rank_baseline_dwen_1000.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_DWEN_QL_1000.txt\n",
      "data/processed/eclipse/bert/exported_rank_DWEN_QL_1000.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_DMS_QL_1000.txt\n",
      "data/processed/eclipse/bert/exported_rank_DMS_QL_1000.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_deepQL_weights_1000.txt\n",
      "data/processed/eclipse/bert/exported_rank_deepQL_weights_1000.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_deepQL_trainable_1000.txt\n",
      "data/processed/eclipse/bert/exported_rank_deepQL_trainable_1000.txt\n",
      "\n",
      "data/processed/eclipse/bert/exported_rank_deepTL_1000.txt\n",
      "data/processed/eclipse/bert/exported_rank_deepTL_1000.txt\n",
      "\n",
      "data/processed/netbeans/bert/exported_rank_baseline_1000.txt\n",
      "data/processed/netbeans/bert/exported_rank_baseline_1000.txt\n",
      "\n",
      "data/processed/netbeans/bert/exported_rank_baseline_dwen_1000.txt\n"
     ]
    }
   ],
   "source": [
    "df = create_dataframe('exported_rank')\n",
    "df_master = create_dataframe('exported_rank_master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markers\n",
    "\n",
    "https://matplotlib.org/3.1.1/api/markers_api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100 = df[df['epoch'] == '100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "MEDIUM_SIZE = 16\n",
    "SMALL_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "\n",
    "#plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "#plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "def build_100_epochs(metric):\n",
    "    # equivalent but more general\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(domains), figsize=(22, 5))\n",
    "\n",
    "    for index, domain in enumerate(domains):\n",
    "        aproachs = df_100['method'].unique()\n",
    "        for method in aproachs:\n",
    "            experiment = df_100[(df_100['method'] == method) & (df_100['domain'] == domain)]\n",
    "            if experiment.shape[0] > 0:\n",
    "                experiment.plot(x='top@k', y=metric, label=method, ax=axes[index], \n",
    "                                marker=experiment['symbol'].values[0], markersize=12)\n",
    "\n",
    "        axes[index].set_ylabel('{} Rate'.format(metric))\n",
    "        axes[index].set_xlabel('K')\n",
    "        text = axes[index].set_title('{}'.format(domain))\n",
    "        lgd = axes[index].legend(loc='upper center', bbox_to_anchor=(0.5, -0.18))\n",
    "        formatter = mticker.ScalarFormatter()\n",
    "        axes[index].xaxis.set_major_formatter(formatter)\n",
    "        axes[index].xaxis.set_major_locator(mticker.FixedLocator([1, 5, 10, 15, 20, 25]))\n",
    "        axes[index].grid(True, axis='y', alpha=.5)\n",
    "\n",
    "    fig.savefig('retrieval_100.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_100_epochs('recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1000 = df[df['epoch'] == '1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "MEDIUM_SIZE = 16\n",
    "SMALL_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "\n",
    "#plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "#plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "def build_1000_epochs(metric):\n",
    "    # equivalent but more general\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(domains), figsize=(22, 5))\n",
    "\n",
    "    for index, domain in enumerate(domains):\n",
    "        aproachs = df['method'].unique()\n",
    "        for method in aproachs:\n",
    "            experiment = df_1000[(df_1000['method'] == method) & (df_1000['domain'] == domain)]\n",
    "            if experiment.shape[0] > 0:\n",
    "                experiment.plot(x='top@k', y=metric, label=method, ax=axes[index], \n",
    "                                marker=experiment['symbol'].values[0], markersize=12)\n",
    "\n",
    "        axes[index].set_ylabel('{} Rate'.format(metric))\n",
    "        axes[index].set_xlabel('K')\n",
    "        text = axes[index].set_title('{}'.format(domain))\n",
    "        lgd = axes[index].legend(loc='upper center', bbox_to_anchor=(0.5, -0.18))\n",
    "        formatter = mticker.ScalarFormatter()\n",
    "        axes[index].xaxis.set_major_formatter(formatter)\n",
    "        axes[index].xaxis.set_major_locator(mticker.FixedLocator([1, 5, 10, 15, 20, 25]))\n",
    "        axes[index].grid(True, axis='y', alpha=.5)\n",
    "\n",
    "    fig.savefig('retrieval_1000.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "build_1000_epochs('recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_1000[df_1000['domain'].isin(['netbeans'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DMS_QL Recall@25 eclipse = 0.59 (without softmax)\n",
    "- DMS_QL Recall@25 eclipse = 0.57 (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "\n",
    "def load_loss(method, base):\n",
    "    loss_dir = 'data/processed/{}/{}'.format(base, 'bert')\n",
    "    loss_dir = os.path.join(loss_dir,'{}_log.pkl'.format(method))\n",
    "\n",
    "    with open(loss_dir, 'rb') as f:\n",
    "        loss = pickle.load(f)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def validation_loss(loss, val_loss):\n",
    "        plt.plot(loss, label='loss')\n",
    "        plt.plot(val_loss, label='val_loss')\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "def validation_loss_grid(loss, val_loss, name, lines, col, index):\n",
    "        ax = plt.subplot(lines, col, index)\n",
    "        plt.plot(loss, label='loss')\n",
    "        plt.plot(val_loss, label='val_loss')\n",
    "        plt.title(name)\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        if(index == 1 or (index % col == 1)):\n",
    "            plt.legend(['train', 'test'], bbox_to_anchor=(-1.05, 1.0), loc='upper left')\n",
    "        plt.grid(True)\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(base, epochs, limit_epochs=1000):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(22, 20))\n",
    "\n",
    "    index_grid = 1\n",
    "    for row, model in enumerate(['deepQL_weights_{}'.format(epochs),\n",
    "                                 'deepQL_trainable_{}'.format(epochs),\n",
    "                                 'baseline_{}'.format(epochs),\n",
    "                                 'DMS_QL_{}'.format(epochs), \n",
    "                                 'DWEN_QL_{}'.format(epochs),\n",
    "                                'deepTL_{}'.format(epochs)]):\n",
    "        try:\n",
    "            ql_loss = load_loss(model, base)\n",
    "            for _, (loss_name, index) in enumerate(zip(['loss', 'Q1', 'Q2', 'Q3', 'Q4'], [0, 5, 6, 7, 8])):\n",
    "                try:\n",
    "                    train = [r[index] for r in ql_loss['train']][:limit_epochs]\n",
    "                    test = [r[index] for r in ql_loss['test']][:limit_epochs]\n",
    "                    ax_r = validation_loss_grid(train, test, loss_name, n_rows, n_cols, index_grid)\n",
    "                    if(index_grid == 1 or (index_grid % n_cols == 1)):\n",
    "                        ax = ax_r\n",
    "                except: pass\n",
    "                index_grid+=1\n",
    "            \n",
    "            plt.text(0, 1.5, model,\n",
    "                 horizontalalignment='center',\n",
    "                 verticalalignment='center',\n",
    "                 transform=ax.transAxes,\n",
    "                 fontsize=20)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(hspace=1.25,\n",
    "                        wspace=0.35)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 6\n",
    "n_cols = 5\n",
    "limit_epochs = 200\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.asarray([[1]]).shape, np.asarray([[.5]]).shape\n",
    "#np.asarray([[1]]) * np.asarray([[.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eclipse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss('eclipse', 100, limit_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss('eclipse', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netbeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss('netbeans', 100, limit_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss('netbeans', epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss('openoffice', 100, limit_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss('openoffice', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How TL is the most important during the learning?\n",
    "\n",
    "Count how many time a model choiced a loss as the most important loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    deepQL_weights_1000\n",
    "    deepQL_trainable_1000\n",
    "    DMS_QL_1000\n",
    "    DWEN_QL_1000\n",
    "    deepTL_100\n",
    "'''\n",
    "loss_data = load_loss('DMS_QL_1000', 'eclipse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "train = loss_data['train']\n",
    "test = loss_data['test']\n",
    "\n",
    "w_name = {\n",
    "    0 : 'Q1',\n",
    "    1 : 'Q2',\n",
    "    2 : 'Q3',\n",
    "    3 : 'Q4'\n",
    "}\n",
    "\n",
    "def high_importance(w):\n",
    "    index = np.argmax(w, axis=0)\n",
    "    return w_name[index]\n",
    "def low_importance(w):\n",
    "    index = np.argmin(w, axis=0)\n",
    "    return w_name[index]\n",
    "def equal_importance(w):\n",
    "    c = collections.Counter(w)\n",
    "    c = [r[0] for r in c.most_common(4) if r[1] > 1]\n",
    "    def get_name(arr):\n",
    "        name = [w_name[e] for e in arr]\n",
    "        return \",\".join(name)\n",
    "    names = [get_name(np.where(np.asarray(w) == e)[0]) for e in c]\n",
    "    return \",\".join(names) if len(names) > 0 else \"none\"\n",
    "\n",
    "loss_status = { 'train' : {}, 'test' : {} }\n",
    "for data, phase in zip([train, test], ['train', 'test']):\n",
    "    loss_status[phase]['high'] = [high_importance(r[1:5]) for r in data]\n",
    "    loss_status[phase]['low'] = [low_importance(r[1:5]) for r in data]\n",
    "    loss_status[phase]['equal'] = [equal_importance(r[1:5]) for r in data]\n",
    "\n",
    "loss_status.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def summary_loss(loss_status, phase, index, index_name):\n",
    "    data = [ np.concatenate([[loss_status[phase]['high'][take_epoch], loss_status[phase]['low'][take_epoch], \n",
    "                              loss_status[phase]['equal'][take_epoch]],\n",
    "                            train[take_epoch][1:5]])\n",
    "            for take_epoch in index]\n",
    "    index = [\"{} epoch(s)\".format(n) for n in index_name]\n",
    "    return pd.DataFrame(data=data, columns=['high', 'low', 'equal', 'Q1', 'Q2', 'Q3', 'Q4'], index=index)\n",
    "\n",
    "def plot_importance(loss_status, phase, list_importance):\n",
    "    data = []\n",
    "    for importance in list_importance:\n",
    "        name = '{}_importance'.format(importance)\n",
    "        stats_loss = pd.DataFrame(data=loss_status[phase][importance], columns=[name])\n",
    "        n_rows = stats_loss.shape[0]\n",
    "        stats_loss = stats_loss.groupby(by=[name]).agg(arg=name).count().to_frame()\n",
    "        stats_loss[name] = stats_loss[name] / n_rows\n",
    "        stats_loss['importance'] = importance\n",
    "        data.append(stats_loss)\n",
    "    merged = pd.concat(data, sort=True)\n",
    "    plt.figure();\n",
    "    merged.plot.bar(by='importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize loss importance on train at 1, 10, 100 and 1000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = [0, 9, 99, 899]\n",
    "index_name = [1, 10, 100, 1000]\n",
    "phase = 'train'\n",
    "summary_loss(loss_status, phase, index, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(loss_status, phase, ['high', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize loss importance on test at 1, 10, 100 and 1000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [0, 9, 99, 899]\n",
    "index_name = [1, 10, 100, 1000]\n",
    "phase = 'test'\n",
    "summary_loss(loss_status, phase, index, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(loss_status, phase, ['high', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize indivual loss for a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    deepQL_weights_1000\n",
    "    deepQL_trainable_1000\n",
    "    DMS_QL_1000\n",
    "    DWEN_QL_1000\n",
    "    deepTL_100\n",
    "'''\n",
    "ql_loss = load_loss('deepQL_weights_1000', 'openoffice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ql_loss['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triplet Loss with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [r[0] for r in ql_loss['train']]\n",
    "test = [r[0] for r in ql_loss['test']]\n",
    "validation_loss(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [r[5] for r in ql_loss['train']][:limit_epochs]\n",
    "test = [r[5] for r in ql_loss['test']][:limit_epochs]\n",
    "\n",
    "validation_loss(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triplet loss pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [r[6] for r in ql_loss['train']]\n",
    "test = [r[6] for r in ql_loss['test']]\n",
    "\n",
    "validation_loss(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triplet loss neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [r[7] for r in ql_loss['train']]\n",
    "test = [r[7] for r in ql_loss['test']]\n",
    "\n",
    "validation_loss(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triplet loss centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [r[8] for r in ql_loss['train']]\n",
    "test = [r[8] for r in ql_loss['test']]\n",
    "\n",
    "validation_loss(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "\n",
    "rows = []\n",
    "\n",
    "for epoch in ['100', '1000']:\n",
    "    for domain in domains:\n",
    "        # Dataset paths\n",
    "        DIR = 'data/processed/{}/{}/'.format(domain, PREPROCESSING)\n",
    "\n",
    "        for method in methods[epoch]:\n",
    "            path = os.path.join(DIR, 'classification_{}.pkl'.format(method))\n",
    "\n",
    "            try:\n",
    "                with open(path, 'rb') as f:\n",
    "                    result = pickle.load(f)\n",
    "\n",
    "                print(path)\n",
    "\n",
    "                rows.append({ 'autor': authors[result['method']], 'acurácia' : round(result['acc_test'], 2), 'roc/auc' : round(result['roc_test'], 2),  \n",
    "                             'domain' : domain })\n",
    "            except:\n",
    "                print(\"Does not exist result for: {}\".format(path))\n",
    "                pass\n",
    "    \n",
    "df_cls = pd.DataFrame(data=rows, columns=['autor', 'acurácia', 'roc/auc', 'domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=len(domains), ncols=2, figsize=(15, 15))\n",
    "\n",
    "for row, domain in enumerate(domains): \n",
    "    plt.text(1.15, 1.08, domain,\n",
    "         horizontalalignment='center',\n",
    "         fontsize=20,\n",
    "         transform = axes[row, 0].transAxes)\n",
    "    ax = df_cls[df_cls['domain'] == domain].set_index('autor')[['acurácia']].plot.barh(ax=axes[row, 0])\n",
    "    #ax.set_title(domain)\n",
    "    ax = df_cls[df_cls['domain'] == domain].set_index('autor')[['roc/auc']].plot.barh(ax=axes[row, 1], color='g')\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    #ax.set_title(domain)\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.55,\n",
    "                    wspace=0.35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
