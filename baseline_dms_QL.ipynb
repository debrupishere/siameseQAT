{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtdA1qs_UQP1"
   },
   "source": [
    "# DMS with QL\n",
    "\n",
    "https://github.com/AdrianUng/keras-triplet-loss-mnist/blob/master/Triplet_loss_KERAS_semi_hard_from_TF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIha-SERnD72"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "# from __future__ import print_function, division\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from annoy import AnnoyIndex\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "# %matplotlib inline\n",
    "\n",
    "from keras.layers import Conv1D, Input, Add, Activation, Dropout, Embedding, MaxPooling1D, \\\n",
    "    GlobalMaxPool1D, Flatten, Dense, Concatenate, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "from keras import optimizers\n",
    "\n",
    "from methods.baseline import Baseline\n",
    "from methods.experiments import Experiment\n",
    "from methods.evaluation import Evaluation\n",
    "from methods.retrieval import Retrieval\n",
    "\n",
    "import os\n",
    "from keras_bert import load_vocabulary\n",
    "import random\n",
    "\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.initializers import TruncatedNormal, RandomUniform\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Dropout, Bidirectional, GlobalAveragePooling1D, TimeDistributed\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "\n",
    "from keras.layers import concatenate, Add, Lambda, merge, Average, Maximum\n",
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uQou7m2-bFO"
   },
   "source": [
    "## Configurações Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-Kn3x_K-aZj"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_T = 20 # 100\n",
    "MAX_SEQUENCE_LENGTH_D = 20 # 500\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "'''\n",
    "    Configuration\n",
    "'''\n",
    "epochs = int(os.environ['epochs'])\n",
    "freeze_train = .1 # 10% with freeze weights\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "verbose = 0\n",
    "loss = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse bugs preproprecessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "DOMAIN = os.environ['base']\n",
    "METHOD = 'DMS_QL_{}'.format(epochs)\n",
    "PREPROCESSING = 'bert'\n",
    "TOKEN = 'bert'\n",
    "# Dataset paths\n",
    "DIR = 'data/processed/{}/{}'.format(DOMAIN, PREPROCESSING)\n",
    "DIR_PAIRS = 'data/normalized/{}'.format(DOMAIN)\n",
    "DATASET = os.path.join('data/normalized/{}'.format(DOMAIN), '{}.csv'.format(DOMAIN))\n",
    "# Glove embeddings\n",
    "GLOVE_DIR='data/embed'\n",
    "# Save model\n",
    "SAVE_PATH = '{}_preprocessing_{}_feature@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_preprocessing_{}_feature_@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)\n",
    "\n",
    "# Extract CORPUs\n",
    "EXTRACT_CORPUS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*********\")\n",
    "print(\"{} for {} epochs in {}\".format(METHOD, epochs, DOMAIN))\n",
    "print(\"*********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "model_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = load_vocabulary(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(DOMAIN, DIR, DATASET, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D,\n",
    "                   token_dict['[CLS]'], token_dict['[SEP]'])\n",
    "evaluation = Evaluation(verbose=0)\n",
    "retrieval = Retrieval()\n",
    "experiment = Experiment(baseline, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment.set_retrieval(retrieval, baseline, DOMAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading bug ids in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bug ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "361006"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.load_ids()\n",
    "len(baseline.bug_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqzt5EKzqzcI"
   },
   "source": [
    "#### Dicionário de títulos e descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4aad03dd344c6abffb23e47fe31b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=361006), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b53e64d4768421d99deb2ef495ebbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 34.9 s, sys: 3.58 s, total: 38.5 s\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "experiment.load_bugs(TOKEN)\n",
    "len(baseline.sentence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing bugs by buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d761d60b00ef474fae11e0ef633b5c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=361006), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "issues_by_buckets = experiment.get_buckets_for_bugs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_train='train_chronological', path_test='test_chronological'\n",
    "experiment.prepare_dataset(issues_by_buckets, path_train='train_chronological', path_test='test_chronological')\n",
    "# Read and create the test queries duplicates\n",
    "retrieval.create_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[275492, 218812],\n",
       " [288296, 264093],\n",
       " [273286, 293887],\n",
       " [57162, 62059],\n",
       " [82146, 67997],\n",
       " [56777, 61857],\n",
       " [169445, 165179],\n",
       " [250521, 273893],\n",
       " [247266, 241461],\n",
       " [36781, 38338]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery bug ids from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_train_ids = experiment.get_train_ids(baseline.train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the corpus train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CORPUS:\n",
    "    corpus = []\n",
    "    export_file = open(os.path.join(DIR, 'corpus_train.txt'), 'w')\n",
    "    for bug_id in tqdm(baseline.bug_set):\n",
    "        bug = baseline.bug_set[bug_id]\n",
    "        title = bug['title']\n",
    "        desc = bug['description']\n",
    "        export_file.write(\"{}\\n{}\\n\".format(title, desc))\n",
    "    export_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6Obtop6UIVD"
   },
   "source": [
    "# Generating tiple of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bug_severity': '2\\n',\n",
       " 'bug_status': '2\\n',\n",
       " 'component': '176\\n',\n",
       " 'creation_ts': '2011-08-10 04:47:00 -0400',\n",
       " 'delta_ts': '2011-09-05 06:47:02 -0400',\n",
       " 'description': '[CLS] hello we have a bug ##zi ##lla \" bug 351 ##70 ##9 \" for creating a snaps ##hot repository for the w ##tp - inc ##uba ##tor service interface editor project with the project \\' s hudson build . we have updated the project \\' s repository po ##ms to extract the update site at \" / home / data / http ##d / download . eclipse . org / web ##to ##ols / inc ##uba ##tor / repository / si ##ed ##itor / snaps ##hot ##s \" , but as expected such directory does not exists . could you help us create it , and apply any additional steps if needed to create the repository ? best regards , dim ##ita ##r ff ##or more information : original bug ##iz ##lla : https : / / bugs . eclipse . org / bugs / show _ bug . c ##gi ? id = 351 ##70 ##9 hudson build job : https : / / hudson . eclipse . org / hudson / view / w ##tp / job / cb ##i - w ##tp . inc - si ##ed ##itor / gi ##t ##we ##b rep ##o : http : / / gi ##t . eclipse . org / c / web ##to ##ols / inc ##uba ##tor / org . eclipse . web ##to ##ols . inc ##uba ##tor . si ##ed ##itor . gi ##t / [SEP]',\n",
       " 'description_segment': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'description_token': array([  101,  7592,  2057,  2031,  1037, 11829,  5831,  4571,  1000,\n",
       "        11829, 28474, 19841,  2683,  1000,  2005,  4526,  1037, 20057,\n",
       "        12326,   102]),\n",
       " 'dup_id': '[]',\n",
       " 'issue_id': 354340,\n",
       " 'priority': '3\\n',\n",
       " 'product': '63\\n',\n",
       " 'resolution': 'FIXED',\n",
       " 'textual_token': array([  101,  3443,  1037, 14176,  2005,  1037, 20057, 12326, 22409,\n",
       "         2006, 13232,  6842,     0,     0,     0,     0,     0,     0,\n",
       "            0,   102,   101,  7592,  2057,  2031,  1037, 11829,  5831,\n",
       "         4571,  1000, 11829, 28474, 19841,  2683,  1000,  2005,  4526,\n",
       "         1037, 20057, 12326,   102]),\n",
       " 'title': '[CLS] create a directory for a snaps ##hot repository on eclipse hudson [SEP]',\n",
       " 'title_segment': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'title_token': array([  101,  3443,  1037, 14176,  2005,  1037, 20057, 12326, 22409,\n",
       "         2006, 13232,  6842,     0,     0,     0,     0,     0,     0,\n",
       "            0,   102]),\n",
       " 'version': '318\\n'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.choice(baseline.bug_ids, 1)[0]\n",
    "baseline.bug_set[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the batch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Train ', 39339)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Train \", len(baseline.dup_sets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data - path\n",
    "# batch_size - 128\n",
    "# n_neg - 1\n",
    "def batch_iterator(self, retrieval, model, data, dup_sets, bug_ids, \n",
    "                   batch_size, n_neg, issues_by_buckets, TRIPLET_HARD=False, FLOATING_PADDING=False):\n",
    "    # global train_data\n",
    "    # global self.dup_sets\n",
    "    # global self.bug_ids\n",
    "    # global self.bug_set\n",
    "\n",
    "    random.shuffle(data)\n",
    "\n",
    "    batch_features = {'title' : [], 'desc' : [], 'info' : []}\n",
    "\n",
    "    n_train = len(data)\n",
    "\n",
    "    batch_triplets, batch_bugs_anchor, batch_bugs_pos, batch_bugs_neg, batch_bugs = [], [], [], [], []\n",
    "\n",
    "    all_bugs = list(issues_by_buckets.keys())\n",
    "    buckets = retrieval.buckets\n",
    "\n",
    "    for offset in range(batch_size):\n",
    "        anchor, pos = data[offset][0], data[offset][1]\n",
    "        batch_bugs_anchor.append(anchor)\n",
    "        batch_bugs_pos.append(pos)\n",
    "        batch_bugs.append(anchor)\n",
    "        batch_bugs.append(pos)\n",
    "        #batch_bugs += dup_sets[anchor]\n",
    "\n",
    "    for anchor, pos in zip(batch_bugs_anchor, batch_bugs_pos):\n",
    "        while True:\n",
    "            neg = self.get_neg_bug(anchor, buckets[issues_by_buckets[anchor]], issues_by_buckets, all_bugs)\n",
    "            bug_anchor = self.bug_set[anchor]\n",
    "            bug_pos = self.bug_set[pos]\n",
    "            if neg not in self.bug_set:\n",
    "                continue\n",
    "            batch_bugs.append(neg)\n",
    "            batch_bugs_neg.append(neg)\n",
    "            bug_neg = self.bug_set[neg]\n",
    "            break\n",
    "        \n",
    "        # triplet bug and master\n",
    "        batch_triplets.append([anchor, pos, neg])\n",
    "    \n",
    "    random.shuffle(batch_bugs)\n",
    "    \n",
    "    for bug_id in batch_bugs:\n",
    "        bug = self.bug_set[bug_id]\n",
    "        self.read_batch_bugs(batch_features, bug)\n",
    "\n",
    "    batch_features['title'] = np.array(batch_features['title'])\n",
    "    batch_features['desc'] = np.array(batch_features['desc'])\n",
    "    batch_features['info'] = np.array(batch_features['info'])\n",
    "    \n",
    "    sim = np.asarray([issues_by_buckets[bug_id] for bug_id in batch_bugs])\n",
    "\n",
    "    input_sample = {}\n",
    "\n",
    "    input_sample = { 'title' : batch_features['title'], \n",
    "                        'description' : batch_features['desc'], \n",
    "                            'info' : batch_features['info'] }\n",
    "\n",
    "    return batch_triplets, input_sample, sim #sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PA5CIhgz7odW",
    "outputId": "ae98fdec-1d54-4b1f-ee0e-4c5633802a18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 482 ms, sys: 3.99 ms, total: 486 ms\n",
      "Wall time: 486 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 128\n",
    "\n",
    "# we want a constant validation group to have a frame of reference for model performance\n",
    "batch_triplets_valid, valid_input_sample, valid_sim = batch_iterator(baseline, retrieval, None, \n",
    "                                                                                      baseline.train_data, \n",
    "                                                                                      baseline.dup_sets_train,\n",
    "                                                                                      bug_train_ids,\n",
    "                                                                                      batch_size_test, 1,\n",
    "                                                                                      issues_by_buckets)\n",
    "\n",
    "validation_sample = [valid_input_sample['title'], \n",
    "             valid_input_sample['description'],\n",
    "            valid_input_sample['info'], valid_sim]\n",
    "\n",
    "# Categorical columns\n",
    "number_of_columns_info = valid_input_sample['info'].shape[1]\n",
    "# Max sequence title\n",
    "MAX_SEQUENCE_LENGTH_T = valid_input_sample['title'].shape[1]\n",
    "MAX_SEQUENCE_LENGTH_D = valid_input_sample['description'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384, 20), (384, 20), (384, 1682), (384,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input_sample['title'].shape, valid_input_sample['description'].shape, valid_input_sample['info'].shape, valid_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24mY22BGnkqp"
   },
   "source": [
    "### Validar entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "colab_type": "code",
    "id": "OhTbr3a5nmrh",
    "outputId": "a2d73e0f-e9ce-4d12-a5c8-f0008d2402d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "#baseline.display_batch(baseline.train_data, baseline.dup_sets_train, bug_train_ids, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Test ', 16995)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Test \", len(baseline.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPrsLs4Kg4Pa"
   },
   "source": [
    "## Pre-trained embeddings\n",
    "\n",
    "Loading pretrained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6p9eE5TWoH7p"
   },
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    }
   ],
   "source": [
    "vocab = baseline.load_vocabulary(os.path.join(DIR, 'vocab_embed.pkl'))\n",
    "#print(np.random.choice(vocab, 10))\n",
    "# for token in vocab:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total vocabulary: 21175'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Total vocabulary: {}\".format(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_embed(baseline, GLOVE_DIR, EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    embed_path = os.path.join(GLOVE_DIR, 'glove.42B.300d.txt')\n",
    "    \n",
    "    f2 = open(embed_path, 'rb')\n",
    "    num_lines = sum(1 for line in f2)\n",
    "    f2.close()\n",
    "    \n",
    "    f = open(embed_path, 'rb')\n",
    "    vocab = baseline.load_vocabulary(os.path.join(baseline.DIR, 'vocab_embed.pkl'))\n",
    "    vocab_size = len(vocab) \n",
    "\n",
    "    # Initialize uniform the vector considering the Tanh activation\n",
    "    embedding_matrix = np.random.uniform(-1.0, 1.0, (num_lines + vocab_size, EMBEDDING_DIM))\n",
    "    embedding_matrix[0, :] = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    loop = tqdm(f)\n",
    "    loop.set_description(\"Loading Glove\")\n",
    "    \n",
    "    i = 0\n",
    "    for line in loop:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embed = np.asarray(tokens[1:], dtype='float32')\n",
    "        embeddings_index[word] = embed\n",
    "        embedding_matrix[i] = embed\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    f.close()\n",
    "    loop.close()\n",
    "\n",
    "    print('Total %s word vectors in Glove 42B 300d.' % len(embeddings_index))\n",
    "\n",
    "    loop = tqdm(total=vocab_size)\n",
    "    loop.set_description('Loading embedding from dataset pretrained')\n",
    "    \n",
    "    for word, embed in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index[word]\n",
    "        else:\n",
    "            embedding_matrix[i] = np.asarray(embed, dtype='float32')\n",
    "        loop.update(1)\n",
    "        i+=1\n",
    "    loop.close()\n",
    "    baseline.embedding_matrix = embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QY-ef3OGoIiq",
    "outputId": "55f4c93c-98bb-4bac-92f2-76bd3b777605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary loaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee741de3ac142f0970b583af50b03f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 1917494 word vectors in Glove 42B 300d.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c397a0ec83943aab00b8e10217a945b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21175), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 37s, sys: 3.97 s, total: 1min 41s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generating_embed(baseline, GLOVE_DIR=GLOVE_DIR, EMBEDDING_DIM=EMBEDDING_DIM) # MAX_NB_WORDS=MAX_NB_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1938669"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(baseline.embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lev5Y7oaFQBd"
   },
   "source": [
    "## Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques\n",
    "\n",
    "https://github.com/tqtg/DuplicateBugFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is missing the padding_idx used in pytorch\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html\n",
    "# https://stackoverflow.com/questions/54824768/rnn-model-gru-of-word2vec-to-regression-not-learning\n",
    "def embedding_layer(embeddings, num_words, embedding_dim, max_sequence_length, trainable):\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                  embedding_dim,\n",
    "                                  name='embedding_layer',\n",
    "                                  weights=[embeddings],\n",
    "                                  embeddings_constraint=MaxNorm(max_value=1, axis=0),\n",
    "#                                   input_length=max_sequence_length,\n",
    "                                  input_length=None,\n",
    "                                  trainable=trainable)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI074wU4Y13y"
   },
   "source": [
    "### CNN with filter 3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "h6YJU9GtFTyq",
    "outputId": "f85cf105-1fd6-491d-d969-7e6936f32739",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cnn_model(embedding_layer, max_sequence_length):\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length,), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None,), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    # Yoon Kim model (https://arxiv.org/abs/1408.5882)\n",
    "    # best combination filter (3, 4, 5) e 128 e 256\n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    n_filters = 64\n",
    "\n",
    "    for index, filter_size in enumerate(filter_sizes):\n",
    "        l_conv = Conv1D(filters=n_filters, kernel_size=filter_size)(embedded_sequences)\n",
    "        l_pool = MaxPooling1D(pool_size=filter_size)(l_conv) # index+1\n",
    "        convs.append(l_pool)\n",
    "\n",
    "    l_merge = Concatenate(axis=1)(convs)\n",
    "\n",
    "    # add a 1D convnet with global maxpooling, instead of Yoon Kim model\n",
    "    #conv = Conv1D(filters=n_filters * 3, kernel_size=3)(l_merge)\n",
    "    layer = GlobalAveragePooling1D()(l_merge)\n",
    "    #layer = Flatten()(l_merge)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "    #layer = LeakyReLU()(layer)\n",
    "\n",
    "    cnn_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureCNNGenerationModel') # inputs=visible\n",
    "\n",
    "    return cnn_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wr6ObTXiaALH"
   },
   "source": [
    "### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "vC7MQXEsaCeG",
    "outputId": "65e647a9-c5d3-4009-b8a4-2e2d97b52684"
   },
   "outputs": [],
   "source": [
    "def lstm_model(embedding_layer, max_sequence_length):\n",
    "    number_lstm_units = 75\n",
    "    rate_drop_lstm = 0\n",
    "    recurrent_dropout = 0\n",
    "\n",
    "    sequence_input = Input(shape=(max_sequence_length, ), name='Feature_BugInput')\n",
    "    #sequence_input = Input(shape=(None, ), name='Feature_BugInput')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    left_layer = LSTM(number_lstm_units, return_sequences=True)(embedded_sequences)\n",
    "    right_layer = LSTM(number_lstm_units, return_sequences=True, go_backwards=True)(left_layer)\n",
    "    \n",
    "    lstm_layer = Concatenate()([left_layer, right_layer])\n",
    "    \n",
    "    #lstm_layer = TimeDistributed(Dense(50))(lstm_layer)\n",
    "    #layer = Flatten()(lstm_layer)\n",
    "    layer = GlobalAveragePooling1D()(lstm_layer)\n",
    "    layer = Dense(300, activation='tanh')(layer)\n",
    "\n",
    "    lstm_feature_model = Model(inputs=[sequence_input], outputs=[layer], name = 'FeatureLstmGenerationModel') # inputs=visible\n",
    "\n",
    "    return lstm_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(input_size):\n",
    "    info_input = Input(shape=(input_size, ), name='Feature_BugInput')\n",
    "    input_size = 300\n",
    "    \n",
    "    for units in [64, 32]:\n",
    "        layer = Dense(units, activation='tanh', kernel_initializer='random_uniform')(info_input)\n",
    "    \n",
    "    layer = Dense(input_size, activation='tanh')(info_input)\n",
    "    \n",
    "    mlp_feature_model = Model(inputs=[info_input], outputs=[layer], name = 'FeatureMlpGenerationModel')\n",
    "    \n",
    "    return mlp_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEedCg5AaTf2"
   },
   "source": [
    "### Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(feature, squared=False):\n",
    "    \"\"\"Computes the pairwise distance matrix with numerical stability.\n",
    "\n",
    "    output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
    "\n",
    "    Args:\n",
    "      feature: 2-D Tensor of size [number of data, feature dimension].\n",
    "      squared: Boolean, whether or not to square the pairwise distances.\n",
    "\n",
    "    Returns:\n",
    "      pairwise_distances: 2-D Tensor of size [number of data, number of data].\n",
    "    \"\"\"\n",
    "    pairwise_distances_squared = math_ops.add(\n",
    "        math_ops.reduce_sum(math_ops.square(feature), axis=[1], keepdims=True),\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.square(array_ops.transpose(feature)),\n",
    "            axis=[0],\n",
    "            keepdims=True)) - 2.0 * math_ops.matmul(feature,\n",
    "                                                    array_ops.transpose(feature))\n",
    "\n",
    "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    pairwise_distances_squared = math_ops.maximum(pairwise_distances_squared, 0.0)\n",
    "    # Get the mask where the zero distances are at.\n",
    "    error_mask = math_ops.less_equal(pairwise_distances_squared, 0.0)\n",
    "\n",
    "    # Optionally take the sqrt.\n",
    "    if squared:\n",
    "        pairwise_distances = pairwise_distances_squared\n",
    "    else:\n",
    "        pairwise_distances = math_ops.sqrt(\n",
    "            pairwise_distances_squared + math_ops.to_float(error_mask) * 1e-16)\n",
    "\n",
    "    # Undo conditionally adding 1e-16.\n",
    "    pairwise_distances = math_ops.multiply(\n",
    "        pairwise_distances, math_ops.to_float(math_ops.logical_not(error_mask)))\n",
    "\n",
    "    num_data = array_ops.shape(feature)[0]\n",
    "    # Explicitly set diagonals to zero.\n",
    "    mask_offdiagonals = array_ops.ones_like(pairwise_distances) - array_ops.diag(\n",
    "        array_ops.ones([num_data]))\n",
    "    pairwise_distances = math_ops.multiply(pairwise_distances, mask_offdiagonals)\n",
    "    return pairwise_distances\n",
    "\n",
    "def masked_maximum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise maximum over chosen elements.\n",
    "\n",
    "    Args:\n",
    "      data: 2-D float `Tensor` of size [n, m].\n",
    "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "      dim: The dimension over which to compute the maximum.\n",
    "\n",
    "    Returns:\n",
    "      masked_maximums: N-D `Tensor`.\n",
    "        The maximized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_minimums = math_ops.reduce_min(data, dim, keepdims=True)\n",
    "    masked_maximums = math_ops.reduce_max(\n",
    "        math_ops.multiply(data - axis_minimums, mask), dim,\n",
    "        keepdims=True) + axis_minimums\n",
    "    return masked_maximums\n",
    "\n",
    "def masked_minimum(data, mask, dim=1):\n",
    "    \"\"\"Computes the axis wise minimum over chosen elements.\n",
    "\n",
    "    Args:\n",
    "      data: 2-D float `Tensor` of size [n, m].\n",
    "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
    "      dim: The dimension over which to compute the minimum.\n",
    "\n",
    "    Returns:\n",
    "      masked_minimums: N-D `Tensor`.\n",
    "        The minimized dimension is of size 1 after the operation.\n",
    "    \"\"\"\n",
    "    axis_maximums = math_ops.reduce_max(data, dim, keepdims=True)\n",
    "    masked_minimums = math_ops.reduce_min(\n",
    "        math_ops.multiply(data - axis_maximums, mask), dim,\n",
    "        keepdims=True) + axis_maximums\n",
    "    return masked_minimums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## required for semi-hard triplet loss:\n",
    "\n",
    "def triplet_loss(vects):\n",
    "    margin = 1.\n",
    "    labels = vects[:, :1]\n",
    " \n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "\n",
    "    embeddings = tf.cast(vects[:, 1:], dtype='float32')\n",
    "\n",
    "    ### Code from Tensorflow function [tf.contrib.losses.metric_learning.triplet_semihard_loss] starts here:\n",
    "    \n",
    "    # Reshape [batch_size] label tensor to a [batch_size, 1] label tensor.\n",
    "    # lshape=array_ops.shape(labels)\n",
    "    # assert lshape.shape == 1\n",
    "    # labels = array_ops.reshape(labels, [lshape[0], 1])\n",
    "\n",
    "    # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = pairwise_distance(embeddings, squared=True)\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = math_ops.logical_not(adjacency)\n",
    "\n",
    "    # global batch_size  \n",
    "    batch_size = array_ops.size(labels) # was 'array_ops.size(labels)'\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = math_ops.logical_and(\n",
    "        array_ops.tile(adjacency_not, [batch_size, 1]),\n",
    "        math_ops.greater(\n",
    "            pdist_matrix_tile, array_ops.reshape(\n",
    "                array_ops.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = array_ops.reshape(\n",
    "        math_ops.greater(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    mask_final = array_ops.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
    "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = array_ops.reshape(\n",
    "        masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = array_ops.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = array_ops.tile(\n",
    "        masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "    semi_hard_negatives = array_ops.where(\n",
    "        mask_final, negatives_outside, negatives_inside)\n",
    "\n",
    "    loss_mat = math_ops.add(margin, pdist_matrix - semi_hard_negatives)\n",
    "\n",
    "    mask_positives = math_ops.cast(\n",
    "        adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
    "        array_ops.ones([batch_size]))\n",
    "\n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = math_ops.reduce_sum(mask_positives)\n",
    "\n",
    "    semi_hard_triplet_loss_distance = math_ops.truediv(\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.maximum(\n",
    "                math_ops.multiply(loss_mat, mask_positives), 0.0)),\n",
    "        num_positives,\n",
    "        name='triplet_semihard_loss')\n",
    "    \n",
    "    ### Code from Tensorflow function semi-hard triplet loss ENDS here.\n",
    "    return semi_hard_triplet_loss_distance\n",
    "\n",
    "def quintet_loss(inputs):\n",
    "    margin = 1.\n",
    "    labels = inputs[:, :1]\n",
    " \n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "\n",
    "    embeddings = inputs[:, 1:]\n",
    "\n",
    "    # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = pairwise_distance(embeddings, squared=True)\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = math_ops.logical_not(adjacency)\n",
    "\n",
    "    # global batch_size  \n",
    "    batch_size = array_ops.size(labels) # was 'array_ops.size(labels)'\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = math_ops.logical_and(\n",
    "        array_ops.tile(adjacency_not, [batch_size, 1]),\n",
    "        math_ops.greater(\n",
    "            pdist_matrix_tile, array_ops.reshape(\n",
    "                array_ops.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = array_ops.reshape(\n",
    "        math_ops.greater(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    \n",
    "    mask_final = array_ops.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
    "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = array_ops.reshape(\n",
    "        masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = array_ops.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = array_ops.tile(\n",
    "        masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "\n",
    "    semi_hard_negatives = array_ops.where(\n",
    "        mask_final, negatives_outside, negatives_inside)\n",
    "    \n",
    "    semi_hard_negatives_mask = math_ops.equal(pdist_matrix, masked_maximum(pdist_matrix, adjacency_not))\n",
    "    \n",
    "    # Remove false negatives with similarity equal to the true negatives\n",
    "    semi_hard_negatives_mask = tf.reshape(tf.cast(semi_hard_negatives_mask, 'int32'), (-1, 1)) * tf.reshape(tf.cast(adjacency_not, 'int32'), (-1, 1))\n",
    "    semi_hard_negatives_mask = tf.cast(tf.reshape(semi_hard_negatives_mask, (batch_size, batch_size)), 'bool')\n",
    "    \n",
    "    # Recovery the bug label from semi-hard-negatives\n",
    "    label_matrix = tf.repeat(tf.reshape(labels, (1, -1)), repeats=[batch_size], axis=0)\n",
    "    semi_hard_negatives_ids = tf.reshape(label_matrix, (-1, 1)) * tf.cast(tf.reshape(semi_hard_negatives_mask, (-1, 1)), 'int32')\n",
    "    semi_hard_negatives_ids = tf.reshape(semi_hard_negatives_ids, (batch_size, batch_size))\n",
    "\n",
    "    i = tf.constant(0)\n",
    "    most_freq_matrix = tf.Variable([])\n",
    "    def most_frequent(i, most_freq_matrix):\n",
    "        batch = tf.gather(semi_hard_negatives_ids, i)\n",
    "        neg_label_default = [tf.unique(batch)[0][0]]\n",
    "        batch = tf.boolean_mask(batch, tf.greater(batch, 0))\n",
    "        unique, _, count = tf.unique_with_counts(batch)\n",
    "        max_occurrences = tf.reduce_max(count)\n",
    "        max_cond = tf.equal(count, max_occurrences)\n",
    "        max_numbers = tf.squeeze(tf.gather(unique, tf.where(max_cond)))\n",
    "        max_numbers = tf.cond(tf.cast(tf.size(unique) > 1, tf.bool), lambda: unique[0], lambda: max_numbers)\n",
    "        max_numbers = tf.cond(tf.cast(tf.shape(unique) == 0, tf.bool), \n",
    "                              lambda: neg_label_default, \n",
    "                              lambda: max_numbers)\n",
    "        most_freq_matrix = tf.concat([most_freq_matrix, [max_numbers]], axis=0)\n",
    "        return [tf.add(i, 1), most_freq_matrix]\n",
    "    _, negatives_ids = tf.while_loop(lambda i, _: i<batch_size, \n",
    "                                        most_frequent, \n",
    "                                        [i, most_freq_matrix],\n",
    "                                       shape_invariants=[i.get_shape(),\n",
    "                                                   tf.TensorShape([None])])\n",
    "    negatives_ids = tf.cast(negatives_ids, 'int32')\n",
    "    labels_neg = tf.reshape(negatives_ids, (-1, 1))\n",
    "    mask_negatives = math_ops.equal(labels_neg, semi_hard_negatives_ids)\n",
    "    mask_negatives = tf.cast(mask_negatives, 'float32')\n",
    "    labels_neg = tf.cast(labels_neg, 'float32')\n",
    "    \n",
    "    mask_positives = math_ops.cast(\n",
    "        adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
    "        array_ops.ones([batch_size]))\n",
    "    \n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = math_ops.reduce_sum(mask_positives)\n",
    "\n",
    "    # Include the anchor to positives\n",
    "    mask_positives_centroids = math_ops.cast(adjacency, dtype=dtypes.float32)\n",
    "\n",
    "    # centroid pos \n",
    "    embed_pos = tf.matmul(mask_positives, embeddings)\n",
    "    num_of_pos = tf.reduce_sum(mask_positives_centroids, axis=1, keepdims=True)\n",
    "    centroid_embed_pos = tf.math.xdivy(embed_pos, num_of_pos)\n",
    "    labels_pos = tf.cast(labels, dtype=dtypes.float32)\n",
    "\n",
    "    # centroid negs\n",
    "    embed_neg = tf.matmul(mask_negatives, embeddings)\n",
    "    num_of_neg = tf.reduce_sum(mask_negatives, axis=1, keepdims=True)\n",
    "    centroid_embed_neg = tf.math.xdivy(embed_neg, num_of_neg)\n",
    "    \n",
    "    i = tf.constant(0)\n",
    "    batch_centroid_matrix = tf.Variable([])\n",
    "    def iter_centroids(i, batch_centroid_matrix):\n",
    "        # anchor\n",
    "        anchor = [tf.gather(embeddings, i)]\n",
    "        label_pos = [tf.gather(labels_pos, i)]\n",
    "        # centroid pos\n",
    "        centroid_pos = [tf.gather(centroid_embed_pos, i)]\n",
    "        # centroid neg\n",
    "        centroid_neg = [tf.gather(centroid_embed_neg, i)]\n",
    "        label_neg = [tf.gather(labels_neg, i)]\n",
    "        # new batch\n",
    "        new_batch = tf.concat([anchor, centroid_pos, centroid_neg], axis=0)\n",
    "        new_labels = tf.concat([label_pos, label_pos, label_neg], axis=0)\n",
    "        # Batch anchor + centroid_positive + centroid_negative\n",
    "        batch_anchor_centroids = tf.concat([new_labels, new_batch], axis=1)\n",
    "        TL_single_triplet = triplet_loss(batch_anchor_centroids)\n",
    "        batch_centroid_matrix = tf.concat([batch_centroid_matrix, [TL_single_triplet]], axis=0)\n",
    "        \n",
    "        return [tf.add(i, 1), batch_centroid_matrix]\n",
    "    _, batch_centroid_matrix = tf.while_loop(lambda i, a: i<batch_size, \n",
    "                                        iter_centroids, \n",
    "                                        [i, batch_centroid_matrix],\n",
    "                                       shape_invariants=[i.get_shape(),\n",
    "                                                   tf.TensorShape([None])])\n",
    "    \n",
    "    TL_centroid = tf.reduce_mean(batch_centroid_matrix)\n",
    "    TL = triplet_loss(inputs)\n",
    "    TL_pos = tf.constant(0.0)\n",
    "    TL_neg = tf.constant(0.0) #tf.reduce_mean(batch_centroid_matrix_neg)\n",
    "   \n",
    "    return K.stack([TL, TL_pos, TL_neg, TL_centroid], axis=0)\n",
    "\n",
    "def quintet_trainable(inputs):\n",
    "    TL = inputs[0]\n",
    "    TL_pos = inputs[1]\n",
    "    TL_neg = inputs[2]\n",
    "    TL_centroid = inputs[3]\n",
    "    TL_anchor_w = inputs[4]\n",
    "    TL_pos_w = inputs[5]\n",
    "    TL_neg_w = inputs[6]\n",
    "    TL_centroid_w = inputs[7]\n",
    "                                                         \n",
    "    TL_anchor_w = tf.math.maximum(0.0, TL_anchor_w)\n",
    "    TL_pos_w = 0.0 # tf.math.maximum(0.0, TL_pos_w)\n",
    "    TL_neg_w = 0.0 #tf.math.maximum(0.0, TL_neg_w)\n",
    "    TL_centroid_w = tf.math.maximum(0.0, TL_centroid_w)\n",
    "\n",
    "    sum_of_median = tf.reduce_sum([TL * TL_anchor_w, TL_centroid * TL_centroid_w]) # \n",
    "    sum_of_weigths = tf.reduce_sum([TL_anchor_w, TL_centroid_w])\n",
    "    weigthed_median = tf.truediv(sum_of_median, sum_of_weigths)    \n",
    "    return K.stack([weigthed_median, TL_anchor_w, TL_pos_w, TL_neg_w, TL_centroid_w, TL, TL_pos, TL_neg, TL_centroid], axis=0)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[0])\n",
    "\n",
    "def TL_w_anchor(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[1])\n",
    "def TL_w_pos(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[2])\n",
    "def TL_w_neg(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[3])\n",
    "def TL_w_centroid(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[4])\n",
    "def TL(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[5])\n",
    "def TL_pos(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[6])\n",
    "def TL_neg(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[7])\n",
    "def TL_centroid(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, sequence_length_info, \n",
    "                  sequence_length_t, sequence_length_d, name):\n",
    "  \n",
    "    bug_t = Input(shape = (sequence_length_t, ), name = 'title_{}'.format(name))\n",
    "    bug_d = Input(shape = (sequence_length_d, ), name = 'desc_{}'.format(name))\n",
    "    bug_i = Input(shape = (sequence_length_info, ), name = 'info_{}'.format(name))\n",
    "    \n",
    "    bug_t_feat = title_feature_model(bug_t)\n",
    "    bug_d_feat = desc_feature_model(bug_d)\n",
    "    bug_i_feat = categorical_feature_model(bug_i)\n",
    "    \n",
    "    #bug_feature_output = Add(name = 'merge_features_{}'.format(name))([bug_i_feat, bug_t_feat, bug_d_feat])\n",
    "    bug_feature_output = concatenate([bug_i_feat, bug_t_feat, bug_d_feat], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    #     bug_feature_output = Activation('tanh')(bug_feature_output)\n",
    "    \n",
    "    # Bug representation layer\n",
    "    # bug_feature_output = Dense(300, activation='tanh')(bug_feature_output)\n",
    "    \n",
    "    bug_feature_model = Model(inputs=[bug_t, bug_d, bug_i], outputs=[bug_feature_output], name = 'merge_features_{}'.format(name))\n",
    "    \n",
    "    return bug_feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuintetWeights(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(QuintetWeights, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = tf.reshape(self.add_weight(name='quintet_kernel_weight', \n",
    "                                      shape=(input_shape[0], self.output_dim),\n",
    "                                      initializer=keras.initializers.Ones(),\n",
    "#                                       initializer=keras.initializers.RandomUniform(minval=0.0, maxval=1.0, seed=None),\n",
    "                                      trainable=False), (1, 1))\n",
    "        super(QuintetWeights, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, (1, 1))\n",
    "        return [K.dot(x, self.kernel), self.kernel]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [input_shape, input_shape]\n",
    "    \n",
    "def max_margin_objective(encoded_anchor, decay_lr=1):\n",
    "    \n",
    "    input_labels = Input(shape=(1,), name='input_label')    # input layer for labels\n",
    "    inputs = np.concatenate([encoded_anchor.input, [input_labels]], -1).tolist()\n",
    "    \n",
    "    encoded_anchor = encoded_anchor.output\n",
    "    \n",
    "    feature = concatenate([input_labels, encoded_anchor])  # concatenating the labels + embeddings\n",
    "    \n",
    "    TL_loss = Lambda(quintet_loss, name='quintet_loss')(feature)\n",
    "    \n",
    "    tl_l = Lambda(lambda x:tf.reshape(x[0], (1,)), name='TL')(TL_loss)\n",
    "    tl_l_p = Lambda(lambda x:tf.reshape(x[1], (1,)), name='TL_pos')(TL_loss)\n",
    "    tl_l_n = Lambda(lambda x:tf.reshape(x[2], (1,)), name='TL_neg')(TL_loss)\n",
    "    tl_l_c = Lambda(lambda x:tf.reshape(x[3], (1, )), name='TL_centroid')(TL_loss)\n",
    "    \n",
    "    TL_w = QuintetWeights(output_dim=1)(tl_l)\n",
    "    TL_pos_w = QuintetWeights(output_dim=1)(tl_l_p)\n",
    "    TL_neg_w = QuintetWeights(output_dim=1)(tl_l_n)\n",
    "    TL_centroid_w = QuintetWeights(output_dim=1)(tl_l_c)\n",
    "    \n",
    "    TL_weight = Lambda(lambda x:tf.reshape(x[1], (1,)), name='TL_weight')(TL_w)\n",
    "    TL_pos_weight = Lambda(lambda x:tf.reshape(x[1], (1,)), name='TL_pos_weight')(TL_pos_w)\n",
    "    TL_neg_weight = Lambda(lambda x:tf.reshape(x[1], (1,)), name='TL_neg_weight')(TL_neg_w)\n",
    "    TL_centroid_weight = Lambda(lambda x:tf.reshape(x[1], (1,)), name='TL_centroid_weight')(TL_centroid_w)\n",
    "    \n",
    "    output = concatenate([tl_l, tl_l_p, tl_l_n, tl_l_c, TL_weight, TL_pos_weight, TL_neg_weight, TL_centroid_weight])\n",
    "    output = Lambda(quintet_trainable, name='quintet_trainable')(output)\n",
    "    \n",
    "    similarity_model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "    # setup the optimization process \n",
    "    similarity_model.compile(optimizer='adam', loss=custom_loss, metrics=[TL_w_anchor, TL_w_pos, TL_w_neg, TL_w_centroid,\n",
    "                                                                         TL, TL_pos, TL_neg, TL_centroid]) \n",
    "    # metrics=[pos_distance, neg_distance, custom_margin_loss]\n",
    "\n",
    "    return similarity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "limit_train = int(epochs * freeze_train) # 10% de 1000 , 100 epocas\n",
    "METHOD = 'DMS_QL_{}'.format(limit_train)\n",
    "SAVE_PATH = '{}_preprocessing_{}_feature@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_preprocessing_{}_feature_@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_loss(result):\n",
    "    with open(os.path.join(DIR,'{}_log.pkl'.format(METHOD)), 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "    print(\"=> result saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-35-cd325db98846>:35: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          581804100   title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          581850792   desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 901)          0           input_label[0][0]                \n",
      "                                                                 merge_features_in[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "quintet_loss (Lambda)           (4,)                 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TL (Lambda)                     (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_pos (Lambda)                 (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_neg (Lambda)                 (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_centroid (Lambda)            (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_1 (QuintetWeigh [(1,), (1,)]         1           TL[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_2 (QuintetWeigh [(1,), (1,)]         1           TL_pos[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_3 (QuintetWeigh [(1,), (1,)]         1           TL_neg[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_4 (QuintetWeigh [(1,), (1,)]         1           TL_centroid[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "TL_weight (Lambda)              (1,)                 0           quintet_weights_1[0][0]          \n",
      "                                                                 quintet_weights_1[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_pos_weight (Lambda)          (1,)                 0           quintet_weights_2[0][0]          \n",
      "                                                                 quintet_weights_2[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_neg_weight (Lambda)          (1,)                 0           quintet_weights_3[0][0]          \n",
      "                                                                 quintet_weights_3[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_centroid_weight (Lambda)     (1,)                 0           quintet_weights_4[0][0]          \n",
      "                                                                 quintet_weights_4[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (8,)                 0           TL[0][0]                         \n",
      "                                                                 TL_pos[0][0]                     \n",
      "                                                                 TL_neg[0][0]                     \n",
      "                                                                 TL_centroid[0][0]                \n",
      "                                                                 TL_weight[0][0]                  \n",
      "                                                                 TL_pos_weight[0][0]              \n",
      "                                                                 TL_neg_weight[0][0]              \n",
      "                                                                 TL_centroid_weight[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quintet_trainable (Lambda)      (9,)                 0           concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,164,159,796\n",
      "Trainable params: 958,396\n",
      "Non-trainable params: 1,163,201,400\n",
      "__________________________________________________________________________________________________\n",
      "Total of  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch: 1 Loss: 0.62, Loss_test: 0.70\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.80, TL_pos: 0.43, TL_neg: 0.27, TL_centroid: 0.29\n",
      "Epoch: 2 Loss: 0.69, Loss_test: 0.69\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.77, TL_pos: 0.61, TL_neg: 0.08, TL_centroid: 0.16\n",
      "Epoch: 3 Loss: 0.72, Loss_test: 0.69\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.74, TL_pos: 0.69, TL_neg: 0.04, TL_centroid: 0.13\n",
      "Epoch: 4 Loss: 0.63, Loss_test: 0.69\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.66, TL_pos: 0.60, TL_neg: 0.06, TL_centroid: 0.16\n",
      "Epoch: 5 Loss: 0.61, Loss_test: 0.69\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.64, TL_pos: 0.58, TL_neg: 0.04, TL_centroid: 0.16\n",
      "Epoch: 6 Loss: 0.70, Loss_test: 0.68\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.72, TL_pos: 0.68, TL_neg: 0.03, TL_centroid: 0.12\n",
      "Epoch: 7 Loss: 0.75, Loss_test: 0.68\n",
      "TL_w: 1.00, TL_pos_w: 1.00, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.77, TL_pos: 0.73, TL_neg: 0.03, TL_centroid: 0.12\n",
      "Epoch: 8 Loss: 0.63, Loss_test: 0.67\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.72, TL_pos: 0.55, TL_neg: 0.10, TL_centroid: 0.18\n",
      "Epoch: 9 Loss: 0.74, Loss_test: 0.66\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.77, TL_pos: 0.71, TL_neg: 0.05, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 10 Loss: 0.69, Loss_test: 0.66\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.73, TL_pos: 0.65, TL_neg: 0.05, TL_centroid: 0.16\n",
      "Epoch: 11 Loss: 0.68, Loss_test: 0.65\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.72, TL_pos: 0.64, TL_neg: 0.04, TL_centroid: 0.14\n",
      "Epoch: 12 Loss: 0.59, Loss_test: 0.64\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.61, TL_pos: 0.58, TL_neg: 0.04, TL_centroid: 0.17\n",
      "Epoch: 13 Loss: 0.56, Loss_test: 0.63\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.62, TL_pos: 0.49, TL_neg: 0.05, TL_centroid: 0.18\n",
      "Epoch: 14 Loss: 0.60, Loss_test: 0.62\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.63, TL_pos: 0.56, TL_neg: 0.04, TL_centroid: 0.13\n",
      "Epoch: 15 Loss: 0.60, Loss_test: 0.61\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.67, TL_pos: 0.53, TL_neg: 0.09, TL_centroid: 0.20\n",
      "Epoch: 16 Loss: 0.60, Loss_test: 0.59\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.66, TL_pos: 0.55, TL_neg: 0.08, TL_centroid: 0.19\n",
      "Epoch: 17 Loss: 0.42, Loss_test: 0.59\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.44, TL_pos: 0.40, TL_neg: 0.03, TL_centroid: 0.17\n",
      "Epoch: 18 Loss: 0.54, Loss_test: 0.58\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.61, TL_pos: 0.47, TL_neg: 0.03, TL_centroid: 0.13\n",
      "Epoch: 19 Loss: 0.51, Loss_test: 0.57\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.54, TL_pos: 0.48, TL_neg: 0.03, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 20 Loss: 0.53, Loss_test: 0.56\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.57, TL_pos: 0.48, TL_neg: 0.04, TL_centroid: 0.14\n",
      "Epoch: 21 Loss: 0.40, Loss_test: 0.55\n",
      "TL_w: 0.99, TL_pos_w: 1.01, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.41, TL_pos: 0.38, TL_neg: 0.02, TL_centroid: 0.13\n",
      "Epoch: 22 Loss: 0.47, Loss_test: 0.54\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.49, TL_pos: 0.45, TL_neg: 0.02, TL_centroid: 0.14\n",
      "Epoch: 23 Loss: 0.48, Loss_test: 0.54\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.51, TL_pos: 0.45, TL_neg: 0.02, TL_centroid: 0.13\n",
      "Epoch: 24 Loss: 0.44, Loss_test: 0.53\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.47, TL_pos: 0.40, TL_neg: 0.02, TL_centroid: 0.08\n",
      "Epoch: 25 Loss: 0.52, Loss_test: 0.52\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.52, TL_pos: 0.51, TL_neg: 0.02, TL_centroid: 0.14\n",
      "Epoch: 26 Loss: 0.30, Loss_test: 0.51\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.34, TL_pos: 0.26, TL_neg: 0.03, TL_centroid: 0.16\n",
      "Epoch: 27 Loss: 0.51, Loss_test: 0.52\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.53, TL_pos: 0.49, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 28 Loss: 0.37, Loss_test: 0.52\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.39, TL_pos: 0.36, TL_neg: 0.02, TL_centroid: 0.13\n",
      "Epoch: 29 Loss: 0.50, Loss_test: 0.52\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.56, TL_pos: 0.44, TL_neg: 0.05, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 30 Loss: 0.46, Loss_test: 0.51\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.49, TL_pos: 0.43, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 31 Loss: 0.47, Loss_test: 0.48\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.51, TL_pos: 0.42, TL_neg: 0.04, TL_centroid: 0.18\n",
      "Epoch: 32 Loss: 0.41, Loss_test: 0.47\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.42, TL_pos: 0.40, TL_neg: 0.02, TL_centroid: 0.17\n",
      "Epoch: 33 Loss: 0.38, Loss_test: 0.46\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.39, TL_pos: 0.36, TL_neg: 0.02, TL_centroid: 0.15\n",
      "Epoch: 34 Loss: 0.42, Loss_test: 0.46\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.44, TL_pos: 0.39, TL_neg: 0.02, TL_centroid: 0.13\n",
      "Epoch: 35 Loss: 0.51, Loss_test: 0.46\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.53, TL_pos: 0.48, TL_neg: 0.03, TL_centroid: 0.13\n",
      "Epoch: 36 Loss: 0.46, Loss_test: 0.45\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.48, TL_pos: 0.44, TL_neg: 0.02, TL_centroid: 0.13\n",
      "Epoch: 37 Loss: 0.31, Loss_test: 0.44\n",
      "TL_w: 0.98, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.34, TL_pos: 0.29, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 38 Loss: 0.17, Loss_test: 0.45\n",
      "TL_w: 0.97, TL_pos_w: 1.02, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 41 Loss: 0.38, Loss_test: 0.44\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.40, TL_pos: 0.37, TL_neg: 0.03, TL_centroid: 0.16\n",
      "Epoch: 42 Loss: 0.35, Loss_test: 0.42\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.39, TL_pos: 0.31, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 43 Loss: 0.24, Loss_test: 0.42\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.25, TL_pos: 0.24, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 44 Loss: 0.16, Loss_test: 0.43\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 45 Loss: 0.31, Loss_test: 0.44\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.33, TL_pos: 0.30, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 46 Loss: 0.21, Loss_test: 0.44\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 47 Loss: 0.23, Loss_test: 0.44\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.25, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.20\n",
      "Epoch: 48 Loss: 0.28, Loss_test: 0.44\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.29, TL_pos: 0.27, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 49 Loss: 0.39, Loss_test: 0.43\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.41, TL_pos: 0.38, TL_neg: 0.02, TL_centroid: 0.16\n",
      "=> result saved!\n",
      "Epoch: 50 Loss: 0.14, Loss_test: 0.43\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.13, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 51 Loss: 0.41, Loss_test: 0.42\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.43, TL_pos: 0.39, TL_neg: 0.02, TL_centroid: 0.11\n",
      "Epoch: 52 Loss: 0.15, Loss_test: 0.43\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.14, TL_neg: 0.00, TL_centroid: 0.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 Loss: 0.22, Loss_test: 0.43\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 54 Loss: 0.30, Loss_test: 0.43\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.31, TL_pos: 0.29, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 55 Loss: 0.30, Loss_test: 0.43\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.31, TL_pos: 0.29, TL_neg: 0.02, TL_centroid: 0.18\n",
      "Epoch: 56 Loss: 0.34, Loss_test: 0.42\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.36, TL_pos: 0.33, TL_neg: 0.02, TL_centroid: 0.13\n",
      "Epoch: 57 Loss: 0.30, Loss_test: 0.41\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.31, TL_pos: 0.29, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 58 Loss: 0.15, Loss_test: 0.41\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 59 Loss: 0.46, Loss_test: 0.41\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.47, TL_pos: 0.45, TL_neg: 0.02, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 60 Loss: 0.32, Loss_test: 0.40\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.33, TL_pos: 0.31, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 61 Loss: 0.28, Loss_test: 0.40\n",
      "TL_w: 0.97, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.29, TL_pos: 0.27, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 62 Loss: 0.28, Loss_test: 0.39\n",
      "TL_w: 0.96, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.29, TL_pos: 0.28, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 63 Loss: 0.33, Loss_test: 0.39\n",
      "TL_w: 0.96, TL_pos_w: 1.03, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.34, TL_pos: 0.32, TL_neg: 0.02, TL_centroid: 0.14\n",
      "Epoch: 64 Loss: 0.37, Loss_test: 0.38\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.38, TL_pos: 0.36, TL_neg: 0.02, TL_centroid: 0.11\n",
      "Epoch: 65 Loss: 0.25, Loss_test: 0.37\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.25, TL_pos: 0.24, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 66 Loss: 0.19, Loss_test: 0.37\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 67 Loss: 0.22, Loss_test: 0.36\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.22, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 68 Loss: 0.18, Loss_test: 0.35\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 69 Loss: 0.30, Loss_test: 0.35\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.30, TL_pos: 0.29, TL_neg: 0.01, TL_centroid: 0.19\n",
      "=> result saved!\n",
      "Epoch: 70 Loss: 0.38, Loss_test: 0.34\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.39, TL_pos: 0.37, TL_neg: 0.02, TL_centroid: 0.16\n",
      "Epoch: 71 Loss: 0.26, Loss_test: 0.34\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.26, TL_pos: 0.26, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 72 Loss: 0.32, Loss_test: 0.34\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.32, TL_pos: 0.32, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 73 Loss: 0.26, Loss_test: 0.34\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.26, TL_pos: 0.26, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 74 Loss: 0.19, Loss_test: 0.34\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 75 Loss: 0.23, Loss_test: 0.34\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.24, TL_pos: 0.22, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 76 Loss: 0.31, Loss_test: 0.34\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.32, TL_pos: 0.30, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 77 Loss: 0.16, Loss_test: 0.34\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.19\n",
      "Epoch: 78 Loss: 0.20, Loss_test: 0.34\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 79 Loss: 0.21, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.17\n",
      "=> result saved!\n",
      "Epoch: 80 Loss: 0.23, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.26, TL_pos: 0.20, TL_neg: 0.02, TL_centroid: 0.22\n",
      "Epoch: 81 Loss: 0.17, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.19\n",
      "Epoch: 82 Loss: 0.28, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.28, TL_pos: 0.28, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 83 Loss: 0.17, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 84 Loss: 0.38, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.39, TL_pos: 0.38, TL_neg: 0.02, TL_centroid: 0.17\n",
      "Epoch: 85 Loss: 0.41, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.42, TL_pos: 0.41, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 86 Loss: 0.14, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 87 Loss: 0.16, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.16, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 88 Loss: 0.36, Loss_test: 0.32\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.36, TL_pos: 0.35, TL_neg: 0.02, TL_centroid: 0.14\n",
      "Epoch: 89 Loss: 0.07, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.12\n",
      "=> result saved!\n",
      "Epoch: 90 Loss: 0.29, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.30, TL_pos: 0.29, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 91 Loss: 0.21, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 92 Loss: 0.12, Loss_test: 0.32\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.02, TL_centroid: 0.13\n",
      "Epoch: 93 Loss: 0.26, Loss_test: 0.32\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.27, TL_pos: 0.26, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 94 Loss: 0.18, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.19\n",
      "Epoch: 95 Loss: 0.25, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.25, TL_pos: 0.24, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 96 Loss: 0.22, Loss_test: 0.33\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 97 Loss: 0.34, Loss_test: 0.32\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.34, TL_pos: 0.34, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 98 Loss: 0.30, Loss_test: 0.32\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.31, TL_pos: 0.30, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 99 Loss: 0.27, Loss_test: 0.32\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.28, TL_pos: 0.27, TL_neg: 0.01, TL_centroid: 0.18\n",
      "=> result saved!\n",
      "Epoch: 100 Loss: 0.15, Loss_test: 0.32\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.14, recall@25: 0.46\n",
      "Best_epoch=89, Best_loss=0.07, Recall@25=0.46\n",
      "CPU times: user 8h 51min 46s, sys: 2h 22min 44s, total: 11h 14min 30s\n",
      "Wall time: 1h 34min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Inspired on https://'pastebin.com/TaGFdcBA\n",
    "# TODO: https://stackoverflow.com/questions/49941903/keras-compute-cosine-distance-between-two-flattened-outputs\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Clear GPU memory\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()\n",
    "\n",
    "# Embeddings\n",
    "desc_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(baseline.embedding_matrix), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_D, \n",
    "                              trainable=False)\n",
    "title_embedding_layer = embedding_layer(embeddings=baseline.embedding_matrix, \n",
    "                              num_words=len(baseline.embedding_matrix), \n",
    "                              embedding_dim=EMBEDDING_DIM, \n",
    "                              max_sequence_length=MAX_SEQUENCE_LENGTH_T, \n",
    "                              trainable=False)\n",
    "\n",
    "# Feature models\n",
    "'''\n",
    "    cnn_model\n",
    "    lstm_model\n",
    "    mlp_model\n",
    "'''\n",
    "desc_feature_model = cnn_model(desc_embedding_layer, MAX_SEQUENCE_LENGTH_D)\n",
    "title_feature_model = lstm_model(title_embedding_layer, MAX_SEQUENCE_LENGTH_T)\n",
    "categorical_feature_model = mlp_model(number_of_columns_info)\n",
    "\n",
    "# Similarity model\n",
    "encoded_anchor = siamese_model(title_feature_model, desc_feature_model, categorical_feature_model, \n",
    "                                     number_of_columns_info, MAX_SEQUENCE_LENGTH_T, MAX_SEQUENCE_LENGTH_D, 'in')\n",
    "\n",
    "similarity_model = max_margin_objective(encoded_anchor, decay_lr=1)\n",
    "\n",
    "# cnn_feature_model.summary()\n",
    "# lstm_feature_model.summary()\n",
    "similarity_model.summary()\n",
    "\n",
    "'''\n",
    "    Experiment\n",
    "'''\n",
    "result = { 'train' : [], 'test' : [] }\n",
    "print(\"Total of \", limit_train)\n",
    "for epoch in range(limit_train):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_sim = batch_iterator(baseline, retrieval, encoded_anchor, baseline.train_data, \n",
    "                                                       baseline.dup_sets_train, bug_train_ids, \n",
    "                                                           batch_size, 1, issues_by_buckets, TRIPLET_HARD=False)\n",
    "    train_batch = [train_input_sample['title'], train_input_sample['description'], train_input_sample['info'], train_sim]\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    h_validation = similarity_model.test_on_batch(x=validation_sample, y=valid_sim)\n",
    "    \n",
    "    # save results\n",
    "    result['train'].append(h)\n",
    "    result['test'].append(h_validation)\n",
    "    \n",
    "    if( (epoch+1) % 10 == 0 or (epoch+1 == limit_train) ):\n",
    "        save_loss(result)\n",
    "    \n",
    "    if (epoch+1 == limit_train): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "        print((\"Epoch: {} Loss: {:.2f}, Loss_test: {:.2f}\\n\" +\n",
    "               \"TL_w: {:.2f}, TL_pos_w: {:.2f}, TL_neg_w: {:.2f}, TL_centroid_w: {:.2f}\\n\" + \n",
    "                \"TL: {:.2f}, TL_pos: {:.2f}, TL_neg: {:.2f}, TL_centroid: {:.2f}, \" +\n",
    "              \"recall@25: {:.2f}\").format(epoch+1, h[0], h_validation[0], h[1], h[2], h[3], \n",
    "                                          h[4], h[5], h[6], h[7], h[8], recall))\n",
    "    else:\n",
    "        print((\"Epoch: {} Loss: {:.2f}, Loss_test: {:.2f}\\n\" +\n",
    "               \"TL_w: {:.2f}, TL_pos_w: {:.2f}, TL_neg_w: {:.2f}, TL_centroid_w: {:.2f}\\n\" + \n",
    "              \"TL: {:.2f}, TL_pos: {:.2f}, TL_neg: {:.2f}, TL_centroid: {:.2f}\").format(\n",
    "            epoch+1, h[0], h_validation[0], h[1], h[2], h[3], h[4], h[5], h[6], h[7], h[8]))\n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "#experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "#experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/eclipse/bert/exported_rank_DMS_QL_100.txt'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "EXPORT_RANK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model 'modelos/model_bert_preprocessing_DMS_QL_100_feature_100epochs_64batch(eclipse).h5' to disk\n"
     ]
    }
   ],
   "source": [
    "experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(limit_train)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(limit_train)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['train']), len(result['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          581804100   title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          581850792   desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 901)          0           input_label[0][0]                \n",
      "                                                                 merge_features_in[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "quintet_loss (Lambda)           (4,)                 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TL (Lambda)                     (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_pos (Lambda)                 (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_neg (Lambda)                 (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TL_centroid (Lambda)            (1,)                 0           quintet_loss[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_1 (QuintetWeigh [(1,), (1,)]         1           TL[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_2 (QuintetWeigh [(1,), (1,)]         1           TL_pos[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_3 (QuintetWeigh [(1,), (1,)]         1           TL_neg[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "quintet_weights_4 (QuintetWeigh [(1,), (1,)]         1           TL_centroid[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "TL_weight (Lambda)              (1,)                 0           quintet_weights_1[0][0]          \n",
      "                                                                 quintet_weights_1[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_pos_weight (Lambda)          (1,)                 0           quintet_weights_2[0][0]          \n",
      "                                                                 quintet_weights_2[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_neg_weight (Lambda)          (1,)                 0           quintet_weights_3[0][0]          \n",
      "                                                                 quintet_weights_3[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "TL_centroid_weight (Lambda)     (1,)                 0           quintet_weights_4[0][0]          \n",
      "                                                                 quintet_weights_4[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (8,)                 0           TL[0][0]                         \n",
      "                                                                 TL_pos[0][0]                     \n",
      "                                                                 TL_neg[0][0]                     \n",
      "                                                                 TL_centroid[0][0]                \n",
      "                                                                 TL_weight[0][0]                  \n",
      "                                                                 TL_pos_weight[0][0]              \n",
      "                                                                 TL_neg_weight[0][0]              \n",
      "                                                                 TL_centroid_weight[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quintet_trainable (Lambda)      (9,)                 0           concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,164,159,796\n",
      "Trainable params: 958,396\n",
      "Non-trainable params: 1,163,201,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = similarity_model.get_layer('concatenate_4')\n",
    "output = Lambda(quintet_trainable, name='quintet_trainable')(model.output)\n",
    "inputs = similarity_model.inputs\n",
    "model = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')\n",
    "\n",
    "# setup the optimization process \n",
    "model.compile(optimizer='adam', loss=custom_loss, metrics=[TL_w_anchor, TL_w_pos, TL_w_neg, TL_w_centroid,\n",
    "                                                                         TL, TL_pos, TL_neg, TL_centroid])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain to use\n",
    "METHOD = 'DMS_QL_{}'.format(epochs)\n",
    "SAVE_PATH = '{}_preprocessing_{}_feature@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)\n",
    "SAVE_PATH_FEATURE = '{}_preprocessing_{}_feature_@number_of_epochs@epochs_64batch({})'.format(PREPROCESSING, METHOD, DOMAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101 Loss: 0.23, Loss_test: 0.32\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.25, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 102 Loss: 0.20, Loss_test: 0.32\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 103 Loss: 0.25, Loss_test: 0.32\n",
      "TL_w: 0.96, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.25, TL_pos: 0.24, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 104 Loss: 0.30, Loss_test: 0.31\n",
      "TL_w: 0.95, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.31, TL_pos: 0.30, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 105 Loss: 0.17, Loss_test: 0.31\n",
      "TL_w: 0.95, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.21\n",
      "Epoch: 106 Loss: 0.22, Loss_test: 0.31\n",
      "TL_w: 0.95, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.24, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 107 Loss: 0.16, Loss_test: 0.31\n",
      "TL_w: 0.95, TL_pos_w: 1.04, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 108 Loss: 0.26, Loss_test: 0.30\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.28, TL_pos: 0.25, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 109 Loss: 0.23, Loss_test: 0.30\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.24, TL_pos: 0.23, TL_neg: 0.01, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 110 Loss: 0.26, Loss_test: 0.30\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.27, TL_pos: 0.25, TL_neg: 0.01, TL_centroid: 0.19\n",
      "Epoch: 111 Loss: 0.19, Loss_test: 0.30\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 112 Loss: 0.24, Loss_test: 0.30\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.24, TL_pos: 0.23, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 113 Loss: 0.16, Loss_test: 0.30\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.22\n",
      "Epoch: 114 Loss: 0.19, Loss_test: 0.30\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.19, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 115 Loss: 0.17, Loss_test: 0.30\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 116 Loss: 0.18, Loss_test: 0.30\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 117 Loss: 0.28, Loss_test: 0.29\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.28, TL_pos: 0.27, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 118 Loss: 0.16, Loss_test: 0.29\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 119 Loss: 0.18, Loss_test: 0.28\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.09\n",
      "=> result saved!\n",
      "Epoch: 120 Loss: 0.30, Loss_test: 0.28\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.31, TL_pos: 0.30, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 121 Loss: 0.29, Loss_test: 0.27\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.30, TL_pos: 0.28, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 122 Loss: 0.23, Loss_test: 0.27\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.24, TL_pos: 0.23, TL_neg: 0.02, TL_centroid: 0.16\n",
      "Epoch: 123 Loss: 0.15, Loss_test: 0.27\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 124 Loss: 0.17, Loss_test: 0.27\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.16, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 125 Loss: 0.12, Loss_test: 0.27\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 126 Loss: 0.35, Loss_test: 0.27\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.36, TL_pos: 0.34, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 127 Loss: 0.11, Loss_test: 0.27\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 128 Loss: 0.15, Loss_test: 0.27\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.13, TL_neg: 0.03, TL_centroid: 0.15\n",
      "Epoch: 129 Loss: 0.09, Loss_test: 0.27\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.18\n",
      "=> result saved!\n",
      "Epoch: 130 Loss: 0.17, Loss_test: 0.26\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 131 Loss: 0.16, Loss_test: 0.26\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 132 Loss: 0.08, Loss_test: 0.26\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 133 Loss: 0.20, Loss_test: 0.26\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 134 Loss: 0.22, Loss_test: 0.25\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.23, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 135 Loss: 0.20, Loss_test: 0.25\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.19, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 136 Loss: 0.23, Loss_test: 0.24\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.23, TL_pos: 0.23, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 137 Loss: 0.23, Loss_test: 0.24\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.23, TL_pos: 0.23, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 138 Loss: 0.11, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 139 Loss: 0.18, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.17\n",
      "=> result saved!\n",
      "Epoch: 140 Loss: 0.13, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 141 Loss: 0.20, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 142 Loss: 0.12, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 143 Loss: 0.24, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.25, TL_pos: 0.24, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 144 Loss: 0.17, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 145 Loss: 0.21, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 146 Loss: 0.21, Loss_test: 0.24\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 147 Loss: 0.10, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 148 Loss: 0.13, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 149 Loss: 0.18, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 150 Loss: 0.18, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 151 Loss: 0.19, Loss_test: 0.23\n",
      "TL_w: 0.95, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 152 Loss: 0.19, Loss_test: 0.23\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.19, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 153 Loss: 0.19, Loss_test: 0.23\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.19, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 154 Loss: 0.27, Loss_test: 0.23\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.27, TL_pos: 0.26, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 155 Loss: 0.19, Loss_test: 0.23\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.19, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 156 Loss: 0.28, Loss_test: 0.23\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.28, TL_pos: 0.27, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 157 Loss: 0.17, Loss_test: 0.23\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 158 Loss: 0.17, Loss_test: 0.24\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.17, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 159 Loss: 0.15, Loss_test: 0.24\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.16\n",
      "=> result saved!\n",
      "Epoch: 160 Loss: 0.23, Loss_test: 0.24\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.24, TL_pos: 0.23, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 161 Loss: 0.11, Loss_test: 0.24\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 162 Loss: 0.16, Loss_test: 0.25\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 163 Loss: 0.10, Loss_test: 0.25\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 164 Loss: 0.16, Loss_test: 0.25\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 165 Loss: 0.13, Loss_test: 0.25\n",
      "TL_w: 0.94, TL_pos_w: 1.05, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 166 Loss: 0.21, Loss_test: 0.25\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 167 Loss: 0.23, Loss_test: 0.24\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.23, TL_pos: 0.23, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 168 Loss: 0.15, Loss_test: 0.24\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 169 Loss: 0.19, Loss_test: 0.23\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.11\n",
      "=> result saved!\n",
      "Epoch: 170 Loss: 0.15, Loss_test: 0.22\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 171 Loss: 0.14, Loss_test: 0.21\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 172 Loss: 0.14, Loss_test: 0.22\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 173 Loss: 0.13, Loss_test: 0.22\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 174 Loss: 0.16, Loss_test: 0.22\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 175 Loss: 0.10, Loss_test: 0.21\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 176 Loss: 0.09, Loss_test: 0.21\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 177 Loss: 0.21, Loss_test: 0.21\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 178 Loss: 0.10, Loss_test: 0.21\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 179 Loss: 0.16, Loss_test: 0.21\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.11\n",
      "=> result saved!\n",
      "Epoch: 180 Loss: 0.16, Loss_test: 0.21\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 181 Loss: 0.10, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 182 Loss: 0.14, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 183 Loss: 0.08, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 184 Loss: 0.20, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 185 Loss: 0.13, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.02, TL_centroid: 0.13\n",
      "Epoch: 186 Loss: 0.15, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 187 Loss: 0.21, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 188 Loss: 0.07, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 189 Loss: 0.17, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.12\n",
      "=> result saved!\n",
      "Epoch: 190 Loss: 0.31, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.32, TL_pos: 0.31, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 191 Loss: 0.10, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 192 Loss: 0.16, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.16, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 193 Loss: 0.21, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 194 Loss: 0.16, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.08\n",
      "Epoch: 195 Loss: 0.12, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 196 Loss: 0.17, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.16, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 197 Loss: 0.20, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 198 Loss: 0.09, Loss_test: 0.19\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 199 Loss: 0.14, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.14, TL_neg: 0.00, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 200 Loss: 0.07, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 201 Loss: 0.12, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 202 Loss: 0.19, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 203 Loss: 0.15, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 204 Loss: 0.16, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 205 Loss: 0.19, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 206 Loss: 0.15, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 207 Loss: 0.13, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 208 Loss: 0.16, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.08\n",
      "Epoch: 209 Loss: 0.10, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 210 Loss: 0.15, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 211 Loss: 0.14, Loss_test: 0.20\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 212 Loss: 0.24, Loss_test: 0.19\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.24, TL_pos: 0.24, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 213 Loss: 0.09, Loss_test: 0.19\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 214 Loss: 0.06, Loss_test: 0.19\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 215 Loss: 0.17, Loss_test: 0.18\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 216 Loss: 0.15, Loss_test: 0.19\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 217 Loss: 0.09, Loss_test: 0.18\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 218 Loss: 0.13, Loss_test: 0.18\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.12, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 219 Loss: 0.13, Loss_test: 0.18\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 220 Loss: 0.19, Loss_test: 0.18\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 221 Loss: 0.08, Loss_test: 0.17\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 222 Loss: 0.20, Loss_test: 0.17\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 223 Loss: 0.18, Loss_test: 0.17\n",
      "TL_w: 0.94, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 224 Loss: 0.08, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 225 Loss: 0.26, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.26, TL_pos: 0.26, TL_neg: 0.01, TL_centroid: 0.08\n",
      "Epoch: 226 Loss: 0.11, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 227 Loss: 0.29, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.30, TL_pos: 0.29, TL_neg: 0.02, TL_centroid: 0.12\n",
      "Epoch: 228 Loss: 0.06, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 229 Loss: 0.11, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.10\n",
      "=> result saved!\n",
      "Epoch: 230 Loss: 0.15, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 231 Loss: 0.08, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 232 Loss: 0.11, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 233 Loss: 0.14, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.08\n",
      "Epoch: 234 Loss: 0.13, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.06\n",
      "Epoch: 235 Loss: 0.15, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 236 Loss: 0.07, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 237 Loss: 0.09, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 238 Loss: 0.13, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 239 Loss: 0.11, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.11\n",
      "=> result saved!\n",
      "Epoch: 240 Loss: 0.17, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.08\n",
      "Epoch: 241 Loss: 0.12, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 242 Loss: 0.06, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 243 Loss: 0.21, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 244 Loss: 0.26, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.26, TL_pos: 0.25, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 245 Loss: 0.16, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.06, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 246 Loss: 0.18, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 247 Loss: 0.06, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 248 Loss: 0.07, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.07\n",
      "Epoch: 249 Loss: 0.09, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.08\n",
      "=> result saved!\n",
      "Epoch: 250 Loss: 0.16, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 251 Loss: 0.13, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 252 Loss: 0.09, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 253 Loss: 0.11, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 254 Loss: 0.20, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 255 Loss: 0.13, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 256 Loss: 0.15, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 257 Loss: 0.18, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 258 Loss: 0.12, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 259 Loss: 0.19, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.19, TL_neg: 0.01, TL_centroid: 0.09\n",
      "=> result saved!\n",
      "Epoch: 260 Loss: 0.11, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 261 Loss: 0.10, Loss_test: 0.18\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 262 Loss: 0.04, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 263 Loss: 0.13, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 264 Loss: 0.07, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 265 Loss: 0.08, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 266 Loss: 0.16, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.16, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 267 Loss: 0.10, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 268 Loss: 0.07, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 269 Loss: 0.10, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 270 Loss: 0.16, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 271 Loss: 0.17, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 272 Loss: 0.10, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 273 Loss: 0.12, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 274 Loss: 0.15, Loss_test: 0.17\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 275 Loss: 0.10, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 276 Loss: 0.07, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 277 Loss: 0.09, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 278 Loss: 0.06, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 279 Loss: 0.12, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 280 Loss: 0.15, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 281 Loss: 0.15, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 282 Loss: 0.14, Loss_test: 0.16\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 283 Loss: 0.10, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 284 Loss: 0.12, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 285 Loss: 0.21, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 286 Loss: 0.16, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 287 Loss: 0.19, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.19, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 288 Loss: 0.11, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 289 Loss: 0.12, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.10\n",
      "=> result saved!\n",
      "Epoch: 290 Loss: 0.09, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.08\n",
      "Epoch: 291 Loss: 0.13, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 292 Loss: 0.19, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.19, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 293 Loss: 0.12, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 294 Loss: 0.15, Loss_test: 0.15\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 295 Loss: 0.14, Loss_test: 0.14\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.14, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 296 Loss: 0.11, Loss_test: 0.14\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 297 Loss: 0.10, Loss_test: 0.14\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 298 Loss: 0.07, Loss_test: 0.14\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 299 Loss: 0.17, Loss_test: 0.14\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 300 Loss: 0.09, Loss_test: 0.14\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 301 Loss: 0.15, Loss_test: 0.14\n",
      "TL_w: 0.93, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 302 Loss: 0.12, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 303 Loss: 0.11, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 304 Loss: 0.07, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 305 Loss: 0.06, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 306 Loss: 0.07, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 307 Loss: 0.11, Loss_test: 0.15\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 308 Loss: 0.05, Loss_test: 0.15\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 309 Loss: 0.10, Loss_test: 0.15\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 310 Loss: 0.03, Loss_test: 0.15\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 311 Loss: 0.18, Loss_test: 0.15\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 312 Loss: 0.14, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.14, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 313 Loss: 0.13, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 314 Loss: 0.08, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 315 Loss: 0.08, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 316 Loss: 0.17, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 317 Loss: 0.11, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 318 Loss: 0.12, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 319 Loss: 0.09, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 320 Loss: 0.13, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 321 Loss: 0.10, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 322 Loss: 0.10, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 323 Loss: 0.19, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.19, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 324 Loss: 0.17, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 325 Loss: 0.20, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.20, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 326 Loss: 0.20, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 327 Loss: 0.08, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 328 Loss: 0.13, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 329 Loss: 0.21, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.09\n",
      "=> result saved!\n",
      "Epoch: 330 Loss: 0.09, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 331 Loss: 0.09, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.07, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 332 Loss: 0.06, Loss_test: 0.15\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 333 Loss: 0.15, Loss_test: 0.15\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 334 Loss: 0.10, Loss_test: 0.15\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 335 Loss: 0.07, Loss_test: 0.15\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 336 Loss: 0.16, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 337 Loss: 0.08, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 338 Loss: 0.21, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.20, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 339 Loss: 0.07, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.11\n",
      "=> result saved!\n",
      "Epoch: 340 Loss: 0.15, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 341 Loss: 0.12, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 342 Loss: 0.10, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 343 Loss: 0.06, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 344 Loss: 0.06, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 345 Loss: 0.05, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 346 Loss: 0.05, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 347 Loss: 0.08, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 348 Loss: 0.13, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 349 Loss: 0.07, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.11\n",
      "=> result saved!\n",
      "Epoch: 350 Loss: 0.09, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 351 Loss: 0.17, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 352 Loss: 0.10, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 353 Loss: 0.08, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 354 Loss: 0.09, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 355 Loss: 0.14, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 356 Loss: 0.09, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 357 Loss: 0.12, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 358 Loss: 0.13, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.13, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 359 Loss: 0.13, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.11\n",
      "=> result saved!\n",
      "Epoch: 360 Loss: 0.08, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.08\n",
      "Epoch: 361 Loss: 0.08, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 362 Loss: 0.05, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 363 Loss: 0.08, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 364 Loss: 0.09, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 365 Loss: 0.11, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 366 Loss: 0.08, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 367 Loss: 0.09, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 368 Loss: 0.06, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 369 Loss: 0.08, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 370 Loss: 0.09, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 371 Loss: 0.06, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 372 Loss: 0.08, Loss_test: 0.13\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 373 Loss: 0.11, Loss_test: 0.14\n",
      "TL_w: 0.92, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.21\n",
      "Epoch: 374 Loss: 0.16, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 375 Loss: 0.13, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 376 Loss: 0.07, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 377 Loss: 0.15, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 378 Loss: 0.07, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 379 Loss: 0.07, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.12\n",
      "=> result saved!\n",
      "Epoch: 380 Loss: 0.08, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 381 Loss: 0.11, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 382 Loss: 0.10, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 383 Loss: 0.10, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 384 Loss: 0.12, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 385 Loss: 0.14, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 386 Loss: 0.08, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 387 Loss: 0.08, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 388 Loss: 0.08, Loss_test: 0.16\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 389 Loss: 0.07, Loss_test: 0.16\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.11\n",
      "=> result saved!\n",
      "Epoch: 390 Loss: 0.08, Loss_test: 0.16\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 391 Loss: 0.06, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 392 Loss: 0.11, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 393 Loss: 0.09, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 394 Loss: 0.06, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 395 Loss: 0.18, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.02, TL_centroid: 0.16\n",
      "Epoch: 396 Loss: 0.07, Loss_test: 0.16\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 397 Loss: 0.13, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 398 Loss: 0.15, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 399 Loss: 0.05, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.19\n",
      "=> result saved!\n",
      "Epoch: 400 Loss: 0.09, Loss_test: 0.16\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 401 Loss: 0.05, Loss_test: 0.16\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 402 Loss: 0.07, Loss_test: 0.16\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 403 Loss: 0.11, Loss_test: 0.16\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 404 Loss: 0.07, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 405 Loss: 0.06, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 406 Loss: 0.09, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 407 Loss: 0.16, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 408 Loss: 0.09, Loss_test: 0.15\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 409 Loss: 0.06, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.16\n",
      "=> result saved!\n",
      "Epoch: 410 Loss: 0.10, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 411 Loss: 0.07, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 412 Loss: 0.06, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 413 Loss: 0.09, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 414 Loss: 0.08, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 415 Loss: 0.03, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 416 Loss: 0.12, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 417 Loss: 0.04, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 418 Loss: 0.08, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 419 Loss: 0.11, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.08\n",
      "=> result saved!\n",
      "Epoch: 420 Loss: 0.12, Loss_test: 0.14\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 421 Loss: 0.10, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 422 Loss: 0.18, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.18, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 423 Loss: 0.06, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 424 Loss: 0.09, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 425 Loss: 0.04, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.08, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 426 Loss: 0.05, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 427 Loss: 0.12, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 428 Loss: 0.07, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 429 Loss: 0.06, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 430 Loss: 0.05, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 431 Loss: 0.07, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 432 Loss: 0.10, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 433 Loss: 0.06, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 434 Loss: 0.08, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 435 Loss: 0.09, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 436 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 437 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 438 Loss: 0.08, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 439 Loss: 0.16, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.10\n",
      "=> result saved!\n",
      "Epoch: 440 Loss: 0.08, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 441 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 442 Loss: 0.04, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 443 Loss: 0.05, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 444 Loss: 0.10, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 445 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 446 Loss: 0.08, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 447 Loss: 0.10, Loss_test: 0.13\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 448 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 449 Loss: 0.12, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.12\n",
      "=> result saved!\n",
      "Epoch: 450 Loss: 0.11, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 451 Loss: 0.15, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 452 Loss: 0.22, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.22, TL_pos: 0.21, TL_neg: 0.02, TL_centroid: 0.13\n",
      "Epoch: 453 Loss: 0.11, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 454 Loss: 0.08, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 455 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 456 Loss: 0.11, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 457 Loss: 0.05, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 458 Loss: 0.11, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 459 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.10\n",
      "=> result saved!\n",
      "Epoch: 460 Loss: 0.07, Loss_test: 0.12\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 461 Loss: 0.11, Loss_test: 0.11\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 462 Loss: 0.04, Loss_test: 0.11\n",
      "TL_w: 0.91, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 463 Loss: 0.07, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.09\n",
      "Epoch: 464 Loss: 0.09, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 465 Loss: 0.10, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 466 Loss: 0.08, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 467 Loss: 0.10, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 468 Loss: 0.07, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 469 Loss: 0.14, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.12\n",
      "=> result saved!\n",
      "Epoch: 470 Loss: 0.08, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 471 Loss: 0.05, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 472 Loss: 0.10, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 473 Loss: 0.10, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 474 Loss: 0.05, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 475 Loss: 0.08, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 476 Loss: 0.08, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 477 Loss: 0.06, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 478 Loss: 0.04, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 479 Loss: 0.06, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 480 Loss: 0.08, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 481 Loss: 0.07, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 482 Loss: 0.07, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 483 Loss: 0.03, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 484 Loss: 0.09, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 485 Loss: 0.08, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 486 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 487 Loss: 0.07, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 488 Loss: 0.09, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 489 Loss: 0.06, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 490 Loss: 0.12, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 491 Loss: 0.05, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 492 Loss: 0.06, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 493 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 494 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 495 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 496 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 497 Loss: 0.11, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 498 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 499 Loss: 0.07, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 500 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 501 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 502 Loss: 0.06, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 503 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 504 Loss: 0.05, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 505 Loss: 0.04, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 506 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 507 Loss: 0.07, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 508 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 509 Loss: 0.06, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.11\n",
      "=> result saved!\n",
      "Epoch: 510 Loss: 0.13, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 511 Loss: 0.07, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 512 Loss: 0.06, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.22\n",
      "Epoch: 513 Loss: 0.07, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 514 Loss: 0.07, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 515 Loss: 0.09, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 516 Loss: 0.06, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 517 Loss: 0.05, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 518 Loss: 0.09, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 519 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.11\n",
      "=> result saved!\n",
      "Epoch: 520 Loss: 0.09, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 521 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 522 Loss: 0.17, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.17, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 523 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 524 Loss: 0.06, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 525 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 526 Loss: 0.21, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.21, TL_pos: 0.21, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 527 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 528 Loss: 0.07, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 529 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 530 Loss: 0.10, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 531 Loss: 0.10, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 532 Loss: 0.11, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 533 Loss: 0.10, Loss_test: 0.11\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 534 Loss: 0.13, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.13, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 535 Loss: 0.07, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 536 Loss: 0.08, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 537 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 538 Loss: 0.06, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 539 Loss: 0.08, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.16\n",
      "=> result saved!\n",
      "Epoch: 540 Loss: 0.06, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 541 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.09, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 542 Loss: 0.14, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 543 Loss: 0.10, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 544 Loss: 0.11, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 545 Loss: 0.12, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 546 Loss: 0.04, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 547 Loss: 0.06, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 548 Loss: 0.11, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 549 Loss: 0.05, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.16\n",
      "=> result saved!\n",
      "Epoch: 550 Loss: 0.04, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 551 Loss: 0.07, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 552 Loss: 0.07, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 553 Loss: 0.03, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 554 Loss: 0.17, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.17, TL_pos: 0.16, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 555 Loss: 0.09, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 556 Loss: 0.06, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 557 Loss: 0.06, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.19\n",
      "Epoch: 558 Loss: 0.13, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 559 Loss: 0.06, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> result saved!\n",
      "Epoch: 560 Loss: 0.06, Loss_test: 0.13\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 561 Loss: 0.05, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 562 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 563 Loss: 0.11, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 564 Loss: 0.09, Loss_test: 0.12\n",
      "TL_w: 0.90, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 565 Loss: 0.05, Loss_test: 0.12\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.08\n",
      "Epoch: 566 Loss: 0.11, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 567 Loss: 0.08, Loss_test: 0.12\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 568 Loss: 0.05, Loss_test: 0.12\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 569 Loss: 0.07, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.17\n",
      "=> result saved!\n",
      "Epoch: 570 Loss: 0.06, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 571 Loss: 0.11, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 572 Loss: 0.04, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 573 Loss: 0.11, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 574 Loss: 0.03, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.25\n",
      "Epoch: 575 Loss: 0.13, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 576 Loss: 0.06, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 577 Loss: 0.05, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.21\n",
      "Epoch: 578 Loss: 0.11, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 579 Loss: 0.07, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.19\n",
      "=> result saved!\n",
      "Epoch: 580 Loss: 0.06, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.05, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 581 Loss: 0.05, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 582 Loss: 0.09, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 583 Loss: 0.04, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 584 Loss: 0.12, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 585 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 586 Loss: 0.06, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 587 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.10\n",
      "Epoch: 588 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 589 Loss: 0.13, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.13\n",
      "=> result saved!\n",
      "Epoch: 590 Loss: 0.04, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 591 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 592 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 593 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 594 Loss: 0.11, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 595 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 596 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 597 Loss: 0.04, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 598 Loss: 0.06, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 599 Loss: 0.10, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.17\n",
      "=> result saved!\n",
      "Epoch: 600 Loss: 0.11, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 601 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 602 Loss: 0.07, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 603 Loss: 0.03, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 604 Loss: 0.04, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 605 Loss: 0.11, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 606 Loss: 0.04, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 607 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 608 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 609 Loss: 0.09, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.17\n",
      "=> result saved!\n",
      "Epoch: 610 Loss: 0.08, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 611 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 612 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 613 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 614 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 615 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 616 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 617 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 618 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 619 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.12\n",
      "=> result saved!\n",
      "Epoch: 620 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 621 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 622 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 623 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.09\n",
      "Epoch: 624 Loss: 0.10, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 625 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 626 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 627 Loss: 0.11, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 628 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 629 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 630 Loss: 0.10, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.08\n",
      "Epoch: 631 Loss: 0.11, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 632 Loss: 0.02, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.02, TL_pos: 0.02, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 633 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 634 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 635 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 636 Loss: 0.04, Loss_test: 0.11\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 637 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 638 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 639 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 640 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 641 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 642 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 643 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 644 Loss: 0.19, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.19, TL_pos: 0.18, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 645 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 646 Loss: 0.08, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 647 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 648 Loss: 0.10, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 649 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 650 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 651 Loss: 0.11, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 652 Loss: 0.09, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 653 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 654 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.10, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 655 Loss: 0.12, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 656 Loss: 0.10, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 657 Loss: 0.06, Loss_test: 0.08\n",
      "TL_w: 0.89, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.22\n",
      "Epoch: 658 Loss: 0.10, Loss_test: 0.09\n",
      "TL_w: 0.89, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 659 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.12\n",
      "=> result saved!\n",
      "Epoch: 660 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 661 Loss: 0.14, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.15, TL_pos: 0.14, TL_neg: 0.01, TL_centroid: 0.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 662 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 663 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 664 Loss: 0.08, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 665 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 666 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 667 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 668 Loss: 0.15, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.16, TL_pos: 0.15, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 669 Loss: 0.11, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.16\n",
      "=> result saved!\n",
      "Epoch: 670 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 671 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 672 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 673 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 674 Loss: 0.02, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.02, TL_pos: 0.02, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 675 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 676 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 677 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 678 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 679 Loss: 0.13, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.13, TL_neg: 0.01, TL_centroid: 0.18\n",
      "=> result saved!\n",
      "Epoch: 680 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.22\n",
      "Epoch: 681 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 682 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 683 Loss: 0.08, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 684 Loss: 0.10, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.22\n",
      "Epoch: 685 Loss: 0.10, Loss_test: 0.08\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 686 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 687 Loss: 0.11, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 688 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 689 Loss: 0.02, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.02, TL_pos: 0.02, TL_neg: 0.00, TL_centroid: 0.18\n",
      "=> result saved!\n",
      "Epoch: 690 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 691 Loss: 0.08, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.12\n",
      "Epoch: 692 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 693 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 694 Loss: 0.06, Loss_test: 0.08\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 695 Loss: 0.11, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 696 Loss: 0.12, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 697 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 698 Loss: 0.09, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 699 Loss: 0.07, Loss_test: 0.08\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 700 Loss: 0.10, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 701 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 702 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 703 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 704 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 705 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 706 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 707 Loss: 0.10, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 708 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 709 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.19\n",
      "=> result saved!\n",
      "Epoch: 710 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 711 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 712 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 713 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 714 Loss: 0.09, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 715 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 716 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 717 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 718 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 719 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 720 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 721 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 722 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 723 Loss: 0.02, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.02, TL_neg: 0.00, TL_centroid: 0.10\n",
      "Epoch: 724 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 725 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.21\n",
      "Epoch: 726 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 727 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 728 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 729 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 730 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 731 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 732 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 733 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 734 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 735 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 736 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 737 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 738 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 739 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 740 Loss: 0.12, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 741 Loss: 0.08, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 742 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 743 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 744 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 745 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 746 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 747 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 748 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 749 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 750 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 751 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 752 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 753 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.12\n",
      "Epoch: 754 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.19\n",
      "Epoch: 755 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 756 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 757 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 758 Loss: 0.08, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 759 Loss: 0.12, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.18\n",
      "=> result saved!\n",
      "Epoch: 760 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 761 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 762 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 763 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.01, TL_centroid: 0.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 764 Loss: 0.11, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 765 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.22\n",
      "Epoch: 766 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 767 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.27\n",
      "Epoch: 768 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 769 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.19\n",
      "=> result saved!\n",
      "Epoch: 770 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 771 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 772 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 773 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 774 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 775 Loss: 0.09, Loss_test: 0.09\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.24\n",
      "Epoch: 776 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 777 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 778 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.88, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.22\n",
      "Epoch: 779 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.23\n",
      "=> result saved!\n",
      "Epoch: 780 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 781 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 782 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 783 Loss: 0.02, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.02, TL_pos: 0.02, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 784 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 785 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 786 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 787 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 788 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 789 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 790 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 791 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.01, TL_centroid: 0.11\n",
      "Epoch: 792 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 793 Loss: 0.08, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.14\n",
      "Epoch: 794 Loss: 0.09, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 795 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 796 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.13\n",
      "Epoch: 797 Loss: 0.09, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.13\n",
      "Epoch: 798 Loss: 0.02, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.02, TL_pos: 0.02, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 799 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.17\n",
      "=> result saved!\n",
      "Epoch: 800 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 801 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.23\n",
      "Epoch: 802 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 803 Loss: 0.14, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.14, TL_pos: 0.13, TL_neg: 0.02, TL_centroid: 0.17\n",
      "Epoch: 804 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.21\n",
      "Epoch: 805 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 806 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 807 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.11, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 808 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 809 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.21\n",
      "=> result saved!\n",
      "Epoch: 810 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 811 Loss: 0.08, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 812 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 813 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Epoch: 814 Loss: 0.08, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 815 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 816 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 817 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.21\n",
      "Epoch: 818 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 819 Loss: 0.12, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.12, TL_neg: 0.01, TL_centroid: 0.16\n",
      "=> result saved!\n",
      "Epoch: 820 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.01, TL_centroid: 0.21\n",
      "Epoch: 821 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 822 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.15\n",
      "Epoch: 823 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 824 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 825 Loss: 0.11, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 826 Loss: 0.03, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 827 Loss: 0.06, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.19\n",
      "Epoch: 828 Loss: 0.06, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 829 Loss: 0.02, Loss_test: 0.07\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.02, TL_neg: 0.00, TL_centroid: 0.15\n",
      "=> result saved!\n",
      "Epoch: 830 Loss: 0.05, Loss_test: 0.07\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 831 Loss: 0.08, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 832 Loss: 0.05, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 833 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 834 Loss: 0.05, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 835 Loss: 0.05, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 836 Loss: 0.07, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.19\n",
      "Epoch: 837 Loss: 0.08, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 838 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.25\n",
      "Epoch: 839 Loss: 0.09, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.00, TL_centroid: 0.20\n",
      "=> result saved!\n",
      "Epoch: 840 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 841 Loss: 0.06, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.23\n",
      "Epoch: 842 Loss: 0.03, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 843 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 844 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 845 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.11\n",
      "Epoch: 846 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 847 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 848 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 849 Loss: 0.12, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.13, TL_pos: 0.12, TL_neg: 0.02, TL_centroid: 0.20\n",
      "=> result saved!\n",
      "Epoch: 850 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 851 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.27\n",
      "Epoch: 852 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 853 Loss: 0.03, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.22\n",
      "Epoch: 854 Loss: 0.04, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.21\n",
      "Epoch: 855 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 856 Loss: 0.10, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 857 Loss: 0.05, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.01, TL_centroid: 0.22\n",
      "Epoch: 858 Loss: 0.11, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.11, TL_pos: 0.11, TL_neg: 0.00, TL_centroid: 0.21\n",
      "Epoch: 859 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.21\n",
      "=> result saved!\n",
      "Epoch: 860 Loss: 0.06, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.19\n",
      "Epoch: 861 Loss: 0.07, Loss_test: 0.10\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 862 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 863 Loss: 0.09, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.09, TL_pos: 0.09, TL_neg: 0.01, TL_centroid: 0.16\n",
      "Epoch: 864 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 865 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 866 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.24\n",
      "Epoch: 867 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.01, TL_centroid: 0.19\n",
      "Epoch: 868 Loss: 0.08, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 869 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.19\n",
      "=> result saved!\n",
      "Epoch: 870 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.21\n",
      "Epoch: 871 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.24\n",
      "Epoch: 872 Loss: 0.06, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.06, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 873 Loss: 0.11, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.12, TL_pos: 0.11, TL_neg: 0.01, TL_centroid: 0.20\n",
      "Epoch: 874 Loss: 0.07, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.21\n",
      "Epoch: 875 Loss: 0.08, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.08, TL_pos: 0.08, TL_neg: 0.01, TL_centroid: 0.18\n",
      "Epoch: 876 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.21\n",
      "Epoch: 877 Loss: 0.02, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.02, TL_pos: 0.02, TL_neg: 0.00, TL_centroid: 0.22\n",
      "Epoch: 878 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.01, TL_centroid: 0.21\n",
      "Epoch: 879 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.17\n",
      "=> result saved!\n",
      "Epoch: 880 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.15\n",
      "Epoch: 881 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 882 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.01, TL_centroid: 0.21\n",
      "Epoch: 883 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.01, TL_centroid: 0.26\n",
      "Epoch: 884 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.17\n",
      "Epoch: 885 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.23\n",
      "Epoch: 886 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.21\n",
      "Epoch: 887 Loss: 0.06, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.06, TL_pos: 0.06, TL_neg: 0.00, TL_centroid: 0.22\n",
      "Epoch: 888 Loss: 0.05, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.21\n",
      "Epoch: 889 Loss: 0.07, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.00, TL_centroid: 0.20\n",
      "=> result saved!\n",
      "Epoch: 890 Loss: 0.10, Loss_test: 0.08\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.10, TL_pos: 0.10, TL_neg: 0.01, TL_centroid: 0.17\n",
      "Epoch: 891 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.87, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 892 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.86, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 893 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.86, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.20\n",
      "Epoch: 894 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.86, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.14\n",
      "Epoch: 895 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.86, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.00, TL_centroid: 0.23\n",
      "Epoch: 896 Loss: 0.07, Loss_test: 0.09\n",
      "TL_w: 0.86, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.07, TL_pos: 0.07, TL_neg: 0.01, TL_centroid: 0.21\n",
      "Epoch: 897 Loss: 0.03, Loss_test: 0.09\n",
      "TL_w: 0.86, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.03, TL_pos: 0.03, TL_neg: 0.01, TL_centroid: 0.19\n",
      "Epoch: 898 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.86, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.18\n",
      "Epoch: 899 Loss: 0.05, Loss_test: 0.09\n",
      "TL_w: 0.86, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.05, TL_pos: 0.05, TL_neg: 0.00, TL_centroid: 0.14\n",
      "=> result saved!\n",
      "Epoch: 900 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.86, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.16\n",
      "Best_epoch=798, Best_loss=0.02, Recall@25=0.46\n"
     ]
    }
   ],
   "source": [
    "end_train = epochs - limit_train\n",
    "for epoch in range(limit_train, end_train):\n",
    "    batch_triplet_train, \\\n",
    "        train_input_sample, train_sim = batch_iterator(baseline, retrieval, encoded_anchor, baseline.train_data, \n",
    "                                                       baseline.dup_sets_train, bug_train_ids, \n",
    "                                                           batch_size, 1, issues_by_buckets, TRIPLET_HARD=False)\n",
    "    train_batch = [train_input_sample['title'], train_input_sample['description'], train_input_sample['info'], train_sim]\n",
    "    \n",
    "    h = similarity_model.train_on_batch(x=train_batch, y=train_sim)\n",
    "    h_validation = similarity_model.test_on_batch(x=validation_sample, y=valid_sim)\n",
    "    \n",
    "    # save results\n",
    "    result['train'].append(h)\n",
    "    result['test'].append(h_validation)\n",
    "    \n",
    "    if( (epoch+1) % 10 == 0 or (epoch+1 == limit_train) ):\n",
    "        save_loss(result)\n",
    "    \n",
    "    if (epoch+1 == limit_train): #(epoch > 1 and epoch % 10 == 0) or (epoch+1 == epochs):\n",
    "        recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, verbose, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "        print((\"Epoch: {} Loss: {:.2f}, Loss_test: {:.2f}\\n\" +\n",
    "               \"TL_w: {:.2f}, TL_pos_w: {:.2f}, TL_neg_w: {:.2f}, TL_centroid_w: {:.2f}\\n\" + \n",
    "                \"TL: {:.2f}, TL_pos: {:.2f}, TL_neg: {:.2f}, TL_centroid: {:.2f}, \" +\n",
    "              \"recall@25: {:.2f}\").format(epoch+1, h[0], h_validation[0], h[1], h[2], h[3], \n",
    "                                          h[4], h[5], h[6], h[7], h[8], recall))\n",
    "    else:\n",
    "        print((\"Epoch: {} Loss: {:.2f}, Loss_test: {:.2f}\\n\" +\n",
    "               \"TL_w: {:.2f}, TL_pos_w: {:.2f}, TL_neg_w: {:.2f}, TL_centroid_w: {:.2f}\\n\" + \n",
    "              \"TL: {:.2f}, TL_pos: {:.2f}, TL_neg: {:.2f}, TL_centroid: {:.2f}\").format(\n",
    "            epoch+1, h[0], h_validation[0], h[1], h[2], h[3], h[4], h[5], h[6], h[7], h[8]))\n",
    "    loss = h[0]\n",
    "    \n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "#experiment.save_model(similarity_model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "#experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "print('Best_epoch={}, Best_loss={:.2f}, Recall@25={:.2f}'.format(best_epoch, best_loss, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 900)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['train']), len(result['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = model.get_layer('merge_features_in')\n",
    "output = encoded.output\n",
    "inputs = similarity_model.inputs[:-1]\n",
    "encoded_anchor = Model(inputs = inputs, outputs = output, name = 'Similarity_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert_preprocessing_DMS_QL_1000_feature1000epochs_64batch(eclipse)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_PATH.replace('@number_of_epochs@', str(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model 'modelos/model_bert_preprocessing_DMS_QL_1000_feature_1000epochs_64batch(eclipse).h5' to disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model saved'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.save_model(model, SAVE_PATH.replace('@number_of_epochs@', str(epochs)))\n",
    "experiment.save_model(encoded_anchor, SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)), verbose=1)\n",
    "\"Model saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbd922ab6fd4fb198c950bd41fd474e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16995), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3c97ada628425998d9db58fde834ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27321), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff65c92fcc840bfb9d2725226b971a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30481), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70480fcddf34a16a6084b4aac3f5965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e02d3fba424c79b72fb553df0208a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c8384789534f20aa557813531fab94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b376838d2b624984b5f8fa1c3410d5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27321), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 900 Loss: 0.04, Loss_test: 0.09\n",
      "TL_w: 0.86, TL_pos_w: 1.12, TL_neg_w: 0.00, TL_centroid_w: 0.00\n",
      "TL: 0.04, TL_pos: 0.04, TL_neg: 0.00, TL_centroid: 0.16, recall@25: 0.57\n"
     ]
    }
   ],
   "source": [
    "recall, exported_rank, debug = experiment.evaluate_validation_test(retrieval, 1, encoded_anchor, issues_by_buckets, bug_train_ids)\n",
    "print((\"Epoch: {} Loss: {:.2f}, Loss_test: {:.2f}\\n\" +\n",
    "       \"TL_w: {:.2f}, TL_pos_w: {:.2f}, TL_neg_w: {:.2f}, TL_centroid_w: {:.2f}\\n\" + \n",
    "        \"TL: {:.2f}, TL_pos: {:.2f}, TL_neg: {:.2f}, TL_centroid: {:.2f}, \" +\n",
    "      \"recall@25: {:.2f}\").format(epoch+1, h[0], h_validation[0], h[1], h[2], h[3], h[4], h[5], h[6], h[7], h[8], recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2:15392,9779,94|14674:0.5633346736431122,10095:0.5581936836242676,14673:0.5481487810611725,8461:0.5406591296195984,9437:0.529998391866684,17942:0.5292403995990753,252:0.5259393751621246,7563:0.5223670899868011,9908:0.5223032534122467,15392:0.5179720520973206,7522:0.517794281244278,4895:0.5174091756343842,9779:0.5111019909381866,11859:0.5092878043651581,7282:0.508865624666214,24133:0.508631020784378,64581:0.5066477954387665,13134:0.5065221786499023,170:0.5022992491722107,7288:0.5000718533992767,178:0.4991546869277954,20729:0.498002290725708,16778:0.4974820613861084,5937:0.49738675355911255,71:0.4942132234573364,43395:0.49379175901412964,12670:0.4934414029121399,7247:0.4912916421890259,12411:0.4890766143798828',\n",
       " '393232:393282,390667,383388|397285:0.5118381679058075,383309:0.5113343000411987,402073:0.506451427936554,412309:0.4995068907737732,387113:0.4977801442146301,355404:0.4947406053543091,421343:0.48736315965652466,408095:0.4869709610939026,410468:0.4862065315246582,405563:0.4778168201446533,421036:0.4731631875038147,376143:0.4717057943344116,405416:0.46915560960769653,401108:0.4667115807533264,385123:0.46341633796691895,394517:0.4629901647567749,391830:0.4616001844406128,403900:0.46115565299987793,387650:0.4604254961013794,375603:0.45976346731185913,404887:0.45277518033981323,406503:0.4527265429496765,367083:0.45222246646881104,399354:0.4507989287376404,416286:0.44785040616989136,340477:0.4473963975906372,405341:0.4453722834587097,395921:0.4451412558555603,424120:0.4447288513183594',\n",
       " '30:205979,38236,99332,71263|21252:0.6019685566425323,21276:0.5921804904937744,24291:0.5887326896190643,10159:0.5881741940975189,19669:0.5856927037239075,12386:0.5843476355075836,22096:0.5841485261917114,22828:0.5786212384700775,23921:0.5688463747501373,15429:0.568585216999054,11633:0.567704051733017,9295:0.5641042590141296,23430:0.5632942616939545,5931:0.5613594353199005,5743:0.5570974051952362,14097:0.5563719570636749,175:0.5529638528823853,21818:0.5510743856430054,19666:0.5503610968589783,21979:0.5496711730957031,14567:0.547574371099472,19744:0.547398716211319,23567:0.544978141784668,14687:0.5436082780361176,12412:0.5435845851898193,14056:0.5389148592948914,19282:0.538860559463501,22835:0.5386587381362915,23060:0.5382515490055084',\n",
       " '131123:234849|153755:0.5312135815620422,70922:0.4577943682670593,140343:0.45359867811203003,83258:0.43871843814849854,30874:0.4326397180557251,275463:0.4223502278327942,25165:0.4189445376396179,145448:0.4183444380760193,163417:0.4129605293273926,108343:0.4126129746437073,46385:0.41063815355300903,123944:0.4066680669784546,97438:0.40665203332901,110748:0.4038190245628357,44707:0.4036957621574402,83651:0.40354394912719727,99076:0.4028828740119934,90875:0.4025658965110779,64272:0.39977943897247314,121261:0.397439181804657,151200:0.3949648141860962,119345:0.39456653594970703,79016:0.3945299983024597,134627:0.3937854766845703,96685:0.39311450719833374,102041:0.3928057551383972,74979:0.3923912048339844,147283:0.39138245582580566,105609:0.3910592794418335',\n",
       " '393277:393864,400436|171830:0.313581645488739,83025:0.291485071182251,331199:0.2687886953353882,352065:0.24386191368103027,244080:0.23650521039962769,422879:0.21626418828964233,319517:0.21423691511154175,379908:0.20995432138442993,331356:0.2085174322128296,346700:0.2064967155456543,319471:0.20439165830612183,400432:0.20296257734298706,318809:0.20240706205368042,328133:0.20142823457717896,366622:0.19960826635360718,382491:0.19362175464630127,272218:0.1933995485305786,186410:0.193212628364563,346237:0.18824899196624756,356008:0.1877688765525818,208936:0.18511563539505005,391025:0.1824207305908203,329383:0.1813327670097351,420131:0.17964565753936768,343009:0.1782381534576416,416279:0.17716974020004272,393192:0.1767851710319519,396390:0.17653852701187134,365487:0.17539846897125244',\n",
       " '131136:150817,149868,145937,65841,102812|101757:0.5331955552101135,106476:0.5276389420032501,111506:0.5238352417945862,150817:0.5122095048427582,81823:0.47815656661987305,102812:0.4767947196960449,107833:0.4746522903442383,95837:0.4722537398338318,100740:0.4721587896347046,105559:0.4692692160606384,49685:0.46843940019607544,80374:0.46640539169311523,107354:0.4644385576248169,108481:0.4638320207595825,81830:0.4601272940635681,82090:0.4601089358329773,96592:0.4565240740776062,83999:0.455680251121521,91361:0.4547995924949646,66803:0.45225995779037476,117023:0.4498937726020813,102606:0.448358952999115,76543:0.4482818841934204,101195:0.4473426342010498,95616:0.4471238851547241,149868:0.4464356303215027,76492:0.44389772415161133,89236:0.4438563585281372,123898:0.44029682874679565',\n",
       " '393282:393232,390667,383388|394628:0.5043538808822632,378975:0.49624258279800415,159331:0.439450740814209,369513:0.39766281843185425,131143:0.3902381658554077,134850:0.37957561016082764,156764:0.3784269094467163,397226:0.37842392921447754,201838:0.3771442770957947,161642:0.37553638219833374,392434:0.37532317638397217,217606:0.36915963888168335,183419:0.36510276794433594,359789:0.36292415857315063,159279:0.35906916856765747,401105:0.3586577773094177,158564:0.35752928256988525,190494:0.3556644916534424,186230:0.3554615378379822,165719:0.35520708560943604,101321:0.35359323024749756,101325:0.35359323024749756,179359:0.3528038263320923,112703:0.3524264693260193,193803:0.3499987721443176,403466:0.34995317459106445,164787:0.3497430682182312,159132:0.3491817116737366,285636:0.34901541471481323',\n",
       " '262212:292851,292845,291839|259768:0.47339528799057007,291839:0.4693302512168884,363947:0.46860790252685547,366680:0.4409893751144409,243979:0.4376823306083679,308331:0.4301765561103821,329416:0.42970776557922363,376285:0.42872899770736694,207855:0.4286196827888489,264447:0.4272080063819885,292845:0.4233396649360657,202652:0.41951990127563477,347495:0.41798293590545654,271713:0.4170328974723816,197989:0.41610556840896606,308333:0.4153013825416565,409109:0.41432082653045654,243615:0.413851797580719,159052:0.4132266044616699,399209:0.41307753324508667,399214:0.4128267765045166,261563:0.41065430641174316,355938:0.40775740146636963,248591:0.4065427780151367,250834:0.406216561794281,284666:0.4057690501213074,338513:0.4035155177116394,186847:0.4033045172691345,242095:0.4022674560546875',\n",
       " '131143:135599|129628:0.5648331344127655,134850:0.5355839729309082,204544:0.5253072381019592,173662:0.5065738260746002,212230:0.49004435539245605,135287:0.47597283124923706,74653:0.4654160737991333,229053:0.46391117572784424,112703:0.46232306957244873,156179:0.46206575632095337,134544:0.4612787961959839,129680:0.4571242928504944,135330:0.4556318521499634,135331:0.4556315541267395,135046:0.45163726806640625,141647:0.4507838487625122,159331:0.4464626908302307,165719:0.4464365839958191,192659:0.44556891918182373,132184:0.4448320269584656,152752:0.4422449469566345,135043:0.44056200981140137,191648:0.43933552503585815,114700:0.43865275382995605,189477:0.4383239150047302,154587:0.43680447340011597,175726:0.43587082624435425,145832:0.4330747127532959,201749:0.4329073429107666',\n",
       " '71:256,228|170:0.552890419960022,15392:0.5440696179866791,7288:0.532846987247467,10509:0.5312944948673248,178:0.5280242264270782,7563:0.5256844460964203,17518:0.5239261090755463,7900:0.5175630450248718,14052:0.5150840580463409,13134:0.5090438425540924,13570:0.5079506635665894,24443:0.5072018802165985,43395:0.5071350336074829,11615:0.5012157559394836,228:0.49679338932037354,8461:0.49668729305267334,2:0.4942132234573364,14674:0.49217283725738525,9312:0.4919435381889343,8202:0.48981088399887085,146:0.48573988676071167,19246:0.4848611354827881,14825:0.4838613271713257,12369:0.482438862323761,18653:0.4818158745765686,88:0.4807130694389343,7899:0.4789204001426697,9779:0.478567898273468,11545:0.4770625829696655',\n",
       " '85:247,10959|23326:0.5848407745361328,15392:0.5775725245475769,10959:0.5653103291988373,19648:0.559920608997345,14290:0.5546757280826569,20456:0.5441126525402069,10739:0.5399035811424255,7618:0.539896696805954,19436:0.5367418527603149,171:0.5355382859706879,170:0.5352672636508942,16161:0.5312842428684235,13570:0.5289941132068634,94:0.5280569195747375,19706:0.5275203883647919,7143:0.5239408910274506,5242:0.5213581919670105,20750:0.5206737816333771,6739:0.5154707729816437,21277:0.5153307616710663,23414:0.5148447453975677,19744:0.5147033929824829,13898:0.5140035152435303,11859:0.5125057101249695,18101:0.5117703378200531,14114:0.5109753608703613,22806:0.5102671384811401,13224:0.5097062587738037,15022:0.5085507929325104',\n",
       " '88:6099,14116|16864:0.5587379932403564,178:0.5477645397186279,12254:0.5428210496902466,94:0.5417867004871368,13570:0.5343570709228516,8202:0.5296546816825867,8461:0.528806209564209,19246:0.5258904993534088,5931:0.5258859992027283,7475:0.5212392210960388,5743:0.5143996775150299,19744:0.5125603973865509,17518:0.5122442543506622,12958:0.5103402137756348,252:0.510078638792038,14024:0.5086289048194885,5242:0.5084929168224335,15392:0.507602870464325,256:0.5063346922397614,9295:0.5046981573104858,11580:0.5042212605476379,10739:0.5040757954120636,5248:0.5015175044536591,171:0.4998825192451477,12386:0.4997652769088745,7564:0.4987429976463318,22094:0.4969162344932556,10909:0.4960140585899353,8560:0.4959830641746521',\n",
       " '131161:44438,103374,98057|99334:0.4955597519874573,99069:0.4925187826156616,107306:0.4848998188972473,127436:0.48427993059158325,158040:0.4824839234352112,80351:0.477111279964447,63859:0.47640782594680786,139892:0.4722197651863098,82127:0.470930278301239,81885:0.4681830406188965,132287:0.4651450514793396,48413:0.46410882472991943,128612:0.4638547897338867,158863:0.4604700803756714,72544:0.4597702622413635,209834:0.4569721817970276,281719:0.4533432722091675,157287:0.4515925645828247,38303:0.45102548599243164,171727:0.4472044110298157,144924:0.44584202766418457,129527:0.4454472064971924,26607:0.4420583248138428,108690:0.4416338801383972,30:0.4409053921699524,76582:0.44090521335601807,47944:0.44023555517196655,125850:0.43634873628616333,133685:0.4358091950416565',\n",
       " '262235:260098,263611|268627:0.6009736955165863,279091:0.5461541712284088,279088:0.5336500108242035,279089:0.5336500108242035,276562:0.5270186960697174,234213:0.5268161594867706,285667:0.5245502591133118,278191:0.5192698240280151,267921:0.5142839848995209,250526:0.50997394323349,194224:0.5069845914840698,258105:0.5063065886497498,274310:0.5061475038528442,260195:0.5015979409217834,276049:0.5015701055526733,276996:0.4983363151550293,250132:0.4982967972755432,298132:0.49812614917755127,235923:0.497061550617218,237250:0.4957478642463684,274173:0.49389517307281494,270162:0.4934539198875427,229403:0.49238431453704834,258461:0.49168455600738525,277244:0.49107789993286133,262582:0.48789840936660767,277265:0.48781079053878784,248874:0.485076904296875,271585:0.48217934370040894',\n",
       " '94:15392,2,9779|19648:0.6154834628105164,5931:0.5817233324050903,15392:0.5717708766460419,20624:0.5704959034919739,9295:0.5641135573387146,20456:0.5606860518455505,19246:0.5571994781494141,23921:0.5532211363315582,171:0.5510927140712738,14959:0.5506568253040314,13570:0.5489480793476105,8461:0.5484881699085236,18653:0.5467472076416016,10959:0.5461435914039612,11861:0.5441069602966309,13521:0.5433040857315063,88:0.5417867004871368,15429:0.5401029884815216,14114:0.5354655086994171,20750:0.5320942103862762,22094:0.5313982963562012,256:0.5313269793987274,146:0.5312412977218628,30:0.5310502648353577,10739:0.530568540096283,23326:0.5292937159538269,85:0.5280569195747375,14687:0.5274559855461121,10159:0.5226558744907379',\n",
       " '131171:202560,96651,172374|154703:0.5434451699256897,119843:0.5317307710647583,108561:0.5276761054992676,125781:0.5201081037521362,156111:0.5170449614524841,125137:0.5131895244121552,125648:0.5116254389286041,133948:0.5075377225875854,127703:0.5064457654953003,109331:0.502821147441864,135009:0.5022187530994415,187340:0.5021880269050598,141777:0.5007871389389038,157567:0.4968610405921936,123601:0.49507904052734375,129180:0.495077908039093,151044:0.494632363319397,111617:0.49387824535369873,175333:0.4937950372695923,154068:0.4934871792793274,112907:0.4920703172683716,137029:0.4911779761314392,155015:0.4887538552284241,160862:0.48844408988952637,109137:0.48676902055740356,124158:0.486519992351532,139543:0.48265695571899414,134578:0.4806559085845947,128226:0.48055219650268555',\n",
       " '393320:394988|400601:0.5670779347419739,296346:0.5484879612922668,366248:0.5431269705295563,402953:0.5367439389228821,390859:0.5360465049743652,366206:0.5328724682331085,326313:0.53150674700737,296388:0.5296582281589508,366199:0.5263703763484955,405645:0.5230562388896942,336726:0.5230221450328827,296608:0.5186082720756531,366179:0.5133402347564697,394988:0.5129241943359375,296389:0.5112106502056122,296387:0.505184680223465,366182:0.4996715188026428,367323:0.4918808937072754,337427:0.4916132092475891,258395:0.49108463525772095,338727:0.4904780387878418,366112:0.48860299587249756,402037:0.4884077310562134,401393:0.486234188079834,405226:0.48242777585983276,293827:0.4803276062011719,402600:0.4770931005477905,367795:0.4738386273384094,327860:0.47321945428848267',\n",
       " '131180:134058,132491,131646|132491:0.5009660124778748,131646:0.4719269871711731,329739:0.43924480676651,369252:0.42252397537231445,134058:0.4225121736526489,365487:0.41287243366241455,372688:0.4068107604980469,323000:0.40596163272857666,96069:0.40176260471343994,401785:0.394305944442749,105703:0.39118075370788574,105557:0.39066290855407715,105558:0.39066290855407715,285367:0.3870967626571655,383643:0.38641220331192017,364419:0.38090628385543823,411731:0.3803420066833496,314717:0.37795400619506836,421756:0.3757227063179016,279074:0.36682558059692383,85179:0.36474859714508057,318809:0.36320745944976807,342819:0.3630293011665344,367221:0.36295086145401,243140:0.36165642738342285,312045:0.36019736528396606,164091:0.35876888036727905,421749:0.35822105407714844,332889:0.35592806339263916',\n",
       " '393332:405833,414629|388386:0.5450544953346252,389593:0.4419901371002197,416273:0.4233664274215698,61481:0.3620883822441101,34706:0.3548681139945984,112330:0.34283751249313354,33475:0.3358803391456604,28801:0.3103410005569458,50853:0.3082200884819031,90741:0.3058227300643921,80949:0.3047814965248108,95316:0.30334681272506714,190563:0.3023265600204468,78016:0.3020700216293335,423582:0.3020084500312805,117018:0.30121463537216187,164090:0.29985880851745605,49801:0.29914867877960205,42299:0.2991224527359009,189553:0.2976430058479309,97247:0.2971324324607849,99964:0.2932007312774658,176429:0.2925305962562561,419578:0.29017841815948486,82002:0.2876697778701782,73262:0.28765416145324707,81957:0.286748468875885,144477:0.2863861918449402,154517:0.2829839587211609',\n",
       " '262266:262871|262871:0.5448777675628662,257970:0.47947824001312256,268920:0.47624439001083374,269320:0.4723338484764099,300849:0.4536325931549072,282581:0.4271218776702881,212798:0.42479902505874634,269182:0.4103802442550659,261793:0.4089025855064392,246816:0.3992581367492676,263265:0.39874160289764404,259145:0.39542216062545776,211431:0.3943663239479065,236922:0.39102238416671753,211235:0.38160252571105957,303248:0.38025856018066406,278529:0.37962526082992554,282548:0.37914812564849854,234769:0.37910038232803345,232666:0.37783539295196533,244920:0.37719839811325073,241735:0.3762317895889282,212622:0.37565159797668457,277491:0.37463563680648804,206747:0.3733760118484497,289225:0.3706851005554199,297611:0.3694896101951599,260093:0.3691413998603821,278146:0.3672698736190796']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exported_rank[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of queries: 16995\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of queries:\", len(retrieval.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert_preprocessing_DMS_QL_1000_feature_1000epochs_64batch(eclipse)'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(SAVE_PATH_FEATURE.replace('@number_of_epochs@', str(epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "info_in (InputLayer)            (None, 1682)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title_in (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_in (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FeatureMlpGenerationModel (Mode (None, 300)          504900      info_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FeatureLstmGenerationModel (Mod (None, 300)          581804100   title_in[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FeatureCNNGenerationModel (Mode (None, 300)          581850792   desc_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_features_in (Concatenate) (None, 900)          0           FeatureMlpGenerationModel[1][0]  \n",
      "                                                                 FeatureLstmGenerationModel[1][0] \n",
      "                                                                 FeatureCNNGenerationModel[1][0]  \n",
      "==================================================================================================\n",
      "Total params: 1,164,159,792\n",
      "Trainable params: 958,392\n",
      "Non-trainable params: 1,163,201,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoded_anchor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27321"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(exported_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/eclipse/bert/exported_rank_DMS_QL_1000.txt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_RANK_PATH = os.path.join(DIR, 'exported_rank_{}.txt'.format(METHOD))\n",
    "print(EXPORT_RANK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_RANK_PATH, 'w') as file_out:\n",
    "    for row in exported_rank:\n",
    "        file_out.write(row + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 - recall_at_1': 0.24,\n",
       " '1 - recall_at_5': 0.4,\n",
       " '2 - recall_at_10': 0.47,\n",
       " '3 - recall_at_15': 0.52,\n",
       " '4 - recall_at_20': 0.55,\n",
       " '5 - recall_at_25': 0.57}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = experiment.evaluation.evaluate(EXPORT_RANK_PATH)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some ideas to visualizate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[baseline] Bug triage with Deep Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
